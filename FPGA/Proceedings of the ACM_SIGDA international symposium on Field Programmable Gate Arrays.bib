@inproceedings{Zheng:2012:SNF:2145694.2145716,
 abstract = {The continuously widening gap between the Non-Recurring Engineering(NRE) and Recurring Engineering (RE) costs of producing Integrated Circuit (IC) products in the past few decades gives high incentives to unauthorized cloning and reverse-engineering of ICs. Existing IC Digital Rights Management (DRM) schemes often demands high overhead in area, power, and performance, or require non-volatile storage. Our goal is to develop a novel Intellectual Property (IP) protection technique that offers universal protection to both Application-Specific Integrated Circuits (ASIC) and Field-Programmable Gate-Arrays (FPGAs) from unauthorized manufacturing and reverse engineering. In this paper we show a proof-of-concept implementation of the basic elements of the technique, as well as a case study of applying the anti-cloning technique to a nontrivial FPGA design.},
 acmid = {2145716},
 address = {New York, NY, USA},
 author = {Zheng, Jason Xin and Potkonjak, Miodrag},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145716},
 isbn = {978-1-4503-1155-7},
 keyword = {IP protection, active hardware metering, unclonable},
 link = {http://doi.acm.org/10.1145/2145694.2145716},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {129--138},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Securing Netlist-level FPGA Design Through Exploiting Process Variation and Degradation},
 year = {2012}
}


@inproceedings{Mehta:2012:LSE:2145694.2145710,
 abstract = {As feature sizes scale toward atomic limits, parameter variation continues to increase, leading to increased margins in both delay and energy. The possibility of very slow devices on critical paths forces designers to increase transistor sizes, reduce clock speed and operate at higher voltages than desired in order to meet timing. With post-fabrication configurability, FPGAs have the opportunity to use slow devices on non-critical paths while selecting fast devices for critical paths. To understand the potential benefit we might gain from component-specific mapping, we quantify the margins associated with parameter variation in FPGAs over a wide range of predictive technologies (45nm-12nm) and gate sizes and show how these margins can be significantly reduced by delay-aware, component-specific routing. For the Toronto 20 benchmark set, we show that component-specific routing can eliminate delay margins induced by variation and reduce energy for energy minimal designs by 1.42-1.98Ã—. We further show that these benefits increase as technology scales.},
 acmid = {2145710},
 address = {New York, NY, USA},
 author = {Mehta, Nikil and Rubin, Raphael and DeHon, Andre},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145710},
 isbn = {978-1-4503-1155-7},
 keyword = {component-specific mapping, minimum energy, variation tolerance},
 link = {http://doi.acm.org/10.1145/2145694.2145710},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {97--106},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Limit Study of Energy \&\#38; Delay Benefits of Component-specific Routing},
 year = {2012}
}


@inproceedings{Hinkfoth:2012:XFW:2145694.2145700,
 abstract = {Recent research has developed a new, entirely digital architecture, called X-ORCA, that determines the phase shift of two periodic signals with a resolution as good as about 20 ps. This paper incorporates the X-ORCA system into a wireless experimental setup to form a localization system. The practical experiments utilize a 2.484 GHz transmitter and run the X-ORCA core on a Cyclone II FPGA. The results indicate that this simple localization system easily yields a spatial resolution in the sub-millimeter range.},
 acmid = {2145700},
 address = {New York, NY, USA},
 author = {Hinkfoth, Matthias and Heinrich, Enrico and Vork\"{o}per, Sebastian and K\"{u}hn, Volker and Salomon, Ralf},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145700},
 isbn = {978-1-4503-1155-7},
 keyword = {localization},
 link = {http://doi.acm.org/10.1145/2145694.2145700},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {29--32},
 publisher = {ACM},
 series = {FPGA '12},
 title = {X-ORCA: FPGA-based Wireless Localization in the Sub-millimeter Range},
 year = {2012}
}


@inproceedings{Li:2012:RAA:2145694.2145722,
 abstract = {Multitude of design freedoms of LDPC codes and practical decoders require fast simulations. FPGA emulation is attractive but inaccessible due to its design complexity. We propose a library and script based approach to automate the construction of FPGA emulations. Code parameters and design parameters are programmed either during run time or by script in design time. We demonstrate the architecture and design flow using the LDPC codes for the latest wireless communication standards: each emulation model was auto-constructed within one minute and the peak emulation throughput reached 3.8 Gb/s on a BEE3 platform.},
 acmid = {2145722},
 address = {New York, NY, USA},
 author = {Li, Haoran and Park, Youn Sung and Zhang, Zhengya},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145722},
 isbn = {978-1-4503-1155-7},
 keyword = {LDPC, decoder architecture, decoder emulation},
 link = {http://doi.acm.org/10.1145/2145694.2145722},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {167--170},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Reconfigurable Architecture and Automated Design Flow for Rapid FPGA-based LDPC Code Emulation},
 year = {2012}
}


@inproceedings{Hadjis:2012:IFA:2145694.2145712,
 abstract = {Resource sharing is a key area-reduction approach in high-level synthesis (HLS) in which a single hardware functional unit is used to implement multiple operations in the high-level circuit specification. We show that the utility of sharing depends on the underlying FPGA logic element architecture and that different sharing trade-offs exist when 4-LUTs vs. 6-LUTs are used. We further show that certain multi-operator patterns occur multiple times in programs, creating additional opportunities for sharing larger composite functional units comprised of patterns of interconnected operators. A sharing cost/benefit analysis is used to inform decisions made in the binding phase of an HLS tool, whose RTL output is targeted to Altera commercial FPGA families: Stratix IV (dual-output 6-LUTs) and Cyclone II (4-LUTs).},
 acmid = {2145712},
 address = {New York, NY, USA},
 author = {Hadjis, Stefan and Canis, Andrew and Anderson, Jason H. and Choi, Jongsok and Nam, Kevin and Brown, Stephen and Czajkowski, Tomasz},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145712},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGAs, field-programmable gate arrays, high-level synthesis, resource sharing},
 link = {http://doi.acm.org/10.1145/2145694.2145712},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {111--114},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Impact of FPGA Architecture on Resource Sharing in High-level Synthesis},
 year = {2012}
}


@inproceedings{Hoang:2012:IDM:2145694.2145696,
 abstract = {In current countermeasure design trends against differential power analysis (DPA), security at gate level is required in addition to the security algorithm. Several dual-rail pre-charge logics (DPL) have been proposed to achieve this goal. Designs using ASIC can attain this goal owing to its backend design restrictions on placement and routing. However, implementing these designs on field programmable gate arrays (FPGA) without information leakage is still a problem because of the difficulty involved in the restrictions on placement and routing on FPGA. This paper describes our novel masked dual-rail pre-charged memory approach, called "intra-masking dual-rail memory on LUT," and its implementation on FPGA for tamper-resistant AES. In the proposed design, all unsafe nodes, such as unmasking and masking, and the dual-rail memory and buses are packed into a single LUT. This makes them balanced and independent of the placement and routing tools. The design is independent of the cryptographic algorithm, and hence, it can be applied to available cryptographic standards such as DES or AES as well as future standards. It requires no special placement or route constraints in its implementation. A correlation power analysis (CPA) attack on 1,000,000 traces of AES implementation on FPGA showed that the secret information is well protected against first-order side-channel attacks. Even though the number of LUTs used for memory in this implementation is seven times greater than that of the conventional unprotected single-rail memory table-lookup AES and three times greater than the implementation based on a composite field, it requires a smaller number of LUTs than all other advanced tamper-resistant implementations such as the wave dynamic differential logic, masked dual-rail pre-charge logic, and threshold.},
 acmid = {2145696},
 address = {New York, NY, USA},
 author = {Hoang, Anh-Tuan and Fujino, Takeshi},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145696},
 isbn = {978-1-4503-1155-7},
 keyword = {AES, differential power analysis (dpa), dual-rail memory, field programmable gate array (fpga), intra-masking dual-rail memory on lut, masking, side-channel attack, tamper resistance},
 link = {http://doi.acm.org/10.1145/2145694.2145696},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {1--10},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Intra-masking Dual-rail Memory on LUT Implementation for Tamper-resistant AES on FPGA},
 year = {2012}
}


@inproceedings{Fowers:2012:PEC:2145694.2145704,
 abstract = {With the emergence of accelerator devices such as multicores, graphics-processing units (GPUs), and field-programmable gate arrays (FPGAs), application designers are confronted with the problem of searching a huge design space that has been shown to have widely varying performance and energy metrics for different accelerators, different application domains, and different use cases. To address this problem, numerous studies have evaluated specific applications across different accelerators. In this paper, we analyze an important domain of applications, referred to as sliding-window applications, when executing on FPGAs, GPUs, and multicores. For each device, we present optimization strategies and analyze use cases where each device is most effective. The results show that FPGAs can achieve speedup of up to 11x and 57x compared to GPUs and multicores, respectively, while also using orders of magnitude less energy.},
 acmid = {2145704},
 address = {New York, NY, USA},
 author = {Fowers, Jeremy and Brown, Greg and Cooke, Patrick and Stitt, Greg},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145704},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, GPU, multicore, parallelism, sliding window, speedup},
 link = {http://doi.acm.org/10.1145/2145694.2145704},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {47--56},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Performance and Energy Comparison of FPGAs, GPUs, and Multicores for Sliding-window Applications},
 year = {2012}
}


@inproceedings{Rollins:2012:RSP:2145694.2145723,
 abstract = {Softcore processors are an attractive alternative to using radiation-hardened processors in space-based applications. Unlike traditional processors however, the logic and routing of a softcore processor are vulnerable to the effects of single-event upsets (SEUs). This paper applies two common SEU mitigation techniques, TMR with checkpointing and DWC with checkpointing, to the LEON3 softcore processor. The improvement in reliabilty over an unmitigated version of the processor is measured using three metrics: the architectural vulnerability factor (AVF), mean time to failure (MTTF), and mean useful instructions to failure (MuITF). Using configuration memory fault injection, we found that DWC with checkpointing improves the MTTF and MuITF by over 35x, and that TMR with triplicated input and outputs improves the MTTF and MITF by over 6000x.},
 acmid = {2145723},
 address = {New York, NY, USA},
 author = {Rollins, Nathaniel H. and Wirthlin, Michael J.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145723},
 isbn = {978-1-4503-1155-7},
 keyword = {AVF, MTTF, MuITF, softcore processors},
 link = {http://doi.acm.org/10.1145/2145694.2145723},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {171--174},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Reliability of a Softcore Processor in a Commercial SRAM-based FPGA},
 year = {2012}
}


@inproceedings{LaForest:2012:OFP:2145694.2145731,
 abstract = {Overlay processor architectures allow FPGAs to be programmed by non-experts using software, but prior designs have mainly been based on the architecture of their ASIC predecessors. In this paper we develop a new processor architecture that from the beginning accounts for and exploits the predefined widths, depths, maximum operating frequencies, and other discretizations and limits of the underlying FPGA components. The result is Octavo, a ten-pipeline-stage eight-threaded processor that operates at the block RAM maximum of 550MHz on a Stratix IV FPGA. Octavo is highly parameterized, allowing us to explore trade-offs in datapath and memory width, memory depth, and number of supported thread contexts.},
 acmid = {2145731},
 address = {New York, NY, USA},
 author = {LaForest, Charles Eric and Steffan, John Gregory},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145731},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, microarchitecture, multithreading, soft processor},
 link = {http://doi.acm.org/10.1145/2145694.2145731},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {219--228},
 publisher = {ACM},
 series = {FPGA '12},
 title = {OCTAVO: An FPGA-centric Processor Family},
 year = {2012}
}


@inproceedings{Dai:2012:STB:2145694.2145706,
 abstract = {Driven by the demand of communication systems, field programmable gate array (FPGA) devices have significantly enhanced their aggregate transceiver bandwidth, reaching terabits per second for the upcoming generation. This paper asks the question whether a single-chip switch fabric can be built that saturates the available transceiver bandwidth. In answering this question, we propose a new switch fabric organization, called Grouped Crosspoint Queued switch, that brings significant memory efficiency over the state-of-the-art organizations. This makes it possible to build high bandwidth, high radix switches directly on FPGA that rivals ASIC performance. The proposal was validated at small scale by a 16x16 160Gps switch on the available Virtex-6 device, and simulated at a larger scale of fat-tree switching network with 5Tbps capacity.},
 acmid = {2145706},
 address = {New York, NY, USA},
 author = {Dai, Zefu and Zhu, Jianwen},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145706},
 isbn = {978-1-4503-1155-7},
 keyword = {crosspoint queued, input queued, output queued, switch fabric, transceiver},
 link = {http://doi.acm.org/10.1145/2145694.2145706},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {67--76},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Saturating the Transceiver Bandwidth: Switch Fabric Design on FPGAs},
 year = {2012}
}


@inproceedings{Fleming:2012:LLE:2145694.2145725,
 abstract = {Traditionally, hardware designs partitioned across multiple FPGAs have had low performance due to the inefficiency of maintaining cycle-by-cycle timing among discrete FPGAs. In this paper, we present a mechanism by which complex designs may be efficiently and automatically partitioned among multiple FPGAs using explicitly programmed latency-insensitive links. We describe the automatic synthesis of an area efficient, high performance network for routing these inter-FPGA links. By mapping a diverse set of large research prototypes onto a multiple FPGA platform, we demonstrate that our tool obtains significant gains in design feasibility, compilation time, and even wall-clock performance.},
 acmid = {2145725},
 address = {New York, NY, USA},
 author = {Fleming, Kermin Elliott and Adler, Michael and Pellauer, Michael and Parashar, Angshuman and Mithal, Arvind and Emer, Joel},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145725},
 isbn = {978-1-4503-1155-7},
 keyword = {DSP, FPGA, compiler, design automation, high-level synthesis, programming languages, switch architecture},
 link = {http://doi.acm.org/10.1145/2145694.2145725},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {175--184},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Leveraging Latency-insensitivity to Ease Multiple FPGA Design},
 year = {2012}
}


@inproceedings{Parandeh-Afshar:2012:RFE:2145694.2145715,
 abstract = {Look-Up Tables (LUTs) are universally used in FPGAs as the elementary logic blocks. They can implement any logic function and thus covering a circuit is a relatively straightforward problem. Naturally, flexibility comes at a price, and increasing the number of LUT inputs to cover larger parts of a circuit has an exponential cost in the LUT complexity. Hence, rarely LUTs with more than 4-6 inputs have been used. In this paper we argue that other elementary logic blocks can provide a better compromise between hardware complexity, flexibility, delay, and input and output counts. Inspired by recent trends in synthesis and verification, we explore blocks based on And-Inverter Graphs (AIGs): they have a complexity which is only linear in the number of inputs, they sport the potential for multiple independent outputs, and the delay is only logarithmic in the number of inputs. Of course, these new blocks are extremely less flexible than LUTs; yet, we show (i) that effective mapping algorithms exist, (ii) that, due to their simplicity, poor utilization is less of an issue than with LUTs, and (iii) that a few LUTs can still be used in extreme unfortunate cases. We show first results indicating that this new logic block combined to some LUTs in hybrid FPGAs can reduce delay up to 22-32% and area by some 16% on average. Yet, we explored only a few design points and we think that these results could still be improved by a more systematic exploration.},
 acmid = {2145715},
 address = {New York, NY, USA},
 author = {Parandeh-Afshar, Hadi and Benbihi, Hind and Novo, David and Ienne, Paolo},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145715},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA logic block, and-inverter cone, and-inverter graph, logic synthesis},
 link = {http://doi.acm.org/10.1145/2145694.2145715},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {119--128},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Rethinking FPGAs: Elude the Flexibility Excess of LUTs with And-inverter Cones},
 year = {2012}
}


@inproceedings{Wu:2012:FDP:2145694.2145713,
 abstract = {Good FPGA placement is crucial to obtain the best Quality of Results (QoR) from FPGA hardware. Although many published global placement techniques place objects in a continuous ASIC-like environment, FPGAs are discrete in nature, and a continuous algorithm cannot always achieve superior QoR by itself. Therefore, discrete FPGA-specific detail placement algorithms are used to improve the global placement results. Unfortunately, most of these detail placement algorithms do not have a global view. This paper presents a discrete "middle" placer that fills the gap between the two placement steps. It works like simulated annealing, but leverages various acceleration techniques. It does not pay the runtime penalty typical of simulated annealing solutions. Experiments show that with this placer, final QoR is significantly better than with the global-detail placer approach.},
 acmid = {2145713},
 address = {New York, NY, USA},
 author = {Wu, Qinghong and McElvain, Kenneth S.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145713},
 isbn = {978-1-4503-1155-7},
 keyword = {computer-aided design (cad), dynamic window, field-programmable gate array (FPGA), individual cell temperature, placement, simulated annealing, window masking},
 link = {http://doi.acm.org/10.1145/2145694.2145713},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {115--118},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Fast Discrete Placement Algorithm for FPGAs},
 year = {2012}
}


@inproceedings{Papamichael:2012:CRC:2145694.2145703,
 abstract = {An FPGA is a peculiar hardware realization substrate in terms of the relative speed and cost of logic vs. wires vs. memory. In this paper, we present a Network-on-Chip (NoC) design study from the mindset of NoC as a synthesizable infrastructural element to support emerging System-on-Chip (SoC) applications on FPGAs. To support our study, we developed CONNECT, an NoC generator that can produce synthesizable RTL designs of FPGA-tuned multi-node NoCs of arbitrary topology. The CONNECT NoC architecture embodies a set of FPGA-motivated design principles that uniquely influence key NoC design decisions, such as topology, link width, router pipeline depth, network buffer sizing, and flow control. We evaluate CONNECT against a high-quality publicly available synthesizable RTL-level NoC design intended for ASICs. Our evaluation shows a significant gain in specializing NoC design decisions to FPGAs' unique mapping and operating characteristics. For example, in the case of a 4x4 mesh configuration evaluated using a set of synthetic traffic patterns, we obtain comparable or better performance than the state-of-the-art NoC while reducing logic resource cost by 58%, or alternatively, achieve 3-4x better performance for approximately the same logic resource usage. Finally, to demonstrate CONNECT's flexibility and extensive design space coverage, we also report synthesis and network performance results for several router configurations and for entire CONNECT networks.},
 acmid = {2145703},
 address = {New York, NY, USA},
 author = {Papamichael, Michael K. and Hoe, James C.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145703},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, NoC, SoC, network-on-chip, system-on-chip},
 link = {http://doi.acm.org/10.1145/2145694.2145703},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {37--46},
 publisher = {ACM},
 series = {FPGA '12},
 title = {CONNECT: Re-examining Conventional Wisdom for Designing Nocs in the Context of FPGAs},
 year = {2012}
}


@inproceedings{Kirchgessner:2012:VVF:2145694.2145728,
 abstract = {Numerous studies have shown significant performance and power benefits of field-programmable gate arrays (FPGAs). Despite these benefits, FPGA usage has been limited by application design complexity caused largely by the lack of code and tool portability across different FPGA platforms, which prevents design reuse. This paper addresses the portability challenge by introducing a framework of architecture and middleware for virtualization of FPGA platforms, collectively named VirtualRC. Experiments show modest overhead of 5-6% in performance and 1% in area, while enabling portability of 11 applications and two high-level synthesis tools across three physical platforms.},
 acmid = {2145728},
 address = {New York, NY, USA},
 author = {Kirchgessner, Robert and Stitt, Greg and George, Alan and Lam, Herman},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145728},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, portability, virtual architectures},
 link = {http://doi.acm.org/10.1145/2145694.2145728},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {205--208},
 publisher = {ACM},
 series = {FPGA '12},
 title = {VirtualRC: A Virtual FPGA Platform for Applications and Tools Portability},
 year = {2012}
}


@inproceedings{Curreri:2012:CVB:2145694.2145701,
 abstract = {High-level synthesis tools increase FPGA productivity but can decrease performance compared to register-transfer level designs. To help optimize high-level synthesis applications, we introduce a bottleneck detection tool that provides a developer with a visualization of communication bandwidth between all application processes, while identifying potential bottlenecks via color coding. We evaluated the tool using third-party applications to identify and optimize bottlenecks in just several minutes, which achieved speedups ranging from 1.25x to 2.18x compared to the original FPGA execution. Overhead was modest with less than 2% resource overhead and 3% frequency overhead.},
 acmid = {2145701},
 address = {New York, NY, USA},
 author = {Curreri, John and Stitt, Greg and George, Alan},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145701},
 isbn = {978-1-4503-1155-7},
 keyword = {bottleneck detection, high-level synthesis, performance analysis, visualization},
 link = {http://doi.acm.org/10.1145/2145694.2145701},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {33--36},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Communication Visualization for Bottleneck Detection of High-level Synthesis Applications},
 year = {2012}
}


@inproceedings{Moctar:2012:RCF:2145694.2145738,
 abstract = {In floating-point datapaths synthesized on FPGAs, the shifters that perform mantissa alignment and normalization consume a disproportionate number of LUTs. Shifters are implemented using several rows of small multiplexers; unfortunately, multiplexer-based logic structures map poorly onto LUTs. FPGAs, meanwhile, contain a large number of multiplexers in the programmable routing network; these multiplexer are placed under static control of the FPGA's configuration bitstream. In this work, we modify some of the routing multiplexers in the intra-cluster routing network of a CLB in an FPGA to implement shifters for floating-point mantissa alignment and normalization; the number of CLBs required for these operations is reduced by 67%. If shifting is not required, the routing multiplexers that have been modified can be configured to operate as normal routing multiplexers, so no functionality is sacrificed. The area overhead incurred by these modifications is small, and there is no need to modify every routing multiplexer in the FPGA. Experiments show that there is no negative impact in terms of clock frequency or routability for benchmarks that do not use the dynamic multiplexers.},
 acmid = {2145738},
 address = {New York, NY, USA},
 author = {Moctar, Yehdhih Ould Mohammed and George, Nithin and Parandeh-Afshar, Hadi and Ienne, Paolo and Lemieux, Guy G.F. and Brisk, Philip},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145738},
 isbn = {978-1-4503-1155-7},
 keyword = {field programmable gate array (FPGA), floating-point, mantissa alignment, normalization},
 link = {http://doi.acm.org/10.1145/2145694.2145738},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {255--264},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Reducing the Cost of Floating-point Mantissa Alignment and Normalization in FPGAs},
 year = {2012}
}


@inproceedings{Panda:2012:DEC:2145694.2145755,
 abstract = {Coarse Grained Reconfigurable Arrays (CGRAs) are a promising class of architectures for accelerating applications using a large number of parallel execution units for high throughput. While they are typically very efficient for a single task, all functional units are required to perform in lock step; this makes some classes of applications more difficult to program and efficiently use resources. Other architectures like Massively Parallel Processor Arrays (MPPAs) are better suited for these applications and excel at executing unrelated tasks simultaneously, but the amount of resources dedicated to a single task is limited. We are developing a new architecture with the design flexibility of an MPPA and the throughput of a CGRA. A key to the flexibility of MPPAs is the ability for subtasks to execute independently instead of in lock step with all other tasks on the array. Adding this capability requires special control circuitry for architectural support in a CGRA. We decribe the modifications required and our solutions. Additionally, we also describe the CAD tool modification and application developer concerns for utilizing the resulting hybrid CGRA/MPPA architecture.},
 acmid = {2145755},
 address = {New York, NY, USA},
 author = {Panda, Robin and Hauck, Scott},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145755},
 isbn = {978-1-4503-1155-7},
 keyword = {architecture, cgra, mppa},
 link = {http://doi.acm.org/10.1145/2145694.2145755},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {269--269},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Dataflow-driven Execution Control in a Coarse-grained Reconfigurable Array (Abstract Only)},
 year = {2012}
}


@inproceedings{Chin:2012:OMI:2145694.2145756,
 abstract = {Programming models assist developers in creating high performance computing systems by forming a higher level abstraction of the target platform. OpenCL has emerged as a standard programming model for heterogeneous systems and there has been recent activity combining OpenCL and FPGAs. This work introduces memory infrastructure for FPGAs and is designed for OpenCL style computation, complementing previous work. An Aggregating Memory Controller is implemented in hardware and aims to maximize bandwidth to external, large, high-latency, high-bandwidth memories by finding the minimal number of external memory burst requests from a vector of requests. A template processing array with soft-processor and hand-coded hardware elements was also designed to drive the memory controller. The Aggregating Memory Controller is described in terms of operation and future scalability and the created processing array is described as a flexible structure that can support many types of processing solutions. A hardware prototype of the memory controller and processing array was implemented on a Virtex-5 LX110T FPGA. Two micro-benchmarks were run on both the soft-processor elements and the hand-coded hardware cores to exercise the memory controller. Results for effective memory bandwidth within the system show that the high-latency can be hidden using the Aggregating Memory Controller by increasing the number of threads within the processing array.},
 acmid = {2145756},
 address = {New York, NY, USA},
 author = {Chin, S. Alexander and Chow, Paul},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145756},
 isbn = {978-1-4503-1155-7},
 keyword = {dram, fpga, memory aggregation, memory coalescing, opencl},
 link = {http://doi.acm.org/10.1145/2145694.2145756},
 location = {Monterey, California, USA},
 numpages = {2},
 pages = {269--270},
 publisher = {ACM},
 series = {FPGA '12},
 title = {OpenCL Memory Infrastructure for FPGAs (Abstract Only)},
 year = {2012}
}


@inproceedings{Andrade:2012:ETE:2145694.2145761,
 abstract = {FPGA devices provide flexible, fast, and low-cost prototyping and production solutions for system design. However, as the design complexity continues to rise, the design and synthesis iterations become a labor intensive and time consuming ordeal. Consequently, it becomes imperative to raise the level of abstraction for FPGA designs, while providing insight into performance metrics early in the design process. In particular, an important design time problem is to determine the maximum clock frequency that a circuit can achieve on a specific FPGA target before full synthesis and implementation. This early quantification can greatly help evaluate key design characteristics without reverting to tedious runs of the full implementation flow. In this work, we focus on the predictability of timing delay of circuits composed of high-level blocks on an FPGA. We are well aware of difficulties in tackling uncertainties in early timing estimation, e.g., an inherent gap between a high-level representation and gates/wires; extremely difficult delay estimation due to the randomness in physical design tools, etc. We show that the estimation uncertainties can be mitigated through a carefully characterized timing database of primitive building blocks and refined timing analysis models. We primarily focus on applications composed of data-intensive word-level arithmetic computations from the DSP domain and specified using static dataflow models. Our experiments indicate that for these applications, timing estimates can be obtained reliably within a good error margin on average and in the worst case. As future work, we plan to fine tune the timing database by modeling resource utilization effects and inter-primitive/actor routing delay via variants of Rent's rule and related efforts. We are also interested in exploring dynamic sub-cycle timing characterization.},
 acmid = {2145761},
 address = {New York, NY, USA},
 author = {Andrade, Hugo and Ghosal, Arkadeb and Limaye, Rhishikesh and Malik, Sadia and Petersen, Newton and Ravindran, Kaushik and Tran, Trung and Wang, Guoqiang and Yang, Guang},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145761},
 isbn = {978-1-4503-1155-7},
 keyword = {early timing analysis, fpga, system-level design},
 link = {http://doi.acm.org/10.1145/2145694.2145761},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {271--271},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Early Timing Estimation for System-level Design Using FPGAs (Abstract Only)},
 year = {2012}
}


@inproceedings{Saha:2012:EIR:2145694.2145753,
 abstract = {FPGAs have become indispensible in processor design, bring-up and debug. Traditionally FPGAs have been used in prototyping, allowing end-users to emulate functionality of a specific component of a processor. However, as the complexity of processors grows, another aspect of processor design, RTL verification, has become a prime target for acceleration using FPGAs. Software-only RTL simulation and verification tools are no longer sufficient for many verification tasks as they often incur long execution time penalties. Software simulation time for a basic Linux kernel bring-up on a BlueGene/Q [1] processor, with 16 user PowerPC A2 cores, for example, could easily exceed several years. An important feature of RTL verification acceleration using FPGAs is its fast debugging capabilities. The ability to quickly and accurately pinpoint the location of an anomaly in an RTL source is highly desirable. This paper proposes efficient in-system debugging techniques on FPGAs for RTL verification. We show how a network of over 45 Virtex 5 LX330 FPGAs can be efficiently used to read out state information of the BlueGene/Q processor. We also demonstrate how the new in-system debugging technique is 250x faster than comparable methods.},
 acmid = {2145753},
 address = {New York, NY, USA},
 author = {Saha, Proshanta and Haymes, Chuck and Bellofatto, Ralph and Brezzo, Bernard and Kapur, Mohit and Asaad, Sameh},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145753},
 isbn = {978-1-4503-1155-7},
 keyword = {fpga debugging, fpga-based acceleration, processor simulation},
 link = {http://doi.acm.org/10.1145/2145694.2145753},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {269--269},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Efficient In-system RTL Verification and Debugging Using FPGAs (Abstract Only)},
 year = {2012}
}


@inproceedings{Bsoul:2012:CAL:2145694.2145737,
 abstract = {A dynamically-controlled power-gated (DCPG) FPGA architecture has recently been proposed to reduce static energy dissipation during idle periods. During a power mode transition from an off state to on state, the wakeup current drawn from power supplies causes a voltage droop on the power distribution network of a device. If not handled appropriately, this current and the associated voltage droop could cause malfunction of the design and/or the device. In DCPG FPGAs, the amount of wakeup current is not known beforehand as the structures of power-gated modules are application dependent; thus, a configurable solution is required to handle wakeup current. In this paper we propose a programmable wakeup architecture for DCPG FPGAs. The proposed solution has two levels: a fixed intra-region level and a configurable inter-region level. The architecture ensures that a power-gated module can be turned on such that the wakeup current constraints are not violated. We study the area and power overheads of the proposed solution. Our results show that the area overhead of the proposed inrush current limiting architecture is less than 2% for a power gating region of size 3x3 or 4x4 tiles, and the leakage power saved is more than 85% in a region of size 4x4 tiles.},
 acmid = {2145737},
 address = {New York, NY, USA},
 author = {Bsoul, Assem A.M. and Wilton, Steven J.E.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145737},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, architecture, inrush current, leakage power, power gating},
 link = {http://doi.acm.org/10.1145/2145694.2145737},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {245--254},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Configurable Architecture to Limit Wakeup Current in Dynamically-controlled Power-gated FPGAs},
 year = {2012}
}


@inproceedings{Chou:2012:SFP:2145694.2145697,
 abstract = {This article pursues speedy packet classification with low on-chip memory requirements realized on Xilinx Virtext-6 FPGA. Based on hashing round-down prefixes specified in filter rules (dubbed HaRP), our implemented classifier is demonstrated to exhibit an extremely low on-chip memory requirement (lowering the byte count per rule by a factor of 8.6 in comparison with its most recent counterpart [2]), taking only 50% of Virtex-6 on-chip memory to store every large rule dataset (with some 30K rules) examined. In addition, it achieves a higher throughput than any known FPGA implementation, reaching more than 200 MPPS (millions packet lookups per second) with 8 processing units and 8 memory banks in the HaRP pipeline to support the line rate over 130 Gbps under bi-directional traffic in the worst case with 40-byte packets. By reducing memory probes per lookup, enhanced HaRP can further boost the classification speed to 255 MPPS.},
 acmid = {2145697},
 address = {New York, NY, USA},
 author = {Chou, Chih-Hsun and Pong, Fong and Tzeng, Nian-Feng},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145697},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGAs, filter datasets, hash tables, memory efficiency, pipelined design, set-associativity},
 link = {http://doi.acm.org/10.1145/2145694.2145697},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {11--20},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Speedy FPGA-based Packet Classifiers with Low On-chip Memory Requirements},
 year = {2012}
}


@inproceedings{Shum:2012:API:2145694.2145711,
 abstract = {FPGA CAD algorithms are heuristic, and generally make use of cost functions to gauge the value of one potential circuit implementation over another. At times, such algorithms must decide between two or more implementation options of apparently equal cost. This work explores the variations in circuit quality, i.e. noise, that arise when CAD algorithms are altered to choose randomly when faced with such equal-cost alternatives. Noise sources are identified in logic synthesis and technology mapping algorithms, and experimental results are presented which show standard deviations of 3.3% and 3.7% from the mean in post-routed delay and power. As a means of dealing with this variation, early timing and power prediction metrics can be applied after technology mapping to find the best circuits in the presence of noise. When applied to designs with over 1.5% variation in delay and power, the best prediction models have a 40% probability of capturing the best circuit when predicting the top 10% of circuits in a group of noise-injected circuits.},
 acmid = {2145711},
 address = {New York, NY, USA},
 author = {Shum, Warren and Anderson, Jason H.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145711},
 isbn = {978-1-4503-1155-7},
 keyword = {CAD, FPGA, noise, prediction},
 link = {http://doi.acm.org/10.1145/2145694.2145711},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {107--110},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Analyzing and Predicting the Impact of CAD Algorithm Noise on FPGA Speed Performance and Power},
 year = {2012}
}


@inproceedings{Cong:2012:FEF:2145694.2145751,
 abstract = {In this study, we explore the use of Resistive RAMs (RRAMs) as candidates for programmable interconnects in FPGAs. An RRAM cell can be programmed between high resistance state and low resistance state, with an on/off ratio close to MOSFET. It provides an opportunity to use an RRAM as a routing switch at a much smaller area cost than its CMOS counterpart. RRAMs can be fabricated over CMOS circuits using CMOS-compatible processes to have a more compact gate array. Our recent work (presented in NanoArch'2011) demonstrated significant potential of area, delay, and power reduction from using RRAMs in FPGAs. But some design problems remain open. The programming of RRAM switches integrated in interconnects is one important problem. We show that the high-level architecture of programming circuits for RRAM switches should be modified to avoid potential logic hazard. Also the programming cells used in previous works have an area overhead even larger than RRAM itself. We manage to reduce this overhead significantly with utilization of the non-arbitrary pattern of RRAM integration in FPGA interconnects. In addition we suggest a novel buffering solution for FPGA interconnects in light of the low area cost of RRAM-based routing switch. We propose on-demand buffer insertion, where buffers can be connected to interconnects via RRAMs to dynamically reflect the demand of the netlist to map onto FPGA. Compared to conventional buffering solution which are pre-determined during fabrication and can only be optimized for general case, our solution shows further area savings and performance improvement. The resulting FPGA architecture using RRAM for programmable interconnects is named FPGA-RR. We provide a complete CAD flow for FPGA-RR.},
 acmid = {2145751},
 address = {New York, NY, USA},
 author = {Cong, Jason and Xiao, Bingjun},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145751},
 isbn = {978-1-4503-1155-7},
 keyword = {buffer, programming, resistive ram, rram fpga},
 link = {http://doi.acm.org/10.1145/2145694.2145751},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {268--268},
 publisher = {ACM},
 series = {FPGA '12},
 title = {FPGA-RR: An Enhanced FPGA Architecture with RRAM-based Reconfigurable Interconnects (Abstract Only)},
 year = {2012}
}


@inproceedings{Bayliss:2012:OSB:2145694.2145727,
 abstract = {Memory bandwidth is critical to achieving high performance in many FPGA applications. The bandwidth of SDRAM memories is, however, highly dependent upon the order in which addresses are presented on the SDRAM interface. We present an automated tool for constructing an application specific on-chip memory address sequencer which presents requests to the external memory with an ordering that optimizes off-chip memory bandwidth for fixed on-chip memory resource. Within a class of algorithms described by affine loop nests, this approach can be shown to reduce both the number of requests made to external memory and the overhead associated with those requests. Data presented shows a trade off between the use of on-chip resources and achievable off-chip memory bandwidth where a range of improvements from 3.6x to 4x gain in efficiency on the external memory interface can be gained at a cost of up to a 1.4x increase in the ALUTs dedicated to address generation circuits in an Altera Stratix III device.},
 acmid = {2145727},
 address = {New York, NY, USA},
 author = {Bayliss, Samuel and Constantinides, George A.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145727},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, SDRAM, loop transformations, memory},
 link = {http://doi.acm.org/10.1145/2145694.2145727},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {195--204},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Optimizing SDRAM Bandwidth for Custom FPGA Loop Accelerators},
 year = {2012}
}


@inproceedings{Laforest:2012:MMF:2145694.2145730,
 abstract = {Multi-ported memories are challenging to implement with FPGAs since the block RAMs included in the fabric typically have only two ports. Any design that requires a memory with more than two ports must therefore be built out of logic elements or by combining multiple block RAMs. The recently-proposed Live Value Table (LVT) design provides a significant operating frequency improvement over conventional approaches. In this paper we present an alternative approach based on the XOR operation that provides multi-ported memories that use far less logic but more block RAMs than LVT designs, and are often smaller and faster for memories that are more than 512 entries deep. We show that (i) both designs can exploit multipumping to trade speed for area savings, (ii) that multipumped XOR designs are significantly smaller but moderately slower than their LVT counterparts, and (iii) that both the LVT and XOR approaches are valuable and useful in different situations, depending on the constraints and resource utilization of the enclosing design.},
 acmid = {2145730},
 address = {New York, NY, USA},
 author = {Laforest, Charles Eric and Liu, Ming G. and Rapati, Emma Rae and Steffan, J. Gregory},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145730},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, XOR, memory, multi-port, parallel},
 link = {http://doi.acm.org/10.1145/2145694.2145730},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {209--218},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Multi-ported Memories for FPGAs via XOR},
 year = {2012}
}


@inproceedings{Pourhashemi:2012:TYI:2145694.2145742,
 abstract = {Designing with field-programmable gate arrays (FPGAs) can face with difficulties due to process variations. Some techniques use reconfigurability of FPGAs to reduce the effects of process variations in these chips. Furthermore, FPGA architecture enhancement is an effective way to degrade the impact of variation. In this paper, various FPGA architectures are examined to identify which architecture can achieve larger parametric yield improvement utilizing multiple configurations as opposed to single configuration. Experimental results show that by increasing cluster size from 4 to 10, yield improvement increases from 2.82X to 4.48X. However, changing look-up table (LUT) size from 4 to 7 results in yield improvement degradation from 2.82X to 1.45X, using 10 configurations compared to single configuration over 20 MCNC benchmark circuits. These results indicate that multi-configuration technique causes larger timing yield improvement in FPGAs with larger cluster size and smaller LUT size.},
 acmid = {2145742},
 address = {New York, NY, USA},
 author = {Pourhashemi, Fatemeh Sadat and Saheb Zamani, Morteza},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145742},
 isbn = {978-1-4503-1155-7},
 keyword = {fpga architecture, multiple configurations, process variation, timing yield},
 link = {http://doi.acm.org/10.1145/2145694.2145742},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {265--265},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Timing Yield Improvement of FPGAs Utilizing Enhanced Architectures and Multiple Configurations Under Process Variation (Abstract Only)},
 year = {2012}
}


@inproceedings{Loke:2012:PFT:2145694.2145750,
 abstract = {In this paper, we present a framework for leakage power reduction in FPGAs with programmable-VT architectures, with focus on dual-VT technology mapping. The use of Reverse Back Bias (RBB) circuit techniques is recognized as one of the possible strategies in mitigating leakage power, a critical problem in circuits deploying deep submicron process technologies. FPGAs with the ability to tune LUT VT via RBB offer the potential of reducing leakage power with no sacrifice to circuit speed. Today, Altera's Stratix line of FPGAs oer some levels of VT programmability, but with optimizations limited to the post-P&R stage. We present a novel technology mapper (RBBMap), logic block packer (RBBPack) and placement-and-routing tool (RBBVPR) that together demonstrate the advantages in moving RBB optimizations upwards to the technology mapping level. Compared to an existing power-optimized technology mapping tool Emap, our framework oers an average of 44.41% savings in average logic block leakage power and 30.88% savings in average total energy consumption. We also illustrate why our work is potentially superior to another comparable work DVMap-2 that utilizes a dual-VDD approach.},
 acmid = {2145750},
 address = {New York, NY, USA},
 author = {Loke, Wei Ting and Ha, Yajun},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145750},
 isbn = {978-1-4503-1155-7},
 keyword = {dual-vt, fpga, multiple voltage, programmable-vt, reverse back bias, technology mapping},
 link = {http://doi.acm.org/10.1145/2145694.2145750},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {268--268},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Power-aware FPGA Technology Mapping for programmable-VT Architectures (Abstract Only)},
 year = {2012}
}


@inproceedings{Chen:2012:ASR:2145694.2145740,
 abstract = {The explosive growth of short read datasets produced by high throughput DNA sequencing technologies poses a challenge to the mapping of short reads to a reference genome in terms of sensitivity and execution speed. Existing methods often use a restrictive error model for computing the alignments to improve speed, whereas more flexible error models are generally too slow for large-scale applications. Although a number of short read mapping software tools have been proposed, designs based on hardware are relatively rare. In this paper, we present a hybrid system for short read mapping utilizing both software and field programmable gate array (FPGA)-based hardware. The compute intensive semi-global alignment operation is accelerated on the FPGA. The proposed FPGA aligner is implemented with a parallel block structure to gain computational efficiency. We also propose a block-wise alignment algorithm to approximate the score of the conventional dynamic programming algorithm. Our performance comparison shows that the FPGA achieves an average speedup of 38 for the alignment operation on a Xilinx Virtex5 FPGA compared to the GASSST software implementation. For the overall execution time, our hybrid system achieves an average speedup of 2.4 compared to GASSST at comparable sensitivity and an average speedup of 1.8 compared to the popular BWA software at a significantly better sensitivity.},
 acmid = {2145740},
 address = {New York, NY, USA},
 author = {Chen, Yupeng and Schmidt, Bertil and Maskell, Douglas Leslie},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145740},
 isbn = {978-1-4503-1155-7},
 keyword = {fpga, hybrid system, parallel processing, semi-global alignment, short read alignment},
 link = {http://doi.acm.org/10.1145/2145694.2145740},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {265--265},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Accelerating Short Read Mapping on an FPGA (Abstract Only)},
 year = {2012}
}


@inproceedings{Seffrin:2012:CAG:2145694.2145748,
 abstract = {Dynamic partial reconfiguration allows the exchange of hardware configurations on FPGAs at run-time. Within a reconfigurable system that supports several different modules, resource requirements for interconnect between these modules may be considerably high. Enabling communication via a crossbar may require too many resources. State-of-the-art modelling methods for partial dynamic reconfiguration already support the fine-grained description of interaction between the partial modules. We propose both an online and an offline method for automatically generating interconnect according to such communication constraints, aiming at a low resource usage. The online algorithm determines an appropriate port assignment for the partial modules by means of a greedy approach and exploits port overlaps. The offline algorithm employs simulated annealing in order to find a proper port assignment and also incorporates the scheme for exploiting port overlaps. Constraint-generated interconnect requires significantly less resources than a crossbar, even if only a random port assignment is used. Proper port assignment by the online method reduces these requirements by an additional 10%, and using the offline method reduces them by an additional 30% on average. Online port assignment is faster than the offline method by several orders of magnitude. The interconnect generation tool introduced in this work takes textual input of communication constraints and automatically generates a corresponding hardware description in VHDL.},
 acmid = {2145748},
 address = {New York, NY, USA},
 author = {Seffrin, Andr{\'e} and Huss, Sorin A.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145748},
 isbn = {978-1-4503-1155-7},
 keyword = {constraint-based design, crossbar, interconnect, partial dynamic reconfiguration, port assignment},
 link = {http://doi.acm.org/10.1145/2145694.2145748},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {267--267},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Constraint-driven Automatic Generation of Interconnect for Partially Reconfigurable Architectures (Abstract Only)},
 year = {2012}
}


@inproceedings{Wang:2012:PFP:2145694.2145754,
 abstract = {This work describes a novel approach to FPGA placement. Most conventional FPGA CAD flow clusters circuits into CLBs prior to placing it. We show that is it possible to achieve 28% and 21% improvement in wirelength and minimum channel width respectively, while suffering only 1.8% in critical path delay by placing individual LUTs directly. By utilizing a good parallel placer, the novel approach can achieve speedups over the conventional uni-processor placers as well.},
 acmid = {2145754},
 address = {New York, NY, USA},
 author = {Wang, Chris C. and Lemieux, Guy G.F.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145754},
 isbn = {978-1-4503-1155-7},
 keyword = {fpga, parallel placement},
 link = {http://doi.acm.org/10.1145/2145694.2145754},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {269--269},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Parallel FPGA Placement Based on Individual LUT Placement (Abstract Only)},
 year = {2012}
}


@inproceedings{Lin:2012:OSA:2145694.2145757,
 abstract = {Compiling high-level user applications for execution on FPGAs often involves synthesizing dataflow graphs beyond the size of the available on-chip computational resources. One way to address this is by folding the execution of the given dataflow graphs onto an array of directly connected simple configurable processing elements (CPEs). Under this scenario, the performance and energy-efficiency of the resulting system depends not only on the mapping schedule of the compute operations on the CPEs, but also on the topology of the interconnect array that connects the CPEs. This paper presents a framework in which the operation scheduler and the underlying CPE interconnect network topology are co-optimized on a per-application basis for energy-efficient FPGA computation. Given the same application, more than 2.5x difference in energy-efficiency was achievable by the use of different common regular array topologies to connect the CPEs. Moreover, by using irregular application-specific interconnect topologies derived from a genetic algorithm, up to 50% improvement in energy-delay-product was achievable when compared to the use of even the best regular topology. The use of such framework is anticipated to serve as part of a rapid high-level FPGA application compiler since minimum hardware place-and-route is needed to generate the optimal schedule and topology.},
 acmid = {2145757},
 address = {New York, NY, USA},
 author = {Lin, Colin Yu and Wong, Ngai and So, Hayden Kwok-Hay},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145757},
 isbn = {978-1-4503-1155-7},
 keyword = {architecture synthesis, dataflow computation, energy-efficient, fpga, operation scheduling},
 link = {http://doi.acm.org/10.1145/2145694.2145757},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {270--270},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Operation Scheduling and Architecture Co-synthesis for Energy-efficient Dataflow Computations on FPGAs (Abstract Only)},
 year = {2012}
}


@inproceedings{Jin:2012:RSV:2145694.2145698,
 abstract = {Many hardware systems for stereo vision have been proposed. Their processing speed is very fast, but the algorithms used in them are limited in order to achieve the high processing speed by simplifying the sequences of the memory accesses and operations. The error rates by them can not compete with those by software programs. In this paper, we describe an FPGA implementation of a tree-structured dynamic programming algorithm. The computational complexity of this algorithm is higher than those by previous hardware systems, but the processing speed of our system is still fast enough for real-time applications, and its error rate is competitive with software algorithms.},
 acmid = {2145698},
 address = {New York, NY, USA},
 author = {Jin, Minxi and Maruyama, Tsutomu},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145698},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, real-time, stereo vision},
 link = {http://doi.acm.org/10.1145/2145694.2145698},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {21--24},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Real-time Stereo Vision System Using a Tree-structured Dynamic Programming on FPGA},
 year = {2012}
}


@inproceedings{Asaad:2012:CCM:2145694.2145720,
 abstract = {Software based tools for simulation are not keeping up with the demands for increased chip and system design complexity. In this paper, we describe a cycle-accurate and cycle-reproducible large-scale FPGA platform that is designed from the ground up to accelerate logic verification of the Bluegene/Q compute node ASIC, a multi-processor SOC implemented in IBM's 45 nm SOI CMOS technology. This paper discusses the challenges for constructing such large-scale FPGA platforms, including design partitioning, clocking & synchronization, and debugging support, as well as our approach for addressing these challenges without sacrificing cycle accuracy and cycle reproducibility. The resulting fullchip simulation of the Bluegene/Q compute node ASIC runs at a simulated processor clock speed of 4 MHz, over 100,000 times faster than the logic level software simulation of the same design. The vast increase in simulation speed provides a new capability in the design cycle that proved to be instrumental in logic verification as well as early software development and performance validation for Bluegene/Q.},
 acmid = {2145720},
 address = {New York, NY, USA},
 author = {Asaad, Sameh and Bellofatto, Ralph and Brezzo, Bernard and Haymes, Chuck and Kapur, Mohit and Parker, Benjamin and Roewer, Thomas and Saha, Proshanta and Takken, Todd and Tierno, Jos{\'e}},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145720},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA-based acceleration, logic emulation, multi-core},
 link = {http://doi.acm.org/10.1145/2145694.2145720},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {153--162},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Cycle-accurate, Cycle-reproducible multi-FPGA System for Accelerating Multi-core Processor Simulation},
 year = {2012}
}


@inproceedings{Chow:2012:MPM:2145694.2145705,
 abstract = {This paper introduces a novel mixed precision methodology applicable to any Monte Carlo (MC) simulation. It involves the use of data-paths with reduced precision, and the resulting errors are corrected by auxiliary sampling. An analytical model is developed for a reconfigurable accelerator system with a field-programmable gate array (FPGA) and a general purpose processor (GPP). Optimisation based on mixed integer geometric programming is employed for determining the optimal reduced precision and optimal resource allocation among the MC data-paths and correction datapaths. Experiments show that the proposed mixed precision methodology requires up to 11 % additional evaluations while less than 4 % of all the evaluations are computed in the reference precision; the resulting designs are up to 7.1 times faster and 3.1 times more energy efficient than baseline double precision FPGA designs, and up to 163 times faster and 170 times more energy efficient than quad-core software designs optimised with the Intel compiler and Math Kernel Library. Our methodology also produces designs for pricing Asian options which are 4.6 times faster and 5.5 times more energy efficient than NVIDIA Tesla C2070 GPU implementations.},
 acmid = {2145705},
 address = {New York, NY, USA},
 author = {Chow, Gary Chun Tak and Tse, Anson Hong Tak and Jin, Qiwei and Luk, Wayne and Leong, Philip H.W. and Thomas, David B.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145705},
 isbn = {978-1-4503-1155-7},
 keyword = {Monte Carlo, mixed precision},
 link = {http://doi.acm.org/10.1145/2145694.2145705},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {57--66},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Mixed Precision Monte Carlo Methodology for Reconfigurable Accelerator Systems},
 year = {2012}
}


@inproceedings{Walsh:2012:FPA:2145694.2145743,
 abstract = {Massively parallel processor arrays have been shown to be an effective and suitable choice for image processing tasks [1]. More recently, some of the state of the art processor arrays have been used for real-time machine vision tasks such as intelligent transport system applications [2] or video processing on mobile applications [3] providing a much more powerful solution than a conventional processor. A number of Single Instruction Multiple Data (SIMD) processor arrays have been implemented on FPGAs [4]-[6], which are particularly suited to implementing such processor architectures because of their similarities of both being arrays of fine grained logic elements. In this work, we propose an FPGA implementation of a processor array where the processing elements (PEs) are as small as possible, while providing local memory sufficient for processing greyscale images. The PE is then replicated to form an array. A 32 Ã— 32 PE array is implemented on a Xilinx Virtex 5 XC5VLX50 FPGA using the four-neighbour connectivity with the possibility to scale up using a larger FPGA. The processor array operates at a frequency of 96 MHz and executes a peak of 98.3 giga operations per second (GOPS) (bit-serial operations). A binary edge detection algorithm is performed in 52.08 ns. Uploading and downloading a binary image in a 32 Ã— 32 array takes an extra 687.5 ns. Sobel edge detection of an 8-bit greyscale image is performed in 5.33 Âµs. Uploading and downloading an 8-bit greyscale image in a 32 Ã— 32 array takes 5.36 Âµs. With larger FPGAs being available in the future, the array sizes comparable to state of the art custom designed ICs can be implemented on these FPGAs.},
 acmid = {2145743},
 address = {New York, NY, USA},
 author = {Walsh, Declan and Dudek, Piotr},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145743},
 isbn = {978-1-4503-1155-7},
 keyword = {architecture, fpga, image processor array, simd},
 link = {http://doi.acm.org/10.1145/2145694.2145743},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {266--266},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Field Programmable Array Core for Image Processing (Abstract Only)},
 year = {2012}
}


@proceedings{Compton:2012:2145694,
 abstract = {Welcome to the 2012 ACM International Symposium on Field-Programmable Gate Arrays (FPGA). FPGA continues to be a premier venue for researchers to present their efforts in a variety of FPGArelated areas: architecture, circuit design, Computer-Aided Design (CAD), FPGA-based computing machines, design studies and applications specially suited to FPGA implementation. In addition to the paper presentations, FPGA provides opportunities for researchers, students and industrial participants to mingle and to personally discuss research. FPGA'12 is the 20th annual meeting for this symposium. A special collection of papers, The FPGA-20, has been compiled to celebrate 20 years of successful FPGA research. A panel of experts chose the papers and Steve Trimberger and AndrÃ© DeHon edited the final contents for this anniversary volume and will present it during the conference. We received 87 submissions this year and selected 20 of these for presentation as full papers (24% acceptance rate) and these will appear in the proceedings as 10-page papers. An additional 16 submissions were selected as 4-page short-paper presentations; these consist of a 5-minute introductory presentation followed by a poster where delegates can ask detailed questions of the authors. An additional 20 poster-only presentations will allow authors to interact with attendees more directly. This year's symposium features a pre-conference workshop, "FPGAs in 2032: Challenges and Opportunities in the Next 20 Years," run by Vaughn Betz (University of Toronto) and Lesley Shannon (Simon Fraser University). All attendees are encouraged to attend. A special anniversary banquet will be held at The Monterey Bay Aquarium.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1155-7},
 location = {Monterey, California, USA},
 note = {420120},
 publisher = {ACM},
 title = {FPGA '12: Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 year = {2012}
}


@inproceedings{Yang:2012:SAG:2145694.2145762,
 abstract = {High-speed IP lookup remains a challenging problem in next generation routers due to the ever increasing line rate and routing table size. In addition, the evolution towards IPv6 also requires long prefix length, sparse prefix distribution, and potentially very large routing tables. In this paper, we propose a novel Combined Length-Infix Pipelined Search (CLIPS) architecture for IPv6 routing table lookup on FPGA. CLIPS solves the longest prefix match (LPM) problem by combining both prefix length and infix pattern search. Binary search in prefix length is performed on the 64-bit routing prefix of IPv6 down to an 8-bit length range in log(64/8)=3 phases; each phase performs a fully-pipelined infix pattern search with only one external memory access. A fourth and the last phase then finds the LPM (if any) within the 8-bit length range in a compressed multi-bit trie. We describe the algorithms and data structures used for the CLIPS construction, run-time operation, dynamic update and false-positive avoidance. The proposed solution improves the on-chip memory efficiency on FPGA and maximizes the external SRAM utilization; additional properties for ensuring the practicality of our scheme include the modular construction, easy dynamic update, and simple resource allocation. Using a state-of-the-art FPGA, our CLIPS prototype supports up to 2.7 millioin IPv6 prefixes when employing 33 Mbits of BRAM and 4 channels of external SRAM. The prototype achieves a sustained throughput of 264 million IPv6 lookups per second, or 135 Gbps with minimum size (64-byte) packets.},
 acmid = {2145762},
 address = {New York, NY, USA},
 author = {Yang, Yi-Hua E. and Erdem, O\u{g}uzhan and Prasanna, Viktor K.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145762},
 isbn = {978-1-4503-1155-7},
 keyword = {binary search tree, ip lookup, longest prefix match, packet forwarding, search trie, tree bitmap},
 link = {http://doi.acm.org/10.1145/2145694.2145762},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {272--272},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Scalable Architecture for 135 GBPS IPv6 Lookup on FPGA (Abstract Only)},
 year = {2012}
}


@inproceedings{Chung:2012:PEC:2145694.2145717,
 abstract = {The CoRAM memory architecture for FPGA-based computing augments traditional reconfigurable fabric with a natural and effective way for applications to interact with off-chip memory and I/O. The two central tenets of the CoRAM memory architecture are (1) the deliberate separation of concerns between computation versus data marshalling and (2) the use of a multithreaded software abstraction to replace FSM-based memory control logic. To evaluate the viability of the CoRAM memory architecture, we developed a full RTL implementation of a CoRAM microarchitecture instance that can be synthesized for standard cells or emulated on FPGAs. The results of our evaluation show that a soft emulation of the CoRAM memory architecture on current FPGAs can be impractical for memory-intensive, large-scale applications due to the high performance and area penalties incurred by the soft mechanisms. The results further show that in an envisioned FPGA built with CoRAM in mind, the introduction of hard macro blocks for data distribution can mitigate these inefficiencies---allowing applications to take advantage of the CoRAM memory architecture for ease of programmability and portability while still enjoying performance and efficiency comparable to RTL-level application development on conventional FPGAs.},
 acmid = {2145717},
 address = {New York, NY, USA},
 author = {Chung, Eric S. and Papamichael, Michael K. and Weisz, Gabriel and Hoe, James C. and Mai, Ken},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145717},
 isbn = {978-1-4503-1155-7},
 keyword = {fpga computing, memory architecture},
 link = {http://doi.acm.org/10.1145/2145694.2145717},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {139--142},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Prototype and Evaluation of the CoRAM Memory Architecture for FPGA-based Computing},
 year = {2012}
}


@inproceedings{Huang:2012:TLB:2145694.2145749,
 abstract = {Three-dimensional (3D) integration is an attractive and promising technology to keep Moore's Law alive, whereas the thermal issue also presents a critical challenge for 3D integrated circuits. Meanwhile, accurate thermal analysis is very time-consuming and thus can hardly be incorporated into most of placement algorithms generally performing numerous iterative refinement steps. As a consequence, in this paper, we first present a fine-grained grid-based thermal model for the 3D regular FPGA architecture and also highlight that lateral heat dissipation paths can no longer be assumed negligible. Then we propose two fast thermal-aware placement algorithms for 3D FPGAs, Standard Deviation (SD) and MineSweeper (MS), in which rapid thermal evaluation instead of slow detailed analysis is utilized. Moreover, both take the lateral heat dissipation into consideration and focus on distributing heat sources more evenly within a layer in a 3D FPGA to avoid creating hotspots. Experimental results show that SD and MS achieve 12.1%/7.6% reduction in maximum temperature and 82%/56% improvement in temperature deviation compared with a classical thermal-unaware placement method only at the cost of minor increase in wirelength and delay. Moreover, MS merely consumes 4% more runtime for producing thermal-aware placement solutions.},
 acmid = {2145749},
 address = {New York, NY, USA},
 author = {Huang, Juinn-Dar and Huang, Ya-Shih and Hsu, Mi-Yu and Chang, Han-Yuan},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145749},
 isbn = {978-1-4503-1155-7},
 keyword = {3d fpgas, logic block placement, thermal-aware placement, three-dimensional integration},
 link = {http://doi.acm.org/10.1145/2145694.2145749},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {268--268},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Thermal-aware Logic Block Placement for 3D FPGAs Considering Lateral Heat Dissipation (Abstract Only)},
 year = {2012}
}


@inproceedings{Mirian:2012:FSC:2145694.2145733,
 abstract = {Much like other computing platforms in the world today, FPGAs are becoming increasingly larger and contain large amounts of reconfigurable logic. This makes FPGAs an acceptable platform for multiprocessor systems. However in today's world of FPGA computing, very limited infrastructure is available to facilitate the creation of cache coherent shared memory systems for FPGAs. This paper introduces FCache, a system for shared memory cache coherent processing on FPGAs. The paper also describes the mapping of the conventional shared bus to FPGAs using two distinct network implemented in FCache. FCache also provides flushing and multithreaded synchronization functionalities, such as locking and unlocking of a mutex variable, which is embedded in its cache component. Despite these additional functionalities, results show that FCache has little resource overhead compared to a previous more simplistic cache coherent system that was targeted for FPGAs.},
 acmid = {2145733},
 address = {New York, NY, USA},
 author = {Mirian, Vincent and Chow, Paul},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145733},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, cache coherency, multiprocessor},
 link = {http://doi.acm.org/10.1145/2145694.2145733},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {233--236},
 publisher = {ACM},
 series = {FPGA '12},
 title = {FCache: A System for Cache Coherent Processing on FPGAs},
 year = {2012}
}


@inproceedings{Liu:2012:ACV:2145694.2145732,
 abstract = {This paper describes the compiler design for VENICE, a new soft vector processor (SVP). The compiler is a new back-end target for Microsoft Accelerator, a high-level data parallel library for C++ and C#. This allows us to automatically compile high-level programs into VENICE assembly code, thus avoiding the process of writing assembly code used by previous SVPs. Experimental results show the compiler can generate scalable parallel code with execution times that are comparable to hand-written VENICE assembly code. On data-parallel applications, VENICE at 100MHz on an Altera DE3 platform runs at speeds comparable to one core of a 3.5GHz Intel Xeon W3690 processor, beating it in performance on four of six benchmarks by up to 3.2x.},
 acmid = {2145732},
 address = {New York, NY, USA},
 author = {Liu, Zhiduo and Severance, Aaron and Singh, Satnam and Lemieux, Guy G.F.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145732},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, SIMD, scratchpad memory, soft processors, vector},
 link = {http://doi.acm.org/10.1145/2145694.2145732},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {229--232},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Accelerator Compiler for the VENICE Vector Processor},
 year = {2012}
}


@inproceedings{Fujita:2012:PDT:2145694.2145759,
 abstract = {Due to continuous increase of design complexity in SoC development, the time required for post-silicon verification and debugging keeps increasing especially for electrical errors and subtle corner case bugs, and it is now understood that some sort of programmability in silicon is essential to reduce the time for post-silicon verification and debugging. Although an easiest way to achieve this is to use FPGA for entire circuits, performance especially in terms of power efficiency compared with pure hardwired logic may be significantly inferior. Here, we discuss partial use of such in-field programmability in control parts of circuits for post-silicon debugging processes for electrical errors and corner case logical bugs. Our method deals with RTL designs in FSMD (Finite State Machine with Datapath) by adding partially in-field programmability, called "patch logic", in their control parts. With our patch logic we can dynamically change the behaviors of circuits in such a way to trace state transition sequences as well as values of internal values periodically. Our patch logic can also check if there is any electrical error or not periodically. Assuming that electrical errors occur very infrequently, an error can be detected by comparing the equivalence on the results of duplicated computations. Through experiments we discuss the area, timing, and power overhead due to the patch logic and also show results on electrical error detection with duplicated computations.},
 acmid = {2145759},
 address = {New York, NY, USA},
 author = {Fujita, Masahiro and Yoshida, Hiroaki},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145759},
 isbn = {978-1-4503-1155-7},
 keyword = {formal analysis, hardware patch, post-silicon debug},
 link = {http://doi.acm.org/10.1145/2145694.2145759},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {271--271},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Post-silicon Debugging Targeting Electrical Errors with Patchable Controllers (Abstract Only)},
 year = {2012}
}


@inproceedings{Wang:2012:CSA:2145694.2145719,
 abstract = {The wide acceptance of bioinformatics, medical imaging and multimedia applications, which have a data-centric favor to them, require more efficient and application-specific systems to be built. Due to the advances in modern FPGA technologies recently, there has been a resurgence in research aimed at accelerator design that leverages FPGAs to accelerate large-scale scientific applications. In this paper, we exploit this trend towards FPGA-based accelerator design and provide a proof-of-concept and comprehensive case study on FPGA-based accelerator design for a single-particle 3D reconstruction application in single-precision floating-point format. The proposed stream architecture is built by first offloading computing-intensive software kernels to dedicated hardware modules, which emphasizes the importance of optimizing computing dominated data access patterns. Then configurable computing streams are constructed by arranging the hardware modules and bypass channels to form a linear deep pipeline. The efficiency of the proposed stream architecture is justified by the reported 2.54 times speedup over a 4-cores CPU. In terms of power efficiency, our FPGA-based accelerator introduces a 7.33 and 3.4 times improvement over a 4-cores CPU and an up-to-date GPU device, respectively.},
 acmid = {2145719},
 address = {New York, NY, USA},
 author = {Wang, Wendi and Duan, Bo and Tang, Wen and Zhang, Chunming and Tang, Guangming and Zhang, Peiheng and Sun, Ninghui},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145719},
 isbn = {978-1-4503-1155-7},
 keyword = {FFT, FPGA, cryo-electron microscopy, memory access patterns, stream processing},
 link = {http://doi.acm.org/10.1145/2145694.2145719},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {143--152},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Coarse-grained Stream Architecture for Cryo-electron Microscopy Images 3D Reconstruction},
 year = {2012}
}


@inproceedings{Bailie:2012:ICA:2145694.2145699,
 abstract = {ICED (Incremental Clustering of Evolving Data) is a novel incremental clustering algorithm designed for data whose characteristics change over time. ICED is an unsupervised clustering technique that assumes no prior knowledge of the incoming data, and supports removing clusters that contain stale data. The user controls the FPGA implementation through a combination of compile time parameters (number of clusters) and run time parameters (distance threshold, fade cycle length). ICED has been applied to a radar application: pulse deinterleaving. ICED is the first implementation of incremental clustering on an FPGA of which we are aware. The implementation runs 39 times faster than an equivalent C implementation on a 3GHz Intel Xeon processor, and is capable of processing radar data in real time.},
 acmid = {2145699},
 address = {New York, NY, USA},
 author = {Bailie, Scott and Leeser, Miriam},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145699},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, clustering, electronic warfare, pulse deinterleaving},
 link = {http://doi.acm.org/10.1145/2145694.2145699},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {25--28},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Incremental Clustering Applied to Radar Deinterleaving: A Parameterized FPGA Implementation},
 year = {2012}
}


@inproceedings{Lavasani:2012:CHT:2145694.2145709,
 abstract = {Gorilla is a methodology for generating FPGA-based solutions especially well suited for data parallel applications with fine grain irregularity. Irregularity simultaneously destroys performance and increases power consumption on many data parallel processors such as General Purpose Graphical Processor Units (GPGPUs). Gorilla achieves high performance and low power through the use of FPGA-tailored parallelization techniques and application-specific hardwired accelerators, processing engines, and communication mechanisms. Automatic compilation from a stylized C language and templates that define the hardware structure coupled with the intrinsic flexibility of FPGAs provide high performance, low power, and programmability. Gorilla's capabilities are demonstrated through the generation of a family of core-router network processors processing up to 100Gbps (200MPPS for 64B packets) supporting any mix of IPv4, IPv6, and Multi-Protocol Label Switching (MPLS) packets on a single FPGA with off-chip IP lookup tables. A 40Gbps version of that network processor was run with an embedded test rig on a Xilinx Virtex-6 FPGA, verifying for performance and correctness. Its measured power consumption is comparable to full custom, commercial network processors. In addition, it is demonstrated how Gorilla can be used to generate merged virtual routers, saving FPGA resources.},
 acmid = {2145709},
 address = {New York, NY, USA},
 author = {Lavasani, Maysam and Dennison, Larry and Chiou, Derek},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145709},
 isbn = {978-1-4503-1155-7},
 keyword = {fpga, network processor, templates},
 link = {http://doi.acm.org/10.1145/2145694.2145709},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {87--96},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Compiling High Throughput Network Processors},
 year = {2012}
}


@inproceedings{Rose:2012:VPA:2145694.2145708,
 abstract = {To facilitate the development of future FPGA architectures and CAD tools -- both embedded programmable fabrics and pure-play FPGAs -- there is a need for a large scale, publicly available software suite that can synthesize circuits into easily-described hypothetical FPGA architectures. These circuits should be captured at the HDL level, or higher, and pass through logical and physical synthesis. Such a tool must provide detailed modelling of area, performance and energy to enable architecture exploration. As software flows themselves evolve to permit design capture at ever higher levels of abstraction, this downstream full-implementation flow will always be required. This paper describes the current status and new release of an ongoing effort to create such a flow - the 'Verilog to Routing' (VTR) project, which is a broad collaboration of researchers. There are three core tools: ODIN II for Verilog Elaboration and front-end hard-block synthesis, ABC for logic synthesis, and VPR for physical synthesis and analysis. ODIN II now has a simulation capability to help verify that its output is correct, as well as specialized synthesis at the elaboration step for multipliers and memories. ABC is used to optimize the 'soft' logic of the FPGA. The VPR-based packing, placement and routing is now fully timing-driven (the previous release was not) and includes new capability to target complex logic blocks. In addition we have added a set of four large benchmark circuits to a suite of previously-released Verilog HDL circuits. Finally, we illustrate the use of the new flow by using it to help architect a floating-point unit in an FPGA, and contrast it with a prior, much longer effort that was required to do the same thing.},
 acmid = {2145708},
 address = {New York, NY, USA},
 author = {Rose, Jonathan and Luu, Jason and Yu, Chi Wai and Densmore, Opal and Goeders, Jeffrey and Somerville, Andrew and Kent, Kenneth B. and Jamieson, Peter and Anderson, Jason},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145708},
 isbn = {978-1-4503-1155-7},
 keyword = {CAD, FPGA, architecture},
 link = {http://doi.acm.org/10.1145/2145694.2145708},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {77--86},
 publisher = {ACM},
 series = {FPGA '12},
 title = {The VTR Project: Architecture and CAD for FPGAs from Verilog to Routing},
 year = {2012}
}


@inproceedings{Chen:2012:FRU:2145694.2145721,
 abstract = {The radiation dose associated with computerized tomography (CT) is significant. Optimization-based iterative reconstruction approaches, e.g., compressive sensing provide ways to reduce the radiation exposure, without sacrificing image quality. However, the computational requirement such algorithms is much higher than that of the conventional Filtered Back Projection (FBP) reconstruction algorithm. This paper describes an FPGA implementation of one important iterative kernel called EM, which is the major computation kernel of a recent EM+TV reconstruction algorithm. We show that a hybrid approach (CPU+GPU+FPGA) can deliver a better performance and energy efficiency than GPU-only solutions, providing 13X boost of throughput than a dual-core CPU implementation.},
 acmid = {2145721},
 address = {New York, NY, USA},
 author = {Chen, Jianwen and Cong, Jason and Yan, Ming and Zou, Yi},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145721},
 isbn = {978-1-4503-1155-7},
 keyword = {3D, CT, FPGA, image reconstruction},
 link = {http://doi.acm.org/10.1145/2145694.2145721},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {163--166},
 publisher = {ACM},
 series = {FPGA '12},
 title = {FPGA-accelerated 3D Reconstruction Using Compressive Sensing},
 year = {2012}
}


@inproceedings{Fu:2012:NFC:2145694.2145747,
 abstract = {FPGA's configurability makes it difficult for FPGA's manufacturers to fully test it. In this paper, a full coverage test method for FPGA's Configurable Logic Blocks (CLBs) is proposed, through which all basic logics of FPGA's every CLB can be fully tested. Innovative test circuits are configured to build repeatable logic arrays for look-up tables, distributed random access memories, configurable registers and other logics. The programmable interconnects needed to connect CLBs in these test circuits are also repeatable, making the configuration process much easier and the test speed much faster. The test method is implemented on different scales of Xilinx Virtex chips, where 19 test configuration circuits are needed to achieve 100% coverage for all CLBs. Besides, the method is transplantable and independent of FPGA's array size. To evaluate the test method reliably and guide the process of test vectors generation, a fault simulator - Turbofault is used to simulate FPGA's test coverage.},
 acmid = {2145747},
 address = {New York, NY, USA},
 author = {Fu, Yong and Wang, Chi and Chen, Liguang and Lai, Jinmei},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145747},
 isbn = {978-1-4503-1155-7},
 keyword = {clb, fault coverage, fpga, test circuits design},
 link = {http://doi.acm.org/10.1145/2145694.2145747},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {267--267},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Novel Full Coverage Test Method for CLBs in FPGA (Abstract Only)},
 year = {2012}
}


@proceedings{Hutchings:2013:2435264,
 abstract = {It is our great pleasure to welcome you to the 2013 ACM International Symposium on FPGAs (FPGA 2013). This year's symposium continues its tradition of being a premier forum for the presentation of FPGA-related research across a wide variety of topics: new FPGA architectures and circuit designs, enhancements to Computer-Aided Design (CAD) algorithms and flows, applications well-suited to FPGAs, and design studies. In addition to facilitating the sharing of research results through the paper and poster presentations, FPGA provides an excellent opportunity for researchers from around the world to mingle and discuss research results and ideas. This year we received 106 submissions from twenty-one countries. The program committee accepted 24 full (ten page) and 4 short (four page) papers, each of which are published in the proceedings, for an acceptance rate of 26%. Full papers will each also have a twenty-minute oral presentation, while short papers will have a five-minute oral presentation, followed by a poster presentation at which attendees can further discuss the work with the authors. Finally we will have four poster sessions in which a total of 37 additional research projects will be displayed on posters, and at which you may ask detailed questions of the authors. This year the symposium begins with a day of tutorials related to high-level synthesis and design flows for FPGAs. A total of four tutorials will be presented in two parallel tracks, and the threehour length of each tutorial allows an in-depth presentation on each of the four design flows and tools. The symposium also includes an evening panel moderated by Jason Cong of UCLA on the question of "Are FPGAs Suffering from the Innovator's Dilemna?" Bring your questions for our panel of industry experts, and enjoy a lively discussion on whether the barriers to entry to the FPGA industry are helping or harming innovation.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1887-7},
 location = {Monterey, California, USA},
 publisher = {ACM},
 title = {FPGA '13: Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 year = {2013}
}


@inproceedings{Gong:2012:FVS:2145694.2145735,
 abstract = {Dynamically reconfigurable systems increase design density and flexibility by allowing hardware modules to be swapped at run time. Systems that employ checkpointing, periodic or phased execution, preemptive multitasking and resource defragmentation, may also need to be able to save and restore the state of a module that is being reconfigured. Existing tools verify the functionality of a system that is undergoing reconfiguration. These tools can also be employed if state is accessed using application logic. However, when state is accessed via the configuration port, functional verification is hindered because the FPGA fabric, which mediates the transfer of state between the application logic and the configuration port, is not being simulated. We describe how to efficiently simulate those aspects of the fabric that are used in accessing module state. To the best of our knowledge, this work is the first to allow cycle-accurate simulation of a system partially reconfiguring both its logic and state and a case study shows that our method is effective in detecting device independent design errors.},
 acmid = {2145735},
 address = {New York, NY, USA},
 author = {Gong, Lingkan and Diessel, Oliver},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145735},
 isbn = {978-1-4503-1155-7},
 keyword = {FPGA, dynamically reconfigurable systems, state saving and restoration, verification},
 link = {http://doi.acm.org/10.1145/2145694.2145735},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {241--244},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Functionally Verifying State Saving and Restoration in Dynamically Reconfigurable Systems},
 year = {2012}
}


@inproceedings{Ananthanarayanan:2012:EFB:2145694.2145744,
 abstract = {Dynamic power management for multi-core system on chip (MPSoC) platforms has become an increasingly critical design problem. In this paper, we present EmPower, an FPGA based emulation, validation and prototyping framework for dynamic power management research targeted at MPSoC platforms. EmPower supports two advanced power management features -- per-core dynamic frequency scaling and clock gating, and power-aware thread migration. We also provide two fully-functional parallel applications for benchmarking -- video encoding and software-defined radio. Our experimental results indicate that EmPower provides up to 36 -- improvement in run-time compared to cycle-accurate software simulations, and enables accurate and efficient exploration of the design space of power management algorithms.},
 acmid = {2145744},
 address = {New York, NY, USA},
 author = {Ananthanarayanan, Sundaram and Ravishankar, Chirag and Garg, Siddharth and Kennings, Andrew},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145744},
 isbn = {978-1-4503-1155-7},
 keyword = {fpga implementation, frequency scaling, power management, thread migration},
 link = {http://doi.acm.org/10.1145/2145694.2145744},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {266--266},
 publisher = {ACM},
 series = {FPGA '12},
 title = {EmPower: FPGA Based Emulation of Dynamic Power Management Algorithms for Multi-core Systems on Chip (Abstract Only)},
 year = {2012}
}


@inproceedings{Akin:2012:AAO:2145694.2145760,
 abstract = {We present a poster showcasing our FPGA implementations of two-dimensional discrete Fourier transform (2D-DFT) on large datasets that must reside off-chip in DRAM. These memory-bound large 2D-DFT computations are at the heart of important scientific computing and image processing applications. The central challenge in creating high-performance implementations is in the carefully orchestrated use of the available off-chip memory bandwidth and on-chip temporary storage. Our implementations derive their efficiency from a combined attention to both the algorithm design to enable efficient DRAM access patterns and datapath design to extract the maximum compute throughput at a given level of memory bandwidth. The poster reports results including a 1024x1024 double-precision 2D-DFT implementation on an Altera DE4 platform (based on a Stratix IV EP4SGX530 with 12 GB/s DRAM bandwidth) that reached over 16 Gflop/s, achieving a much higher ratio of performance-to-memory-bandwidth than both state-of-the-art CPU and GPU implementations.},
 acmid = {2145760},
 address = {New York, NY, USA},
 author = {Akin, Berkin and Milder, Peter A. and Franchetti, Franz and Hoe, James C.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145760},
 isbn = {978-1-4503-1155-7},
 keyword = {2d-dft, bandwidth, dram, fft, fpga},
 link = {http://doi.acm.org/10.1145/2145694.2145760},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {271--271},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Algorithm and Architecture Optimization for Large Size Two Dimensional Discrete Fourier Transform (Abstract Only)},
 year = {2012}
}


@proceedings{Wawrzynek:2011:1950413,
 abstract = {We welcome you to the 19th annual ACM International Symposium on Field-Programmable Gate Arrays. This is premier venue for disseminating research advances in a wide range of topic areas related to FPGAs and FPGA-like technologies. In response to the FPGA 2011 Call for Papers, 82 papers were submitted. From these, the program committee accepted 21 full-length papers (25.6% acceptance rate). We also continued the practice started in 2010 of accepting a number of short (fourpage) papers in order to broaden the participation in the conference, and highlight interesting new projects. The authors of these papers are given the opportunity to give a five-minute oral presentation, followed by a poster presentation to spur discussion. This year we have 16 short papers. Additionally, there are over 20 poster-only presentations that allow authors to interact with attendees more directly. This year's symposium features a pre-conference workshop, "The Role of FPGAs in a Converged Future with Heterogeneous Programmable Processors", run by Jonathan Rose (University of Toronto) and Guy Lemieux (University of British Columbia). All FPGA 2011 attendees are encouraged to participate. We will also have an evening panel, organized by John Wawrzynek (UC Berkeley), entitled "Should the Academic Community Launch an Open Source FPGA Device and Tools Effort?"},
 address = {New York, NY, USA},
 isbn = {978-1-4503-0554-9},
 location = {Monterey, CA, USA},
 note = {480110},
 publisher = {ACM},
 title = {FPGA '11: Proceedings of the 19th ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 year = {2011}
}


@inproceedings{Boland:2012:SAA:2145694.2145726,
 abstract = {The freedom over the choice of numerical precision is one of the key factors that can only be exploited throughout the datapath of an FPGA accelerator, providing the ability to trade the accuracy of the final computational result with the silicon area, power, operating frequency, and latency. However, in order to tune the precision used throughout hardware accelerators automatically, a tool is required to verify that the hardware will meet an error or range specification for a given precision. Existing tools to perform this task typically suffer either from a lack of tightness of bounds or require a large execution time when applied to large scale algorithms; in this work, we propose an approach that can both scale to larger examples and obtain tighter bounds, within a smaller execution time, than the existing methods. The approach we describe also provides a user with the ability to trade the quality of bounds with execution time of the procedure, making it suitable within a word-length optimization framework for both small and large-scale algorithms. We demonstrate the use of our approach on instances of iterative algorithms to solve a system of linear equations. We show that because our approach can track how the relative error decreases with increasing precision, unlike the existing methods, we can use it to create smaller hardware with guaranteed numerical properties. This results in a saving of 25% of the area in comparison to optimizing the precision using competing analytical techniques, whilst requiring a smaller execution time than the these methods, and saving almost 80% of area in comparison to adopting IEEE double precision arithmetic.},
 acmid = {2145726},
 address = {New York, NY, USA},
 author = {Boland, David and Constantinides, George A.},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145726},
 isbn = {978-1-4503-1155-7},
 keyword = {precision analysis, range analysis, word-length optimisation},
 link = {http://doi.acm.org/10.1145/2145694.2145726},
 location = {Monterey, California, USA},
 numpages = {10},
 pages = {185--194},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Scalable Approach for Automated Precision Analysis},
 year = {2012}
}


@inproceedings{Cheah:2012:LFS:2145694.2145734,
 abstract = {As Field Programmable Gate Arrays (FPGAs) have advanced, the capabilities and variety of embedded resources have increased. In the last decade, signal processing has become one of the main driving applications for FPGA adoption, so FPGA vendors tailored their architectures to such applications. The resulting embedded digital signal processing (DSP) blocks have now advanced to the point of supporting a wide range of operations. In this paper, we explore how these DSP blocks can be applied to general computation. We show that the DSP48E1 blocks in Xilinx Virtex-6 devices support a wide range of standard processor instructions which can be designed into the core of a basic processor with minimal additional logic usage.},
 acmid = {2145734},
 address = {New York, NY, USA},
 author = {Cheah, Hui Yan and Fahmy, Suhaib A. and Maskell, Douglas L. and Kulkarni, Chidamber},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145734},
 isbn = {978-1-4503-1155-7},
 keyword = {DSP blocks, FPGA, hard macro, processor architecture, soft processor},
 link = {http://doi.acm.org/10.1145/2145694.2145734},
 location = {Monterey, California, USA},
 numpages = {4},
 pages = {237--240},
 publisher = {ACM},
 series = {FPGA '12},
 title = {A Lean FPGA Soft Processor Built Using a DSP Block},
 year = {2012}
}


@inproceedings{Wen:2012:MMA:2145694.2145741,
 abstract = {A uniform FPGA-based architecture, an efficient programming model and a simple mapping method are paramount for PPGA technology to be more widely accepted. This paper presents MASALA, a dynamically reconfigurable FPGA-based accelerator specifically for parallel programs written in thread-intensive and explicit memory management (TEMM) programming models. The system uses TEMM programming model to parallelize the demanding application, including decomposing the application into separate thread blocks, decoupling compute and data load/store etc. Hardware engines are included into the MASALA by using partial dynamic reconfigure modules, each of which encapsulates Thread Process Engine implementing the thread functionality in hardware. A data dispatching scheme is also included in MASALA to enable the explicit communication among multiple memory hierarchies such as between inter-hardware engines, the host processor and hardware engines. At last, the paper illustrates a Multi-FPGA prototype system of the presented architecture: MASALA-SX. A large synthetic aperture radar (SAR) image formatting experiment shows that the MASALA architecture facilitates the construction of a TEMM program accelerator by providing it with greater performance and less power consumption than current CPU platforms, but without sacrificing programmability, flexibility and scalability.},
 acmid = {2145741},
 address = {New York, NY, USA},
 author = {Wen, Mei and Wu, Nan and Yang, Qianming and Zhang, Chunyuan and Zhao, Liang},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145741},
 isbn = {978-1-4503-1155-7},
 keyword = {accelerator, explicit memory management, fpga, masala, sar, thread-intensive},
 link = {http://doi.acm.org/10.1145/2145694.2145741},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {265--265},
 publisher = {ACM},
 series = {FPGA '12},
 title = {The Masala Machine: Accelerating Thread-intensive and Explicit Memory Management Programs with Dynamically Reconfigurable FPGAs (Abstract Only)},
 year = {2012}
}


@inproceedings{Savage:2012:AFR:2145694.2145746,
 abstract = {This paper discusses how to generate mobile robots' behaviors using genetic algorithms, GA. The behaviors are built using state machines implemented in a programmable logic device, an FPGA, and they are encoded in such a way that a state machine architecture executes them, controlling the overall operation of a small mobile robot. The behaviors generated by the GA are evaluated according to a fitness function that grades their performance. Basically, the fitness function evaluates the robot's performance when it goes from an origin to a destination. In our approach each individuals' chromosome represents, given a set of inputs coming from the sensors and the current state, the next state and outputs that controls the robot's movements. For each generation the GA needs to evaluate population's individuals, doing this with the real robot it would required to much time, that would be impossible to do. Thus, the GA needs a simulator, as close as it can be to the real robot and its environment. The simulator gets the individuals' chromosomes and executes the algorithm state machine represented by them, it simulates the movements of the robot depending of the output generated in the present state and the simulated robot's sensors. Our objective was to prove that GA is a good option as a method for finding behaviors for mobile robots' navigation and also that these behaviors can be implemented in FPGAs.},
 acmid = {2145746},
 address = {New York, NY, USA},
 author = {Savage, Jesus and Savage, Rodrigo and Morales-Aguirre, Marco and Kuri-Morales, Angel},
 booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
 doi = {10.1145/2145694.2145746},
 isbn = {978-1-4503-1155-7},
 keyword = {genetic algorithms, robots behaviors},
 link = {http://doi.acm.org/10.1145/2145694.2145746},
 location = {Monterey, California, USA},
 numpages = {1},
 pages = {267--267},
 publisher = {ACM},
 series = {FPGA '12},
 title = {Adaptive FPGA-based Robotics State Machine Architecture Derived with Genetic Algorithms (Abstract Only)},
 year = {2012}
}


