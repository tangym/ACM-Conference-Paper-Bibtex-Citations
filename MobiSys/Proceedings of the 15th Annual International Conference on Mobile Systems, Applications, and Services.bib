@inproceedings{Lee:2017:DMC:3081333.3089326,
 abstract = {In-app advertising has become a significant source of revenue for mobile app. In order to improve the effectiveness of in-app ads, most ad networks focus on targeting a user based on the user's personal information collected from their ad library inside mobile apps and the global knowledge built from big data on ad servers. However, sharing user's sensitive information with the ad servers may raise privacy concerns. As opposed to targeting users, mobile contextual advertising seeks to target the app page a user is viewing. In this demo, we present a novel mobile contextual advertising platform, called MoCA, which is designed to improve the semantic relevance of in-app ads in a stand-alone, privacy-protecting manner on mobile devices. MoCA understands the semantics of app page and ads, and then matches semantically relevant ads to the page inside mobile devices. To the best of our knowledge, this is the first work to implement the mobile contextual advertising platform based on the semantic approach without resort to ad servers.},
 acmid = {3089326},
 address = {New York, NY, USA},
 author = {Lee, Jung-Hyun and Jun, So-Young and Park, So-Jung and Kim, Kang-Min and Lee, SangKeun},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089326},
 isbn = {978-1-4503-4928-4},
 keyword = {in-app advertising, mobile contextual advertising, tiny text intelligence},
 link = {http://doi.acm.org/10.1145/3081333.3089326},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {181--181},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Mobile Contextual Advertising Platform Based on Tiny Text Intelligence},
 year = {2017}
}


@inproceedings{Yan:2017:PRR:3081333.3089312,
 abstract = {Since the introduction of the smartphone, mobile computing has become pervasive in our society. Meanwhile, Mobile devices have evolved far beyond the stereotypical personal devices and been employed in various traditional real-time embedded domains. Of the currently available mobile systems, Android has seen the most widespread deployment outside of the consumer electronics market. Its open source nature has prompted its ubiquitous adoption in sensing, medical, robotics, and autopilot applications. However, it is not surprising that Android does not provide any real-time guarantee since it is designed as a mobile system and optimised for mobility, user experience, and energy efficiency. Although there has been much interest in adopting Android in real-time contexts, surprisingly little work has been done to examine the suitability of Android for real-time systems. Existing work only provides solutions to traditional problems, including real-time garbage collection at the virtual machine layer, real-time OS scheduling and resource management. While it is critical to address these issues, it is by no means sufficient. After all, Android is a vast system that is more than a Java virtual machine and a kernel. Our work examines the internals of Android, the Android programming model, libraries and core systems services. We discuss the implications and challenges of adapting Android constructs and core system services for real-time and present a solution for each, name RTDroid, as a whole system. It is unique in that it redesigns Android's internal components, replaces Android's Dalvik/ART with a real-time Java virtual machine, FijiVM, and leverages off-the-shelf real-time OSes. RTDroid also provides an event-driven programming model for the development of real-time applications. To retain a familiar style of Android application, we make a number of changes to the Android abstractions and how they interact with the underlying system as well as each other. We aim to leave legacy Android code unaffected and expose real-time features to components which have timeliness requirements. More specifically, Our programming model consist of four parts: 1) real-time constructs for real-time expressiveness, 2) a real-time extension to Android's application manifest for the real-time configuration, 3) real-time communication channels that enable construct interactions with real-time semantics, 4) pause-less memory management with scoped memory. To validate the predictability of RTDroid's implementation, we firstly report a number of micro-benchmark results with RTDroid basic constructs. Then, we demonstrate three real-world applications implemented in RTDroid and provide statistic results. Our results illustrate that, at least in these use-cases, the modified platform delivers significantly better time predictability than stock Android and reduces the code complexity as compared to the traditional real-time programming paradigm, RTSJ.},
 acmid = {3089312},
 address = {New York, NY, USA},
 author = {Yan, Yin and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089312},
 isbn = {978-1-4503-4928-4},
 keyword = {RTDroid, android},
 link = {http://doi.acm.org/10.1145/3081333.3089312},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {168--168},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: RTDroid: A Real-Time Solution with Android},
 year = {2017}
}


@inproceedings{Ki:2017:DFA:3081333.3089330,
 abstract = {We demonstrate AutoClicker, a fully automated UI testing system for large-scale Android apps using multiple devices. It provides a way to quickly and easily verify that a large number of Android apps behave correctly at runtime in a repeatable manner.},
 acmid = {3089330},
 address = {New York, NY, USA},
 author = {Ki, Taeyeon and Simeonov, Alexander and Park, Chang Min and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089330},
 isbn = {978-1-4503-4928-4},
 keyword = {UI testing, autoclicker, test automation},
 link = {http://doi.acm.org/10.1145/3081333.3089330},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {185--185},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Fully Automated UI Testing System for Large-scale Android Apps Using Multiple Devices},
 year = {2017}
}


@inproceedings{Bi:2017:PAW:3081333.3089320,
 abstract = {Chronic disease is one of the most pressing health challenges facing the United States (and an increasing set of other countries). The onset or progression of diseases like obesity, diabetes, and metabolic disorder are strongly related to eating behavior, and scientists are still trying to fully understand the complex mixture of diet, exercise, genetics, sociocultural context, and physical environment that lead to these diseases. Health science, however, has no effective means for automatically measuring eating behavior in free-living conditions. The Auracle aims to be a wearable earpiece that detects eating behavior, to be fielded by health-science researchers in their efforts to study eating behavior and ultimately to develop interventions useful to individuals striving to address chronic disease related to eating.},
 acmid = {3089320},
 address = {New York, NY, USA},
 author = {Bi, Shengjie and Davernport, Ellen and Gong, Jun and Peterson, Ronald and Skinner, Joseph and Storer, Kevin and Wang, Tao and Caine, Kelly and Halter, Ryan and Kotz, David and Odame, Kofi and Sorber, Jacob and Yang, Xing-Dong},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089320},
 isbn = {978-1-4503-4928-4},
 link = {http://doi.acm.org/10.1145/3081333.3089320},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {176--176},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Auracle: A Wearable Device for Detecting and Monitoring Eating Behavior},
 year = {2017}
}


@inproceedings{Liu:2017:PVR:3081333.3089304,
 abstract = {With continuing advances in the development of low-power electronics, including sensors and actuators, we anticipate a rapid expansion of pervasive computing. Wearable devices, in particular, require new modes for interaction -- many have no keyboard or touchscreen. In this work, we focus on user authentication on wearable devices. For an entertainment device, such as a VR headset, it can recognize the user and load the right game profile or music playlist. For a house climate-control system, it can adjust the environment to the wearer's preference. Most compellingly, for a health-monitoring device, it can label the sensor data with the correct identity so that the data can be stored in the correct health record. (A mix-up of sensor data could lead to incorrect decisions, with harm to the patient.) Because not all devices are personal devices -- my phone, your fitness sensor -- many devices will need to automatically recognize their wearer. They may have no interface for user identification (or PIN or password for authentication). Thus, we need a simple, wearable biometric technique to identify the user -- which could be embedded in one authentication device that shares the identity with a body-area network of other devices (earlier confirmed to be on the same body). This device should be trained once, for each user that might wear it, but thenceforth be completely automatic. Although a wristband could use a physiological biometric to recognize its wearer; we seek an alternative biometric, notably, one that might work for devices mounted on the head, neck, or chest.},
 acmid = {3089304},
 address = {New York, NY, USA},
 author = {Liu, Rui and Cornelius, Cory and Rawassizadeh, Reza and Peterson, Ron and Kotz, David},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089304},
 isbn = {978-1-4503-4928-4},
 keyword = {authentication, biometrics},
 link = {http://doi.acm.org/10.1145/3081333.3089304},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {160--160},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Vocal Resonance As a Passive Biometric},
 year = {2017}
}


@inproceedings{Menuka:2017:PAE:3081333.3089323,
 abstract = {Like software, hardware also has bugs. These bugs, or errata, can cause unexpected behaviors, reducing performance and causing malfunctions in the entire system. As there is no way to fix an erratum after hardware is deployed, its harmful effects are often mitigated by software workarounds, usually in low-level software such as operating system. The goal of our work is to ensure system correctness and security against the harmful effects of errata and their workarounds. The first step is to systematically understand them in the wild. In this poster, we present our early results from analyzing errata in the ARM Cortex-A family of microarchitecture, introduced by ARM itself, and their workarounds. We studied publicly available ARM errata documentations and examined source code of low-level software, namely Linux kernel, U-Boot and ARM Trusted firmware.},
 acmid = {3089323},
 address = {New York, NY, USA},
 author = {Menuka, Nisal and Zhong, Lin},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089323},
 isbn = {978-1-4503-4928-4},
 keyword = {ARM errata, software workarounds, types of errata fixes},
 link = {http://doi.acm.org/10.1145/3081333.3089323},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {179--179},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: ARM Errata and Their Software Workarounds},
 year = {2017}
}


@inproceedings{Liu:2017:BSR:3081333.3081344,
 abstract = {Advanced driver assistance systems and, in particular automated driving offers an unprecedented opportunity to transform the safety, efficiency, and comfort of road travel. Developing such safety technologies requires an understanding of not just common highway and city traffic situations but also a plethora of widely different unusual events (e.g., object on the road way and pedestrian crossing highway, etc.). While each such event may be rare, in aggregate they represent a significant risk that technology must address to develop truly dependable automated driving and traffic safety technologies. By developing technology to scale road data acquisition to a large number of vehicles, this paper introduces a low-cost yet reliable solution, BigRoad, that can derive internal driver inputs (i.e., steering wheel angles, driving speed and acceleration) and external perceptions of road environments (i.e., road conditions and front-view video) using a smartphone and an IMU mounted in a vehicle. We evaluate the accuracy of collected internal and external data using over 140 real-driving trips collected in a 3-month time period. Results show that BigRoad can accurately estimate the steering wheel angle with 0.69 degree median error, and derive the vehicle speed with 0.65 km/h deviation. The system is also able to determine binary road conditions with 95% accuracy by capturing a small number of brakes. We further validate the usability of BigRoad by pushing the collected video feed and steering wheel angle to a deep neural network steering wheel angle predictor, showing the potential of massive data acquisition for training self-driving system using BigRoad.},
 acmid = {3081344},
 address = {New York, NY, USA},
 author = {Liu, Luyang and Li, Hongyu and Liu, Jian and Karatas, Cagdas and Wang, Yan and Gruteser, Marco and Chen, Yingying and Martin, Richard P.},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081344},
 isbn = {978-1-4503-4928-4},
 keyword = {IMU, road data acquisition, self-driving, smartphone},
 link = {http://doi.acm.org/10.1145/3081333.3081344},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {371--384},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {BigRoad: Scaling Road Data Acquisition for Dependable Self-Driving},
 year = {2017}
}


@inproceedings{Hamatani:2017:PSK:3081333.3089306,
 abstract = {Water accounts for about 60% of the human body, and when the body loses it (e.g., through urine, sweat, etc.) in higher rate than its intake rate (through drinking), dehydration symptoms occur. The dehydration causes many severe health problems like organ and cognitive impairment. Therefore, it is critical for the human to drink water in a sustained manner to avoid dehydration. To prevent humans from dehydration, continuous day-scale tracking of the water intake is needed. In this paper, we propose an unobtrusive method to recognize the drinking activity as well as estimate the water intake amount in milliliter scale by leveraging smartwatches. Our basic idea is to track the arm motion and discriminate the drinking activities from the similar hand-based motions like food intake, phone calls, etc. Thereafter, we estimate the water intake amount from the drinking duration.},
 acmid = {3089306},
 address = {New York, NY, USA},
 author = {Hamatani, Takashi and Elhamshary, Moustafa and Uchiyama, Akira and Higashino, Teruo},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089306},
 isbn = {978-1-4503-4928-4},
 keyword = {activity recognition, hand gesture, water intake, wearable sensor},
 link = {http://doi.acm.org/10.1145/3081333.3089306},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {162--162},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Smartwatch Knows How Much You Drink},
 year = {2017}
}


@inproceedings{Ki:2017:REA:3081333.3081341,
 abstract = {This paper proposes a new technique that enables open innovation in mobile platforms. Our technique allows third-party developers to modify, instrument, or extend platform API calls and deploy their modifications seamlessly. The uniqueness of our technique is that it enables modifications completely at the app layer without requiring any platform-level changes. This allows practical openness---third parties can easily distribute their modifications for a platform without the need to update the entire platform. To demonstrate the benefits of our technique, we have developed a prototype on Android called Reptor and used it to instrument real-world apps with novel functionality. Our evaluation in realistic scenarios shows that Reptor has little overhead in performance and energy, and only modest overhead in memory usage that ranges from 0.6% to 10% for the observed worst cases.},
 acmid = {3081341},
 address = {New York, NY, USA},
 author = {Ki, Taeyeon and Simeonov, Alexander and Jain, Bhavika Pravin and Park, Chang Min and Sharma, Keshav and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081341},
 isbn = {978-1-4503-4928-4},
 keyword = {API virtualization, android app instrumentation, android platform instrumentation, platform openness},
 link = {http://doi.acm.org/10.1145/3081333.3081341},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {399--412},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Reptor: Enabling API Virtualization on Android for Platform Openness},
 year = {2017}
}


@inproceedings{Brunette:2017:ODK:3081333.3081365,
 abstract = {In resource-constrained communities, organizations often use information and communication technologies to amplify their limited resources to improve education, health, and economic opportunity. Over two-thirds of the world's population have mobile phones, yet less than half are connected to the Internet [23]. Organizations helping disadvantaged populations often rely on mobile devices as their primary computing resource because of their availability in resource-constrained contexts. However, to reach under-served populations, mobile applications often operate in areas with no connectivity or challenged network environments. Unfortunately, many mobile application frameworks are generally not well-suited for long periods of disconnected data collection and management. Furthermore, mobile application frameworks are generally aimed at users with significant technical skills and resources. In this paper, we discuss our experiences building, deploying, and refining the Open Data Kit (ODK) 2.0 tool suite. ODK 2.0 is a modular application framework that facilitates organizations with limited technical capacity to build application-specific information services for use in disconnected environments. We discuss ODK 2.0's flexible abstractions that enable users of varying technical skill levels to create customizable mobile data management solutions. We present ODK 2.0 case studies involving multiple organizations and discuss lessons learned from building a service-based mobile application framework for disconnected data management.},
 acmid = {3081365},
 address = {New York, NY, USA},
 author = {Brunette, Waylon and Sudar, Samuel and Sundt, Mitchell and Larson, Clarice and Beorse, Jeffrey and Anderson, Richard},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081365},
 isbn = {978-1-4503-4928-4},
 keyword = {ICTD, disconnected operation, mobile application framework, mobile data management, mobile databases, open data kit},
 link = {http://doi.acm.org/10.1145/3081333.3081365},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {440--452},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Open Data Kit 2.0: A Services-Based Application Framework for Disconnected Data Management},
 year = {2017}
}


@inproceedings{Maes:2017:AHE:3081333.3081474,
 abstract = {BIO: Pattie Maes is the Alexander W. Dreyfoos (1954) Professor in MIT's Program in Media Arts and Sciences and associate head of the Program in Media Arts and Sciences. She founded and directs the Media Lab's Fluid Interfaces research group. Previously, she founded and ran the Software Agents group. Prior to joining the Media Lab, Maes was a visiting professor and a research scientist at the MIT Artificial Intelligence Lab. She holds bachelor's and PhD degrees in computer science from the Vrije Universiteit Brussel in Belgium. Her areas of expertise are human-computer interaction and artificial intelligence. Maes is the editor of three books, and is an editorial board member and reviewer for numerous professional journals and conferences. She has received several awards: FastCompany named her one of 50 most influential designers (2011). Newsweek magazine named her one of the "100 Americans to watch for" in the year 2000; TIME Digital selected her as a member of the Cyber-Elite, the top 50 technological pioneers of the high-tech world; the World Economic Forum honored her with the title "Global Leader for Tomorrow"; Ars Electronica awarded her the 1995 World Wide Web category prize; and in 2000 she was recognized with the "Lifetime Achievement Award" by the Massachusetts Interactive Media Council. She also received an honorary doctorate from the Vrije Universiteit Brussel in Belgium. Her 2009 TED talk is among the most watched TED talks ever. In addition to her academic endeavors, Maes has been active as an entrepreneur as cofounder of several venture-backed companies including Firefly Networks (sold to Microsoft) and Open Ratings (sold to Dun & Bradstreet). She remains an advisor and investor to several MIT spinoffs.},
 acmid = {3081474},
 address = {New York, NY, USA},
 author = {Maes, Pattie},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081474},
 isbn = {978-1-4503-4928-4},
 keyword = {keynote talk},
 link = {http://doi.acm.org/10.1145/3081333.3081474},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {1--1},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Augmenting the Human Experience},
 year = {2017}
}


@inproceedings{Zhu:2017:EHV:3081333.3081335,
 abstract = {For over one decade, research in visible light positioning has focused on using modulated LEDs as location landmarks. But the need for specialized LED fixtures, and the associated retrofitting cost, has been hindering the adoption of VLP. In this paper, we forgo this approach and design iLAMP to enable reliable, high-precision VLP using conventional LEDs and fluorescent lamps inside today's buildings. Our key observation is that these lamps intrinsically possess hidden visual features, which are imperceptible to human eyes, but can be extracted by capturing and processing the lamps' images using a computational imaging framework. Simply using commodity smartphones' front cameras, our approach can identify lamps within a building with close to 100% accuracy. Furthermore, we develop a geometrical model which combines the camera image with gyroscope/accelerometer output, to estimate a smartphone's 3D location and heading direction relative to each lamp landmark. Our field tests demonstrate a mean localization (heading) precision of 3 cm (2.6 degree) and 90-percentile 3.5 cm (2.8 degree), even if a single lamp falls in the camera's field of view.},
 acmid = {3081335},
 address = {New York, NY, USA},
 author = {Zhu, Shilin and Zhang, Xinyu},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081335},
 isbn = {978-1-4503-4928-4},
 keyword = {indoor localization, mobile computing, ubiquitous computing, visible light system},
 link = {http://doi.acm.org/10.1145/3081333.3081335},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {96--108},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Enabling High-Precision Visible Light Localization in Today's Buildings},
 year = {2017}
}


@inproceedings{Zhang:2017:PSD:3081333.3089313,
 abstract = {Smartphone device inputs, such as inputs from touchscreen, sensors, and GPS, carry sensitive user information, but are vulnerable to passive and active attacks. We present our ongoing design and implementation of SDIF, a Secure Device Input Framework for smartphones. The core components of SDIF are a small and dedicated bare-metal hypervisor built using ARM hardware virtualization support and a user-space sandbox framework. They collectively ensures SDIF's support for unmodified OSes and apps. SDIF guarantees the secure device inputs from hardware to target applications with two key designs. The first is a design of a secure path for input data to be delivered from input device drivers to target applications. The second is a design of trusted device data reading, which ensures input data generated by hardware is faithfully put to device driver memory.},
 acmid = {3089313},
 address = {New York, NY, USA},
 author = {Zhang, Xin and Bai, Yongshu and Hao, Pengzhan and Zhang, Yifan},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089313},
 isbn = {978-1-4503-4928-4},
 keyword = {device inputs, hypervisor, mobile device, virtualization},
 link = {http://doi.acm.org/10.1145/3081333.3089313},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {169--169},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Securing Device Inputs for Smartphones Using Hypervisor Based Approach},
 year = {2017}
}


@inproceedings{Lee:2017:PMP:3081333.3089295,
 abstract = {Current designs of battery-powered uninterruptible power supplies only provide power for a short time, and offer few control options. We combined a compact synchronous generator with a battery with 10% of the capacity of a UPS of the same rating to produce an uninterruptible generator supply (UGS). The controller of this UGS runs FreeRTOS, which enables it to respond quickly to a power outage. A wifi module provides connectivity to a web server for real-time monitoring and management on a remote PC or cellphone.},
 acmid = {3089295},
 address = {New York, NY, USA},
 author = {Lee, Chulju and Kang, Kyungtae},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089295},
 isbn = {978-1-4503-4928-4},
 keyword = {UGS, freertos, mobile power management},
 link = {http://doi.acm.org/10.1145/3081333.3089295},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {151--151},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Mobile Power Management Using FreeRTOS-based Uninterruptable Generator Supply},
 year = {2017}
}


@inproceedings{Roy:2017:DRN:3081333.3089334,
 abstract = {We demonstrate that high frequency ultrasonic sounds can be designed to become recordable by unmodified smartphone microphones, while remaining inaudible to humans. The core idea lies in exploiting nonlinearities in microphone hardware with a combination of ultrasound frequencies. These frequencies can be regulated to carry data bits, thereby enabling an acoustic (but inaudible) communication channel to today's microphones. Other applications include jamming spy microphones in the environment, live watermarking of music in a concert, and even acoustic Denial-of-Service (DoS) attacks.},
 acmid = {3089334},
 address = {New York, NY, USA},
 author = {Roy, Nirupam and Hassanieh, Haitham and Roy Choudhury, Romit},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089334},
 isbn = {978-1-4503-4928-4},
 keyword = {acoustic, acoustic denial of service, inaudible sound, nonlinear acoustic, nonlinearity, privacy, security, smartphone},
 link = {http://doi.acm.org/10.1145/3081333.3089334},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {189--189},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Riding the Non-linearities to Record Ultrasound with Smartphones},
 year = {2017}
}


@inproceedings{Georgiev:2017:AMA:3081333.3081358,
 abstract = {GPUs have recently enjoyed increased popularity as general purpose software accelerators in multiple application domains including computer vision and natural language processing. However, there has been little exploration into the performance and energy trade-offs mobile GPUs can deliver for the increasingly popular workload of deep-inference audio sensing tasks, such as, spoken keyword spotting in energy-constrained smartphones and wearables. In this paper, we study these trade-offs and introduce an optimization engine that leverages a series of structural and memory access optimization techniques that allow audio algorithm performance to be automatically tuned as a function of GPU device specifications and model semantics. We find that parameter optimized audio routines obtain inferences an order of magnitude faster than sequential CPU implementations, and up to 6.5x times faster than cloud offloading with good connectivity, while critically consuming 3-4x less energy than the CPU. Under our optimized GPU, conventional wisdom about how to use the cloud and low power chips is broken. Unless the network has a throughput of at least 20Mbps (and a RTT of 25 ms or less), with only about 10 to 20 seconds of buffering audio data for batched execution, the optimized GPU audio sensing apps begin to consume less energy than cloud offloading. Under such conditions we find the optimized GPU can provide energy benefits comparable to low-power reference DSP implementations with some preliminary level of optimization; in addition to the GPU always winning with lower latency.},
 acmid = {3081358},
 address = {New York, NY, USA},
 author = {Georgiev, Petko and Lane, Nicholas D. and Mascolo, Cecilia and Chu, David},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081358},
 isbn = {978-1-4503-4928-4},
 keyword = {audio sensing, mobile GPU offloading},
 link = {http://doi.acm.org/10.1145/3081333.3081358},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {306--318},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Accelerating Mobile Audio Sensing Algorithms Through On-Chip GPU Offloading},
 year = {2017}
}


@inproceedings{Jeon:2017:PMP:3081333.3089299,
 abstract = {This poster presents Pixelsior, a new mobile platform service for photo data management in mobile apps.},
 acmid = {3089299},
 address = {New York, NY, USA},
 author = {Jeon, Kyungho and Chandrashekhara, Sharath and Dantu, Karthik and Ko, Steven Y.},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089299},
 isbn = {978-1-4503-4928-4},
 keyword = {android, image data, mobile, photo, pixelsior},
 link = {http://doi.acm.org/10.1145/3081333.3089299},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {155--155},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Mobile Photo Data Management As a Platform Service},
 year = {2017}
}


@inproceedings{Yun:2017:SFA:3081333.3081356,
 abstract = {Next generation devices, such as virtual reality (VR), augmented reality (AR), and smart appliances, demand a simple and intuitive way for users to interact with them. To address such needs, we develop a novel acoustic based device-free tracking system, called Strata, to enable a user to interact with a nearby device by simply moving his finger. In Strata, a mobile (e.g., smartphone) transmits known audio signals at inaudible frequency, and analyzes the received signal reflected by the moving finger to track the finger location. To explicitly take into account multipath propagation, the mobile estimates the channel impulse response (CIR), which characterizes signal traversal paths with different delays. Each channel tap corresponds to the multipath effects within a certain delay range. The mobile selects the channel tap corresponding to the finger movement and extracts the phase change of the selected tap to accurately estimate the distance change of a finger. Moreover, it estimates the absolute distance of the finger based on the change in CIR using a novel optimization framework. We then combine the absolute and relative distance estimates to accurately track the moving target. We implement our tracking system on Samsung Galaxy S4 mobile phone. Through micro-benchmarks and user studies, we show that our system achieves high tracking accuracy and low latency without extra hardware.},
 acmid = {3081356},
 address = {New York, NY, USA},
 author = {Yun, Sangki and Chen, Yi-Chao and Zheng, Huihuang and Qiu, Lili and Mao, Wenguang},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081356},
 isbn = {978-1-4503-4928-4},
 keyword = {acoustic tracking, channel impulse response, gesture recognition},
 link = {http://doi.acm.org/10.1145/3081333.3081356},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {15--28},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Strata: Fine-Grained Acoustic-based Device-Free Tracking},
 year = {2017}
}


@inproceedings{Xiong:2017:ISG:3081333.3081343,
 abstract = {Facial paralysis makes patients lose their facial movements, which can incur eye damage even blindness since patients are incapable of blinking. The paralysis usually occurs on just one side of the face, and clinical trials show that electrical stimulation could trigger blink. Based on such observations, we design and implement a pair of smart glasses iBlink to assist facial paralysis patients to blink. The basic idea is to monitor the normal side of the face with a camera and stimulate the paralysed side, so that the blink of the both eyes become symmetric. To the best of our knowledge, this is the first piece of wearable device for facial paralysis therapy. Our contributions are: First, we propose an eye-blink detection mechanism based on deep convolutional neural network (CNN), which can detect asymmetric blinks of patients under various illumination conditions with an accuracy above 99%. Our eye-image library for training CNN models is published online for further related studies, which contains more than $30,000$ eye images. Second, we design and implement an automatic stimulation circuits to generate electrical impulse for stimulating the patient's facial nerve branches, which can configure operational parameters in a self-adaptive manner for different patients. Third, we implement the entire iBlink system, which integrates the two functions above and a communication function module for tele-medicine applications. Moreover, we conduct clinical trials in a hospital, in order to obtain the design basis and verify effectiveness of our device.},
 acmid = {3081343},
 address = {New York, NY, USA},
 author = {Xiong, Sijie and Zhu, Sujie and Ji, Yisheng and Jiang, Binyao and Tian, Xiaohua and Zheng, Xuesheng and Wang, Xinbing},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081343},
 isbn = {978-1-4503-4928-4},
 keyword = {facial paralysis, smart glasses},
 link = {http://doi.acm.org/10.1145/3081333.3081343},
 location = {Niagara Falls, New York, USA},
 numpages = {12},
 pages = {359--370},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {iBlink: Smart Glasses for Facial Paralysis Patients},
 year = {2017}
}


@inproceedings{Oh:2017:MPM:3081333.3081348,
 abstract = {In recent years, the explosion of diverse smart devices such as mobile phones, TVs, watches, and even cars, has completely changed our lives. We communicate with friends through social network services (SNSs) whenever we want, buy stuff without visiting shops, and enjoy multimedia wherever we are, thanks to these devices. However, these smart devices cannot simply interact with each other even though they are right next to each other. For example, when you want to read a PDF stored on a smartphone on a larger TV screen, you need to do complicated work or plug in a bunch of cables. In this paper, we introduce M+, an extension of Android that supports cross-device functionality sharing in a transparent manner. As a platform-level solution, M+ enables unmodified Android applications to utilize not only application functionalities but also system functionalities across devices, as if they were to utilize them inside the same device. In addition to secure connection setup, M+ also allows performing of permission checks for remote applications in the same way as for local. Our experimental results show that M+ enables transparent cross-device sharing for various functionalities and achieves performance close to that of within-device sharing unless a large amount of data is transferred.},
 acmid = {3081348},
 address = {New York, NY, USA},
 author = {Oh, Sangeun and Yoo, Hyuck and Jeong, Dae R. and Bui, Duc Hoang and Shin, Insik},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081348},
 isbn = {978-1-4503-4928-4},
 keyword = {functionality sharing, inter-process communication, multi-device mobile platform, remote procedure call},
 link = {http://doi.acm.org/10.1145/3081333.3081348},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {332--344},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Mobile Plus: Multi-device Mobile Platform for Cross-device Functionality Sharing},
 year = {2017}
}


@inproceedings{Chandrashekhara:2017:DBA:3081333.3089327,
 abstract = {BlueMountain is a system that enables building pluggable data management solutions which can be linked with any Android app at runtime, without requiring any modifications to the Android platform. BlueMountain simplifies the app development, provides flexibility to end users, and works with existing apps.},
 acmid = {3089327},
 address = {New York, NY, USA},
 author = {Chandrashekhara, Sharath and Ki, Taeyeon and Jeon, Kyungho and Dantu, Karthik and Ko, Steven Y.},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089327},
 isbn = {978-1-4503-4928-4},
 keyword = {bytecode instrumentation, data management, mobile systems},
 link = {http://doi.acm.org/10.1145/3081333.3089327},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {182--182},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: BlueMountain: An Architecture to Customize Data Management on Mobile Systems},
 year = {2017}
}


@inproceedings{Hao:2017:PEE:3081333.3089307,
 abstract = {Being powered by battery and the reliance on expensive cellular data while users are on the move are holding smart mobile devices from being widely used in those long-lasted, computation-intensive, or highly network-reliant usage scenarios. In the meantime, more and more mobile workloads and optimizations now rely on the cloud, such as mobile cloud offloading, cloud-based mobile web optimization, and cloud-based network traffic redundancy reduction. However, it is hard to perform large-scale and personalized support or optimization for mobile workloads without significant computation resource increase on the cloud, as well as higher bandwidth requirement on the networks. We target solving the above two problems by enabling edge-hosed personalized services (EPS for short). The idea of EPS is twofold. One is enabling developer-customizable and power-and-traffic-efficient network communication on the "last-hop" communication between mobile devices and the network edge. The other is distributing cloud services for mobile workloads to network edge, so that they can be done on a personalized basis, while enjoying much lower communication latency to/from mobile devices.},
 acmid = {3089307},
 address = {New York, NY, USA},
 author = {Hao, Pengzhan and Bai, Yongshu and Zhang, Xin and Zhang, Yifan},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089307},
 isbn = {978-1-4503-4928-4},
 keyword = {edge computing, mobile devices, network bandwdith},
 link = {http://doi.acm.org/10.1145/3081333.3089307},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {163--163},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: EPS: Edge-hosted Personal Services for Mobile Users},
 year = {2017}
}


@inproceedings{He:2017:PCM:3081333.3089296,
 abstract = {Charging mobile devices fast alleviates users' impatience in waiting for their devices to be charged. So, fast charging has been the focus of both industry and academia, developing and deploying various technologies, such as Quick Charge by Qualcomm, TurboPower by Motorola, Flash Charge by OPPO, etc. Fast charging, unfortunately, accelerates the capacity fading of device battery because it follows the Constant Current, Constant Voltage (CCCV) charge principle without considering the behavior of how users charge their devices. CCCV charging principle is a two-phase charging process consisting of (i) Constant-Current Charge (CC-Chg) and (ii) Constant-Voltage Charge (CV-Chg) [2] where CV-Chg is usually triggered at the end of charging (e.g., 80-100%) to stabilize the battery condition. However, fast charging technologies are agnostic of users' available charging time, resulting in premature termination of the planned charging if users only have limited time. This, in turn, leads to an incomplete CV-Chg phase or even skipping it completely. From our empirical measurements, we discovered that CV-Chg relaxes the batteries and slows down their capacity fading by up to 80% [1] incomplete CV-Chg shortens the battery life significantly over time!},
 acmid = {3089296},
 address = {New York, NY, USA},
 author = {He, Liang and Tung, Yu-Chih and Shin, Kang G.},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089296},
 isbn = {978-1-4503-4928-4},
 keyword = {interactive charging},
 link = {http://doi.acm.org/10.1145/3081333.3089296},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {152--152},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Charge My Phone As I Instruct},
 year = {2017}
}


@inproceedings{Virmani:2017:POA:3081333.3081340,
 abstract = {WiFi based gesture recognition systems have recently proliferated due to the ubiquitous availability of WiFi in almost every modern building. The key limitation of existing WiFi based gesture recognition systems is that they require the user to be in the same configuration (i.e., at the same position and in same orientation) when performing gestures at runtime as when providing training samples, which significantly restricts their practical usability. In this paper, we propose a WiFi based gesture recognition system, namely WiAG, which recognizes the gestures of the user irrespective of his/her configuration. The key idea behind WiAG is that it first requests the user to provide training samples for all gestures in only one configuration and then automatically generates virtual samples for all gestures in all possible configurations by applying our novel translation function on the training samples. Next, for each configuration, it generates a classification model using virtual samples corresponding to that configuration. To recognize gestures of a user at runtime, as soon as the user performs a gesture, WiAG first automatically estimates the configuration of the user and then evaluates the gesture against the classification model corresponding to that estimated configuration. Our evaluation results show that when user's configuration is not the same at runtime as at the time of providing training samples, WiAG significantly improves the gesture recognition accuracy from just 51.4% to 91.4%.},
 acmid = {3081340},
 address = {New York, NY, USA},
 author = {Virmani, Aditya and Shahzad, Muhammad},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081340},
 isbn = {978-1-4503-4928-4},
 keyword = {WiFi, agnostic, gesture recognition, orientation, position},
 link = {http://doi.acm.org/10.1145/3081333.3081340},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {252--264},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Position and Orientation Agnostic Gesture Recognition Using WiFi},
 year = {2017}
}


@inproceedings{Jian:2017:PTB:3081333.3089318,
 abstract = {The position of a wireless access point (AP) in wireless networks has been found to have a considerable impact on the overall network performance in indoor scenarios. Recent work has investigated the impact of the AP's location on the received signal strength of clients [1], and has shown that a 1:7x throughput improvement can be achieved by simply moving the AP in a 2ft. x 2ft. region. The benefits of small scale AP mobility is chiefly caused by mitigating multipath effects. In fact, the multipath effect has a significant impact on network performance and can be dramatically altered even with mere centimeter level movement of a Tx or a Rx. In this work, we investigate how network throughput performance can be improved if the AP is able to adapt its orientation. We consider two types of orientation changes - that of the AP's base platform (base orientation), and that of its antennas (antenna orientation). We show using experimental analysis that network throughput performance can be improved 1:8x by simply adapting AP's orientation.},
 acmid = {3089318},
 address = {New York, NY, USA},
 author = {Jian, Yubing and Lall, Shruti and Sivakumar, Raghupathy},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089318},
 isbn = {978-1-4503-4928-4},
 keyword = {antenna orientation, base orientation, self-positioning AP},
 link = {http://doi.acm.org/10.1145/3081333.3089318},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {174--174},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Twirl:: On the Benefits of Adapting Orientation of a WiFi Access-Point},
 year = {2017}
}


@inproceedings{Rahmati:2017:HPI:3081333.3081334,
 abstract = {Many of the everyday decisions a user makes rely on the suggestions of online recommendation systems. These systems amass implicit (e.g.,location, purchase history, browsing history) and explicit (e.g.,reviews, ratings) feedback from multiple users, produce a general consensus, and provide suggestions based on that consensus. However, due to privacy concerns, users are uncomfortable with implicit data collection, thus requiring recommendation systems to be overly dependent on explicit feedback. Unfortunately, users do not frequently provide explicit feedback. This hampers the ability of recommendation systems to provide high-quality suggestions. We introduce Heimdall, the first privacy-respecting implicit preference collection framework that enables recommendation systems to extract user preferences from their activities in a privacy respecting manner. The key insight is to enable recommendation systems to run a collector on a user's device and precisely control the information a collector transmits to the recommendation system back-end. Heimdall introduces immutable blobs as a mechanism to guarantee this property. We implemented Heimdall on the Android platform and wrote three example collectors to enhance recommendation systems with implicit feedback. Our performance results suggest that the overhead of immutable blobs is minimal, and a user study of 166 participants indicates that privacy concerns are significantly less when collectors record only specific information--a property that Heimdall enables.},
 acmid = {3081334},
 address = {New York, NY, USA},
 author = {Rahmati, Amir and Fernandes, Earlence and Eykholt, Kevin and Chen, Xinheng and Prakash, Atul},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081334},
 isbn = {978-1-4503-4928-4},
 keyword = {implicit feedback, internet of things, privacy, recommendation systems},
 link = {http://doi.acm.org/10.1145/3081333.3081334},
 location = {Niagara Falls, New York, USA},
 numpages = {11},
 pages = {453--463},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Heimdall: A Privacy-Respecting Implicit Preference Collection Framework},
 year = {2017}
}


@inproceedings{Guner:2017:PAO:3081333.3089303,
 abstract = {The number of smartphone users globally has already exceeded 2 Billion, and this number is expected to reach 3 Billion by 2020 [2]. It is also estimated that smartphone mobile data traffic (cellular + WiFi) will reach 370 Exabytes per year by that time, exceeding PC Internet traffic the first time in the history [4]. An average smartphone consumes between 300 -- 1200 milliwatts power [1] depending on the type of applications it is running, and most of the energy in smartphone applications is spent for networked I/O. During an active data transfer, the cellular (i.e., GSM) and WiFi components of a smartphone consume more power than its CPU, RAM, and even LCD+graphics card at the highest brightness level [3,1]. Although the mobile data traffic and the amount of energy spent for it increase at a very fast pace, the battery capacities of smartphones do not increase at the same rate. In this work, we analyze the effects of different application layer data transfer protocol parameters (such as the number of parallel data streams per file, the level of concurrent file transfers, and the I/O request size) on mobile data transfer throughput and energy consumption. Figure 1 shows the achieved end-to-end throughput, total energy consumption, and the change in instantaneous power consumption during a wide-area data transfer with increased concurrency level. This figure presents the break point for the throughput versus energy consumption trade-off very well. As long as the energy gain due to the decreased transfer time is more than the loss due to the increased instantaneous power consumption, then we save energy at this device while increasing the throughput. But this is not always the case. We observe that although the throughput continues to increase up to a certain concurrency level, the total energy consumption does not continue to decrease, instead comes to a balance and starts increasing again. The main reason for this is the server and network components are typically not energy proportional. When used wisely, these parameters have a potential to improve the end-to-end data transfer performance and decrease total energy consumption at a great extent, but improper use of these parameters can also hurt the performance of the data transfers due to increased load at the end-systems and congested links in the network. For this reason, it is crucial to find the best combination for these parameters with the least intrusion and overhead to the system resource utilization and power consumption. Our contributions within this work are the following: (1) To the best of our knowledge, we are first to provide an in depth analysis of the effects of application layer data transfer protocol parameters on the energy consumption of mobile phones. (2) We show that significant energy savings can be achieved with application-layer solutions at the mobile systems during data transfer with no or minimal performance penalty. (3) We also show that, in many cases, performance increase and energy savings can be achieved simultaneously.},
 acmid = {3089303},
 address = {New York, NY, USA},
 author = {Guner, Kemal and Kosar, Tevfik},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089303},
 isbn = {978-1-4503-4928-4},
 keyword = {big-data, energy efficiency on smartphones, energy-aware mobile data transfers, mobile throughput optimization, protocol tuning},
 link = {http://doi.acm.org/10.1145/3081333.3089303},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {159--159},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Application-Layer Optimization of Performance vs Energy in Mobile Network I/O},
 year = {2017}
}


@inproceedings{Kudo:2017:PMS:3081333.3089292,
 abstract = {The paper describes a rapid and accurate time-synchronization technique for smartphones using their built-in cameras and its preliminary evaluations for application development.},
 acmid = {3089292},
 address = {New York, NY, USA},
 author = {Kudo, Koki and Sugimoto, Masanori and Akiyama, Takayuki and Hashizume, Hiromichi},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089292},
 isbn = {978-1-4503-4928-4},
 keyword = {LED illumination, camera synchronization, smartphone},
 link = {http://doi.acm.org/10.1145/3081333.3089292},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {148--148},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Multicamera Synchronization for Smartphones Using Optimally Modulated Illuminations},
 year = {2017}
}


@inproceedings{Wilson:2017:TBV:3081333.3081342,
 abstract = {Internet-of-Things devices often collect and transmit sensitive information like camera footage, health monitoring data, or whether someone is home. These devices protect data in transit with end-to-end encryption, typically using TLS connections between devices and associated cloud services. But these TLS connections also prevent device owners from observing what their own devices are saying about them. Unlike in traditional Internet applications, where the end user controls one end of a connection (e.g., their web browser) and can observe its communication, Internet-of-Things vendors typically control the software in both the device and the cloud. As a result, owners have no way to audit the behavior of their own devices, leaving them little choice but to hope that these devices are transmitting only what they should. This paper presents TLS--Rotate and Release (TLS-RaR), a system that allows device owners (e.g., consumers, security researchers, and consumer watchdogs) to authorize devices, called auditors, to decrypt and verify recent TLS traffic without compromising future traffic. Unlike prior work, TLS-RaR requires no changes to TLS's wire format or cipher suites, and it allows the device's owner to conduct a surprise inspection of recent traffic, without prior notice to the device that its communications will be audited.},
 acmid = {3081342},
 address = {New York, NY, USA},
 author = {Wilson, Judson and Wahby, Riad S. and Corrigan-Gibbs, Henry and Boneh, Dan and Levis, Philip and Winstein, Keith},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081342},
 isbn = {978-1-4503-4928-4},
 keyword = {IoT, TLS, TLS 1.3, TLS-RAR, TLS-rotate and release, auditing, decrypt, internet of things, middlebox, proxy, transport layer security},
 link = {http://doi.acm.org/10.1145/3081333.3081342},
 location = {Niagara Falls, New York, USA},
 numpages = {11},
 pages = {464--474},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Trust but Verify: Auditing the Secure Internet of Things},
 year = {2017}
}


@inproceedings{Park:2017:PTQ:3081333.3089300,
 abstract = {Although Wireless Access in Vehicular Environment (WAVE) will be legally enforced from 2020 after the recent move by the U.S. Government [1], there is still an unresolved security issue. It is data plausibility, which is not addressed in any standard that comprises the WAVE framework. In particular, an attacker may forge false position values in safety beacons in order to cause unsafe response from startled receiving vehicles. The data plausibility is a longstanding issue for which various approaches based on sensor fusion, behavior analysis and communication constraints have been proposed. However, none of these completely solve the problem.},
 acmid = {3089300},
 address = {New York, NY, USA},
 author = {Park, Yongtae and Kuk, Seungho},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089300},
 isbn = {978-1-4503-4928-4},
 keyword = {vehicular communication},
 link = {http://doi.acm.org/10.1145/3081333.3089300},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {156--156},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Towards Quick Angular Check to Rebuff Forged Position Attacks in Vehicular Communication},
 year = {2017}
}


@inproceedings{Liu:2017:PIP:3081333.3089298,
 abstract = {Receiving push notifications is one of the key features of smartwatches. In our recent measurement study involving 27 smartwatch users [1], we found that push notifications are used by more than 200 applications, dominated by instant messaging, emails, social media, etc. In this work, we propose a suite of methods to optimize the performance, energy efficiency, and usability of smartwatch push notifications, which have several salient features distinguishing them from regular notifications received on a smartphone: requiring heavy phonewatch cooperation, being delivered over short-range Bluetooth link, and incurring non-trivial energy consumption on watches with very limited battery capacity. Considering these factors, our proposed work focuses on four aspects as elaborated.},
 acmid = {3089298},
 address = {New York, NY, USA},
 author = {Liu, Xing and Yao, Yunsheng and Qian, Feng},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089298},
 isbn = {978-1-4503-4928-4},
 keyword = {push notification, smartwatch},
 link = {http://doi.acm.org/10.1145/3081333.3089298},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {154--154},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Improve Push Notification on Smartwatches},
 year = {2017}
}


@inproceedings{Huynh:2017:DMG:3081333.3081360,
 abstract = {The rapid emergence of head-mounted devices such as the Microsoft Holo-lens enables a wide variety of continuous vision applications. Such applications often adopt deep-learning algorithms such as CNN and RNN to extract rich contextual information from the first-person-view video streams. Despite the high accuracy, use of deep learning algorithms in mobile devices raises critical challenges, i.e., high processing latency and power consumption. In this paper, we propose DeepMon, a mobile deep learning inference system to run a variety of deep learning inferences purely on a mobile device in a fast and energy-efficient manner. For this, we designed a suite of optimization techniques to efficiently offload convolutional layers to mobile GPUs and accelerate the processing; note that the convolutional layers are the common performance bottleneck of many deep learning models. Our experimental results show that DeepMon can classify an image over the VGG-VeryDeep-16 deep learning model in 644ms on Samsung Galaxy S7, taking an important step towards continuous vision without imposing any privacy concerns nor networking cost.},
 acmid = {3081360},
 address = {New York, NY, USA},
 author = {Huynh, Loc N. and Lee, Youngki and Balan, Rajesh Krishna},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081360},
 isbn = {978-1-4503-4928-4},
 keyword = {continuous vision, deep learning, mobile gpu, mobile sensing},
 link = {http://doi.acm.org/10.1145/3081333.3081360},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {82--95},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {DeepMon: Mobile GPU-based Deep Learning Framework for Continuous Vision Applications},
 year = {2017}
}


@inproceedings{Naderiparizi:2017:GPE:3081333.3081347,
 abstract = {We consider the problem of continuous computer-vision based analysis of video streams from mobile cameras over extended periods. Given high computational demands, general visual processing must currently be offloaded to the cloud. To reduce mobile battery and bandwidth consumption, recent proposals offload only "interesting" video frames, discarding the rest. However, determining what to discard is itself typically a power-hungry computer vision calculation, very often well beyond what most mobile devices can afford on a continuous basis. We present the Glimpse system, a re-design of the conventional mobile video processing pipeline to support such "early discard" flexibly, efficiently and accurately. Glimpse is a novel architecture that gates wearable vision using low-power vision modalities. Our proposed architecture adds novel sensing, processing, algorithmic and programming-system components to the camera pipeline to this end. We present a complete implementation and evaluation of our design. In common settings, Glimpse reduces mobile power and data usage by more than one order of magnitude relative to earlier designs, and moves continuous vision on lightweight wearables to the realm of the practical.},
 acmid = {3081347},
 address = {New York, NY, USA},
 author = {Naderiparizi, Saman and Zhang, Pengyu and Philipose, Matthai and Priyantha, Bodhi and Liu, Jie and Ganesan, Deepak},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081347},
 isbn = {978-1-4503-4928-4},
 keyword = {continuous mobile vision, energy efficient wearable vision system, low-power early discard, low-power vision modalities},
 link = {http://doi.acm.org/10.1145/3081333.3081347},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {292--305},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Glimpse: A Programmable Early-Discard Camera Architecture for Continuous Mobile Vision},
 year = {2017}
}


@inproceedings{AmiriSani:2017:SSP:3081333.3081346,
 abstract = {Many mobile applications deliver and show sensitive and private textual content to users including messages, social network posts, account information, and verification codes. All such textual content must only be displayed to the user but must be strongly protected from unauthorized access in the device. Unfortunately, this is not the case in mobile devices today: malware that can compromise the operating system, e.g., gain root or kernel privileges, can easily access textual content of other applications. In this paper, we present SchrodinText, a system solution for strongly protecting the confidentiality of application's selected UI textual content from a fully compromised operating system. SchrodinText leverages a novel security monitor based on two hardware features on modern ARM processors: virtualization hardware and TrustZone. Our key contribution is a set of novel techniques that allow the operating system to perform the text rendering without needing access to the text itself, hence minimizing the Trusted Computing Base (TCB). These techniques, collectively called oblivious rendering, enable the operating system to rasterize and lay out all the characters without access to the text; the monitor only resolves the right character glyphs onto the framebuffer observed by the user and protects them from the operating system, e.g., against DMA attacks. We present our prototype using an ARM Juno development board and Android operating system. We show that SchrodinText incurs noticeable overhead but that its performance is usable.},
 acmid = {3081346},
 address = {New York, NY, USA},
 author = {Amiri Sani, Ardalan},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081346},
 isbn = {978-1-4503-4928-4},
 keyword = {UI safety, mobile devices, text protection, trustzone, virtualization},
 link = {http://doi.acm.org/10.1145/3081333.3081346},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {197--210},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {SchrodinText: Strong Protection of Sensitive Textual Content of Mobile Applications},
 year = {2017}
}


@inproceedings{Islam:2017:SMO:3081333.3081338,
 abstract = {In this paper, we study the overhearing problem of continuous acoustic sensing devices such as Amazon Echo, Google Home, or such voice-enabled home hubs, and develop a system called SoundSifter that mitigates personal or contextual information leakage due to the presence of unwanted sound sources in the acoustic environment. Instead of proposing modifications to existing home hubs, we build an independent embedded system that connects to a home hub via its audio input. Considering the aesthetics of home hubs, we envision SoundSifter as a smart sleeve or a cover for these devices. SoundSifter has hardware and software to capture the audio, isolate signals from distinct sound sources, filter out signals that are from unwanted sources, and process the signals to enforce policies such as personalization before the signals enter into an untrusted system like Amazon Echo or Google Home. We conduct empirical and real-world experiments to demonstrate that SoundSifter runs in real-time, is noise resilient, and supports selective and personalized voice commands that commercial voice-enabled home hubs do not.},
 acmid = {3081338},
 address = {New York, NY, USA},
 author = {Islam, Md Tamzeed and Islam, Bashima and Nirjon, Shahriar},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081338},
 isbn = {978-1-4503-4928-4},
 keyword = {acoustic sensing, audio privacy, sound source separation},
 link = {http://doi.acm.org/10.1145/3081333.3081338},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {29--41},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {SoundSifter: Mitigating Overhearing of Continuous Listening Devices},
 year = {2017}
}


@inproceedings{Nguyen:2017:DFM:3081333.3089328,
 abstract = {Using touchscreens has largely limited user inputs to small form-factor devices. To address this constraint, we explore a novel input mechanism, dubbed PaperKey, that enables users to interact with mobile devices by performing multi-finger typing gestures on a surface where the device is placed. Using acceleration signals on the device, PaperKey infers the user's type events and then leverages a vision based technique for detecting the exact typing locations on a paper keyboard layout. Compared to single audio, image, or vibration sensing, this work accurately localizes keystrokes with faster processing speed. Additionally, this mechanism keeps the mobility of devices by working without external sensors.},
 acmid = {3089328},
 address = {New York, NY, USA},
 author = {Nguyen, Anh and Nguyen, Duy and Nguyen, Nhan and Ashok, Ashwin and Nguyen, Binh and Pham, Bao and Vu, Tam},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089328},
 isbn = {978-1-4503-4928-4},
 keyword = {multi-finger typing, paper keyboard, touching vibration, vision-based localization},
 link = {http://doi.acm.org/10.1145/3081333.3089328},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {183--183},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Fusing Mobile Sensors for Paper Keyboard On-the-Go},
 year = {2017}
}


@inproceedings{Chauhan:2017:BBA:3081333.3081355,
 abstract = {We propose BreathPrint, a new behavioural biometric signature based on audio features derived from an individual's commonplace breathing gestures. Specifically, BreathPrint uses the audio signatures associated with the three individual gestures: sniff, normal, and deep breathing, which are sufficiently different across individuals. Using these three breathing gestures, we develop the processing pipeline that identifies users via the microphone sensor on smartphones and wearable devices. In BreathPrint, a user performs breathing gestures while holding the device very close to their nose. Using off-the-shelf hardware, we experimentally evaluate the BreathPrint prototype with 10 users, observed over seven days. We show that users can be authenticated reliably with an accuracy of over 94% for all the three breathing gestures in intra-sessions and deep breathing gesture provides the best overall balance between true positives (successful authentication) and false positives (resiliency to directed impersonation and replay attacks). Moreover, we show that this breathing sound based biometric is also robust to some typical changes in both physiological and environmental context, and that it can be applied on multiple smartphone platforms. Early results suggest that breathing based biometrics show promise as either to be used as a secondary authentication modality in a multimodal biometric authentication system or as a user disambiguation technique for some daily lifestyle scenarios.},
 acmid = {3081355},
 address = {New York, NY, USA},
 author = {Chauhan, Jagmohan and Hu, Yining and Seneviratne, Suranga and Misra, Archan and Seneviratne, Aruna and Lee, Youngki},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081355},
 isbn = {978-1-4503-4928-4},
 keyword = {authentication, breathing gestures, security, usability},
 link = {http://doi.acm.org/10.1145/3081333.3081355},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {278--291},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {BreathPrint: Breathing Acoustics-based User Authentication},
 year = {2017}
}


@inproceedings{Chan:2017:PLV:3081333.3081353,
 abstract = {Recent studies have demonstrated the potential of light-to-camera communications for realizing applications such as localization, augmented reality and vehicle-to-vehicle communications. However, the fundamental requirement of visible light communications, flicker-free illumination, becomes a key limitation hindering existing technologies from serving a camera at larger distances. To break this limitation, this paper presents POLI, a light-to-camera communication system that exploits a novel POlarized Light Intensity modulation scheme to provide reliable communications for a wide range of distances. The key idea of POLI is to hide the information with the polarization direction of the light, to which human eyes are insensitive. Taking advantage of this, POLI can change the intensity of the polarized light as slowly as possible, at a rate determined by the range the system would support, but does not generate flickers. By using an optical component to "transform polarization directions to colors", POLI allows a camera to leverage its received RGB values as the three spatial dimensions to recover the information carried in different data streams. POLI further incorporates a number of designs to tackle the non-linearity effect of a camera, which is especially critical for an intensity-based modulation scheme. We implemented a prototype using the USRP N200 combined with off-the-shelf optical components. The experimental results show that POLI delivers to its camera receiver a throughput proportional to the dynamic channel conditions. The achievable throughput can be up to 71 bytes per second at short distances, while the service range can be up to 40 meters.},
 acmid = {3081353},
 address = {New York, NY, USA},
 author = {Chan, Chun-Ling and Tsai, Hsin-Mu and Lin, Kate Ching-Ju},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081353},
 isbn = {978-1-4503-4928-4},
 keyword = {camera communications, mimo, intensity modulation, visible light communications},
 link = {http://doi.acm.org/10.1145/3081333.3081353},
 location = {Niagara Falls, New York, USA},
 numpages = {12},
 pages = {109--120},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {POLI: Long-Range Visible Light Communications Using Polarized Light Intensity Modulation},
 year = {2017}
}


@inproceedings{Hardin:2017:PMP:3081333.3089314,
 abstract = {An increasing number of wearable devices support the execution of multiple third-party applications, increasing the functionality and flexibility of these devices. These multi-application, multi-tenant devices provide users with more options, and application developers with a standard platform. Typical ultra-low-power wearable devices, however, lack the type of hardware memory protection mechanisms~-- such as Memory Management Units (MMU)~-- needed to safely separate applications. At best, they provide a Memory Protection Unit (MPU), which allows the user to configure read/write/execute permissions for a few distinct regions of memory. At worst, no hardware memory protection is provided. MPU capabilities vary across hardware platforms, with many shortcomings: (1)~the MPU may only support a few distinct memory regions (fewer than one per application), (2)~the MPU may not protect all regions of memory, like hardware registers, and (3)~MPU protection boundary rules can be arcane, because they depend on opaque hardware implementations. Our key observation is that by supplementing a limited segment MPU with runtime checks, and using compile-time static analysis to explicitly layout applications in memory, we can guarantee application isolation (sandboxing) even on these limited MPUs, with lower overhead than software-only solutions.},
 acmid = {3089314},
 address = {New York, NY, USA},
 author = {Hardin, Taylor and Hester, Josiah and Proctor, Patrick and Sorber, Jacob and Kotz, David},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089314},
 isbn = {978-1-4503-4928-4},
 keyword = {memory protection, wearables},
 link = {http://doi.acm.org/10.1145/3081333.3089314},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {170--170},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Memory Protection in Ultra-Low-Power Multi-Application Wearables},
 year = {2017}
}


@inproceedings{Tran:2017:POM:3081333.3089319,
 abstract = {Passive indoor positioning systems (PIPS) enable non-invasive tracking of mobile devices (e.g., smartphones, Wi-Fi tags) using enterprise network infrastructure. This empowers operators of large airports and retail facilities to optimize cost-intensive resource allocation as well as to provide location-based services to their customers such as geo-fencing and proximity marketing. However, existing PIPS often generate noisy location estimates due to unpredictable interference and attenuation of wireless signals in indoor environments. To address this problem, we propose a novel map matching approach that uses a floor map to constrain location estimates to possible paths a mobile user can take.},
 acmid = {3089319},
 address = {New York, NY, USA},
 author = {Tran, Huy and Pandey, Santosh and Bulusu, Nirupama},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089319},
 isbn = {978-1-4503-4928-4},
 keyword = {hidden Markov model, map matching, passive indoor positioning system},
 link = {http://doi.acm.org/10.1145/3081333.3089319},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {175--175},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Online Map Matching for Passive Indoor Positioning Systems},
 year = {2017}
}


@proceedings{Balan:2016:2938559,
 abstract = {It is our great pleasure to bring you the proceedings for the 14th ACM Conference on Mobile Systems, Applications, and Services (ACM MobiSys 2016). We hope you enjoy this technical material behind the conference that attracts a diverse set of attendees from both academia and industry and is a leading venue for publications and idea exchange on mobile systems. ACM MobiSys 2016 has a highly selective, single-track program featuring research related to mobile systems and applications. It is an ideal venue to address research challenges facing the design, development, deployment, use, and fundamental limits of these systems. Our paper review process this year was highly selective. Out of 197 submissions, the technical program committee accepted only 31 for publication and presentation as full papers, yielding an acceptance rate around 15.73%. Submitted papers underwent a rigorous, multistage review process. First, we checked all submissions for compliance, general quality, and topic match. We administratively rejected those not meeting our submission criteria. We assigned 3 reviewers to papers that survived this stage from the program committee and the external review committee. At the conclusion of this stage, those papers where none of the reviewers recommended acceptance were rejected. We then assigned at least 2 additional reviewers from the program committee to papers that survived, thus totaling at least 5 reviews per paper. An online discussion phase then ensued, resulting in the PC recommending 59 papers for discussion at the PC meeting. The PC meeting was held in person in St. Augustine, FL, USA, the day before ACM HotMobile 2016. At the conclusion of the PC meeting, we tentatively accepted 31 papers to the conference. All tentatively accepted papers were assigned shepherds to help ensure that the authors produce a final manuscript that satisfactorily addresses reviewer comments. All shepherded papers were ultimately accepted to the conference. Our program this year covers an exciting set of topics including operating systems, transport, networking, sensing, security and privacy. It also includes a poster/demo session, a panel, and keynote speakers.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4416-6},
 location = {Singapore, Singapore},
 publisher = {ACM},
 title = {MobiSys '16 Companion: Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion},
 year = {2016}
}


@inproceedings{Hong:2017:PSA:3081333.3089293,
 abstract = {Currently, the smartphone has become an essential communication and amusement tool, which has strong computing power and a variety of functions. Especially, the market share of smartphone with android system account for 84% in 2016[1]. Under android system, a large of privacy data (e.g. photos or videos) are stored in external storage (emulated Sdcard storage), which can be accessed by installed apps. This not only results in privacy leakage but also incurs ransomware attack[2] (e.g. simplocker). Therefore, we present Sdguard, an app, can implement fine-grain permission control based on Linux DAC mechanism and detect ransomware which encrypts content of file stored in external storage or lock user screen. To install Sdguard app, we need to ensure that the smartphone has been rooted and use FUSE filesystem on external storage. During installing, sdcard daemon of android (i.e. FUSE daemon) is replaced by our customized sdcard daemon. After rebooting system, the customized daemon is loaded, and each component of Sdguard is running.},
 acmid = {3089293},
 address = {New York, NY, USA},
 author = {Hong, Shuangxi and Liu, Chuanchang and Ren, Bingfei and Chen, Junliang},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089293},
 isbn = {978-1-4503-4928-4},
 keyword = {android system, fuse filesystem, permission control, ransomware},
 link = {http://doi.acm.org/10.1145/3081333.3089293},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {149--149},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Sdguard: An Android Application Implementing Privacy Protection and Ransomware Detection},
 year = {2017}
}


@inproceedings{Huynh:2017:DDB:3081333.3089331,
 abstract = {
An abstract is not available.
},
 acmid = {3089331},
 address = {New York, NY, USA},
 author = {Huynh, Loc N. and Balan, Rajesh Krishna and Lee, Youngki},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089331},
 isbn = {978-1-4503-4928-4},
 keyword = {continuous vision, deep learning, mobile GPU, mobile sensing},
 link = {http://doi.acm.org/10.1145/3081333.3089331},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {186--186},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: DeepMon: Building Mobile GPU Deep Learning Models for Continuous Vision Applications},
 year = {2017}
}


@inproceedings{Roy:2017:BMM:3081333.3081366,
 abstract = {Consider sounds, say at 40kHz, that are completely outside the human's audible range (20kHz), as well as a microphone's recordable range (24kHz). We show that these high frequency sounds can be designed to become recordable by unmodified microphones, while remaining inaudible to humans. The core idea lies in exploiting non-linearities in microphone hardware. Briefly, we design the sound and play it on a speaker such that, after passing through the microphone's non-linear diaphragm and power-amplifier, the signal creates a "shadow" in the audible frequency range. The shadow can be regulated to carry data bits, thereby enabling an acoustic (but inaudible) communication channel to today's microphones. Other applications include jamming spy microphones in the environment, live watermarking of music in a concert, and even acoustic denial-of-service (DoS) attacks. This paper presents BackDoor, a system that develops the technical building blocks for harnessing this opportunity. Reported results achieve upwards of 4kbps for proximate data communication, as well as room-level privacy protection against electronic eavesdropping.},
 acmid = {3081366},
 address = {New York, NY, USA},
 author = {Roy, Nirupam and Hassanieh, Haitham and Roy Choudhury, Romit},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081366},
 isbn = {978-1-4503-4928-4},
 keyword = {acoustic jamming, acoustics, communication, inaudible sound, nonlinear acoustics, privacy, security, smartphone, speech privacy, ultrasound, voice authentication},
 link = {http://doi.acm.org/10.1145/3081333.3081366},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {2--14},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {BackDoor: Making Microphones Hear Inaudible Sounds},
 year = {2017}
}


@inproceedings{Guan:2017:TSE:3081333.3081349,
 abstract = {The rapid evolution of Internet-of-Things (IoT) technologies has led to an emerging need to make them smarter. A variety of applications now run simultaneously on an ARM-based processor. For example, devices on the edge of the Internet are provided with higher horsepower to be entrusted with storing, processing and analyzing data collected from IoT devices. This significantly improves efficiency and reduces the amount of data that needs to be transported to the cloud for data processing, analysis and storage. However, commodity OSes are prone to compromise. Once they are exploited, attackers can access the data on these devices. Since the data stored and processed on the devices can be sensitive, left untackled, this is particularly disconcerting. In this paper, we propose a new system, TrustShadow that shields legacy applications from untrusted OSes. TrustShadow takes advantage of ARM TrustZone technology and partitions resources into the secure and normal worlds. In the secure world, TrustShadow constructs a trusted execution environment for security-critical applications. This trusted environment is maintained by a lightweight runtime system that coordinates the communication between applications and the ordinary OS running in the normal world. The runtime system does not provide system services itself. Rather, it forwards requests for system services to the ordinary OS, and verifies the correctness of the responses. To demonstrate the efficiency of this design, we prototyped TrustShadow on a real chip board with ARM TrustZone support, and evaluated its performance using both microbenchmarks and real-world applications. We showed TrustShadow introduces only negligible overhead to real-world applications.},
 acmid = {3081349},
 address = {New York, NY, USA},
 author = {Guan, Le and Liu, Peng and Xing, Xinyu and Ge, Xinyang and Zhang, Shengzhi and Yu, Meng and Jaeger, Trent},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081349},
 isbn = {978-1-4503-4928-4},
 keyword = {IoT, arm trustzone, malicious operating systems, trusted execution},
 link = {http://doi.acm.org/10.1145/3081333.3081349},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {488--501},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {TrustShadow: Secure Execution of Unmodified Applications with ARM TrustZone},
 year = {2017}
}


@inproceedings{Shen:2017:PAM:3081333.3089315,
 abstract = {This paper proposes a new technique for detecting mobile malware based on information flow analysis. Our approach focuses on the structure of information flows we gather in our analysis, and the patterns of behavior present in information flows. Our analysis not only gathers simple flows that have a single source and a single sink, but also Multi-Flows that either start from a single source and flow to multiple sinks, or start from multiple sources and flow to a single sink. This analysis captures more complex behavior that both recent malware and recent benign applications exhibit. We leverage N-gram analysis to understand both unique and common behavioral patterns present in Multi-Flows. Our tool leverages N-gram analysis over sequences of API calls that occur along control flow paths in Multi-Flows to precisely analyze Multi-Flows with respect to app behavior.},
 acmid = {3089315},
 address = {New York, NY, USA},
 author = {Shen, Feng and Del Vecchio, Justin and Mohaisen, Aziz and Ko, Steven Y. and Ziarek, Lukasz},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089315},
 isbn = {978-1-4503-4928-4},
 keyword = {information flow analysis, malware detection, multi-flow, security},
 link = {http://doi.acm.org/10.1145/3081333.3089315},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {171--171},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Android Malware Detection Using Multi-Flows and API Patterns},
 year = {2017}
}


@inproceedings{Wei:2017:DCI:3081333.3089339,
 abstract = {Indoor positioning enables location-based services for a wide range of commercial applications [4]. Existing visible light positioning (VLP) systems [5, 7] leverage the high image resolution of a receiving camera to support high positioning accuracy. However, power-hungry cameras are not desirable in many scenarios, e.g., smart factories, where small objects need to be accurately located and tracked. In this demo, we introduce CELLI, an indoor VLP system that only uses a single luminary as the transmitter and requires only a simple light sensor to achieve high accuracy with centimeter-level error. The key idea is to provide the spatial resolution capability from the transmitter instead of the receiver, so that the complexity of the receiver can be minimized. In particular, a small Liquid Crystal Display (LCD) is installed at the transmitter to project a large number of narrow and interference-free polarized light beams to different spatial cells. A receiving light sensor identifies its located cell by detecting the unique polarization-modulated signals projected to that cell, as shown in Fig. 1. CELLI further incorporates several novel designs to overcome the technical challenges such as reducing the positioning latency, which is typically limited by the long optical response time of an LCD, and transforming a cell coordinate to the global 3D position using only a single light. We have prototyped our design using off-the-shelf optical and electronic components, and experimentally shown that CELLI achieves a median 3D positioning error less than 12 cm and a median 2D error less than 2.7 cm.},
 acmid = {3089339},
 address = {New York, NY, USA},
 author = {Wei, Yu-Lin and Huang, Chang-Jung and Tsai, Hsin-Mu and Lin, Kate Ching-Ju},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089339},
 isbn = {978-1-4503-4928-4},
 keyword = {visible light positioning},
 link = {http://doi.acm.org/10.1145/3081333.3089339},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {194--194},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: CELLI: Indoor Positioning Using Polarized Sweeping Light Beams},
 year = {2017}
}


@inproceedings{Zhou:2017:BAS:3081333.3081363,
 abstract = {The lack of digital floor plans is a huge obstacle to pervasive indoor location based services (LBS). Recent floor plan construction work crowdsources mobile sensing data from smartphone users for scalability. However, they incur long time (e.g., weeks or months) and tremendous efforts in data collection, and many rely on images thus suffering technical and privacy limitations. In this paper, we propose BatMapper, which explores a previously untapped sensing modality -- acoustics -- for fast, fine grained and low cost floor plan construction. We design sound signals suitable for heterogeneous microphones on commodity smartphones, and acoustic signal processing techniques to produce accurate distance measurements to nearby objects. We further develop robust probabilistic echo-object association, recursive outlier removal and probabilistic resampling algorithms to identify the correspondence between distances and objects, thus the geometry of corridors and rooms. We compensate minute hand sway movements to identify small surface recessions, thus detecting doors automatically. Experiments in real buildings show BatMapper achieves 1-2cm distance accuracy in ranges up around 4m; a 2-3 minute walk generates fine grained corridor shapes, detects doors at 92% precision and 1~2m location error at 90-percentile; and tens of seconds of measurement gestures produce room geometry with errors <0.3m at 80-percentile, at 1-2 orders of magnitude less data amounts and user efforts.},
 acmid = {3081363},
 address = {New York, NY, USA},
 author = {Zhou, Bing and Elbadry, Mohammed and Gao, Ruipeng and Ye, Fan},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081363},
 isbn = {978-1-4503-4928-4},
 keyword = {acoustic sensing, indoor floor plans},
 link = {http://doi.acm.org/10.1145/3081333.3081363},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {42--55},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {BatMapper: Acoustic Sensing Based Indoor Floor Plan Construction Using Smartphones},
 year = {2017}
}


@inproceedings{Xiong:2017:DIS:3081333.3089337,
 abstract = {Facial paralysis is a disease caused by nerve damage, which can make patients lose facial movements. Facial paralysis patients usually have muscles on one side of the face noticeably droop, which seriously impacts the person's quality of life as shown in Fig. [skull]. Worse still, the eye on the affected side is unable to blink and will become dry and infected by debries, which can incur eye damage even blindness. To the best of scientists' knowledge, the paralysis is due to the pressure incurred by infection in the tunnel containing main trunk of facial nerves, where the tunnel is inside of the people's head termed as the Facial canal. In this demo, we present iBlink [1], a novel system to help paralysis patients to blink. Paralysis usually occurs in just one side of the face, and clinical trials show that electrical stimulation could trigger blink. Based on such observations, the basic idea of iBlink is to monitor the normal side of the face with a camera and stimulate the paralysed side, so that eye-movements of the both sides become symmetric.},
 acmid = {3089337},
 address = {New York, NY, USA},
 author = {Xiong, Sijie and Zhu, Sujie and Ji, Yisheng and Jiang, Binyao and Tian, Xiaohua and Zheng, Xuesheng and Wang, Xinbing},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089337},
 isbn = {978-1-4503-4928-4},
 keyword = {facial paralysis, smart glasses},
 link = {http://doi.acm.org/10.1145/3081333.3089337},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {192--192},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: IBlink: Smart Glasses for Facial Paralysis Patients},
 year = {2017}
}


@inproceedings{Ravindranath:2017:DLV:3081333.3089340,
 abstract = {Live streaming is an increasingly popular way to broadcast videos ranging from formal news channels to kitten cams to home security camera feeds. Live streaming marries the rich detail of video with the timeliness of live transmission and the ease of use of consumer cameras, thus promising to vastly increase the amount of detailed, up-to-the minute information available about the real world. The volume of potentially interesting footage brings up the question of how end-users can avoid being glued to one (or worse, many) streams of videos waiting for events of interest. In this demo, we present Lookout, a system that allows users to register standing queries, called triggers over live video streams. Lookout then notifies the user when events of interest to them occur in their streams of interest. For example, a user could point to a cat cam and write a trigger that sends a notification when the cat wakes up and starts moving. Users can also write triggers to look for certain news being covered in a live new channel, a gamer moving to a certain level in a Twitch stream, a stranger showing up in a outdoor surveillance camera, etc.},
 acmid = {3089340},
 address = {New York, NY, USA},
 author = {Ravindranath, Lenin and Philipose, Matthai and Bodik, Peter and Bahl, Paramvir},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089340},
 isbn = {978-1-4503-4928-4},
 keyword = {video indexing, video queries, video triggers},
 link = {http://doi.acm.org/10.1145/3081333.3089340},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {195--195},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Live Video Stream Triggers},
 year = {2017}
}


@inproceedings{Bang:2017:DSN:3081333.3089329,
 abstract = {We present an entirely novel concept of retrieving social media data, called sigSocial. It integrates social media data of various sources, using a semantic classifier. Nowadays, people use multiple social media simultaneously, acquiring information with ease. However, accessing numerous services to reach different channels is bothersome. Also, the volume of information one can process is limited. Our aim is to reduce this burden, providing easiness and efficiency. In other words, we attempt to build a single service that integrates information from various platforms. The application has three main features. First, it enables users to explore multiple social media without accessing them separately. Second, it organizes information retrieved from social medias into well-defined classes. Finally, it works as a stand-alone application, the mechanism of which is internal to the device, not relying on any external servers or networks. This method respects user privacy, which has recently gained much attention.},
 acmid = {3089329},
 address = {New York, NY, USA},
 author = {Bang, Hyunwoong and Kim, Hyunsub and Lee, SangKeun},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089329},
 isbn = {978-1-4503-4928-4},
 keyword = {semantic classification, social media, tiny text intelligence},
 link = {http://doi.acm.org/10.1145/3081333.3089329},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {184--184},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: SigSocial: A Novel Social Media Aggregation Service Using a Tiny Text Intelligence},
 year = {2017}
}


@inproceedings{Wei:2017:CIP:3081333.3081352,
 abstract = {Existing visible light positioning (VLP) systems leverage the high image resolution of a receiving camera to support high positioning accuracy. However, power-hungry cameras might not always be applicable for many scenarios, such as smart factories, in which small objects require to be accurately localized and tracked. In this paper, we introduce CELLI, an indoor VLP system that only uses a single luminary as the transmitter and requires only a simple light sensor to achieve an extremely high accuracy with centimeter-level error. The key idea is to provide the spatial resolution capability from the transmitter instead of the receiver, so that the complexity of the receiver can be minimized. In particular, a small LCD is installed at the transmitter to project a large number of narrow and interference-free polarized light beams to different spatial cells. A receiving light sensor identifies its located cell by detecting the unique polarization-modulated signals projected to that cell. CELLI further incorporates a number of novel designs to overcome the technical challenges such as reducing the positioning latency, which is typically limited by the long optical response time of an LCD, and transforming a cell coordinate to the global 3D position using only a single light. We have prototyped our design using off-the-shelf optical and electrical components, and experimentally shown that CELLI achieves a median 3D positioning error less than 11.8 cm and a median 2D positioning error to less than 2.7 cm.},
 acmid = {3081352},
 address = {New York, NY, USA},
 author = {Wei, Yu-Lin and Huang, Chang-Jung and Tsai, Hsin-Mu and Lin, Kate Ching-Ju},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081352},
 isbn = {978-1-4503-4928-4},
 keyword = {indoor positioning, polarized, visible light positioning},
 link = {http://doi.acm.org/10.1145/3081333.3081352},
 location = {Niagara Falls, New York, USA},
 numpages = {12},
 pages = {136--147},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {CELLI: Indoor Positioning Using Polarized Sweeping Light Beams},
 year = {2017}
}


@inproceedings{Hansel:2017:DAF:3081333.3089333,
 abstract = {We present a framework - AWSense - for eased sensing data collection from an Apple Watch wearable device. The framework eases the access, transmission and export of sensing data from the device. This data comprises: heart rate, raw acceleration, and computed device motion. In our demo, we present sample applications built on top of this framework to show its capabilities, of real-time presentation and recording of the sensing data.},
 acmid = {3089333},
 address = {New York, NY, USA},
 author = {H\"{a}nsel, Katrin and Haddadi, Hamed and Alomainy, Akram},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089333},
 isbn = {978-1-4503-4928-4},
 keyword = {sensing libraries, wearable computing},
 link = {http://doi.acm.org/10.1145/3081333.3089333},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {188--188},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: AWSense: A Framework for Collecting Sensing Data from the Apple Watch},
 year = {2017}
}


@inproceedings{Xiong:2017:PCI:3081333.3089316,
 abstract = {Camera snapshot images are widely used in IoT applications. However, when the applications are deployed in rural areas or poorly-performing networks, the images offloading usually exhausts the limited network resources. While we can certainly revamp the network links, we can also optimize the payload at the same time. In this paper, we propose a middlebox system design that exploits the patterns of similarity between consecutive camera snapshots to alleviate the network load. Our preliminary results show that despite of small errors introduced in the images, the amount of reduced payloads could be a valuable choice to alleviate poorly performing networks.},
 acmid = {3089316},
 address = {New York, NY, USA},
 author = {Xiong, Wei and Zheleva, Mariya},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089316},
 isbn = {978-1-4503-4928-4},
 keyword = {camera, wireless networks},
 link = {http://doi.acm.org/10.1145/3081333.3089316},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {172--172},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Camera Images Offloading in Low-resource Wireless Networks},
 year = {2017}
}


@inproceedings{Feng:2017:PMT:3081333.3089294,
 abstract = {Customizable mobile services are usually expressed with complex services composed of different atomic services. Fine-grained atomic mobile services are not so convenient for end users to reuse. Considering that in identical or similar service domains, a great deal of the business logics and functions are reusable within the scope. So we present a template-based framework to allow reuse of services and to achieve rapid mobile application development. The reusable fine-grained service logics and functions are encapsulated into comparatively coarse-grained templates, from which the designers can create the personalized composite services and edit the templates efficiently.},
 acmid = {3089294},
 address = {New York, NY, USA},
 author = {Feng, Yimeng and Cheng, Bo and Zhao, Shuai and Zhai, Zhongyi and Wang, Zhaoning and Niu, Meng and Chen, Junliang},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089294},
 isbn = {978-1-4503-4928-4},
 keyword = {cross-platform mobile application development, mobile application development environment, rapid mobile application development, template based service creation},
 link = {http://doi.acm.org/10.1145/3081333.3089294},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {150--150},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: MobiTemplate: A Template-based Rapid Cross-Platform Mobile Application Development Environment},
 year = {2017}
}


@inproceedings{Liu:2017:CSU:3081333.3081351,
 abstract = {Smartwatch has become one of the most popular wearable computers on the market. We conduct an IRB-approved measurement study involving 27 Android smartwatch users. Using a 106-day dataset collected from our participants, we perform in-depth characterization of three key aspects of smartwatch usage "in the wild": usage patterns, energy consumption, and network traffic. Based on our findings, we identify key aspects of the smartwatch ecosystem that can be further improved, propose recommendations, and point out future research directions.},
 acmid = {3081351},
 address = {New York, NY, USA},
 author = {Liu, Xing and Chen, Tianyu and Qian, Feng and Guo, Zhixiu and Lin, Felix Xiaozhu and Wang, Xiaofeng and Chen, Kai},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081351},
 isbn = {978-1-4503-4928-4},
 keyword = {power model, smartwatch, wearable devices},
 link = {http://doi.acm.org/10.1145/3081333.3081351},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {385--398},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Characterizing Smartwatch Usage in the Wild},
 year = {2017}
}


@inproceedings{Kim:2017:PVC:3081333.3089301,
 abstract = {As autonomous vehicles loom as reality, and the vehicle communication starts to be enforced by law from 2020, protecting vulnerable road users (VRUs) using vehicle communication is receiving attention. The current vehicle-to-pedestrian (V2P) communication as stipulated by the standards such as SAE J2735 implies that it is the vehicles that take the responsibility for VRU protection. User devices are essentially beacons that transmit Personal Safety Messages (PSMs), and upon receiving PSMs, the drivers (or autonomous vehicles) take necessary measures to protect them. We, however, believe that the road users also need information about nearby vehicles to protect themselves from dangerous situations. Using other technologies than the standard Dedicated Short Range Communication (DSRC), there have been existing works for VRU protection. They use Wi-Fi or Wi-Fi Direct as replacements of DSRC. An automaker tested DSRC for VRU protection, but no technical detail has been presented. An important issue with the existing VRU protection proposals is that they are fraught with false alarms, which lowers the utility of the whole idea. Although one can come up with a highly precise collision prediction model, any such model will generate a huge number of false alarms, especially in urban environments. For example, if a pedestrian walks along a sidewalk well protected from the driveway, all passing vehicles will generate an alert to the pedestrian and vice versa. So our approach instead provides intuitive visual cues to the smartphone user looking at the screen, so that they can use their discretion to determine the level of danger for themselves.},
 acmid = {3089301},
 address = {New York, NY, USA},
 author = {Kim, Taeho and Han, Wongoo and Park, Yongtae},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089301},
 isbn = {978-1-4503-4928-4},
 keyword = {smartphone, vehicle-to-everything (V2X) communication, visual cue, vulnerable road user},
 link = {http://doi.acm.org/10.1145/3081333.3089301},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {157--157},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Visual Cue-Based VRU Protection on Smartphones},
 year = {2017}
}


@inproceedings{Park:2017:DED:3081333.3089336,
 abstract = {We demonstrate Gesto, a dynamic gesture mapping tool. It provides users to map any gesture to a certain UI event that the users need. Also, the mapping can be easily changed by users.},
 acmid = {3089336},
 address = {New York, NY, USA},
 author = {Park, Chang Min and Ki, Taeyeon and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089336},
 isbn = {978-1-4503-4928-4},
 keyword = {API, UI events, dynamic gesture mapping},
 link = {http://doi.acm.org/10.1145/3081333.3089336},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {191--191},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Enabling Dynamic Gesture Mapping with UI Events},
 year = {2017}
}


@inproceedings{Afroze:2017:PHI:3081333.3089308,
 abstract = {Hypertension is the single most significant risk factor for heart disease, stroke and kidney disease. The key causes of hypertension can be directly linked to the lifestyle of the patient, including age, family history, smoking, obesity etc. Our work consists of an interactive mobile application that acquires these lifestyle information and use several recommendation techniques to warn and guide the user towards well-being. So far, this is one of the earliest approaches in this domain for a developing country like Bangladesh.},
 acmid = {3089308},
 address = {New York, NY, USA},
 author = {Afroze, Syeda Farzia and Shezan, Faysal Hossain and Sharmin, Sadia},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089308},
 isbn = {978-1-4503-4928-4},
 keyword = {human computer interaction, hypertension, m-Health, recommendation system},
 link = {http://doi.acm.org/10.1145/3081333.3089308},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {164--164},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: HeartFit: An Intuitive Smartphone Application for Well-being of Hypertensive Patients},
 year = {2017}
}


@inproceedings{Yoo:2017:CSE:3081333.3081357,
 abstract = {Imagine a densely packed crowd that gathers to convey a common message, such as people in a candlelight vigil or a protest. We envision an innovation through mobile computing technologies to empower such a crowd by enabling them simply to hold their phones up and create a massive collective visualization on top of them. We propose Card-stunt as a Service (CaaS). CaaS is a service enabling a densely packed crowd to instantly visualize symbols using their mobile devices and a server-side service. The key challenge toward realizing an instant collective visualization is how to achieve instant, infrastructure-free, decimeter-level localization of individuals in a massively packed crowd, while maintaining low latency. CaaS addresses the challenges by mobile visible-light angle-of-arrival (AoA) sensing and scalable constrained optimization. It reconstructs relative locations of all individuals and dispatches individualized timed pixels to each one so that they can do their part in the overall visualization. We evaluate CaaS with extensive experiments under diverse reality settings as well as under synthetic workloads scaling up to tens of thousands of people. We deploy CaaS to 49 participants so that they successfully perform a collective visualization cheering up MobiSys.},
 acmid = {3081357},
 address = {New York, NY, USA},
 author = {Yoo, Chungkuk and Hwang, Inseok and Kang, Seungwoo and Kim, Myung-Chul and Kim, Seonghoon and Won, Daeyoung and Gu, Yu and Song, Junehwa},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081357},
 isbn = {978-1-4503-4928-4},
 keyword = {card stunt, collective visualization, mobile-crowd service, optimization, relative localization, visual light communication},
 link = {http://doi.acm.org/10.1145/3081333.3081357},
 location = {Niagara Falls, New York, USA},
 numpages = {15},
 pages = {121--135},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Card-stunt As a Service: Empowering a Massively Packed Crowd for Instant Collective Expressiveness},
 year = {2017}
}


@inproceedings{Lee:2017:PRA:3081333.3089317,
 abstract = {Vehicular applications are increasingly connected to cloud services. For example, route planning, gas price applications, and Siri-like personal assistants all respond to user queries based in part on cloud processing. Network communication thus is often a substantial component of user-perceived latency in vehicular applications. Current vehicular computing platforms typically connect to the cloud using a single cellular network provider. Network conditions can change rapidly as a vehicle moves due to geographical variation in coverage, radio shadows, and differing traffic density. Such variation is often exacerbated by connection re-establishment after an interface has entered a sleep state. Thus, vehicular applications can often appear unresponsive due to high wireless network latency. Even worse, the responsiveness is unpredictable; high tail latency makes some user interactions take longer, even when most interactions complete in an acceptable amount of time. This unpredictability is especially worrisome in a vehicular environment, in which occasional unexpected performance anomalies distract the driver of the vehicle.},
 acmid = {3089317},
 address = {New York, NY, USA},
 author = {Lee, HyunJong and Flinn, Jason},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089317},
 isbn = {978-1-4503-4928-4},
 keyword = {autonomous vehicle, connected vehicle, raven, redundancy, vehicular networking},
 link = {http://doi.acm.org/10.1145/3081333.3089317},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {173--173},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Redundancy Aided Vehicular Networking},
 year = {2017}
}


@inproceedings{Mathur:2017:DRE:3081333.3081359,
 abstract = {Wearable devices with built-in cameras present interesting opportunities for users to capture various aspects of their daily life and are potentially also useful in supporting users with low vision in their everyday tasks. However, state-of-the-art image wearables available in the market are limited to capturing images periodically and do not provide any real-time analysis of the data that might be useful for the wearers. In this paper, we present DeepEye - a match-box sized wearable camera that is capable of running multiple cloud-scale deep learn- ing models locally on the device, thereby enabling rich analysis of the captured images in near real-time without offloading them to the cloud. DeepEye is powered by a commodity wearable processor (Snapdragon 410) which ensures its wearable form factor. The software architecture for DeepEye addresses a key limitation with executing multiple deep learning models on constrained hardware, that is their limited runtime memory. We propose a novel inference software pipeline that targets the local execution of multiple deep vision models (specifically, CNNs) by interleaving the execution of computation-heavy convolutional layers with the loading of memory-heavy fully-connected layers. Beyond this core idea, the execution framework incorporates: a memory caching scheme and a selective use of model compression techniques that further minimizes memory bottlenecks. Through a series of experiments, we show that our execution framework outperforms the baseline approaches significantly in terms of inference latency, memory requirements and energy consumption.},
 acmid = {3081359},
 address = {New York, NY, USA},
 author = {Mathur, Akhil and Lane, Nicholas D. and Bhattacharya, Sourav and Boran, Aidan and Forlivesi, Claudio and Kawsar, Fahim},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081359},
 isbn = {978-1-4503-4928-4},
 keyword = {computer vision, deep learning, embedded devices, local execution, wearables},
 link = {http://doi.acm.org/10.1145/3081333.3081359},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {68--81},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {DeepEye: Resource Efficient Local Execution of Multiple Deep Vision Models Using Wearable Commodity Hardware},
 year = {2017}
}


@inproceedings{Agadakos:2017:TOP:3081333.3081345,
 abstract = {The proliferation of mobile devices, equipped with numerous sensors and Internet connectivity, has laid the foundation for the emergence of a diverse set of crowdsourcing services. By leveraging the multitude, geographical dispersion, and technical abilities of smartphones, these services tackle challenging tasks by harnessing the power of the crowd. One such service, Crowd GPS, has gained traction in the industry and research community alike, materializing as a class of systems that track lost objects or individuals (e.g., children or elders). While these systems can have significant impact, they suffer from major privacy threats. In this paper, we highlight the inherent risks to users from the centralized designs adopted by such services and demonstrate how adversaries can trivially misuse one of the most popular crowd GPS services to track their users. As an alternative, we present Techu, a privacy-preserving crowd GPS service for tracking Bluetooth tags. Our architecture follows a hybrid decentralized approach, where an untrusted server acts as a bulletin board that collects reports of tags observed by the crowd, while observers store the location information locally and only disclose it upon proof of ownership of the tag. Techu does not require user authentication, allowing users to remain anonymous. As no user authentication is required and cloud messaging queues are leveraged for communication between users, users remain anonymous. Our security analysis highlights the privacy offered by Techu, and details how our design prevents adversaries from tracking or identifying users. Finally, our experimental evaluation demonstrates that Techu has negligible impact on power consumption, and achieves superior effectiveness to previously proposed systems while offering stronger privacy guarantees.},
 acmid = {3081345},
 address = {New York, NY, USA},
 author = {Agadakos, Ioannis and Polakis, Jason and Portokalidis, Georgios},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081345},
 isbn = {978-1-4503-4928-4},
 keyword = {ble tags, crowd gps, location privacy, location-based services, privacy-preserving protocol, user tracking},
 link = {http://doi.acm.org/10.1145/3081333.3081345},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {475--487},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Techu: Open and Privacy-Preserving Crowdsourced GPS for the Masses},
 year = {2017}
}


@inproceedings{Ki:2017:DRE:3081333.3089338,
 abstract = {We demonstrate Reptor, a bytecode instrumentation tool enabling API virtualization on Android. It provides a general way to alter functionality of platform APIs on Android. With Reptor, third-party developers can modify the behavior of platform APIs according to their needs. All modifications are completely at the app layer without modifying the underlying platform. This allows practical openness---third-party developers can easily distribute their modifications for a platform without the need to update the entire platform.},
 acmid = {3089338},
 address = {New York, NY, USA},
 author = {Ki, Taeyeon and Simeonov, Alexander and Park, Chang Min and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089338},
 isbn = {978-1-4503-4928-4},
 keyword = {API virtualization, android app instrumentation, android platform instrumentation, platform openness},
 link = {http://doi.acm.org/10.1145/3081333.3089338},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {193--193},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Reptor: Enabling API Virtualization on Android for Platform Openness},
 year = {2017}
}


@inproceedings{Lee:2017:PLL:3081333.3089302,
 abstract = {When integrated with push notifications, a live migration function can be used to ensure that systems have a high reliability in cases of hardware failures. However, the dependencies for a large range of hardware devices need to be addressed before realizing emergency live migration. Our platform introduces container-based light virtualization and an automated build function to isolate an application so that it can be deployed on different devices such as Edison, Raspberry Pi model B, BeagleBone Black, and Odroid XU3.},
 acmid = {3089302},
 address = {New York, NY, USA},
 author = {Lee, Jaemyoun and Kang, Kyungtae},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089302},
 isbn = {978-1-4503-4928-4},
 keyword = {container, live migration, system resilience, virtualization},
 link = {http://doi.acm.org/10.1145/3081333.3089302},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {158--158},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: A Lightweight Live Migration Platform with Container-based Virtualization for System Resilience},
 year = {2017}
}


@inproceedings{Shangguan:2017:EGI:3081333.3081364,
 abstract = {Increasing numbers of everyday objects in libraries, stores and warehouses are instrumented with passive RFID tags, resulting in a ripe opportunity for gesture-based interactions with people. By a simple act of picking up and gesturing with an RFID-tagged object, users can send their opinions and sentiments about that object to the cloud. Prior work in RFID-based gesture tracking relies on multiple bulky and expensive antennas and readers to function, which incurs unacceptable infrastructure costs for large-scale ubiquitous deployment (over an entire warehouse or mall, for example) thus hindering practical adoption. In this paper, we propose Pantomime, the first RFID-based gesture recognition system that uses just a single antenna per geographical area of coverage. Our key insight is to replace the conventional multiple antenna single tag tracking framework with an equivalent multiple tag single antenna system. Through a novel tag coordination protocol and a lightweight tracking algorithm, Pantomime enables accurate gesture tracking that works for objects tagged with just two RFID tags. We implement a real-time prototype of Pantomime with commercial off-the-shelf (COTS) RFID readers and antennas. Extensive evaluations and real-world case studies in a classroom and a retail store demonstrate that Pantomime achieves comparable gesture tracking accuracy (87%) to state-of-the-art multi-antenna schemes (88%) at a minimal deployment cost.},
 acmid = {3081364},
 address = {New York, NY, USA},
 author = {Shangguan, Longfei and Zhou, Zimu and Jamieson, Kyle},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081364},
 isbn = {978-1-4503-4928-4},
 keyword = {human-object interaction, rfid, tracking},
 link = {http://doi.acm.org/10.1145/3081333.3081364},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {239--251},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Enabling Gesture-based Interactions with Objects},
 year = {2017}
}


@proceedings{Choudhury:2017:3081333,
 abstract = {It is our pleasure and privilege to serve as program chairs for ACM MobiSys 2017 -- the 15th ACM International Conference on Mobile Systems, Applications, and Services. We hope you enjoy this technical material behind the conference that attracts a diverse set of attendees from both academia and industry and is a leading venue for publications and idea exchange on mobile systems. ACM MobiSys 2017 has a highly selective, single-track program featuring research related to mobile systems and applications. It is an ideal venue to address research challenges facing the design, development, deployment, use, and fundamental limits of these systems. Notes on the review process: Since its inception in 2003 MobiSys has had a single-blind review policy where the identity of the reviewers is not revealed to the authors but the reviewers know the names, affiliations and contact information of the authors. Beginning 2017, we modified this policy so that the identity of the authors was not revealed to the reviewers during the initial review of the paper. However, once preliminary outcomes were decided, identities of the authors was revealed to enable referees to ask appropriate questions, making it easier to compare the new results with the author(s) previously published work and to ensure that a true advance was being reported. Our paper review process this year was highly selective. Out of 188 submissions, the technical program committee accepted only 34 for publication and presentation as full papers, yielding an acceptance rate around 18%. Submitted papers underwent a rigorous, multi-stage review process. First, we checked all submissions for compliance, general quality, and topic match. We administratively rejected those not meeting our submission criteria. We assigned 3 reviewers to papers that survived this stage from the program committee and the external review committee. At the conclusion of this stage, those papers where none of the reviewers were enthusiastic about acceptance were rejected. We then assigned at least 2 additional reviewers from the program committee to papers that survived, thus totaling at least 5 reviews per paper. An online discussion phase then ensued, resulting in the PC recommending 60 papers for discussion at the PC meeting. The PC meeting was held in person in Sonoma CA, USA, the day after ACM HotMobile 2017. At the conclusion of the PC meeting, we accepted 34 papers to the conference. Several accepted papers were assigned shepherds to help ensure that the authors produce a final manuscript that satisfactorily addresses reviewer comments. The program: Our program this year covers an exciting set of topics including sensing using acoustic, RF, and light signals, novel communication techniques, deep learning on mobiles, mobile performance, security and privacy, and operating systems. It also includes a keynote by Pattie Maes on human augmentation i.e. how systems can actively assist people with memory, learning, decision making, communication and physical skills, a SIGMOBILE Outstanding Contribution Award talk by Norman Abramson, recognized for his pioneering work on the ALOHAnet wireless networking system, five invited talks on trends in deep learning on mobiles, virtual reality, internet of things, biomedical diagnostics using phones, and large-scale wireless testbeds, brief talks by five Test-of-Time award winners, as well as an extensive poster/demo session.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4928-4},
 location = {Niagara Falls, New York, USA},
 publisher = {ACM},
 title = {MobiSys '17: Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 year = {2017}
}


@inproceedings{Yoo:2017:DCS:3081333.3089332,
 abstract = {Consider a massive crowd who gathered together to convey their common voice to public, e.g., supporters of a team sitting together in a stadium, people doing a candlelight vigil in a public square, and so on. Imagine that they hold up their smartphone displays which collectively compose a huge public screen; the crowd's messages are now shown big on the top of them. We present CaaS [3], a mobile service to realize such an instant, massive, collective visualization with commodity smartphones and cloud services. In this demo, we demonstrate the collective localization feature of CaaS so that the audience can watch a given pattern or symbol collectively displayed on top of arbitrarily positioned phones (See the video demo, https://goo.gl/GfsORc).},
 acmid = {3089332},
 address = {New York, NY, USA},
 author = {Yoo, Chungkuk and Hwang, Inseok and Kang, Seungwoo and Kim, Myung-Chul and Kim, Seonghoon and Won, Daeyoung and Gu, Yu and Song, Junehwa},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089332},
 isbn = {978-1-4503-4928-4},
 keyword = {card stunt, collective visualization, mobile-crowd service, optimization, relative localization, visible light communication},
 link = {http://doi.acm.org/10.1145/3081333.3089332},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {187--187},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Card-stunt As a Service: Empowering a Massively Packed Crowd for Instant Collective Expressiveness},
 year = {2017}
}


@inproceedings{Wang:2017:ECO:3081333.3081337,
 abstract = {Work offloading allows a mobile device, i.e., the client, to execute its computation-intensive code remotely on a more powerful server to improve its performance and to extend its battery life. However, the difference in instruction set architectures (ISAs) between the client and the server poses a great challenge to work offloading. Most of the existing solutions rely on language-level virtual machines to hide such differences. Therefore, they have to tie closely to the specific programming languages. Other approaches try to recompile the mobile applications to achieve the specific goal of offloading, so their applicability is limited to the availability of the source code. To overcome the above limitations, we propose to extend the capability of dynamic binary translation across clients and servers to offload the identified computation-intensive binary code regions automatically to the server at runtime. With this approach, the native binaries on the client can be offloaded to the server seamlessly without the limitations mentioned above. A prototype has been implemented using an existing retargetable dynamic binary translator. Experimental results show that our system achieves 1.93X speedup with 48.66% reduction in energy consumption for six real-world applications, and 1.62X speedup with 42.4% reduction in energy consumption for SPEC CINT2006 benchmarks.},
 acmid = {3081337},
 address = {New York, NY, USA},
 author = {Wang, Wenwen and Yew, Pen-Chung and Zhai, Antonia and McCamant, Stephen and Wu, Youfeng and Bobba, Jayaram},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081337},
 isbn = {978-1-4503-4928-4},
 keyword = {computation offloading, dynamic binary optimization, dynamic binary translation, offloading target selection},
 link = {http://doi.acm.org/10.1145/3081333.3081337},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {319--331},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Enabling Cross-ISA Offloading for COTS Binaries},
 year = {2017}
}


@inproceedings{Niu:2017:PDS:3081333.3089297,
 abstract = {Internet of Things(IoT) was first coined in 1999 by Kevin Ashton. However with the technologies advancement, it seems that intelligent devices will invisibly be embedded in our life in few years. Enormous amounts of data need be exchanged every seconds. It calls for a seamless effect and easily interpretable communicating architecture. The research proposal will try to address some challenges and possible path in IoT enabled smarthome. It focuses primarily on two categories. Firstly, devices in IoT field is always distributed. So, there is a distributed IoT services architecture instead of traditional control-center solution. However, those devices are also limited in a certain area (such as a home local network). In order to reduce delay and burden, those distributed devices collect context information though a self-organizing broadcast network, and determine their next action based on that context data. Secondly, using Docker (a lightweight hardware-agnostic and platform-agnostic container) to package services. In our smarthome network, IoT services are distributed across different home electronics. Docker shields all the differences, so that we can quickly deploy and update module in the smarthome network after purchasing new electronics.},
 acmid = {3089297},
 address = {New York, NY, USA},
 author = {Niu, Meng and Cheng, Bo and Zhai, Zhongyi and Feng, Yimeng and Chen, Junliang},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089297},
 isbn = {978-1-4503-4928-4},
 keyword = {IoT service, docker, internet of thing, self-organizing},
 link = {http://doi.acm.org/10.1145/3081333.3089297},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {153--153},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Docker-Based Self-Organizing IoT Services Architecture for Smarthome},
 year = {2017}
}


@inproceedings{Katevas:2017:DDG:3081333.3089335,
 abstract = {Researchers from different disciplines have examined crowd behavior in the past by employing a variety of methods including ethnographic studies, computer vision techniques and manual annotation based data analysis. However, because of the inherent difficulties in collecting, processing and analyzing the data, it is difficult to obtain large data sets for study. In this work we present a system for detecting stationary interactions inside crowds, depending entirely on the sensors available in a modern smartphone device such as Bluetooth Smart (BLE) and Accelerometer. By utilizing Apple's iBeaconTM implementation of Bluetooth Smart using SensingKit1, our open-source multi-platform mobile sensing framework [1], we are able to detect the proximity of users carrying a smartphone in their pocket. We then use an algorithm based on graph theory to predict group interactions inside the crowd. Previous work in this area has been limited to the detection of interactions between only two people and therefore our approach goes beyond current state of the art in its ability to detect group formations with more than two people involved. Our approach is particularly beneficial to the design and implementation of crowd behavior analytics, design of influence strategies, and algorithms for crowd reconfiguration.},
 acmid = {3089335},
 address = {New York, NY, USA},
 author = {Katevas, Kleomenis and Tokarchuk, Laurissa and Haddadi, Hamed and Clegg, Richard G. and Irfan, Muhammad},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089335},
 isbn = {978-1-4503-4928-4},
 keyword = {ble, crowd sensing, group formations, ibeacon, mobile sensing, rssi, social interactions, social network analysis},
 link = {http://doi.acm.org/10.1145/3081333.3089335},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {190--190},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Demo: Detecting Group Formations Using iBeacon Technology},
 year = {2017}
}


@inproceedings{Sasaki:2017:PEE:3081333.3089324,
 abstract = {We propose "SmileWave", the first selfie social networking service to reveal the existence of emotional cognation through smiling selfies on the social network. We conducted multiple rounds of in-the-wild user studies with 86 cumulative total users for total duration of 5 weeks. Throughout the entire study, we confirmed the occurrence of smile-based emotional contagion over social network, not only in the momentary duration but in longer term period.},
 acmid = {3089324},
 address = {New York, NY, USA},
 author = {Sasaki, Wataru and Obuchi, Mikio and Egashira, Kazuki and Isokawa, Naohiro and Furukawa, Yuki and Nishiyama, Yuuki and Okoshi, Tadashi and Nakazawa, Jin},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089324},
 isbn = {978-1-4503-4928-4},
 keyword = {emotional contagion, mobile sensing, social network},
 link = {http://doi.acm.org/10.1145/3081333.3089324},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {180--180},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Extensive Evaluation of Emotional Contagion on Smiling Selfies over Social Network},
 year = {2017}
}


@inproceedings{Zeng:2017:MSM:3081333.3081336,
 abstract = {Correct identification of prescription pills based on their visual appearance is a key step required to assure patient safety and facilitate more effective patient care. With the availability of high-quality cameras and computational power on smartphones, it is possible and helpful to identify unknown prescription pills using smartphones. Towards this goal, in 2016, the U.S. National Library of Medicine (NLM) of the National Institutes of Health (NIH) announced a nationwide competition, calling for the creation of a mobile vision system that can recognize pills automatically from a mobile phone picture under unconstrained real-world settings. In this paper, we present the design and evaluation of such mobile pill image recognition system called MobileDeepPill. The development of MobileDeepPill involves three key innovations: a triplet loss function which attains invariances to real-world noisiness that deteriorates the quality of pill images taken by mobile phones; a multi-CNNs model that collectively captures the shape, color and imprints characteristics of the pills; and a Knowledge Distillation-based deep model compression framework that significantly reduces the size of the multi-CNNs model without deteriorating its recognition performance. Our deep learning-based pill image recognition algorithm wins the First Prize (champion) of the NIH NLM Pill Image Recognition Challenge. Given its promising performance, we believe MobileDeepPill helps NIH tackle a critical problem with significant societal impact and will benefit millions of healthcare personnel and the general public.},
 acmid = {3081336},
 address = {New York, NY, USA},
 author = {Zeng, Xiao and Cao, Kai and Zhang, Mi},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081336},
 isbn = {978-1-4503-4928-4},
 keyword = {deep neural network model compression, mobile deep learning systems, mobile health, unconstrained pill image recognition},
 link = {http://doi.acm.org/10.1145/3081333.3081336},
 location = {Niagara Falls, New York, USA},
 numpages = {12},
 pages = {56--67},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {MobileDeepPill: A Small-Footprint Mobile Deep Learning System for Recognizing Unconstrained Pill Images},
 year = {2017}
}


@inproceedings{Mao:2017:IFM:3081333.3081362,
 abstract = {With the availability of inexpensive and powerful drones, it is possible to let drones automatically follow a user for video taping. This can not only reduce cost, but also support video taping in situations where otherwise not possible (e.g., during private moments or at inconvenient locations like indoor rock climbing). While there have been many follow-me drones on the market for outdoors, which rely on GPS, enabling indoor follow-me function is more challenging due to the lack of an effective approach to track users in indoor environments. To this end, we develop a holistic system that lets a mobile phone carried by a user accurately track the drone's relative location and control it to maintain a specified distance and orientation for automatic video taping. We develop a series of techniques to (i) track a drone's location using acoustic signals with sub-centimeter errors even under strong propeller noise from the drone and complicated multipath in indoor environments, and (ii) solve practical challenges in applying model predictive control (MPC) framework to control the drone. The latter consists of developing measurement-based flight models, designing measurement techniques to provide feedback to the controller, and predicting the user's movement. We implement our system on AR Drone 2.0 and Samsung S7. The extensive evaluation shows that our drone can follow a user effectively and maintain a specified following distance and orientation within 2-3 cm and 1-3 degree errors, respectively. The videos taped by the drone during flight are smooth according to the jerk metric.},
 acmid = {3081362},
 address = {New York, NY, USA},
 author = {Mao, Wenguang and Zhang, Zaiwei and Qiu, Lili and He, Jian and Cui, Yuchen and Yun, Sangki},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081362},
 isbn = {978-1-4503-4928-4},
 keyword = {FMCW, MPC, acoustic signals, drone, music, tracking},
 link = {http://doi.acm.org/10.1145/3081333.3081362},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {345--358},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Indoor Follow Me Drone},
 year = {2017}
}


@inproceedings{He:2017:IUC:3081333.3081350,
 abstract = {Charging mobile devices "fast" has been the focus of both industry and academia, leading to the deployment of various fast charging technologies. However, existing fast charging solutions are agnostic of users' available time for charging their devices, causing early termination of the intended/planned charging. This, in turn, accelerates the capacity fading of device battery and thus shortens the device operation. In this paper, we propose a novel user-interactive charging paradigm, called iCharge, that tailors the device charging to the user's real-time availability and need. The core of iCharge is a relaxation-aware (R-Aware) charging algorithm that maximizes the charged capacity within the user's available time and slows down the battery's capacity fading. iCharge also integrates R-Aware with existing fast charging algorithms via a user-interactive interface, allowing users to choose a charging method based on their availability and need. We evaluate iCharge via extensive laboratory experiments and field-tests on Android phones, as well as user studies. R-Aware is shown to slow down the battery fading by more than 36% on average, and up to 60% in extreme cases, when compared to existing fast charging algorithms. This slowdown of capacity fading translates to, for instance, an up to 2-hour extension of the LTE time for a Nexus 5X phone after its use for 2 years, according to our trace-driven analysis of 976 device charging cases of 7 users over 3 months.},
 acmid = {3081350},
 address = {New York, NY, USA},
 author = {He, Liang and Tung, Yu-Chih and Shin, Kang G.},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081350},
 isbn = {978-1-4503-4928-4},
 keyword = {battery fading, battery relaxation, mobile devices, user-interactive charging},
 link = {http://doi.acm.org/10.1145/3081333.3081350},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {413--426},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {iCharge: User-Interactive Charging of Mobile Devices},
 year = {2017}
}


@inproceedings{Popleteev:2017:PIG:3081333.3089310,
 abstract = {This study investigates the impact of small ground truth (GT) errors on indoor positioning systems based on Wi-Fi fingerprinting. The results demonstrate that even centimeter-scale GT deviations cause severe degradation of measured localization accuracy.},
 acmid = {3089310},
 address = {New York, NY, USA},
 author = {Popleteev, Andrei},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089310},
 isbn = {978-1-4503-4928-4},
 keyword = {RSS, WLAN, fingerprinting, ground truth, indoor localization, performance evaluation, small-scale fading},
 link = {http://doi.acm.org/10.1145/3081333.3089310},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {166--166},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Impact of Ground Truth Errors on Wi-Fi Localization Accuracy},
 year = {2017}
}


@inproceedings{Klingler:2017:PFT:3081333.3089322,
 abstract = {We present OpenC2X, an Open Source approach to field testing of vehicular networking solutions. Field Operational Test (FOT) and real-world experimentation are becoming more relevant to our research community as well as to industry and regulation. Unfortunately, available commercial solutions make experimental modifications to the protocol stack time consuming or prohibit it completely. To overcome this limitation, we implemented the ETSI ITS-G5 stack on a standard embedded PC hardware and running Linux system. OpenC2X is the first complete Open Source experimentation and prototyping platform. Our system is fully interoperable to commercial solutions, yet easily extensible with new protocols and applications for vehicular networks.},
 acmid = {3089322},
 address = {New York, NY, USA},
 author = {Klingler, Florian and Pannu, Gurjashan Singh and Sommer, Christoph and Bloessl, Bastian and Dressler, Falko},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089322},
 isbn = {978-1-4503-4928-4},
 keyword = {field testing, prototype, vehicular networking},
 link = {http://doi.acm.org/10.1145/3081333.3089322},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {178--178},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Field Testing Vehicular Networks Using OpenC2X},
 year = {2017}
}


@inproceedings{Xie:2017:AMW:3081333.3081367,
 abstract = {Despite the 4G LTE's 10X capacity improvement over 3G, mobile Web loading latency remains a major issue that hampers user experience. The root cause lies in the inefficient transport-layer that underutilizes LTE capacity, due to high channel dynamics, wireless link losses, and insufficient application traffic to propel the bandwidth probing. In this paper, we propose Cellular Link-Aware Web loading (CLAW), which boosts mobile Web loading using a physical-layer informed transport protocol. CLAW harnesses the limited PHY-layer statistics available on LTE phones to quantitatively model the LTE channel resource utilization, which is then translated into a transport window that best fits the bandwidth. Consequently, CLAW can estimate and fully utilize the available bandwidth almost within one RTT. In addition, CLAW can precisely differentiate LTE wireless loss from congestion loss, and identify the rare cases when the wireline backhaul becomes the bottleneck. We have prototyped CLAW on commodity LTE phones. Across a wide range of experimental settings, CLAW consistently reduces Web loading latency by more than 30%, compared to classical TCP variants and state-of-the-art congestion controls for cellular networks.},
 acmid = {3081367},
 address = {New York, NY, USA},
 author = {Xie, Xiufeng and Zhang, Xinyu and Zhu, Shilin},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081367},
 isbn = {978-1-4503-4928-4},
 keyword = {LTE, TCP, cross-layer protocol, mobile web, physical-layer},
 link = {http://doi.acm.org/10.1145/3081333.3081367},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {427--439},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Accelerating Mobile Web Loading Using Cellular Link Information},
 year = {2017}
}


@inproceedings{Zhu:2017:ORN:3081333.3081339,
 abstract = {Tomorrow's autonomous mobile devices need accurate, robust and real-time sensing of their operating environment. Today's solutions fall short. Vision or acoustic-based techniques are vulnerable against challenging lighting conditions or background noise, while more robust laser or RF solutions require either bulky expensive hardware or tight coordination between multiple devices. This paper describes the design, implementation and evaluation of Ulysses, a practical environmental imaging system using colocated 60GHz radios on a single mobile device. Unlike alternatives that require specialized hardware, Ulysses reuses low-cost commodity networking chipsets available today. Ulysses' new imaging approach leverages RF beamforming, operates on specular (direct) reflection, and integrates the device's movement trajectory with sensing. Ulysses also includes a navigation component that uses the same 60GHz radios to compute "safety regions" where devices can move freely without collision, and to compute optimal paths for imaging within safety regions. Using our implementation of a small robotic car prototype, our experimental results show that Ulysses images objects meters away with cm-level precision, and provides accurate estimates of objects' surface materials.},
 acmid = {3081339},
 address = {New York, NY, USA},
 author = {Zhu, Yanzi and Yao, Yuanshun and Zhao, Ben Y. and Zheng, Haitao},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081339},
 isbn = {978-1-4503-4928-4},
 keyword = {60GHz wireless, imaging, mobile system},
 link = {http://doi.acm.org/10.1145/3081333.3081339},
 location = {Niagara Falls, New York, USA},
 numpages = {13},
 pages = {265--277},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Object Recognition and Navigation Using a Single Networking Device},
 year = {2017}
}


@inproceedings{Moravapalle:2017:POP:3081333.3089311,
 abstract = {Application Mobilization, or the ability of an enterprise employee to rely on mobile devices such as smartphones and tablets, to continue to perform business workflows even when mobile, is seen as a game changer to improve productivity. However, the practical adoption of enterprise mobility is very much in its in fancy, and seemingly has barriers. We posit that these barriers include heavy user-burden in accomplishing tasks (e.g. number of actions required to execute a workflow), high cost of mobile access (e.g. latency for content fetching), and irrelevance of available mobile functions (e.g. mobile app defeaturization done inappropriately).The novelty of our research is in a unified observe-patternize-mimic paradigm we explore to address these barriers, based on a simple question: could patterns in user-behavior be learned, and leveraged for reducing user-burden? If patterns are discovered, then we show that intelligent mimicking of these patterns at appropriate junctures can considerably relieve the mobile user burden. We motivate this paradigm through three application scenarios representing read, write, and act usage modalities.},
 acmid = {3089311},
 address = {New York, NY, USA},
 author = {Moravapalle, Uma Parthavi and Sanadhya, Shruti and Tsao, Cheng-Lin and Sivakumar, Raghupathy},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089311},
 isbn = {978-1-4503-4928-4},
 keyword = {enterprise applications, patterns, redundancy, user-behavior},
 link = {http://doi.acm.org/10.1145/3081333.3089311},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {167--167},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Observe. Patternize. Mimic.: Leveraging Patterns in Mobile-User Behavior for Enterprise Applications},
 year = {2017}
}


@inproceedings{Abramson:2017:AW:3081333.3081475,
 abstract = {
An abstract is not available.
},
 acmid = {3081475},
 address = {New York, NY, USA},
 author = {Abramson, Norman},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081475},
 isbn = {978-1-4503-4928-4},
 keyword = {ALOHA, networks, random access, wireless},
 link = {http://doi.acm.org/10.1145/3081333.3081475},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {196--196},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {ALOHA to the Web},
 year = {2017}
}


@inproceedings{Agarwal:2017:PCV:3081333.3089321,
 abstract = {Brain-computer interfaces (BCIs) allow users to communicate to a nearby computing device (computer, smartphone, etc.) using thoughts or other covert actions that result in a detectable change in brain-waves. Consider a BCI command to be a word consisting of a sequence of characters. Each character is a thought or action that can be reliably detected through brain waves. For this work, we specifically consider eye-blinks as the user action of interest. Eye-blinks are an interesting modality for BCI commands because of their easy detectability and naturalness (and hence covertness). It turns out that there is an interesting trade-off between the complexity of characters and the length of words. In this work, we perform a user-study to answer a simple, but important, question pertaining to eye-blinks based BCI command design: do users prefer shorter characters (and hence longer words) or shorter words (and hence longer characters) when performing commands?. We present a simple eye-blink language consisting of words and characters and use real user-experiments to study the aforementioned trade-off.},
 acmid = {3089321},
 address = {New York, NY, USA},
 author = {Agarwal, Mohit and Sivakumar, Raghupathy},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089321},
 isbn = {978-1-4503-4928-4},
 keyword = {brain-computer interfaces (BCIS), eye-blinks},
 link = {http://doi.acm.org/10.1145/3081333.3089321},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {177--177},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Characters vs. Words: Observations on Command Design for Brain-Computer Interfaces},
 year = {2017}
}


@inproceedings{Soltanaghaei:2017:POS:3081333.3089305,
 abstract = {A large amount of energy could be saved by detecting home occupancy and automatically controlling the lights, HVAC, water heating, and other mechanical systems. Existing systems rely on motion information, which usually fail to detect occupied rooms with stationary people. In this project, we study the possibility of converting commodity WiFi access points to occupancy sensors by exploiting multipath reflections as individual spatial sensors. The proposed method measures fine-grained distortions caused by human body on phase and amplitude of WiFi signals. Our initial results suggest that formulating WiFi parameters into angle of arrival provides a more sensitive metric to measure occupancy.},
 acmid = {3089305},
 address = {New York, NY, USA},
 author = {Soltanaghaei, Elahe and Kalyanaraman, Avinash and Whitehouse, Kamin},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089305},
 isbn = {978-1-4503-4928-4},
 keyword = {CSI, WiFi, multipath propagation, occupancy detection},
 link = {http://doi.acm.org/10.1145/3081333.3089305},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {161--161},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Occupancy State Detection Using WiFi Signals},
 year = {2017}
}


@inproceedings{Luo:2017:SSC:3081333.3081361,
 abstract = {Android Application Framework is an integral and foundational part of the Android system. Each of the 1.4 billion Android devices relies on the system services of Android Framework to manage applications and system resources. Given its critical role, a vulnerability in the framework can be exploited to launch large-scale cyber attacks and cause severe harms to user security and privacy. Recently, many vulnerabilities in Android Framework were exposed, showing that it is vulnerable and exploitable. However, most of the existing research has been limited to analyzing Android applications, while there are very few techniques and tools developed for analyzing Android Framework. In particular, to our knowledge, there is no previous work that analyzes the framework through symbolic execution, an approach that has proven to be very powerful for vulnerability discovery and exploit generation. We design and build the first system, Centaur, that enables symbolic execution of Android Framework. Due to some unique characteristics of the framework, such as its middleware nature and extraordinary complexity, many new challenges arise and are tackled in Centaur. In addition, we demonstrate how the system can be applied to discovering new vulnerability instances, which can be exploited by several recently uncovered attacks against the framework, and to generating PoC exploits.},
 acmid = {3081361},
 address = {New York, NY, USA},
 author = {Luo, Lannan and Zeng, Qiang and Cao, Chen and Chen, Kai and Liu, Jian and Liu, Limin and Gao, Neng and Yang, Min and Xing, Xinyu and Liu, Peng},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081361},
 isbn = {978-1-4503-4928-4},
 keyword = {android framework, concolic execution, exploit generation, symbolic execution, vulnerability discovery},
 link = {http://doi.acm.org/10.1145/3081333.3081361},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {225--238},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {System Service Call-oriented Symbolic Execution of Android Framework with Applications to Vulnerability Discovery and Exploit Generation},
 year = {2017}
}


@inproceedings{Nguyen:2017:MDP:3081333.3081354,
 abstract = {Drones are increasingly flying in sensitive airspace where their presence may cause harm, such as near airports, forest fires, large crowded events, secure buildings, and even jails. This problem is likely to expand given the rapid proliferation of drones for commerce, monitoring, recreation, and other applications. A cost-effective detection system is needed to warn of the presence of drones in such cases. In this paper, we explore the feasibility of inexpensive RF-based detection of the presence of drones. We examine whether physical characteristics of the drone, such as body vibration and body shifting, can be detected in the wireless signal transmitted by drones during communication. We consider whether the received drone signals are uniquely differentiated from other mobile wireless phenomena such as cars equipped with Wi- Fi or humans carrying a mobile phone. The sensitivity of detection at distances of hundreds of meters as well as the accuracy of the overall detection system are evaluated using software defined radio (SDR) implementation.},
 acmid = {3081354},
 address = {New York, NY, USA},
 author = {Nguyen, Phuc and Truong, Hoang and Ravindranathan, Mahesh and Nguyen, Anh and Han, Richard and Vu, Tam},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3081354},
 isbn = {978-1-4503-4928-4},
 keyword = {RF sensing, drone body shifting, drone body vibration, drone detection},
 link = {http://doi.acm.org/10.1145/3081333.3081354},
 location = {Niagara Falls, New York, USA},
 numpages = {14},
 pages = {211--224},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Matthan: Drone Presence Detection by Identifying Physical Signatures in the Drone's RF Communication},
 year = {2017}
}


@inproceedings{Nair:2017:PFM:3081333.3089309,
 abstract = {Urban floods have become a constant threat to human life and property. Also, high resolution cameras in smart phones have become ubiquitous. This work involves using Computer Vision algorithms to estimate the depth of flooding based on images taken by the general public which are geo-tagged and time-stamped. This approach will help in the implementation of effective and timely urban flood relief and management. This data can also be used to assess the effectiveness of preventive measures taken in the past and to plan remedial measures in the future.},
 acmid = {3089309},
 address = {New York, NY, USA},
 author = {Nair, Bhavana B. and Rao, Sethuraman N.},
 booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
 doi = {10.1145/3081333.3089309},
 isbn = {978-1-4503-4928-4},
 keyword = {computer vision, deep learning, face detection, flood monitoring, gender classification, human segmentation},
 link = {http://doi.acm.org/10.1145/3081333.3089309},
 location = {Niagara Falls, New York, USA},
 numpages = {1},
 pages = {165--165},
 publisher = {ACM},
 series = {MobiSys '17},
 title = {Poster: Flood Monitoring Using Computer Vision},
 year = {2017}
}


