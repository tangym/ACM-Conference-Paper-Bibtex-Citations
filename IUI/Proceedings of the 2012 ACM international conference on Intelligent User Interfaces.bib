@inproceedings{Pedemonte:2012:TAF:2166966.2167005,
 abstract = {As applications are developed, functional tests ensure they continue to function as expected. Nowadays, functional testing is mostly done manually, with human testers verifying a system's functionality themselves, following hand-written instructions. While there exist tools supporting functional test automation, in practice they are hard to use, require programming skills, and do not provide good support for test maintenance. In this paper, we take an alternative approach: we semi-automatically convert hand-written instructions into automated tests. Our approach consists of two stages: first, employing machine learning and natural language processing to compute an intermediate representation from test steps; and second, interactively disambiguating that representation to create a fully automated test. These two stages comprise a complete system for converting hand-written functional tests into automated tests. We also present a quantitative study analyzing the effectiveness of our approach. Our results show that 70% of manual test steps can be automatically converted to automated test steps with no user intervention.},
 acmid = {2167005},
 address = {New York, NY, USA},
 author = {Pedemonte, Pablo and Mahmud, Jalal and Lau, Tessa},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167005},
 isbn = {978-1-4503-1048-2},
 keyword = {manual test automation, natural language processing, supervised learning},
 link = {http://doi.acm.org/10.1145/2166966.2167005},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {227--236},
 publisher = {ACM},
 series = {IUI '12},
 title = {Towards Automatic Functional Test Execution},
 year = {2012}
}


@inproceedings{Doryab:2012:ARC:2166966.2167023,
 abstract = {This paper presents a recommender system for teams of medical professionals working collaboratively in hospital operating rooms. The system recommends relevant virtual actions, such as retrieval of information resources and initiation of communication with professionals outside the operating rooms. Recommendations are based on the current state of the ongoing operation as recognised from sensor data using machine learning techniques. The selection and non-selection of virtual actions during operations are interpreted as implicit feedback and used to update the weight matrices that guide recommendations. A pilot user study involving medical professionals indicates that the adaptation mechanism is effective and that the system provides adequate recommendations.},
 acmid = {2167023},
 address = {New York, NY, USA},
 author = {Doryab, Afsaneh and Togelius, Julian and Bardram, Jakob},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167023},
 isbn = {978-1-4503-1048-2},
 keyword = {collaborative work, context-aware, hospitals, information retrieval, operating room, recommendation},
 link = {http://doi.acm.org/10.1145/2166966.2167023},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {301--304},
 publisher = {ACM},
 series = {IUI '12},
 title = {Activity-aware Recommendation for Collaborative Work in Operating Rooms},
 year = {2012}
}


@inproceedings{Bigdelou:2012:FPD:2166966.2167040,
 abstract = {In this paper, we introduce a flexible framework that can facilitate the definition of 3D gesture-based interfaces. Highlighting the need for context awareness in complex domains, such as the operating room, we argue how the proposed architecture can overcome integration challenges. Through a real-life scenario, an intra-operative medical image viewer, we demonstrate how the proposed framework can be used in practice to define user interfaces in collaborative environments, where the behavior and the system response can be adapted based on the current workflow stage and individual user requirements. Finally, we demonstrate how the defined interface can be manipulated using a high-level visual programming interface. The extensibility of the proposed architecture makes it applicable to a wide range of scenarios.},
 acmid = {2167040},
 address = {New York, NY, USA},
 author = {Bigdelou, Ali and Schwarz, Loren and Benz, Tobias and Navab, Nassir},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167040},
 isbn = {978-1-4503-1048-2},
 keyword = {context awareness, framework, gesture-based interaction},
 link = {http://doi.acm.org/10.1145/2166966.2167040},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {335--336},
 publisher = {ACM},
 series = {IUI '12},
 title = {A Flexible Platform for Developing Context-aware 3D Gesture-based Interfaces},
 year = {2012}
}


@inproceedings{Bahram:2012:CVD:2166966.2167009,
 abstract = {CAVIAR is designed to aid people with vision impairment in locating, identifying, and acquiring objects in their peripersonal space. A mobile phone, worn on the chest, captures video in front of the user; the computer vision component locates the user's hand and objects in the video stream. The auditory component informs the user about the presence of objects. On user confirmation, the reaching component sends signals to vibrotactile actuators on the user's wristband, guiding the hand to a specific object. This paper describes an end-to-end prototype of CAVIAR and its formative evaluation.},
 acmid = {2167009},
 address = {New York, NY, USA},
 author = {Bahram, Sina and Chakraborty, Arpan and St. Amant, Robert},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167009},
 isbn = {978-1-4503-1048-2},
 keyword = {accessibility, haptic, mobile, tactile},
 link = {http://doi.acm.org/10.1145/2166966.2167009},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {245--248},
 publisher = {ACM},
 series = {IUI '12},
 title = {CAVIAR: A Vibrotactile Device for Accessible Reaching},
 year = {2012}
}


@inproceedings{Camara:2012:FIL:2166966.2167020,
 abstract = {On September 19th 2011, Facebook introduced "Intelligent Lists" which are Friends Lists (FL) automatically created and pre-filled based on users' and their contacts' profiles information (education, work, city of living, kin, etc.). In early 2011, we conducted a study on contact management in Facebook in order to understand users' real needs. Outcomes from this study suggest several recommendations, some of which can be found today in the Facebook Intelligent Lists. This paper provides explanations on the recent evolution in Facebook contact management. The user study involved 148 participants. From their Facebook accounts, we retrieved 340 Friends Lists and 347 family ties. In the overall, the study has led to numerous interesting outocomes. In this paper, we focus on those related to Friends Lists and, particularly, on recommendations that have not yet been implemented in Facebook.},
 acmid = {2167020},
 address = {New York, NY, USA},
 author = {Camara, Fatoumata and Calvary, Ga\"{e}lle and Demumieux, Rachel and Mandran, Nadine},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167020},
 isbn = {978-1-4503-1048-2},
 keyword = {contact management, facebook, recommendations, sns},
 link = {http://doi.acm.org/10.1145/2166966.2167020},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {289--292},
 publisher = {ACM},
 series = {IUI '12},
 title = {Where Do Facebook Intelligent Lists Come from?},
 year = {2012}
}


@inproceedings{Forsblom:2012:OBS:2166966.2167011,
 abstract = {Advances in positioning technologies have resulted in a surge of location-based recommendation systems for mobile devices. A central challenge in these systems is to avoid the so-called filter bubble effect, i.e., that people are not only exposed to information that is in line with their personal ecosystem, but that they can also discover novel and otherwise interesting content. We present results from a field study of a mobile recommendation system that has been aimed to support serendipitous discovery of events at an urban culture festival. Results from the study indicate that suitably designed recommendations together with access to relevant external information sources can lead to serendipitous discovery of new content, such as new artists, bands or individual songs. Our results also indicate that proximity has little effect on the effectiveness of serendipitous recommendations.},
 acmid = {2167011},
 address = {New York, NY, USA},
 author = {Forsblom, Andreas and Nurmi, Petteri and \AAman, Pirkka and Liikkanen, Lassi},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167011},
 isbn = {978-1-4503-1048-2},
 keyword = {mobile recommendations, serendipity, urban computing},
 link = {http://doi.acm.org/10.1145/2166966.2167011},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {253--256},
 publisher = {ACM},
 series = {IUI '12},
 title = {Out of the Bubble: Serendipitous Even Recommendations at an Urban Music Festival},
 year = {2012}
}


@inproceedings{Vatavu:2012:OAF:2166966.2167022,
 abstract = {One Feature (1F) is a simple and intuitive pruning strategy that reduces considerably the amount of computations required by Nearest-Neighbor gesture classifiers while still preserving the high recognition rate. Performance results are reported for 1F by analyzing a large set of candidate features showing recognition rates of 99% with a peak reduction in computations of 70%. 1F is easy to implement, flexible with respect to the choice of the feature, and exploits the intuition of the designer by exposing clear inner workings.},
 acmid = {2167022},
 address = {New York, NY, USA},
 author = {Vatavu, Radu-Daniel},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167022},
 isbn = {978-1-4503-1048-2},
 keyword = {classification, comparing classifiers, feature selection, gesture descriptors, gesture recognition, nearest neighbor, pruning, training set},
 link = {http://doi.acm.org/10.1145/2166966.2167022},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {297--300},
 publisher = {ACM},
 series = {IUI '12},
 title = {1F: One Accessory Feature Design for Gesture Recognizers},
 year = {2012}
}


@inproceedings{Gilroy:2012:PIS:2166966.2167039,
 abstract = {The dominant interaction paradigm in Interactive Storytelling (IS) systems so far has been active interventions by the user by means of a variety of modalities. PINTER is an IS system that uses physiological inputs - surface electromyography (EMG) and galvanic skin response (GSR) [1] - as a form of passive interaction, opening up the possibility of the use of traditional filmic techniques [2, 3] to implement IS without requiring immersion-breaking interactive responses. The goal of this demonstration is to illustrate the ways in which passive interaction combined with filmic visualisation, dialogue and music, and a plan-based narrative generation approach can form a new basis for an adaptive interactive narrative.},
 acmid = {2167039},
 address = {New York, NY, USA},
 author = {Gilroy, Stephen and Porteous, Julie and Charles, Fred and Cavazza, Marc},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167039},
 isbn = {978-1-4503-1048-2},
 keyword = {interactive storytelling, physiological input},
 link = {http://doi.acm.org/10.1145/2166966.2167039},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {333--334},
 publisher = {ACM},
 series = {IUI '12},
 title = {PINTER: Interactive Storytelling with Physiological Input},
 year = {2012}
}


@inproceedings{Mahmud:2012:IWU:2166966.2167058,
 abstract = {Massive amounts of data are being generated on social media sites, such as Twitter and Facebook. People from all walks of life share data about social events, express opinions, discuss their interests, publicize businesses, recommend products, and, explicitly or implicitly, reveal personal information. This workshop will focus on the use of social media data for creating models of individual users from the content that they publish. Deeper understanding of user behavior and associated attributes can benefit a wide range of intelligent applications, such as social recommender systems and expert finders, as well as provide the foundation in support of novel user interfaces (e.g., actively engaging the crowd in mixed-initiative question-answering systems). These applications and interfaces may offer significant benefits to users across a wide variety of domains, such as retail, government, healthcare and education. User modeling from public social media data may also reveal information that users would prefer to keep private. Such concerns are particularly important because individuals do not have complete control over the information they share about themselves. For example, friends of a user may inadvertently divulge private information about that user in their own posts. In this workshop we will also discuss possible mechanisms that users might employ to monitor what information has been revealed about themselves on social media and obfuscate any sensitive information that has been accidentally revealed.},
 acmid = {2167058},
 address = {New York, NY, USA},
 author = {Mahmud, Jalal and Nichols, Jeffrey and Zhou, Michelle},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167058},
 isbn = {978-1-4503-1048-2},
 keyword = {social media, user modeling},
 link = {http://doi.acm.org/10.1145/2166966.2167058},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {397--400},
 publisher = {ACM},
 series = {IUI '12},
 title = {1st International Workshop on User Modeling from Social Media},
 year = {2012}
}


@inproceedings{Dias:2012:MLH:2166966.2167013,
 abstract = {Nowadays, people spend time using services to track their music listening history. Although these services provide statistics and small graphics/charts, they are mainly used to record and to allow direct access to the information, not providing any visualization and exploration functionality. In this paper we describe a new approach for browsing and visualizing music listening histories, which combines a timeline-based visualization, with a set of synchronized-views and an interactive filtering mechanism to provide a flexible and easy to use solution. This was complemented with brushing and highlighting techniques that allow users to observe trends on artists, albums and tracks listening. Experimental evaluation with users revealed that they were able to complete all the proposed tasks with a low error rate, and that they found the solution easy to use. Moreover, users liked our approach for browsing and exploring listening histories, emphasizing its flexibility and effectiveness, and founding the full experience engaging and rewarding.},
 acmid = {2167013},
 address = {New York, NY, USA},
 author = {Dias, Ricardo and Fonseca, Manuel J. and Gon\c{c}alves, Daniel},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167013},
 isbn = {978-1-4503-1048-2},
 keyword = {interactive browsing, listening history, visualization},
 link = {http://doi.acm.org/10.1145/2166966.2167013},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {261--264},
 publisher = {ACM},
 series = {IUI '12},
 title = {Music Listening History Explorer: An Alternative Approach for Browsing Music Listening History Habits},
 year = {2012}
}


@inproceedings{Schwartz:2012:WLA:2166966.2167057,
 abstract = {The workshop explores the interactions between location awareness and Dual/Mixed Reality in smart environments and the impact on culture and society. The main scope of this workshop is: How can the Dual Reality paradigm be used to improve applications in smart environments and which new possibilities are opened up by these paradigms? This includes positioning methods and location-based services using the DR paradigm, such as navigation services and group interaction services (location-based social signal processing). The workshop is also open to discuss sensor and actuator technologies that may help to realize the synchronization of the virtual and real world. The main scope of this workshop is: How can the Dual Reality paradigm be used to improve location-based and socially-aware services and other applications in smart environments?},
 acmid = {2167057},
 address = {New York, NY, USA},
 author = {Schwartz, Tim and Kahl, Gerrit and Pulkkinen, Teemu and Nurmi, Petteri and Dim, Eyal and Applin, Sally},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167057},
 isbn = {978-1-4503-1048-2},
 keyword = {dual reality, location-based services, mixed reality, positioning, social anthropology},
 link = {http://doi.acm.org/10.1145/2166966.2167057},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {393--396},
 publisher = {ACM},
 series = {IUI '12},
 title = {2Nd Workshop on Location Awareness for Mixed and Dual Reality (LAMDa'12)},
 year = {2012}
}


@inproceedings{Gomer:2012:EEC:2166966.2167050,
 abstract = {In recent years, we've seen a huge growth in the level of user-supplied reviews posted online. These reviews range from feedback on eBay or comments on sites such as YouTube, to social bookmarking sites like StumbleUpon that allow users to comment on almost any page on the web. I'm interested in how these comments are incorporated into evaluative judgements by the users that read them, and how we can improve them through better user interfaces in order to maximise their value to other users. The work draws on psychology and neurology, as well as ideas around credibility from information science, to design and test the impact of intelligent interface changes and behaviour on review composition and ascertain how the composition of a review can make it more or less useful.},
 acmid = {2167050},
 address = {New York, NY, USA},
 author = {Gomer, Richard},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167050},
 isbn = {978-1-4503-1048-2},
 keyword = {comment, feedback, nudge, qualitative, review},
 link = {http://doi.acm.org/10.1145/2166966.2167050},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {367--370},
 publisher = {ACM},
 series = {IUI '12},
 title = {Eliciting Evaluative Comments from Users in Web 2.0 Scenarios},
 year = {2012}
}


@inproceedings{Zhou:2012:FSM:2166966.2167001,
 abstract = {REACH is an intelligent, people-finding system that helps users to find someone in their social directory, especially those whom they do not fully remember or barely know. It analyzes a user's communication and social networking data to automatically extract all the contacts and derive multiple facets to characterize each contact in relation to the user. It then employs a personalized, faceted search to retrieve and present a ranked list of matched contacts based on their properties. A preliminary evaluation shows the effectiveness of our approach.},
 acmid = {2167001},
 address = {New York, NY, USA},
 author = {Zhou, Michelle and Zhang, Wei and Smith, Barton and Varga, Erika and Farias, Martin and Badenes, Hernan},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167001},
 isbn = {978-1-4503-1048-2},
 keyword = {contact, multifaceted people finding, social directory},
 link = {http://doi.acm.org/10.1145/2166966.2167001},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {203--206},
 publisher = {ACM},
 series = {IUI '12},
 title = {Finding Someone in My Social Directory Whom I Do Not Fully Remember or Barely Know},
 year = {2012}
}


@inproceedings{Szekely:2012:IUA:2166966.2167015,
 abstract = {Humans have difficulty evaluating the effects of uncertainty on schedules. People often mitigate the effects of uncertainty by adding slack based on experience and non-stochastic analyses such as the critical path method (CPM). This is costly as it leads to longer than necessary schedules, and can be ineffective without a clear understanding of where slack is needed. COMPASS is an interactive real-time tool that analyzes schedule uncertainty for a stochastic task network. An important feature is that it concurrently calculates stochastic critical paths and critical tasks. COMPASS visualizes this information on top of a traditional Gantt view, giving users insight into how delays caused by uncertain durations propagate down the schedule. Evaluations with 10 users show that users can use COMPASS to answer a variety of questions about the possible evolutions of a schedule (e.g., what is the likelihood that all activities will complete before a given date?)},
 acmid = {2167015},
 address = {New York, NY, USA},
 author = {Szekely, Pedro and Chang, Yu-Han and Maheswaran, Rajiv and Wang, Yan and Cheng, Huihui and Singh, Karan},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167015},
 isbn = {978-1-4503-1048-2},
 keyword = {gantt chart, monte carlo simulation, plan understanding, schedule visualization, uncertainty analysis, visualization},
 link = {http://doi.acm.org/10.1145/2166966.2167015},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {269--272},
 publisher = {ACM},
 series = {IUI '12},
 title = {Interactive Uncertainty Analysis},
 year = {2012}
}


@inproceedings{Hussein:2012:WSM:2166966.2167059,
 abstract = {The International Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS 2012) aims to identify emerging trends in interactive system design using semantic models.},
 acmid = {2167059},
 address = {New York, NY, USA},
 author = {Hussein, Tim and Lukosch, Stephan and Paulheim, Heiko and Ziegler, J\"{u}rgen and Calvary, Ga\"{e}lle},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167059},
 isbn = {978-1-4503-1048-2},
 keyword = {adaptive interactive systems, interface design, model-driven user interfaces, semantic models, usability},
 link = {http://doi.acm.org/10.1145/2166966.2167059},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {401--404},
 publisher = {ACM},
 series = {IUI '12},
 title = {3rd Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS): (SEMAIS)},
 year = {2012}
}


@inproceedings{Sonntag:2012:RMD:2166966.2167031,
 abstract = {With RadSpeech, we aim to build the next generation of intelligent, scalable, and user-friendly semantic search interfaces for the medical imaging domain, based on semantic technologies. Ontology-based knowledge representation is used not only for the image contents, but also for the complex natural language understanding and dialogue management process. This demo shows a speech-based annotation system for radiology images and focuses on a new and effective way to annotate medical image regions with a specific medical, structured, diagnosis while using speech and pointing gestures on the go.},
 acmid = {2167031},
 address = {New York, NY, USA},
 author = {Sonntag, Daniel and Schulz, Christian and Reuschling, Christian and Galarraga, Luis},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167031},
 isbn = {978-1-4503-1048-2},
 keyword = {healthcare, mobility, speech dialogue},
 link = {http://doi.acm.org/10.1145/2166966.2167031},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {317--318},
 publisher = {ACM},
 series = {IUI '12},
 title = {RadSpeech's Mobile Dialogue System for Radiologists},
 year = {2012}
}


@inproceedings{Bunt:2012:EAI:2166966.2166996,
 abstract = {Intelligent interactive systems (IIS) have great potential to improve users' experience with technology by tailoring their behaviour and appearance to users' individual needs; however, these systems, with their complex algorithms and dynamic behaviour, can also suffer from a lack of comprehensibility and transparency. We present the results of two studies examining the comprehensibility of, and desire for explanations with deployed, low-cost IIS. The first study, a set of interviews with 21 participants, reveals that i) comprehensibility is not always dependent on explanations, and ii) the perceived cost of viewing explanations tends to outweigh the anticipated benefits. Our second study, a two-week diary study with 14 participants, confirms these findings in the context of daily use, with participants indicating a desire for an explanation in only 7% of diary entries. We discuss the implications of our findings for the design of explanation facilities.},
 acmid = {2166996},
 address = {New York, NY, USA},
 author = {Bunt, Andrea and Lount, Matthew and Lauzon, Catherine},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166996},
 isbn = {978-1-4503-1048-2},
 keyword = {comprehensibility, diary studies, explanations, qualitative evaluations, recommender systems, transparency},
 link = {http://doi.acm.org/10.1145/2166966.2166996},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {169--178},
 publisher = {ACM},
 series = {IUI '12},
 title = {Are Explanations Always Important?: A Study of Deployed, Low-cost Intelligent Interactive Systems},
 year = {2012}
}


@inproceedings{Leiva:2012:IUI:2166966.2167028,
 abstract = {This paper demonstrates a general framework to restyle UI widgets, in order to adapt them to the user behavior. Different implementation examples illustrate its feasibility. The value of this methodology comes from the fact that it is suited to any application language or toolkit supporting structured data hierarchies and style sheets; e.g., interfaces created in HTML, XUL, Flex/AIR (ActionScript), or Java. As described in the paper, an explicit end user intervention is not required, and changes are gradually applied so that they are not intrusive for the user.},
 acmid = {2167028},
 address = {New York, NY, USA},
 author = {Leiva, Luis},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167028},
 isbn = {978-1-4503-1048-2},
 keyword = {adaptive interfaces, implicit interaction, redesign},
 link = {http://doi.acm.org/10.1145/2166966.2167028},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {311--312},
 publisher = {ACM},
 series = {IUI '12},
 title = {Interaction-based User Interface Redesign},
 year = {2012}
}


@inproceedings{Antonelli:2012:WAW:2166966.2167033,
 abstract = {Wanteat is a framework and a suite of applications which allow users to interact with and explore mixed social networks of smart objects and people in the gastronomy domain, thus promoting the cultural heritage of a territory. Wanteat interaction model is based on the concept of a "wheel" [1].},
 acmid = {2167033},
 address = {New York, NY, USA},
 author = {Antonelli, Fabrizio and Biamino, Giulia and Carmagnola, Francesca and Cena, Federica and Chiabrando, Elisa and Console, Luca and Cuciti, Vincenzo and Demichelis, Matteo and Fassio, Franco and Franceschi, Fabrizio and Furnari, Roberto and Gena, Cristina and Geymonat, Marina and Grimaldi, Piercarlo and Grillo, Pierluigi and Guercio, Elena and Likavec, Silvia and Lombardi, Ilaria and Mana, Dario and Marcengo, Alessandro and Mioli, Michele and Mirabelli, Mario and Perrero, Monica and Picardi, Claudia and Protti, Federica and Rapp, Amon and Sandon, Roberta and Simeoni, Rossana and Dupr{\'e}, Daniele Theseider and Torre, Ilaria and Toso, Andrea and Torta, Fabio and Vernero, Fabiana},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167033},
 isbn = {978-1-4503-1048-2},
 keyword = {cultural heritage, gastronomy, mobile applications, playful interaction, smart objects, social web of things},
 link = {http://doi.acm.org/10.1145/2166966.2167033},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {321--322},
 publisher = {ACM},
 series = {IUI '12},
 title = {Wheeling Around with Wanteat: Exploring Mixed Social Networks in the Gastronomy Domain},
 year = {2012}
}


@inproceedings{Feld:2012:MTP:2166966.2166974,
 abstract = {The next big step in embedded, mobile speech recognition will be to allow completely free input as it is needed for messaging like SMS or email. However, unconstrained dictation remains error-prone, especially when the environment is noisy. In this paper, we compare different methods for improving a given free-text dictation system used to enter textbased messages in embedded mobile scenarios, where distraction, interaction cost, and hardware limitations enforce strict constraints over traditional scenarios. We present a corpus-based evaluation, measuring the trade-off between improvement of the word error rate versus the interaction steps that are required under various parameters. Results show that by post-processing the output of a "black box" speech recognizer (e.g. a web-based speech recognition service), a reduction of word error rate by 55% (10.3% abs.) can be obtained. For further error reduction, however, a richer representation of the original hypotheses (e.g. lattice) is necessary.},
 acmid = {2166974},
 address = {New York, NY, USA},
 author = {Feld, Michael and Momtazi, Saeedeh and Freigang, Farina and Klakow, Dietrich and M\"{u}ller, Christian},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166974},
 isbn = {978-1-4503-1048-2},
 keyword = {automotive, error correction, messaging, speech recognition},
 link = {http://doi.acm.org/10.1145/2166966.2166974},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {37--40},
 publisher = {ACM},
 series = {IUI '12},
 title = {Mobile Texting: Can post-ASR Correction Solve the Issues? An Experimental Study on Gain vs. Costs},
 year = {2012}
}


@inproceedings{Bastos:2012:DFU:2166966.2167026,
 abstract = {In the character animation industry, animators use facial UI's to animate a character's face. A facial UI provides widgets and handles that the animator interacts with to control the character's facial regions. This paper presents a facial UI design approach to control the animation of the six basic facial expressions of the anthropomorphic face. The design is based in square shaped widgets holding circular handles that allow the animator to produce the muscular activity relative to the basic facial expressions. We have implemented a prototype of the facial UI design in the Blender open-source animation software and did a preliminary pilot study with three animators. Two parameters were evaluated: the number of clicks and the time taken to animate the six basic facial expressions. The study reveals there was little variation in the values each animator marked for both parameters, despite the natural difference in their creative performance.},
 acmid = {2167026},
 address = {New York, NY, USA},
 author = {Bastos, Pedro and Alvarez Blanco, Xenxo and Orvalho, Ver\'{o}nica},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167026},
 isbn = {978-1-4503-1048-2},
 keyword = {facial animation, handles, user interfaces, widgets},
 link = {http://doi.acm.org/10.1145/2166966.2167026},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {307--308},
 publisher = {ACM},
 series = {IUI '12},
 title = {A Demo of a Facial UI Design Approach for Digital Artists},
 year = {2012}
}


@inproceedings{Nichols:2012:SSE:2166966.2166999,
 abstract = {The status updates posted to social networks, such as Twitter and Facebook, contain a myriad of information about what people are doing and watching. During events, such as sports games, many updates are sent describing and expressing opinions about the event. In this paper, we describe an algorithm that generates a journalistic summary of an event using only status updates from Twitter as a source. Temporal cues, such as spikes in the volume of status updates, are used to identify the important moments within an event, and a sentence ranking method is used to extract relevant sentences from the corpus of status updates describing each important moment within an event. We evaluate our algorithm compared to human-generated summaries and the previous best summarization algorithm, and find that the results of our method are superior to the previous algorithm and approach the readability and grammaticality of the human-generated summaries.},
 acmid = {2166999},
 address = {New York, NY, USA},
 author = {Nichols, Jeffrey and Mahmud, Jalal and Drews, Clemens},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166999},
 isbn = {978-1-4503-1048-2},
 keyword = {implicit crowdsourcing, journalism, social media, status updates},
 link = {http://doi.acm.org/10.1145/2166966.2166999},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {189--198},
 publisher = {ACM},
 series = {IUI '12},
 title = {Summarizing Sporting Events Using Twitter},
 year = {2012}
}


@inproceedings{Lu:2012:EMA:2166966.2167000,
 abstract = {We present Enterprise Priority Inbox Classifier (EPIC), an automatic personalized email prioritization system based on a topic-based user model built from the user's email data and relevant enterprise information. The user model encodes the user's topics of interest and email processing behaviors (e.g. read/reply/file) at the granularity of pair-wise interactions between the user and each of his/her email contacts. Given a new message, the user model is used in combination with the message metadata and content to determine the values of a set of contextual features. Contextual features include people-centric features representing information about the user's interaction history and relationship with the email sender, as well as message-centric features focusing on the properties of the message itself. Based on these feature values, EPIC uses a dynamic strategy to combine a global priority classifier with a user-specific classifier for determining the message's priority. An evaluation of EPIC based on 2,064 annotated email messages from 11 users, using 10-fold cross-validation, showed that the system achieves an average accuracy of 81.3%. The user-specific classifier contributed an improvement of 11.5%. Lastly we report on findings regarding the relative value of different contextual features for email prioritization.},
 acmid = {2167000},
 address = {New York, NY, USA},
 author = {Lu, Jie and Wen, Zhen and Pan, Shimei and Lai, Jennifer},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167000},
 isbn = {978-1-4503-1048-2},
 keyword = {email, enterprise, prioritization, priority inbox, user model},
 link = {http://doi.acm.org/10.1145/2166966.2167000},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {199--202},
 publisher = {ACM},
 series = {IUI '12},
 title = {EPIC: A Multi-tiered Approach to Enterprise Email Prioritization},
 year = {2012}
}


@inproceedings{Said:2012:KFU:2166966.2167034,
 abstract = {Collaborative Filtering Recommender Systems come in a wide variety of variants. In this paper we present a system for visualizing and comparing recommendations provided by different collaborative recommendation algorithms. The system utilizes a set of context-aware, hybrid, and other collaborative filtering solutions in order to generate various recommendations from which its users can pick those corresponding best to their current situation (i.e. context). All user interaction is fed back to the system in order to additionally improve the quality of the recommendations. Additionally, users can explicitly ask the system to treat certain recommenders as more important than others, or disregard them completely if the list of recommended movies is not to their liking.},
 acmid = {2167034},
 address = {New York, NY, USA},
 author = {Said, Alan and De Luca, Ernesto William and Kille, Benjamin and Jain, Brijnesh and Micus, Immo and Albayrak, Sahin},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167034},
 isbn = {978-1-4503-1048-2},
 keyword = {analysis, context-awareness, evaluation, human factors, movie recommendation, personalization, recommender systems, user-centric evaluation},
 link = {http://doi.acm.org/10.1145/2166966.2167034},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {323--324},
 publisher = {ACM},
 series = {IUI '12},
 title = {KMulE: A Framework for User-based Comparison of Recommender Algorithms},
 year = {2012}
}


@inproceedings{Martinez-Gomez:2012:QAI:2166966.2167055,
 abstract = {Eye-tracking devices find applications in human-machine interaction, hypothesis testing in psycholinguistic and usability studies, relevant feature extraction when designing models related to human behavior and to build user-centered information systems. We aim at providing a general and robust framework to do quantitative analysis and inference using data collected by eye-trackers when users read text. To achieve this objective, first the accuracy of eye-trackers has to be increased beyond sensor capabilities by using information from the content or the structure of the text. Then, natural language processing techniques will be used to process text appearing on the screen and the recognized reading word sequence. Within this framework, it will be possible to better understand user's intentions, record knowledge acquisition and predict information needs. The intention is to build a user model and user model of the World from texts that users have read. This opens the door to more personalized systems with on-line adaptation capabilities.},
 acmid = {2167055},
 address = {New York, NY, USA},
 author = {Martinez-Gomez, Pascual},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167055},
 isbn = {978-1-4503-1048-2},
 keyword = {eye-tracking, natural language processing, quantitative approaches, user-centered systems},
 link = {http://doi.acm.org/10.1145/2166966.2167055},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {389--392},
 publisher = {ACM},
 series = {IUI '12},
 title = {Quantitative Analysis and Inference on Gaze Data Using Natural Language Processing Techniques},
 year = {2012}
}


@inproceedings{Ajmera:2012:ACC:2166966.2167017,
 abstract = {Word clouds are extensively used to present a summary of the prominent words in a document on the World Wide Web. Such clouds give the user an idea about the content of the document. In this paper we present a mechanism to create and render an audio cloud for audio content. Such audio clouds are expected to provide a similar summary of the audio documents. They have wide applicability in various domains, especially for low-literate users who currently do not use the Internet but interact with audio-based systems. Detecting words from an audio content is challenging, especially if the audio is in languages for which a speech recognition system does not exist. We present a language-independent mechanism to detect frequently occurring words within an audio document. We then present four ways to render these words that form an audio cloud. The four prototypes for rendering the audio cloud are based on varying the amplitude, the voice quality, echo and the repetition of audio words. An evaluation study conducted across 32 users suggests that literate and low-literate users easily understand the concept of audio cloud.},
 acmid = {2167017},
 address = {New York, NY, USA},
 author = {Ajmera, Jitendra and Deshmukh, Om D and Jain, Anupam and Nanavati, Amit Anil and Rajput, Nitendra and Srivastava, Saurabh},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167017},
 isbn = {978-1-4503-1048-2},
 keyword = {audio cloud, language independent, low-literate},
 link = {http://doi.acm.org/10.1145/2166966.2167017},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {277--280},
 publisher = {ACM},
 series = {IUI '12},
 title = {Audio Cloud: Creation and Rendering},
 year = {2012}
}


@inproceedings{Kristensson:2012:PCP:2166966.2166972,
 abstract = {We empirically compare five different publicly-available phrase sets in two large-scale (N = 225 and N = 150) crowdsourced text entry experiments. We also investigate the impact of asking participants to memorize phrases before writing them versus allowing participants to see the phrase during text entry. We find that asking participants to memorize phrases increases entry rates at the cost of slightly increased error rates. This holds for both a familiar and for an unfamiliar text entry method. We find statistically significant differences between some of the phrase sets in terms of both entry and error rates. Based on our data, we arrive at a set of recommendations for choosing suitable phrase sets for text entry evaluations.},
 acmid = {2166972},
 address = {New York, NY, USA},
 author = {Kristensson, Per Ola and Vertanen, Keith},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166972},
 isbn = {978-1-4503-1048-2},
 keyword = {crowdsourcing, keyboards, phrase sets, text entry},
 link = {http://doi.acm.org/10.1145/2166966.2166972},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {29--32},
 publisher = {ACM},
 series = {IUI '12},
 title = {Performance Comparisons of Phrase Sets and Presentation Styles for Text Entry Evaluations},
 year = {2012}
}


@inproceedings{Nobrega:2012:SIR:2166966.2167030,
 abstract = {In this work we present an interactive prototype for an interface that supports the interaction with virtual objects integrated in a real life scenario. The user can reshape or re-design a real space with virtual objects using several pictures of the desired space. The images are analyzed for known features such as surfaces, edges, floor location and room orientation. Using these elements, it is possible to devise an augmented reality system where the user can add virtual objects to the scenario. The smart interface attaches the objects to the scene elements (e.g., floor) automatically. The current demo loads images from user files or takes a snapshot directly from the camera. The high-level features are automatically detected, but can be manually adjusted. A use-case example of an augmented reality application is presented.},
 acmid = {2167030},
 address = {New York, NY, USA},
 author = {N\'{o}brega, Rui and Correia, Nuno},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167030},
 isbn = {978-1-4503-1048-2},
 keyword = {augmented reality, computer vision, hci, image recognition},
 link = {http://doi.acm.org/10.1145/2166966.2167030},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {315--316},
 publisher = {ACM},
 series = {IUI '12},
 title = {Smart Interface for Reshaping Photos in 3D},
 year = {2012}
}


@inproceedings{Buschbeck:2012:WUI:2166966.2167038,
 abstract = {Intelligent technologies have been used in various ways to support more effective representation and processing of media and documents in terms of the events that they refer to. This demo presents some innovations that have been introduced in a web-based interface to a repository of media and documents that are organized in terms of hierarchically structured events.},
 acmid = {2167038},
 address = {New York, NY, USA},
 author = {Buschbeck, Sven and Jameson, Anthony and Schneeberger, Tanja and Woll, Robin},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167038},
 isbn = {978-1-4503-1048-2},
 keyword = {events, interaction, visualization},
 link = {http://doi.acm.org/10.1145/2166966.2167038},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {331--332},
 publisher = {ACM},
 series = {IUI '12},
 title = {A Web-based User Interface for Interaction with Hierarchically Structured Events},
 year = {2012}
}


@inproceedings{Paulheim:2012:EUL:2166966.2167029,
 abstract = {While statistics are omnipresent, e.g., depicting the corruption in different countries, it is often not trivial to find the explanation for a statistical effect, e.g., why the corruption is higher in some countries than in others. The necessary facts that can explain a statistic are often not contained in the statistics file itself. This demo shows Explain-a-LOD, a tool for generating possible explanations for statistics from Linked Open Data. The tool accepts statistical data as input, and it automatically retrieves data from the Linked Open Data cloud and generates possible explanations.},
 acmid = {2167029},
 address = {New York, NY, USA},
 author = {Paulheim, Heiko},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167029},
 isbn = {978-1-4503-1048-2},
 keyword = {data analysis, linked open data, semantic web, statistics},
 link = {http://doi.acm.org/10.1145/2166966.2167029},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {313--314},
 publisher = {ACM},
 series = {IUI '12},
 title = {Explain-a-LOD: Using Linked Open Data for Interpreting Statistics},
 year = {2012}
}


@inproceedings{Cheema:2012:PSI:2166966.2166977,
 abstract = {We present PhysicsBook, a prototype system that enables users to solve physics problems using a sketch-based interface and then animates any diagram used in solving the problem to show that the solution is correct. PhysicsBook recognizes the diagrams in the solution and infers relationships among diagram components through the recognition of mathematics and annotations such as arrows and dotted lines. For animation, PhysicsBook uses a customized physics engine that provides entry points for hand-written mathematics and diagrams. We discuss the design of PhysicsBook, including details of algorithms for sketch recognition, inference of user intent and creation of animations based on the mathematics written by a user. Specifically, we describe how the physics engine uses domain knowledge to perform data transformations in instances where it cannot use a given equation directly. This enables PhysicsBook to deal with domains of problems that are not directly related to classical mechanics. We provide examples of scenarios of how PhysicsBook could be used as part of an intelligent tutoring system and discuss the strengths and weaknesses of our current prototype. Lastly, we present the findings of a preliminary usability study with five participants.},
 acmid = {2166977},
 address = {New York, NY, USA},
 author = {Cheema, Salman and LaViola, Joseph},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166977},
 isbn = {978-1-4503-1048-2},
 keyword = {inferring user intent, mathematical sketching, sketch recognition, sketch-based user interfaces},
 link = {http://doi.acm.org/10.1145/2166966.2166977},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {51--60},
 publisher = {ACM},
 series = {IUI '12},
 title = {PhysicsBook: A Sketch-based Interface for Animating Physics Diagrams},
 year = {2012}
}


@inproceedings{Kang:2012:MTS:2166966.2166998,
 abstract = {This paper presents and evaluates three computational models for recommending credible topic-specific information in Twitter. The first model focuses on credibility at the user level, harnessing various dynamics of information flow in the underlying social graph to compute a rating. The second model applies a content-based strategy to compute a finer-grained credibility score for individual tweets. Lastly, we discuss a third model which combines facets from both models in a hybrid method, using both averaging and filtering hybrid strategies. To evaluate our novel credibility models, we perform an evaluation on 7 topic specific data sets mined from the Twitter streaming API, with specific focus on a data set of 37K users who tweeted about the topic "Libya". Results show that the social model outperfoms hybrid and content-based prediction models in terms of predictive accuracy over a set of manually collected credibility ratings on the "Libya" dataset.},
 acmid = {2166998},
 address = {New York, NY, USA},
 author = {Kang, Byungkyu and O'Donovan, John and H\"{o}llerer, Tobias},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166998},
 isbn = {978-1-4503-1048-2},
 keyword = {credibility, data mining, microblogs, social networking, trust},
 link = {http://doi.acm.org/10.1145/2166966.2166998},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {179--188},
 publisher = {ACM},
 series = {IUI '12},
 title = {Modeling Topic Specific Credibility on Twitter},
 year = {2012}
}


@inproceedings{Sharmin:2012:SCC:2166966.2166992,
 abstract = {Reuse of existing presentation materials is prevalent among knowledge workers. However, finding the most appropriate material for reuse is challenging. Existing information management and search tools provide inadequate support for reuse due to their dependence on users' ability to effectively categorize, recall, and recognize existing materials. Based on our findings from an online survey and contextual interviews, we designed and implemented a slide-based contextual recommender, ConReP, for supporting reuse of presentation materials. ConReP utilizes a user-selected slide as a search-key, recommends materials based on similarity to the selected slide, and provides a local-context-based visual representation of the recommendations. Users input provides new insight into presentation reuse and reveals that slide-based search is more effective than keyword-based search, local-context-based visual representation helps in better recall and recognition, and shows the promise of this general approach of exploiting individual slides and local-context for better presentation reuse.},
 acmid = {2166992},
 address = {New York, NY, USA},
 author = {Sharmin, Moushumi and Bergman, Lawrence and Lu, Jie and Konuru, Ravi},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166992},
 isbn = {978-1-4503-1048-2},
 keyword = {contextual recommendation, local context, slide-based search, visual representation},
 link = {http://doi.acm.org/10.1145/2166966.2166992},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {129--138},
 publisher = {ACM},
 series = {IUI '12},
 title = {On Slide-based Contextual Cues for Presentation Reuse},
 year = {2012}
}


@inproceedings{Tiroshi:2012:GBU:2166966.2167051,
 abstract = {An overload in service applications and websites induced by ubiquitous connectivity has brought the need for personalization, as a way to cope with it. However, the need for providing every service with a user model calls for interoperable user models, since user details are scattered in many different systems (e.g., online services such as mail/banking/healthcare/ecommerce sites/social networks), each storing the user's details, preferences and history in different representations and data formats. Various approaches for user modeling interoperability were studied from different perspectives (general ontologies, personalized ontologies, mediation), but so far the challenges are yet to be met. This paper proposes a new way for representing user models, an abstracted graph based one, which will support both interoperability and advanced user modeling features.},
 acmid = {2167051},
 address = {New York, NY, USA},
 author = {Tiroshi, Amit},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167051},
 isbn = {978-1-4503-1048-2},
 keyword = {graphs, personalization, ubiquitous user modeling},
 link = {http://doi.acm.org/10.1145/2166966.2167051},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {371--374},
 publisher = {ACM},
 series = {IUI '12},
 title = {Graph Based User Modeling},
 year = {2012}
}


@inproceedings{Dennis:2012:QVP:2166966.2167016,
 abstract = {This paper describes how a set of stories, each conveying a personality trait from the Five Factor Model at a high or low level, were developed using Amazon's Mechanical Turk. These stories will be used to develop interfaces that adapt to personality using a User as Wizard method. The paper shows how difficult it is to construct stories that convey a single personality trait. It also shows how such stories can be constructed for most cases, and how Mechanical Turk can aid to achieve this.},
 acmid = {2167016},
 address = {New York, NY, USA},
 author = {Dennis, Matt and Masthoff, Judith and Mellish, Chris},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167016},
 isbn = {978-1-4503-1048-2},
 keyword = {adaptation, personality, user stories, validation},
 link = {http://doi.acm.org/10.1145/2166966.2167016},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {273--276},
 publisher = {ACM},
 series = {IUI '12},
 title = {The Quest for Validated Personality Trait Stories},
 year = {2012}
}


@inproceedings{Dong:2012:TIR:2166966.2166995,
 abstract = {User opinions and reviews are an important part of the modern web and all major e-commerce sites typically provide their users with the ability to provide and access customer reviews across their product catalog. Indeed this has become a vital part of the service provided by sites like Amazon and TripAdvisor, so much so that many of us will routinely check appropriate product reviews before making a purchase decision, regardless of whether we intend to purchase online or not. The importance of reviews has highlighted the need to help users to produce better reviews and in this paper we describe the development and evaluation of a Reviewer's Assistant for this purpose. We describe a browser plugin that is designed to work with major sites like Amazon and to provide users with suggestions as they write their reviews. These suggestions take the form of topics (e.g. product features) that a reviewer may wish to write about and the suggestions automatically adapt as the user writes their review. We describe and evaluate a number of different algorithms to identify useful topics to recommend to the user and go on to describe the results of a preliminary live-user trial.},
 acmid = {2166995},
 address = {New York, NY, USA},
 author = {Dong, Ruihai and McCarthy, Kevin and O'Mahony, Michael and Schaal, Markus and Smyth, Barry},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166995},
 isbn = {978-1-4503-1048-2},
 keyword = {browser plugin., intelligent user interfaces, text mining, writer's assistance},
 link = {http://doi.acm.org/10.1145/2166966.2166995},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {159--168},
 publisher = {ACM},
 series = {IUI '12},
 title = {Towards an Intelligent Reviewer's Assistant: Recommending Topics to Help Users to Write Better Product Reviews},
 year = {2012}
}


@inproceedings{Bandara:2012:SOS:2166966.2167036,
 abstract = {Over the last few years, the conventional brick and mortar business model has been challenged by the proliferation of smartphone-based shopping apps, which exploit the weaknesses of this conventional model. As an alternative to these apps, we have developed Ubira [1], a patent-pending service platform that allows healthy online/offline competition rather than merely exploiting the weaknesses. This business model provides brick and mortar shops a fair chance to compete with online stores while creating a seamless shopping experience for in-store customers based on an online/offline partnership. The main design challenge in Ubira has been to promote serendipity in shopping rather than bargain hunting, and integrate the legacy inventory systems of brick and mortar businesses into the platform. To overcome these challenges, we have made some critical design choices based on context awareness and seamful design methods.},
 acmid = {2167036},
 address = {New York, NY, USA},
 author = {Bandara, Udana},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167036},
 isbn = {978-1-4503-1048-2},
 keyword = {context awareness, mobile shopping interface, retailers},
 link = {http://doi.acm.org/10.1145/2166966.2167036},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {327--328},
 publisher = {ACM},
 series = {IUI '12},
 title = {Seamless Online/Offline Shopping Experience Design for In-store Customers},
 year = {2012}
}


@inproceedings{Johnston:2012:CMD:2166966.2167042,
 abstract = {Multimodal interaction allows users to specify commands using combinations of inputs from multiple different modalities. For example, in a local search application, a user might say "gas stations" while simultaneously tracing a route on a touchscreen display. In this demonstration, we describe the extension of our cloud-based speech recognition architecture to a Multimodal Semantic Interpretation System (MSIS) that supports processing of multimodal inputs streamed over HTTP. We illustrate the capabilities of the framework using Speak4itSM, a deployed mobile local search application supporting combined speech and gesture input. We provide interactive demonstrations of Speak4it on the iPhone and iPad and explain the challenges of supporting true multimodal interaction in a deployed mobile service.},
 acmid = {2167042},
 address = {New York, NY, USA},
 author = {Johnston, Michael and Ehlen, Patrick},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167042},
 isbn = {978-1-4503-1048-2},
 keyword = {gesture, multimodal, speech},
 link = {http://doi.acm.org/10.1145/2166966.2167042},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {339--340},
 publisher = {ACM},
 series = {IUI '12},
 title = {Collecting Multimodal Data in the Wild},
 year = {2012}
}


@inproceedings{Smith:2012:MLA:2166966.2167021,
 abstract = {Recent developments in machine listening present opportunities for innovative new paradigms for computer-human interaction. Voice recognition systems demonstrate a typical approach that conforms to event oriented control models. However, acoustic sound is continuous, and highly dimensional, presenting a rich medium for computer interaction. Unsupervised machine learning models present great potential for real-time machine listening and understanding of audio and sound data. We propose a method for harnessing unsupervised machine learning algorithms, Adaptive Resonance Theory specifically, in order to inform machine listening, build musical context information, and drive real-time interactive performance systems. We present the design and evaluation of this model leveraging the expertise of trained, improvising musicians.},
 acmid = {2167021},
 address = {New York, NY, USA},
 author = {Smith, Benjamin and Garnett, Guy},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167021},
 isbn = {978-1-4503-1048-2},
 keyword = {adaptive resonance theory, artificial intelligence, machine listening, music, unsupervised machine learning},
 link = {http://doi.acm.org/10.1145/2166966.2167021},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {293--296},
 publisher = {ACM},
 series = {IUI '12},
 title = {Machine Listening: Acoustic Interface with ART},
 year = {2012}
}


@inproceedings{Bigdelou:2012:ASI:2166966.2166981,
 abstract = {Computerized medical systems play a vital role in the operating room, however, sterility requirements and interventional workflow often make interaction with these devices challenging for surgeons. Typical solutions, such as delegating physical control of keyboard and mouse to assistants, add an undesirable level of indirection. We present a touchless, gesture-based interaction framework for the operating room that lets surgeons define a personalized set of gestures for controlling arbitrary medical computerized systems. Instead of using cameras for capturing gestures, we rely on a few wireless inertial sensors, placed on the arms of the surgeon, eliminating the dependence on illumination and line-of-sight. A discriminative gesture recognition approach based on kernel regression allows us to simultaneously classify performed gestures and to track the relative spatial pose within each gesture, giving surgeons fine-grained control of continuous parameters. An extensible software architecture enables a dynamic association of learned gestures to arbitrary intraoperative computerized systems. Our experiments illustrate the performance of our approach and encourage its practical applicability.},
 acmid = {2166981},
 address = {New York, NY, USA},
 author = {Bigdelou, Ali and Schwarz, Loren and Navab, Nassir},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166981},
 isbn = {978-1-4503-1048-2},
 keyword = {gesture-based interaction, inertial sensors, operating room},
 link = {http://doi.acm.org/10.1145/2166966.2166981},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {75--84},
 publisher = {ACM},
 series = {IUI '12},
 title = {An Adaptive Solution for Intra-operative Gesture-based Human-machine Interaction},
 year = {2012}
}


@inproceedings{Dong:2012:FDI:2166966.2167041,
 abstract = {User opinions and reviews are an important part of the modern web and all major e-commerce sites typically provide their users with the ability to provide and access customer reviews across their product catalog. The importance of reviews has driven the need to improve the review quality by providing interactive support for the reviewer and we will demonstrate the first version of an Intelligent Reviewer's Assistant for this purpose. Our browser plugin is designed to work with major sites like Amazon and to provide users with suggestions as they write their reviews. In particular, these suggestions take the form of topics (e.g. product features) that a reviewer may wish to write about and the suggestions automatically adapt as the user writes their review.},
 acmid = {2167041},
 address = {New York, NY, USA},
 author = {Dong, Ruihai and McCarthy, Kevin and O'Mahony, Michael and Schaal, Markus and Smyth, Barry},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167041},
 isbn = {978-1-4503-1048-2},
 keyword = {intelligent user interfaces, writer's assistance},
 link = {http://doi.acm.org/10.1145/2166966.2167041},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {337--338},
 publisher = {ACM},
 series = {IUI '12},
 title = {First Demonstration of the Intelligent Reviewer's Assistant},
 year = {2012}
}


@inproceedings{Kristensson:2012:CRO:2166966.2166983,
 abstract = {In this paper we present a new bimanual markerless gesture interface for 3D full-body motion tracking sensors, such as the Kinect. Our interface uses a probabilistic algorithm to incrementally predict users' intended one-handed and twohanded gestures while they are still being articulated. It supports scale and translation invariant recognition of arbitrarily defined gesture templates in real-time. The interface supports two ways of gesturing commands in thin air to displays at a distance. First, users can use one-handed and two-handed gestures to directly issue commands. Second, users can use their non-dominant hand to modulate single-hand gestures. Our evaluation shows that the system recognizes one-handed and two-handed gestures with an accuracy of 92.7%--96.2%.},
 acmid = {2166983},
 address = {New York, NY, USA},
 author = {Kristensson, Per Ola and Nicholson, Thomas and Quigley, Aaron},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166983},
 isbn = {978-1-4503-1048-2},
 keyword = {gesture recognition, motion tracking, wall-sized displays},
 link = {http://doi.acm.org/10.1145/2166966.2166983},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {89--92},
 publisher = {ACM},
 series = {IUI '12},
 title = {Continuous Recognition of One-handed and Two-handed Gestures Using 3D Full-body Motion Tracking Sensors},
 year = {2012}
}


@inproceedings{DemmansEpp:2012:TPJ:2166966.2166973,
 abstract = {Many people cannot communicate effectively with those around them. The causes vary but several tools and strategies can support their communication. These tools, which collectively fall under the banner of Assistive and Augmentative Communication (AAC), are rarely adaptive. Of those that are, few provide context-based or just-in-time vocabulary support to users even though the proliferation of smartphones makes this possible. To meet this need, we developed four algorithms to retrieve relevant vocabulary from Internet-based corpora. We used discourse completion tasks to evaluate each algorithm's ability to identify appropriate vocabulary across a set of specific contexts. The results indicate that our approach identifies appropriate context-specific words that complement general AAC vocabularies: when combined with a typical base vocabulary, the algorithms outperformed the support provided by the base vocabulary alone. They did this by adding small targeted vocabularies.},
 acmid = {2166973},
 address = {New York, NY, USA},
 author = {Demmans Epp, Carrie and Djordjevic, Justin and Wu, Shimu and Moffatt, Karyn and Baecker, Ronald M.},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166973},
 isbn = {978-1-4503-1048-2},
 keyword = {aac, adaptivity, vocabulary support},
 link = {http://doi.acm.org/10.1145/2166966.2166973},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {33--36},
 publisher = {ACM},
 series = {IUI '12},
 title = {Towards Providing Just-in-time Vocabulary Support for Assistive and Augmentative Communication},
 year = {2012}
}


@inproceedings{Martinez-Gomez:2012:IRT:2166966.2167012,
 abstract = {Applications using eye-tracking devices need a higher accuracy in recognition when the task reaches a certain complexity. Thus, more sophisticated methods to correct eye-tracking measurement errors are necessary to lower the penetration barrier of eye-trackers in unconstrained tasks. We propose to take advantage of the content or the structure of textual information displayed on the screen to build informed error-correction algorithms that generalize well. The idea is to use feature-based image registration techniques to perform a linear transformation of gaze coordinates to find a good alignment with text printed on the screen. In order to estimate the parameters of the linear transformation, three optimization strategies are proposed to avoid the problem of local minima, namely Monte Carlo, multi-resolution and multi-blur optimization. Experimental results show that a more precise alignment of gaze data with words on the screen can be achieved by using these methods, allowing a more reliable use of eye-trackers in complex and unconstrained tasks.},
 acmid = {2167012},
 address = {New York, NY, USA},
 author = {Martinez-Gomez, Pascual and Chen, Chen and Hara, Tadayoshi and Kano, Yoshinobu and Aizawa, Akiko},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167012},
 isbn = {978-1-4503-1048-2},
 keyword = {error correction, image registration, text-gaze alignment},
 link = {http://doi.acm.org/10.1145/2166966.2167012},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {257--260},
 publisher = {ACM},
 series = {IUI '12},
 title = {Image Registration for Text-gaze Alignment},
 year = {2012}
}


@inproceedings{Horiuchi:2012:VSL:2166966.2166989,
 abstract = {Theater is a collaborative art form that involves production team members with different specialties. Because theater involves various technical elements, such as stage design and lighting, the production team must work in cooperation among various departments to design a theatrical production. When planning a theatrical production, it is difficult to visualize the stage as a whole and to incorporate the ideas of production team members from various departments. In this paper, we propose a system for reproducing the theatrical stage by means of a virtual stage linked to a physical miniature stage. The miniature stage is presented on a tabletop interface, and the virtual stage is created by computer graphics to reflect the actions on the miniature stage in real time. By actually presenting theatrical production ideas in two spaces, users can more easily collaborate and gain a comprehensive view of the stage.},
 acmid = {2166989},
 address = {New York, NY, USA},
 author = {Horiuchi, Yosuke and Inoue, Tomoo and Okada, Ken-ichi},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166989},
 isbn = {978-1-4503-1048-2},
 keyword = {tabletop interface, tangible interface, theater, virtual space},
 link = {http://doi.acm.org/10.1145/2166966.2166989},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {109--118},
 publisher = {ACM},
 series = {IUI '12},
 title = {Virtual Stage Linked with a Physical Miniature Stage to Support Multiple Users in Planning Theatrical Productions},
 year = {2012}
}


@inproceedings{Matsumura:2012:UEE:2166966.2167025,
 abstract = {We present universal earphones that use both a proximity sensor and a skin conductance sensor and we demonstrate several implicit interaction techniques they achieve by automatically detecting the context of use. The universal earphones have two main features. The first involves detecting the left and right sides of ears, which provides audio to either ear, and the second involves detecting the shared use of earphones and this provides mixed stereo sound to both earphones. These features not merely free users from having to check the left and right sides of earphones, but they enable them to enjoy sharing stereo audio with other people.},
 acmid = {2167025},
 address = {New York, NY, USA},
 author = {Matsumura, Kohei and Sakamoto, Daisuke and Inami, Masahiko and Igarashi, Takeo},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167025},
 isbn = {978-1-4503-1048-2},
 keyword = {earphones, implicit interaction, intelligent interface},
 link = {http://doi.acm.org/10.1145/2166966.2167025},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {305--306},
 publisher = {ACM},
 series = {IUI '12},
 title = {Universal Earphones: Earphones with Automatic Side and Shared Use Detection},
 year = {2012}
}


@inproceedings{Satyanarayan:2012:UOS:2166966.2166987,
 abstract = {Large-scale display walls, and the high-resolution visualizations they support, promise to become ubiquitous. Natural interaction with them, especially in collaborative environments, is increasingly important and yet remains an on-going challenge. Part of the problem is a resolution mismatch between low-resolution input devices and high-resolution display walls. In addition, enabling concurrent use by multiple users is difficult - for example, how would this large workspace be managed for multiple users and what novel collaborative interactions could occur? In this paper, we present an overlay interface element superimposed on wall-display applications to help constrain interaction, focus attention on subsections of a display wall, and facilitate a collaborative multi-user workflow.},
 acmid = {2166987},
 address = {New York, NY, USA},
 author = {Satyanarayan, Arvind and Weibel, Nadir and Hollan, James},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166987},
 isbn = {978-1-4503-1048-2},
 keyword = {high-resolution ultra-scale displays, multi-scale interaction, multiuser interaction},
 link = {http://doi.acm.org/10.1145/2166966.2166987},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {105--108},
 publisher = {ACM},
 series = {IUI '12},
 title = {Using Overlays to Support Collaborative Interaction with Display Walls},
 year = {2012}
}


@inproceedings{Scott-Harden:2012:AFR:2166966.2167047,
 abstract = {Active Forms are interactive artefacts that are a focal point of attention for the user. Such devices are interactive and can change shape. They are embedded with both sensors and actuators and are a visualisation and embodiment of some application or service. To be more specific, Active Forms are defined as interactive products or devices that can render content thanks to perceptible changes to their physical form and appearance. We see Active Forms as ideal gateway for the interaction with and the control of Responsive Environments (RE) as defined in [1]. Tangible interaction is the precursor of Active Forms, it was essentially about coupling digital content and physical elements of an interface in an integrating combination. The content is about the internal state of the products and about some of the application(s) and service(s) they support. The tangible interaction focuses on the interface or systems that are physically embodied in the physical artifact. Tangible User Interfaces (TUI) are reactive devices that require a user input to change shape. Active Forms, on the other hand are interactive devices that change shape and appearance. The changes in the Active Forms are a result of either, user actions or internal actuators, both the physical form, such as shape or size, and the appearance, such as colour or temperature, can change. Within Active Forms, there is a balance to be had between the cognitive load on the user, the selection of modalities, the media bandwidth and the user attention. The aim being to have the Active Forms as the user focus of interaction and attention. We have listed below some of the key features of Active Forms: Active Forms are interactive devices that are both reactive to user actions and proactive in displaying information. Active Forms are a gateway to applications or services within the RE and there is a change to the internal state of the device. The user actions and the device reactions of an Active Form are merged and are spatially co-located. Active Forms act as their embodiment, as physical objects, Active Forms also have aesthetic value per se. § The changes in the Active Forms are a result of either, user actions or internal actuators, both the physical form, such as shape or size, and the appearance, such as colour or temperature, can change.},
 acmid = {2167047},
 address = {New York, NY, USA},
 author = {Scott-Harden, Simon},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167047},
 isbn = {978-1-4503-1048-2},
 keyword = {embedded interaction, interactive products, merged modalities, smart objects, tangible interaction, user experience},
 link = {http://doi.acm.org/10.1145/2166966.2167047},
 location = {Lisbon, Portugal},
 numpages = {6},
 pages = {353--358},
 publisher = {ACM},
 series = {IUI '12},
 title = {Active Forms for Responsive Environments},
 year = {2012}
}


@inproceedings{DeLuca:2012:WCR:2166966.2167061,
 abstract = {Context-aware information is widely available in various ways and is becoming more and more important for enhancing retrieval performance and recommendation results. The current main issue to cope with is not only recommending or retrieving the most relevant items and content, but defining them ad hoc. Other relevant issues include personalizing and adapting the information and the way it is displayed to the user's current situation and interests. Ubiquitous computing further provides new means for capturing user feedback on items and providing information.},
 acmid = {2167061},
 address = {New York, NY, USA},
 author = {De Luca, Ernesto William and B\"{o}hmer, Matthias and Said, Alan and Chi, Ed},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167061},
 isbn = {978-1-4503-1048-2},
 keyword = {context-awareness, information retrieval, recommender systems},
 link = {http://doi.acm.org/10.1145/2166966.2167061},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {409--412},
 publisher = {ACM},
 series = {IUI '12},
 title = {2Nd Workshop on Context-awareness in Retrieval and Recommendation: (CaRR 2012)},
 year = {2012}
}


@inproceedings{Gao:2012:DRH:2166966.2167053,
 abstract = {Although the persuasion-based health behavior change systems have achieved certain success particularly in motivating physical activity, researchers now start criticizing that persuasion-based systems have problems in taking over too much control, paying not enough attention to people's thinking, and failing in acknowledging external constraints and exploring resources. The alternative notion of reflection has been supported by different researchers' views, and in my thesis work I aim to explore this notion in the context of dietary change. The main goal of my thesis work is to explore what people think in the different food- related activities and apply those understandings into system designs to foster and assist people's reflection on everyday dietary change.},
 acmid = {2167053},
 address = {New York, NY, USA},
 author = {Gao, Feng},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167053},
 isbn = {978-1-4503-1048-2},
 keyword = {behavior change, dietary change, reflection},
 link = {http://doi.acm.org/10.1145/2166966.2167053},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {379--382},
 publisher = {ACM},
 series = {IUI '12},
 title = {Design for Reflection on Health Behavior Change},
 year = {2012}
}


@inproceedings{Kim:2012:PIA:2166966.2166979,
 abstract = {Social networking has gained immense traction in many areas, including teaching and learning. Networking sites for teachers aim to facilitate teacher communication and information sharing, but fall short of their potential. In order to support more effective use of online resources and better communication among teachers, we develop a suite of new user modeling and recommendation capabilities within a middle school teacher networking site. We foster collaboration among novice and experienced teachers when they share similar interests, enabling new mentoring relationships, and promote the use of relevant educational resources. We illustrate our approach with an implemented system called PedConnect that analyzes user activities and presents intelligent suggestions for collaboration and resource use.},
 acmid = {2166979},
 address = {New York, NY, USA},
 author = {Kim, Jihie and Chang, Yu-Han and Cai, Sen and Jain, Siddharth},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166979},
 isbn = {978-1-4503-1048-2},
 keyword = {teacher social networking, topic modeling, user profiling},
 link = {http://doi.acm.org/10.1145/2166966.2166979},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {71--74},
 publisher = {ACM},
 series = {IUI '12},
 title = {PedConnect: An Intelligent Assistant for Teacher Social Networking},
 year = {2012}
}


@inproceedings{Ziebart:2012:PPT:2166966.2166968,
 abstract = {Numerous interaction techniques have been developed that make "virtual" pointing at targets in graphical user interfaces easier than analogous physical pointing tasks by invoking target-based interface modifications. These pointing facilitation techniques crucially depend on methods for estimating the relevance of potential targets. Unfortunately, many of the simple methods employed to date are inaccurate in common settings with many selectable targets in close proximity. In this paper, we bring recent advances in statistical machine learning to bear on this underlying target relevance estimation problem. By framing past target-driven pointing trajectories as approximate solutions to well-studied control problems, we learn the probabilistic dynamics of pointing trajectories that enable more accurate predictions of intended targets.},
 acmid = {2166968},
 address = {New York, NY, USA},
 author = {Ziebart, Brian and Dey, Anind and Bagnell, J. Andrew},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166968},
 isbn = {978-1-4503-1048-2},
 keyword = {continuous control, cursor prediction, probabilistic inference},
 link = {http://doi.acm.org/10.1145/2166966.2166968},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {1--10},
 publisher = {ACM},
 series = {IUI '12},
 title = {Probabilistic Pointing Target Prediction via Inverse Optimal Control},
 year = {2012}
}


@inproceedings{Baldwin:2012:TOA:2166966.2166969,
 abstract = {Software (soft) keyboards are becoming increasingly popular on mobile devices. To attempt to improve soft keyboard input accuracy, key-target resizing algorithms that dynamically change the size of each key's target area have been developed. Although methods that employ personalized touch models have been shown to outperform general models, previous work has relied upon laboratory-based offline calibration to collect the data necessary to build these models. Such approaches are unrealistic and interuptive, and it is unlikely that offline calibration can be applied in a realistic usage setting, as hundreds or thousands of touch points are necessary to build the models. To combat this problem, this paper explores the possibility of online adaptation of key-target resizing algorithms. In particular, we propose and examine three online data collection methods that can be used to build and dynamically update personalized key-target resizing models. Our results suggest that a data collection methodology that makes inference based on vocabulary and error correction behavior is able to perform on par with gold standard personalized models, while reducing relative error rate by 10.4% over general models. This approach is simple, computationally inexpensive, and calculable via information that the system already has access to. Additionally, we show that these models can be built quickly, requiring less than one week's worth of text input by an average mobile device user.},
 acmid = {2166969},
 address = {New York, NY, USA},
 author = {Baldwin, Tyler and Chai, Joyce},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166969},
 isbn = {978-1-4503-1048-2},
 keyword = {key-target resizing, online adaptation, personalization},
 link = {http://doi.acm.org/10.1145/2166966.2166969},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {11--20},
 publisher = {ACM},
 series = {IUI '12},
 title = {Towards Online Adaptation and Personalization of Key-target Resizing for Mobile Devices},
 year = {2012}
}


@inproceedings{Leiva:2012:SFA:2166966.2167027,
 abstract = {Many devices generate large amounts of data that follow some sort of sequentiality, e.g., motion sensors, e-pens, or eye trackers, and therefore these data often need to be compressed for classification, storage, and/or retrieval purposes. This paper introduces a simple, accurate, and extremely fast technique inspired by the well-known K-means algorithm to properly cluster sequential data. We illustrate the feasibility of our algorithm on a web-based prototype that works with trajectories derived from mouse and touch input. As can be observed, our proposal outperforms the classical K-means algorithm in terms of accuracy (better, well-formed segmentations) and performance (less computation time).},
 acmid = {2167027},
 address = {New York, NY, USA},
 author = {Leiva, Luis and Vidal, Enrique},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167027},
 isbn = {978-1-4503-1048-2},
 keyword = {clustering, sequential data, trajectory segmentation},
 link = {http://doi.acm.org/10.1145/2166966.2167027},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {309--310},
 publisher = {ACM},
 series = {IUI '12},
 title = {Simple, Fast, and Accurate Clustering of Data Sequences},
 year = {2012}
}


@inproceedings{Graells:2012:LUM:2166966.2167006,
 abstract = {Time series data is pervasive in many domains and interactive visualization of such data is useful for a wide range of tasks including analysis and prediction. In spite of the importance of visualizing time series data and the fact that time series data is often easily interpretable, traditional approaches are either very simple and limited, or are aimed at domain experts. In this paper, we propose a novel interactive visualization paradigm for exploring and comparing multiple sets of time series data. In particular, we propose a focus+context approach, where a "focus" segment of a time series is zoomed into and visualized using a linear layout at one scale, while the remaining segments of the time series (i.e., the context) are visualized using spiral data layouts. Our paradigm allows the user to dynamically select and compare different sections of each time series independently, facilitating the exploration of time series data in a fun and engaging way.},
 acmid = {2167006},
 address = {New York, NY, USA},
 author = {Graells, Eduardo and Jaimes, Alejandro},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167006},
 isbn = {978-1-4503-1048-2},
 keyword = {focus + context, time series, visual interfaces, visualization},
 link = {http://doi.acm.org/10.1145/2166966.2167006},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {237--240},
 publisher = {ACM},
 series = {IUI '12},
 title = {Lin-spiration: Using a Mixture of Spiral and Linear Visualization Layouts to Explore Time Series},
 year = {2012}
}


@inproceedings{Ehlen:2012:MIP:2166966.2166970,
 abstract = {Speak4it™ is a mobile search application that leverages multimodal input and integration to allow users to search for and act on local business information. We present an initial empirical analysis of user interaction with a multimodal local search application deployed in the field with real users. Specifically, we focus on queries involving multimodal commands, and analyze multimodal interaction behaviors seen in a deployed multimodal system.},
 acmid = {2166970},
 address = {New York, NY, USA},
 author = {Ehlen, Patrick and Johnston, Michael},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166970},
 isbn = {978-1-4503-1048-2},
 keyword = {gesture, location-based, multimodal, search, speech},
 link = {http://doi.acm.org/10.1145/2166966.2166970},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {21--24},
 publisher = {ACM},
 series = {IUI '12},
 title = {Multimodal Interaction Patterns in Mobile Local Search},
 year = {2012}
}


@inproceedings{Gehring:2012:UIN:2166966.2166985,
 abstract = {During sales conversations, gestures and mimics are of high importance to communicate information about a product. One prominent example for such sales gestures is the meat and cheese counter, which is one of the remaining spots in supermarkets where sales persons interact with customers. Interactions at such counters in supermarkets normally follow a simple protocol. The customer points at an item of choice. The employee takes out the item and, in most of the cases the product needs to be cut to fit the amount the customer wants to buy. Often it is ambiguous about what specific product the customer and the employees are talking about. Up to now, there are just a few efforts in HCI research to enrich communication at the point of sale. In this paper we report and analyze one scenario in which an intelligent natural user interface can support communication between customer and employee in a sales conversation. Furthermore, we report on our prototype that is able to track pointing gestures by using a depth camera and to display information about items pointed at.},
 acmid = {2166985},
 address = {New York, NY, USA},
 author = {Gehring, Sven and L\"{o}chtefeld, Markus and Daiber, Florian and B\"{o}hmer, Matthias and Kr\"{u}ger, Antonio},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166985},
 isbn = {978-1-4503-1048-2},
 keyword = {gestural interaction, pointing, sales conversation},
 link = {http://doi.acm.org/10.1145/2166966.2166985},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {97--100},
 publisher = {ACM},
 series = {IUI '12},
 title = {Using Intelligent Natural User Interfaces to Support Sales Conversations},
 year = {2012}
}


@inproceedings{Curran:2012:TRC:2166966.2167019,
 abstract = {Recent computer vision approaches are aimed at richer image interpretations that extend the standard recognition of objects in images (e.g., cars) to also recognize object attributes (e.g., cylindrical, has-stripes, wet). However, the more idiosyncratic and abstract the notion of an object attribute (e.g., cool car), the more challenging the task of attribute recognition. This paper considers whether end users can help vision algorithms recognize highly idiosyncratic attributes, referred to here as subjective attributes. We empirically investigated how end users recognized three subjective attributes of carscool, cute, and classic. Our results suggest the feasibility of vision algorithms recognizing subjective attributes of objects, but an interactive approach beyond standard supervised learning from labeled training examples is needed.},
 acmid = {2167019},
 address = {New York, NY, USA},
 author = {Curran, William and Moore, Travis and Kulesza, Todd and Wong, Weng-Keen and Todorovic, Sinisa and Stumpf, Simone and White, Rachel and Burnett, Margaret},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167019},
 isbn = {978-1-4503-1048-2},
 keyword = {classification, computer vision, human factors., interactive machine learning},
 link = {http://doi.acm.org/10.1145/2166966.2167019},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {285--288},
 publisher = {ACM},
 series = {IUI '12},
 title = {Towards Recognizing "Cool": Can End Users Help Computer Vision Recognize Subjective Attributes of Objects in Images?},
 year = {2012}
}


@inproceedings{Hangal:2012:EBS:2166966.2166994,
 abstract = {In the digital age, users can have perfect recall of their online experiences. In this paper, we explore how this recall can be leveraged during web browsing. We have built a system called the Experience-Infused Browser that indexes a user's digital history such as email and chat archives. As the user browses the web, it observes the contents of pages viewed, and appropriately highlights named entities on the page that the user has encountered in the past. This browser has two benefits. First, it highlights terms on the page that occur frequently in the user's communications, effectively personalizing the page for the user. Second, the system can remind the user of names that he has encountered in the past but may not remember. We evaluated how users reacted to the browser during organic web browsing. Our users have reported that it was useful on crowded web pages to surface content that they otherwise may have missed, and in recalling serendipitous connections to people that they had forgotten. Most of our users said they would use the browser beyond the experimental study, indicating that they derived clear benefit from it.},
 acmid = {2166994},
 address = {New York, NY, USA},
 author = {Hangal, Sudheendra and Nagpal, Abhinay and Lam, Monica},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166994},
 isbn = {978-1-4503-1048-2},
 keyword = {annotation, email, personal digital archives, personalization, web browsing},
 link = {http://doi.acm.org/10.1145/2166966.2166994},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {149--158},
 publisher = {ACM},
 series = {IUI '12},
 title = {Effective Browsing and Serendipitous Discovery with an Experience-infused Browser},
 year = {2012}
}


@inproceedings{delaVilla:2012:LST:2166966.2166978,
 abstract = {The search for truthful health information through Internet is an increasingly complex process due to the growing amount of resources. Access to information can be difficult to control even in environments where the goal pursued is well-defined, as in the case of learning activities with medical students. In this paper, we present a computer tool devised to ease the process of understanding medical concepts from information in clinical case histories. To this end, it automatically constructs concept maps and presents reliable information from different ontologies and knowledge bases. The two main components of the system are an Intelligent Information Access interface and a Concept Map Graph that retrieves medical concepts from a text input, and provides rich information and semantically related concepts. The paper includes a user evaluation of the first component and a systematic assessment for the second component. Results show that our proposal can be efficient and useful for students in a medical learning environment.},
 acmid = {2166978},
 address = {New York, NY, USA},
 author = {de la Villa, Manuel and Aparicio, Fernando and Ma\~{n}a, Manuel J. and de Buenaga, Manuel},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166978},
 isbn = {978-1-4503-1048-2},
 keyword = {concept-based learning, health informatics, learning-based interaction, ontologies, semantic interoperability, software systems in medicine, visual information retrieval},
 link = {http://doi.acm.org/10.1145/2166966.2166978},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {61--70},
 publisher = {ACM},
 series = {IUI '12},
 title = {A Learning Support Tool with Clinical Cases Based on Concept Maps and Medical Entity Recognition},
 year = {2012}
}


@inproceedings{Verma:2012:IIB:2166966.2167037,
 abstract = {Authentication interfaces are GUIs that provide the protection for an application or system. In this paper, we present icAuth: a novel image and color based authentication interface for the authentication process. We enhance the existing Image Based Authentication (IBA) with an additional interactive method. In our approach, the user not only chooses image(s) as a key during the registration process, but also clicks on various regions on the image to generate an additional key. This additional key is in the form of a sequence of colors that correspond to the clicked areas. In essence, the user chooses a color sequence along with the selected images. During the next authentication process, the user has to produce the same color sequence on the recognized images. The user is required to remember the same switching sequence among the images, without having to memorize the precise location of the initial clicks during setup.},
 acmid = {2167037},
 address = {New York, NY, USA},
 author = {Verma, Pramod},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167037},
 isbn = {978-1-4503-1048-2},
 keyword = {iba, security, usability},
 link = {http://doi.acm.org/10.1145/2166966.2167037},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {329--330},
 publisher = {ACM},
 series = {IUI '12},
 title = {icAuth: Image-color Based Authentication System},
 year = {2012}
}


@inproceedings{Bellucci:2012:ARE:2166966.2167004,
 abstract = {The effort and time required to develop user interface models has been one of the main limitations to the adoption of model-based approaches, which enable intelligent processing of user interface descriptions. In this paper, we present a tool to perform reverse engineering of interactive dynamic Web applications into a model-based framework able to describe them at various abstraction levels. We indicate how information in HTML, HTML 5, CSS, Ajax and JavaScript is transformed into such logical framework, which facilitates adaptation to other types of interactive devices. We also discuss how this reverse engineering tool has been exploited in an environment for run-time adaptation or migration of interactive Web applications to various devices in ubiquitous use cases.},
 acmid = {2167004},
 address = {New York, NY, USA},
 author = {Bellucci, Federico and Ghiani, Giuseppe and Patern\`{o}, Fabio and Porta, Claudio},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167004},
 isbn = {978-1-4503-1048-2},
 keyword = {model-based user interface descriptions, user interface reverse engineering, web applications},
 link = {http://doi.acm.org/10.1145/2166966.2167004},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {217--226},
 publisher = {ACM},
 series = {IUI '12},
 title = {Automatic Reverse Engineering of Interactive Dynamic Web Applications to Support Adaptation Across Platforms},
 year = {2012}
}


@inproceedings{Campbell:2012:CRF:2166966.2166993,
 abstract = {We investigate new interfaces that allow users to specify topics of interest in streams of weblog stories by providing relevance feedback to a search algorithm. Noting that weblog stories often contain photographs taken by the blogger during the course of the narrated events, we investigate whether these photographs can serve as a proxy for the whole post when users are making judgments as to the post's relevance. We developed a new story annotation interface for collecting relevance feedback with three variations: users are presented either with the full post as it appears in a weblog, an embedded photograph, or only the title of the post. We describe a user evaluation that compares annotation time, quality, and subjective user experience across each of these three conditions. The results show that relevance judgments based on embedded photographs or titles are far less accurate than when reading the whole weblog post, but the time required to acquire an accurate model of the user's topic interest is greatly reduced.},
 acmid = {2166993},
 address = {New York, NY, USA},
 author = {Campbell, Amy and Wienberg, Christopher and Gordon, Andrew},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166993},
 isbn = {978-1-4503-1048-2},
 keyword = {photographs, relevance feedback, user interfaces for machine learning, user study, weblogs},
 link = {http://doi.acm.org/10.1145/2166966.2166993},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {139--148},
 publisher = {ACM},
 series = {IUI '12},
 title = {Collecting Relevance Feedback on Titles and Photographs in Weblog Posts},
 year = {2012}
}


@inproceedings{Ludwig:2012:IPA:2166966.2167008,
 abstract = {Within an Air Operations Center (AOC), planners make crucial decisions to create the air plan for any given day. They are expected to complete the plan in part by pairing targeting or collection tasks with the available platforms. Any assistance these planners can acquire to help create the plan in a timely manner would make the entire process more efficient and effective. This paper describes the Intelligent Pairing Assistant (IPA) prototype, which would provide pairing recommendations at specific decision points in the planning process. IPA is designed as a plug-in for software systems already in use within AOCs. The primary contribution described in this paper is the application of existing research in intelligent user interfaces to a novel domain.},
 acmid = {2167008},
 address = {New York, NY, USA},
 author = {Ludwig, Jeremy and Geiselman, Eric},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167008},
 isbn = {978-1-4503-1048-2},
 keyword = {air operations center, intelligent user interface, pairing, reinforcement learning},
 link = {http://doi.acm.org/10.1145/2166966.2167008},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {241--244},
 publisher = {ACM},
 series = {IUI '12},
 title = {Intelligent Pairing Assistant for Air Operation Centers},
 year = {2012}
}


@inproceedings{Luong:2012:VPL:2166966.2167003,
 abstract = {Visual programming languages (VPLs) provide notations for representing both the intermediate and the final results of a knowledge engineering process. Whereas some VPLs particularly focus on control flow and/or data flow of a software, very few VPLs stress on the interactive dimension of application (dialogue flow). This paper focuses on a VPL allowing designers to specify interactions between a user and a system, in the field of Web-based geographic applications. We first present the underlying interaction model that the VPL is based on, and then the detailed characteristics of the VPL. We show how this VPL has been integrated in a graphical design framework allowing designers to immediately assess their specification. Then we illustrate the way to use the framework from the design step to the final code generation step. Last, we detail an experimentation aiming at evaluating the strengths and the weaknesses of our VPL.},
 acmid = {2167003},
 address = {New York, NY, USA},
 author = {Luong, The Nhan and Etcheverry, Patrick and Marquesuza\`{a}, Christophe and Nodenot, Thierry},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167003},
 isbn = {978-1-4503-1048-2},
 keyword = {geographic application design, interaction design, visual authoring tools, visual design language},
 link = {http://doi.acm.org/10.1145/2166966.2167003},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {207--216},
 publisher = {ACM},
 series = {IUI '12},
 title = {A Visual Programming Language for Designing Interactions Embedded in Web-based Geographic Applications},
 year = {2012}
}


@inproceedings{Kulesza:2012:EAP:2166966.2167052,
 abstract = {Intelligent agents are becoming ubiquitous in the lives of users, but the research community has only recently begun to study how people establish trust in and communicate with such agents. I plan to design an explanation-centric approach to support end users in personalizing their intelligent agents and in assessing their strengths and weaknesses. My goal is to define an approach that helps people understand when they can rely on their intelligent agents' decisions, and allows them to directly debug their agents' reasoning when it does not align with their own.},
 acmid = {2167052},
 address = {New York, NY, USA},
 author = {Kulesza, Todd},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167052},
 isbn = {978-1-4503-1048-2},
 keyword = {end-user programming, interactive machine learning, mental models, trust},
 link = {http://doi.acm.org/10.1145/2166966.2167052},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {375--378},
 publisher = {ACM},
 series = {IUI '12},
 title = {An Explanation-centric Approach for Personalizing Intelligent Agents},
 year = {2012}
}


@inproceedings{Biswas:2012:DIU:2166966.2167060,
 abstract = {This workshop aims to gap the bridge between mainstream research on intelligent systems and accessibility researchers by presenting papers and demonstrations on developing adaptable multimodal systems for elderly and disabled users. The workshop is organized in the context of EU GUIDE project and focus on Web and Digital TV applications. However the research and applications are relevant for different platforms like computers, tablet and ubiquitous devices. The workshop consists of a keynote speech on standardization of developing intelligent and accessible system followed by five paper and demonstration presentations. A set of papers from this workshop will later appear at the International Journal of Digital Television.},
 acmid = {2167060},
 address = {New York, NY, USA},
 author = {Biswas, Pradipta and Langdon, Pat and Jung, Christoph and Hamisu, Pascal and Duarte, Carlos and Almeida, Luis},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167060},
 isbn = {978-1-4503-1048-2},
 keyword = {assistive technology, e-inclusion, human-computer interaction, usability evaluation, user model},
 link = {http://doi.acm.org/10.1145/2166966.2167060},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {405--408},
 publisher = {ACM},
 series = {IUI '12},
 title = {Developing Intelligent User Interfaces for e-Accessibility and e-Inclusion},
 year = {2012}
}


@inproceedings{Weninger:2012:DPP:2166966.2167044,
 abstract = {Interactive maps on the internet have become frequently used means to convey spatial information to the public. However, many maps are not developed to suit a variety of users and thus lead to frustration. To user-center maps we therefore recommend to personalize them to individual users. As many parameters that can be used as a trigger for personalization are not easy to be logged on the internet, we suggest user-map interaction. Interaction can be easily tracked and gives comprehensive information about map use. Since no interpretation of user-map interaction is available it is the aim of this PhD to observe interaction, and to evaluate and interpret it. We hypothesize that there are map interaction patterns, means recurring sequences of consecutive actions which are necessary to complete a task. Our goal is to deduce parameters for personalization from these map interaction patterns.},
 acmid = {2167044},
 address = {New York, NY, USA},
 author = {Weninger, Beate},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167044},
 isbn = {978-1-4503-1048-2},
 keyword = {adaptive maps, interaction, interactive maps, personalization},
 link = {http://doi.acm.org/10.1145/2166966.2167044},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {341--344},
 publisher = {ACM},
 series = {IUI '12},
 title = {Deducing Parameters for Personalizing Maps from Map Interaction Patterns},
 year = {2012}
}


@proceedings{Pu:2011:1943403,
 abstract = {It is our great pleasure to welcome you to the 2011 ACM International Conference on Intelligent User Interfaces -- IUI'11. Intelligent User Interfaces (IUI) is the premier conference for reporting on the study of user interfaces with intelligent devices. This topic is of increasing importance as the consumer is interfacing with a wide variety of devices with embedded computation and connectivity and the computer is fading into the background. IUI is where the community of people interested in Human-Computer Interaction (HCI) meets the Artificial Intelligence (AI) community. We have retained the successful format of the conference with Long Papers, Short Papers and Demonstrations. The accepted submissions cover a wide range of topics, including handheld devices, multimodal interfaces, social computing and navigation, intelligent help agents, input technologies, user modeling and personalization, intelligent authoring and information presentation, and pen-based interfaces. Geographically, the accepted work also represents researchers and institutions in many countries across four continents, including Argentina, Australia, Belgium, Canada, China, Denmark, Finland, France, Germany, Ireland, Israel, Italy, Japan, Korea, Netherlands, Pakistan, Spain, Switzerland, Thailand, United Kingdom, and the United States of America. As always, the selection process has been the object of careful consideration and multiple discussions. In order to ensure that all topics were adequately covered more than 150 experts have contributed to the selection of this year's program, and we trust that this had a very positive impact on the relevance and quality of individual reviews. We are grateful to the reviewers, the program committee and the senior program committee, who worked very hard in reviewing papers and providing feedback for authors. Following a trend adopted by several high-quality conferences, we had a rebuttal phase for Long Papers. We have asked the Senior PC moderators and the Demo Chair to formulate recommendations for acceptance and in the vast majority of cases it has been straightforward for us to endorse their choice. It is always down to the Program Chairs to make final decisions, sometimes difficult ones, on the total number of contributions to be accepted. Out of 180 submissions, we selected 28 long papers, 36 short papers and 15 demo papers. We have adopted a continuity policy from previous editions (around 30% for Long Papers); this year's overall acceptance rate achieves the right balance between selectivity and openness to innovative papers. The conference program highlights three invited talks: Andrei Broder from Yahoo! Research, Eric Horvitz from Microsoft Research and Ken Perlin from New York University. We are also glad that we got Anthony Jameson from DFKI GmbH and Joseph Konstan from the University of Minnesota as tutorial speakers. This year's Conference also features ten workshops, covering several hot topics in the area of IUI, with strong emphasis on multimodality of interfaces, smart interaction and personalization including: Sketch recognition, Semantic Models for Adaptive Interactive Systems, Intelligent User Interfaces for Developing Regions, Context-Awareness in Retrieval and Recommendation, Multimodal Interfaces for Automotive Applications, Visual Interfaces to the Social and Semantic Web, Location-Awareness for Mixed and Dual Reality, Eye Gaze in Intelligent Human Machine Interaction, Interacting with Smart Objects and Personalized Access to Cultural Heritage.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-0419-1},
 location = {Palo Alto, CA, USA},
 note = {608110},
 publisher = {ACM},
 title = {IUI '11: Proceedings of the 16th International Conference on Intelligent User Interfaces},
 year = {2011}
}


@inproceedings{Jiang:2012:UGM:2166966.2166982,
 abstract = {Gesture inputs on multi-touch tabletops usually involve multiple fingers (more than two) and casual touchdowns or liftoffs of fingers. This flexibility of touch gestures allows more natural user interaction, but also poses new challenges for accurate recognition of multi-touch gestures. To address these challenges, we propose a new approach to recognize flexible multi-touch stroke gestures on tabletops. Based on a user study on multi-touch unistroke gestures, we develop a gesture recognition method by extracting key strokes embedded in flexible multi-touch input. Our evaluation study result shows that this method can greatly improve the recognition accuracy of flexible multi-touch unistroke gestures on tabletops.},
 acmid = {2166982},
 address = {New York, NY, USA},
 author = {Jiang, Yingying and Tian, Feng and Zhang, Xiaolong and Liu, Wei and Dai, Guozhong and Wang, Hongan},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166982},
 isbn = {978-1-4503-1048-2},
 keyword = {flexible gesture inputs, multi-touch interaction, unistroke gesture recognition},
 link = {http://doi.acm.org/10.1145/2166966.2166982},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {85--88},
 publisher = {ACM},
 series = {IUI '12},
 title = {Unistroke Gestures on Multi-touch Interaction: Supporting Flexible Touches with Key Stroke Extraction},
 year = {2012}
}


@inproceedings{Young:2012:SDT:2166966.2166976,
 abstract = {The style in which a robot moves, expressed through its gait or locomotion, can convey effective messages to people. For example, a robot could move aggressively in reaction to a person's actions, or alternatively react using a set of careful, submissive movements. Designing, implementing and programming robotic interfaces that react to users' actions with properly styled movements can be a difficult, daunting, and time consuming technical task. On the other hand, most people can easily perform such stylistic tasks and movements, for example, through acting them out. Following this observation, we propose to enable people to use their existing teaching skills to directly demonstrate to robots, via in-situ acting, a desired style of interaction. In this paper we present an initial style-by-demonstration (SBD) proof-of-concept of our approach, allowing people to teach a robot specific, interactive locomotion styles by providing a demonstration. We present a broomstick-robot interface for directly demonstrating locomotion style to a collocated robot, and a design critique evaluation by experienced programmers that compares our SBD approach to traditional programming methods.},
 acmid = {2166976},
 address = {New York, NY, USA},
 author = {Young, James and Ishii, Kentaro and Igarashi, Takeo and Sharlin, Ehud},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166976},
 isbn = {978-1-4503-1048-2},
 keyword = {locomotion style, programming by demonstration, qualitative evaluation, social human robot interaction, style by demonstration, tangible user interfaces},
 link = {http://doi.acm.org/10.1145/2166966.2166976},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {41--50},
 publisher = {ACM},
 series = {IUI '12},
 title = {Style by Demonstration: Teaching Interactive Movement Style to Robots},
 year = {2012}
}


@proceedings{Kim:2013:2451176,
 abstract = {It is our great pleasure to welcome you to the 2013 International Conference on Intelligent User Interfaces (IUI'13). This year marks the eighteenth meeting of this conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, increasing the intelligence of both in the process. The call for papers attracted 195 submissions from Asia, Canada, Europe, Africa, and the United States. The program committee accepted 43 papers covering a diverse set of topics, including brain-computer interaction, social media analysis, automated design, and crowdsourcing. The program opens with a keynote by Professor Luis von Ahn on "Duolingo: Learn a Language for Free while Helping to Translate the Web," and closes with a keynote by Professor Monica S. Lam on "How Mobile Disrupts Social As We Know it." We also have an excellent poster and demonstration program consisting of 14 demos and 22 posters selected from a pool of 64 total submissions. In addition, the conference provides two exciting tutorials and four interesting workshops. The tutorials feature an introduction to Human Computation by Edith Law and an introduction to knowledge acquisition from the web and social media by Zornitsa Kozareva. The workshops cover topics ranging from interactive machine learning to IUI for developing worlds. No conference of this size could be organized without the help of a large number of individuals who volunteer an enormous amount of their own time. Their names can be found in the following pages and each and every one of these extraordinary volunteers deserve our thanks. We want to especially recognize all of the members of the organizing committee, who put in countless hours over nearly a year to make the conference happen. If you see one of them in the hotel bar at the conference, please buy them a beverage of their choice. We must also thank our senior program committee for coordinating the review process and all 654 members of the program committee for providing high quality reviews that exceeded even our lofty expectations. Last, but certainly not least, we must thank the authors for providing the content for the program that is the foundation of any successful conference. We look forward to your presentations!},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1966-9},
 location = {Santa Monica, California, USA},
 publisher = {ACM},
 title = {IUI '13 Companion: Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 year = {2013}
}


@inproceedings{Kang:2012:LPA:2166966.2167014,
 abstract = {We present LogicPad, a pen-based application for boolean algebra visualization that lets users manipulate boolean function representations through handwritten symbol and gesture recognition coupled with a drag-and-drop interface. We discuss LogicPad's user interface and the general algorithm used for verifying the equivalence of three different boolean function representations: boolean expressions, truth tables, and logic gate diagrams. We also conducted a short, informal user study evaluating LogicPad's user interface, visualization techniques, and overall performance. Results show that visualizations were generally well-liked and verification results matched user expectations.},
 acmid = {2167014},
 address = {New York, NY, USA},
 author = {Kang, Bo and LaViola, Joseph},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167014},
 isbn = {978-1-4503-1048-2},
 keyword = {boolean algebra, logic verification, pen-based user interface, sketch understanding},
 link = {http://doi.acm.org/10.1145/2166966.2167014},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {265--268},
 publisher = {ACM},
 series = {IUI '12},
 title = {LogicPad: A Pen-based Application for Visualization and Verification of Boolean Algebra},
 year = {2012}
}


@inproceedings{Smith:2012:MIA:2166966.2167054,
 abstract = {A person's choice of what to communicate and how to communicate it depends on the information he or she believes is shared with the audience. This presents a challenge for natural language interfaces, because it is hard for people to predict what information they share with the interface and how it will use this information to interpret their text. This is especially difficult for pragmatic-level assumptions supplied by the interpreter that go beyond the information in the surface text, because these assumptions are negotiated in dialogue and frequently revised or redacted. We have built a calendaring interface that allows users to communicate English event descriptions. This constrained task gives us a clear criteria for communication success and failure. Failures are opportunities to acquire and revise assumptions: to collect lexical and semantic knowledge from a variety of users. By lowering the interaction barrier so end users can contribute to the linguistic interpretation process, we can collect culture-specific lexical and semantic knowledge directly from the members of the cultural group who possess it. This knowledge is essential for the pragmatic task of deriving what a speaker meant from what they said. The goal of this research is to make the assumptions involved with interpreting natural language explicit to the user. Using a model of language generation and interpretation based on planning and plan recognition, we capture, through user contributions, word definitions and commonsense assumptions - and we represent both as belief-changing actions. Using visualizations and a direct manipulation interface, users can access the interpretation status, inspect which assumptions were made, and suggest or modify existing assumptions. With the aim of providing the functionally equivalent of the negotiation stage in interpersonal dialogue, we evaluate the interface by how it allows users to revise and extend assumptions toward successful interpretation.},
 acmid = {2167054},
 address = {New York, NY, USA},
 author = {Smith, Dustin},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167054},
 isbn = {978-1-4503-1048-2},
 keyword = {commonsense, end-user programming, event management, knowledge acquisition, natural language interfaces},
 link = {http://doi.acm.org/10.1145/2166966.2167054},
 location = {Lisbon, Portugal},
 numpages = {6},
 pages = {383--388},
 publisher = {ACM},
 series = {IUI '12},
 title = {Managing Implicit Assumptions in Natural Language Interfaces},
 year = {2012}
}


@inproceedings{Liu:2012:GYI:2166966.2167046,
 abstract = {Information technology (IT) support of office work has increased rapidly in functionality, but the interaction styles have evolved more slowly. This project explores interaction design opportunities of IT supported tools in the context of office work. A series of (contextual) interviews was conducted with Generation Y office workers, aiming to identify their interaction qualities. Three interactive prototypes were built to map these interaction qualities and to demonstrate future ways of working. This project resulted in a set of design guidelines, aiming to support Generation Y interactions in future office work. Designers and researchers who focus on understanding (rich interactions in) the work context would benefit from the result of this project.},
 acmid = {2167046},
 address = {New York, NY, USA},
 author = {Liu, Wei},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167046},
 isbn = {978-1-4503-1048-2},
 keyword = {design guidelines, generation y office worker, interaction qualities, interactive prototyping},
 link = {http://doi.acm.org/10.1145/2166966.2167046},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {349--352},
 publisher = {ACM},
 series = {IUI '12},
 title = {Generation Y Interactions},
 year = {2012}
}


@inproceedings{Amma:2012:ADM:2166966.2167032,
 abstract = {We demonstrate our airwriting interface for mobile hands-free text entry. The interface enables a user to input text into a computer by writing in the air like on an imaginary blackboard. Hand motion is measured by an accelerometer and a gyroscope attached to the back of the hand and data is sent wirelessly to the processing computer. The system can continuously recognize arbitrary sentences based on a predefined vocabulary in real-time. The recognizer uses Hidden Markov Models (HMM) together with a statistical language model. We achieve a user-independent word error rate of 11% for a 8K vocabulary based on an experiment with nine users.},
 acmid = {2167032},
 address = {New York, NY, USA},
 author = {Amma, Christoph and Schultz, Tanja},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167032},
 isbn = {978-1-4503-1048-2},
 keyword = {accelerometers, gesture recognition, handwriting recognition, human computer interaction, wearable computing},
 link = {http://doi.acm.org/10.1145/2166966.2167032},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {319--320},
 publisher = {ACM},
 series = {IUI '12},
 title = {Airwriting: Demonstrating Mobile Text Input by 3D-space Handwriting},
 year = {2012}
}


@inproceedings{Kurdyukova:2012:SUI:2166966.2166984,
 abstract = {The paper investigates the iPad gestures that users naturally perform for data transfer. We examine the transfer between two iPads, iPad and a tabletop, and iPad and a public display. Three gesture modalities are investigated: multi-touch gestures, performed using iPad display, spatial gestures, performed by manipulating iPad in 3D space, and direct contact gestures, involving the physical contact of iPad and other device. We report on user choices of the modalities and gesture types, and derive critical points for the design of iPad gestures.},
 acmid = {2166984},
 address = {New York, NY, USA},
 author = {Kurdyukova, Ekaterina and Redlin, Matthias and Andr{\'e}, Elisabeth},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166984},
 isbn = {978-1-4503-1048-2},
 keyword = {multi-display interaction, tablet pc, user-defined gestures},
 link = {http://doi.acm.org/10.1145/2166966.2166984},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {93--96},
 publisher = {ACM},
 series = {IUI '12},
 title = {Studying User-defined iPad Gestures for Interaction in Multi-display Environment},
 year = {2012}
}


@inproceedings{Leite:2012:VM:2166966.2167049,
 abstract = {Virtual Marionette is a research on digital puppetry, an interdisciplinary approach that brings the art of puppetry into the world of digital animation. Inspired in the traditional marionette technology our intention is to study novel interfaces as an interaction platform for creating artistic contents based on computer animated puppets. The overall goal of this thesis is to research and deploy techniques and methods for the manipulation of articulated puppets in real-time with low-cost interfaces to establish an interaction model for digital puppetry.},
 acmid = {2167049},
 address = {New York, NY, USA},
 author = {Leite, Lu\'{\i}s},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167049},
 isbn = {978-1-4503-1048-2},
 keyword = {computer kinematics, digital puppetry, human computer interaction, interactive animation, performance animation, real-time animation, virtual marionette},
 link = {http://doi.acm.org/10.1145/2166966.2167049},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {363--366},
 publisher = {ACM},
 series = {IUI '12},
 title = {Virtual Marionette},
 year = {2012}
}


@proceedings{Duarte:2012:2166966,
 abstract = {It is our great pleasure to welcome you to the 2012 ACM International Conference on Intelligent User Interfaces -- IUI'12 and to Lisboa, Portugal. Starting in 1993, IUI is now on its 17th edition and has established itself has the premier venue for reporting outstanding research and development on intelligent user interface. The IUI series continues to be the principal forum for the meeting of the Human-Computer Interaction (HCI) and the Artificial Intelligence (AI) communities. This gives rise to unique, creative, interdisciplinary contributions. This year's meeting showcases those topics, with works covering innovations in mobile interfaces, collaboration technology, affective interfaces, multimodal interfaces, pen interfaces, haptic and gesture interfaces, multi-touch interfaces, speech interfaces, gaze-based interfaces, tabletop interfaces, health applications, entertainment applications, adaptive narratives and theater, sports and in-vehicle applications, geographic applications, social media interfaces, educational interfaces, sketch recognition, human-robot interfaces, personalization and assistive technologies, end-user programming, ubiquitous and smart environments, locationaware interfaces, recommender interfaces, persuasive interfaces, web-based interfaces and agentbased interfaces. Building on previous years' success, the IUI 2012 call for papers attracted 134 full paper submissions and 78 short paper submissions. To ensure the highest possible quality we assembled a team of 48 senior program committee members and 367 reviewers. This guaranteed that every submission had at least three reviews plus one meta-review. This was followed by a rebuttal phase, keeping the procedure started two years ago. We believe that this process has guaranteed the highest quality possible for this year technical program and we would like to thank all the senior program committee members and reviewers for their hard work in making sure the most relevant works were selected. Through this very thorough review process we were able to accept 18 full papers, 15 short papers and 16 poster presentations, meaning an acceptance rate of 13% for full papers, 16% for oral presentations and 23% for combined oral and poster presentations. In addition to the full and short papers presentations and poster presentations, IUI will also feature a Demonstrations session for which 18 submissions were accepted from a total of 26 submissions. This year, the IUI programme includes three notable invited speakers sharing their innovative work and experiences with the conference participants: Alex 'Sandy' Pentland from the MIT Human Dynamic Lab, Christopher Bishop from Microsoft Research and Takeo Igarashi from the University of Tokyo. In order to foster the growth of the community, IUI 2012 will feature for the first time in the IUI series a Doctoral Consortium. Its success can be measured by the 12 high quality submissions received. Doctoral Consortium students will also be able to exhibit their work to the main conference audience in the poster session, thus promoting their insertion into the IUI community. We would also like to thank the conference sponsors and supporters that made it possible to provide financial support for Doctoral Consortium attendees and other students participating in the conference. Nine full-day workshops will take place at IUI 2012 covering diverse trending topics in the IUI area: Activity Context Representation: Techniques and Languages; Developing Intelligent User Interfaces for e-Accessibility and e-Inclusion; Context-awareness in Retrieval and Recommendation (CaRR 2012); 3rd Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS); Scent and Scensibility; User Modeling from Social Media; 2nd Workshop on Interacting with Smart Objects; 2nd Workshop on Location Awareness for Mixed and Dual Reality (LaMDa'12); 1st International Workshop on Ubiquitous Personalization (UP'2012). IUI 2012 continues and extends the cooperation with the ACM Transactions on Interactive Intelligent Systems (TiiS). Besides the streamlined processing of journal submissions based on IUI 2012 papers, IUI 2012 will feature a special session where authors of recently accepted articles for the ACM TiiS will spotlight key contributions of their work. It is our conviction that it will benefit greatly every member of the IUI community. We would like to thank Anthony Jameson and John Riedl, the Editors in Chief of TiiS, for their cooperation.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1048-2},
 location = {Lisbon, Portugal},
 note = {608120},
 publisher = {ACM},
 title = {IUI '12: Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 year = {2012}
}


@inproceedings{Miller:2012:GTD:2166966.2166986,
 abstract = {This paper describes a glove with which users enter input by tapping fingertips with the thumb or by rubbing the thumb over the palmar surfaces of the middle and index fingers. The glove has been informally tested as the controller for two semi-autonomous robots in a a 3D simulation environment. A preliminary evaluation of the glove's performance is presented.},
 acmid = {2166986},
 address = {New York, NY, USA},
 author = {Miller, Sam and Smith, Andy and Bahram, Sina and St. Amant, Robert},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166986},
 isbn = {978-1-4503-1048-2},
 keyword = {glove-based interaction, mobile, proprioception, tactile, wearable},
 link = {http://doi.acm.org/10.1145/2166966.2166986},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {101--104},
 publisher = {ACM},
 series = {IUI '12},
 title = {A Glove for Tapping and Discrete 1D/2D Input},
 year = {2012}
}


@inproceedings{Wong:2012:EOI:2166966.2167045,
 abstract = {The current formats used for presenting mathematics either on paper or in electronic form have usability limitations that make learning mathematics challenging. The concept of an Organic User Interface, promises a natural interface that blends with the human ecology system and therefore affords smoother transition and improved usability. This research aims to examine how the affordances of an Organic User Interface influence users learning of important mathematical concepts. The relationship between learning time and the usability factors, or affordances of an Organic User Interface will be determined and contrasted with those of Graphical User Interfaces.},
 acmid = {2167045},
 address = {New York, NY, USA},
 author = {Wong, Bee Suan},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167045},
 isbn = {978-1-4503-1048-2},
 keyword = {affordance, learning time, organic user interface, usability},
 link = {http://doi.acm.org/10.1145/2166966.2167045},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {345--348},
 publisher = {ACM},
 series = {IUI '12},
 title = {Evaluating an Organic Interface for Learning Mathematics},
 year = {2012}
}


@inproceedings{Goldhaber:2012:UTI:2166966.2167048,
 abstract = {Access to Information and Communication Technology (ICT) has the potential to improve the quality of life for many members of the ageing population. However, some older users lack the intrinsic motivation to learn to use this technology, and poor user interface design is partly to blame. The research presented here investigates how motivation theory can be applied to interface design in order to encourage older users to learn to use ICT. In addition to a brief literature review, an overview of methods, research goals, and current research status are presented.},
 acmid = {2167048},
 address = {New York, NY, USA},
 author = {Goldhaber, Tanya},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167048},
 isbn = {978-1-4503-1048-2},
 keyword = {ageing population, inclusive design, information and communication technology (ict), intrinsic motivation},
 link = {http://doi.acm.org/10.1145/2166966.2167048},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {359--362},
 publisher = {ACM},
 series = {IUI '12},
 title = {Using Theories of Intrinsic Motivation to Support ICT Learning for the Ageing Population},
 year = {2012}
}


@inproceedings{Silva:2012:IDR:2166966.2166971,
 abstract = {We present a system for in-vehicle driver recognition based on biometric information extracted from electrocardiographic (ECG) signals collected at the hands. We recur to non-intrusive techniques, that are easy to integrate into components with which the driver naturally interacts with, such as the steering wheel. This system is applicable to the automatic customization of vehicle settings according to the perceived driver, being also prone to expand the security features of the vehicle through the detection of hands-off steering wheel events in a continuous or near-continuous manner. We have performed randomized tests for performance evaluation of the system, in a subject identification scenario, using closed sets of up to 5 subjects, showing promising results for the intended application.},
 acmid = {2166971},
 address = {New York, NY, USA},
 author = {Silva, Hugo and Louren\c{c}o, Andr{\'e} and Fred, Ana},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166971},
 isbn = {978-1-4503-1048-2},
 keyword = {biometrics, customization, ecg, user identification, vehicles},
 link = {http://doi.acm.org/10.1145/2166966.2166971},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {25--28},
 publisher = {ACM},
 series = {IUI '12},
 title = {In-vehicle Driver Recognition Based on Hand ECG Signals},
 year = {2012}
}


@inproceedings{Sanchez-Cortina:2012:PIS:2166966.2167035,
 abstract = {A system to transcribe speech data is presented following an interactive paradigm in which both, the system produces automatically speech transcriptions and the user is assisted by the system to amend output errors as efficiently as possible. Partially supervised transcriptions with a tolerance error fixed by the user are used to incrementally adapt the underlying system models. The prototype uses a simple yet effective method to find an optimal balance between recognition error and supervision effort.},
 acmid = {2167035},
 address = {New York, NY, USA},
 author = {Sanchez-Cortina, Isaias and Serrano, Nicol\'{a}s and Sanchis, Alberto and Juan, Alfons},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167035},
 isbn = {978-1-4503-1048-2},
 keyword = {computer-assisted speech transcription, confidence measures, interactive machine learning, speech recognition},
 link = {http://doi.acm.org/10.1145/2166966.2167035},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {325--326},
 publisher = {ACM},
 series = {IUI '12},
 title = {A Prototype for Interactive Speech Transcription Balancing Error and Supervision Effort},
 year = {2012}
}


@inproceedings{Zhao:2012:PRO:2166966.2167018,
 abstract = {In this paper we analyze pointing techniques for simple remote control of nearby and distant objects in an outdoor environment, using a mobile phone. In an experiment we determine the accuracy of pointing at targets from a few meters to a few hundred meters away, either by focusing the phone's camera on a target or holding the phone at waist level in the direction of the target. We describe a simulated network application in which users can activate and control one or more responsive objects using either interaction technique.},
 acmid = {2167018},
 address = {New York, NY, USA},
 author = {Zhao, YangLei and Chakraborty, Arpan and Hong, Kyung Wha and Kakaraddi, Shishir and St. Amant, Robert},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167018},
 isbn = {978-1-4503-1048-2},
 keyword = {no keywords},
 link = {http://doi.acm.org/10.1145/2166966.2167018},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {281--284},
 publisher = {ACM},
 series = {IUI '12},
 title = {Pointing at Responsive Objects Outdoors},
 year = {2012}
}


@inproceedings{Gilroy:2012:EPU:2166966.2166990,
 abstract = {Previous Interactive Storytelling systems have been designed to allow active user intervention in an unfolding story, using established multi-modal interactive techniques to influence narrative development. In this paper we instead explore the use of a form of passive interaction where users' affective responses, measured by physiological proxies, drive a process of narrative adaptation. We introduce a system that implements a passive interaction loop as part of narrative generation, monitoring users' physiological responses to an on-going narrative visualization and using these to adapt the subsequent development of character relationships, narrative focus and pacing. Idiomatic cinematographic techniques applied to the visualization utilize existing theories of establishing characteristic emotional tone and viewer expectations to foster additional user response. Experimental results support the applicability of filmic emotional theories in a non-film visual realization, demonstrating significant appropriate user physiological response to narrative events and "emotional cues". The subsequent narrative adaptation provides a variation of viewing experience with no loss of narrative comprehension.},
 acmid = {2166990},
 address = {New York, NY, USA},
 author = {Gilroy, Stephen and Porteous, Julie and Charles, Fred and Cavazza, Marc},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2166990},
 isbn = {978-1-4503-1048-2},
 keyword = {entertainment computing, interactive storytelling, passive interaction, physiological},
 link = {http://doi.acm.org/10.1145/2166966.2166990},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {119--128},
 publisher = {ACM},
 series = {IUI '12},
 title = {Exploring Passive User Interaction for Adaptive Narratives},
 year = {2012}
}


@inproceedings{Liu:2012:CWP:2166966.2167010,
 abstract = {Due to small screens, inaccuracy of input and other limitations of mobile devices, revisitation of Web pages in mobile browsers takes more time than that in desktop browsers. In this paper, we propose a novel approach to facilitate revisitation. We designed AutoWeb, a system that clusters opened Web pages into different topics based on their contents. Users can quickly find a desired opened Web page by narrowing down the searching scope to a group of Web pages that share the same topic. Clustering accuracy is evaluated to be 92.4% and computing resource consumption was proved to be acceptable. A user study was conducted to explore user experience and how much AutoWeb facilitates revisitation. Results showed that AutoWeb could save up a significant time for revisitation and participants rated the system highly.},
 acmid = {2167010},
 address = {New York, NY, USA},
 author = {Liu, Jie and Yu, Chun and Xu, Wenchang and Shi, Yuanchun},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 doi = {10.1145/2166966.2167010},
 isbn = {978-1-4503-1048-2},
 keyword = {clustering, mobile web, revisitation},
 link = {http://doi.acm.org/10.1145/2166966.2167010},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {249--252},
 publisher = {ACM},
 series = {IUI '12},
 title = {Clustering Web Pages to Facilitate Revisitation on Mobile Devices},
 year = {2012}
}


