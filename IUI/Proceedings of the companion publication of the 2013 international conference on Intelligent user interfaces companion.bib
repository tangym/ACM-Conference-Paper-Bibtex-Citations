@inproceedings{Mezhoudi:2013:UIA:2451176.2451184,
 abstract = {With the growing need for intelligent software, exploring the potential of Machine Learning (ML) algorithms for User Interface (UI) adaptation becomes an ultimate requirement. The work reported in this paper aims at enhancing the UI interaction by using a Rule Management Engine (RME) in order to handle a training phase for personalization. This phase is intended to teach to the system novel adaptation strategies based on the end-user feedback concerning his interaction (history, preferences...). The goal is also to ensure an adaptation learning by capitalizing on the user feedbacks via a promoting/demoting technique, and then to employ it later in different levels of the UI development.},
 acmid = {2451184},
 address = {New York, NY, USA},
 author = {Mezhoudi, Nesrine},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451184},
 isbn = {978-1-4503-1966-9},
 keyword = {adaptation based on machine learning algorithms, user interfaces},
 link = {http://doi.acm.org/10.1145/2451176.2451184},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {25--28},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {User Interface Adaptation Based on User Feedback and Machine Learning},
 year = {2013}
}


@proceedings{Kim:2013:2449396,
 abstract = {It is our great pleasure to welcome you to the 2013 International Conference on Intelligent User Interfaces (IUI'13). This year marks the eighteenth meeting of this conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, increasing the intelligence of both in the process. The call for papers attracted 195 submissions from Asia, Canada, Europe, Africa, and the United States. The program committee accepted 43 papers covering a diverse set of topics, including brain-computer interaction, social media analysis, automated design, and crowdsourcing. The program opens with a keynote by Professor Luis von Ahn on "Duolingo: Learn a Language for Free while Helping to Translate the Web," and closes with a keynote by Professor Monica S. Lam on "How Mobile Disrupts Social As We Know it." We also have an excellent poster and demonstration program consisting of 14 demos and 22 posters selected from a pool of 64 total submissions. In addition, the conference provides two exciting tutorials and four interesting workshops. The tutorials feature an introduction to Human Computation by Edith Law and an introduction to knowledge acquisition from the web and social media by Zornitsa Kozareva. The workshops cover topics ranging from interactive machine learning to IUI for developing worlds. No conference of this size could be organized without the help of a large number of individuals who volunteer an enormous amount of their own time. Their names can be found in the following pages and each and every one of these extraordinary volunteers deserve our thanks. We want to especially recognize all of the members of the organizing committee, who put in countless hours over nearly a year to make the conference happen. If you see one of them in the hotel bar at the conference, please buy them a beverage of their choice. We must also thank our senior program committee for coordinating the review process and all 654 members of the program committee for providing high quality reviews that exceeded even our lofty expectations. Last, but certainly not least, we must thank the authors for providing the content for the program that is the foundation of any successful conference. We look forward to your presentations!},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1965-2},
 location = {Santa Monica, California, USA},
 publisher = {ACM},
 title = {IUI '13: Proceedings of the 2013 International Conference on Intelligent User Interfaces},
 year = {2013}
}


@inproceedings{Bourke:2013:RIS:2451176.2451219,
 abstract = {Information streams allow social network users to receive and interact with the latest messages from friends and followers. But as our social graphs grow and mature it becomes increasingly difficult to deal with the information overload that these realtime streams introduce. Some social networks, like Facebook, use proprietary interestingness metrics to rank messages in an effort to improve stream relevance and drive engagement. In this paper we evaluate learning to rank approaches to rank content based on a variety of features taken from live-user data.},
 acmid = {2451219},
 address = {New York, NY, USA},
 author = {Bourke, Steven and O'Mahony, Michael and Rafter, Rachael and Smyth, Barry},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451219},
 isbn = {978-1-4503-1966-9},
 keyword = {facebook, information stream;, learning to rank, social recommendation, social streams},
 link = {http://doi.acm.org/10.1145/2451176.2451219},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {99--100},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Ranking in Information Streams},
 year = {2013}
}


@inproceedings{Islam:2013:ARA:2451176.2451225,
 abstract = {This research proposes a novel computer-vision-based approach for skill assessment by observing a surgeon's hand and surgical tool movements in minimally invasive surgical training, which can be extended to the evaluation in real surgeries. Videos capturing the surgical field are analyzed using a system composed of a series of computer vision algorithms. The system automatically detects major skill measuring features from surgical task videos and provides real-time performance feedback on objective and quantitative measurement of surgical skills.},
 acmid = {2451225},
 address = {New York, NY, USA},
 author = {Islam, Gazi and Li, Baoxin and Kahol, Kanav},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451225},
 isbn = {978-1-4503-1966-9},
 keyword = {computer vision, feature detection, skill assessment, surgical training},
 link = {http://doi.acm.org/10.1145/2451176.2451225},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {111--112},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {An Affordable Real-time Assessment System for Surgical Skill Training},
 year = {2013}
}


@proceedings{Kim:2013:2451176,
 abstract = {It is our great pleasure to welcome you to the 2013 International Conference on Intelligent User Interfaces (IUI'13). This year marks the eighteenth meeting of this conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, increasing the intelligence of both in the process. The call for papers attracted 195 submissions from Asia, Canada, Europe, Africa, and the United States. The program committee accepted 43 papers covering a diverse set of topics, including brain-computer interaction, social media analysis, automated design, and crowdsourcing. The program opens with a keynote by Professor Luis von Ahn on "Duolingo: Learn a Language for Free while Helping to Translate the Web," and closes with a keynote by Professor Monica S. Lam on "How Mobile Disrupts Social As We Know it." We also have an excellent poster and demonstration program consisting of 14 demos and 22 posters selected from a pool of 64 total submissions. In addition, the conference provides two exciting tutorials and four interesting workshops. The tutorials feature an introduction to Human Computation by Edith Law and an introduction to knowledge acquisition from the web and social media by Zornitsa Kozareva. The workshops cover topics ranging from interactive machine learning to IUI for developing worlds. No conference of this size could be organized without the help of a large number of individuals who volunteer an enormous amount of their own time. Their names can be found in the following pages and each and every one of these extraordinary volunteers deserve our thanks. We want to especially recognize all of the members of the organizing committee, who put in countless hours over nearly a year to make the conference happen. If you see one of them in the hotel bar at the conference, please buy them a beverage of their choice. We must also thank our senior program committee for coordinating the review process and all 654 members of the program committee for providing high quality reviews that exceeded even our lofty expectations. Last, but certainly not least, we must thank the authors for providing the content for the program that is the foundation of any successful conference. We look forward to your presentations!},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1966-9},
 location = {Santa Monica, California, USA},
 publisher = {ACM},
 title = {IUI '13 Companion: Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 year = {2013}
}


@inproceedings{Hwang:2013:MMM:2451176.2451207,
 abstract = {In this paper, we present the Magnetic Marionette, a magnetically driven elastic controller that enables tangible interaction on mobile devices. This technique can determine eight different gestures in excess of 99% accuracy by sensing and tracking the magnets embedded on the controller. The advantage of this technique is that it is lightweight, battery-free, and inexpensive because it uses a magnetometer, which is already embedded in smart phones today. This simple and noble technique allows users to achieve richer tactile feedback, expand their interaction area, and enhance expressiveness without the need for hardware modification.},
 acmid = {2451207},
 address = {New York, NY, USA},
 author = {Hwang, Sungjae and Ahn, Myungwook and Wohn, Kwangyun},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451207},
 isbn = {978-1-4503-1966-9},
 keyword = {magnetometer, mobile device, pattern recognition, pseudo sensor, sensor repurposing, tangible controller, tui},
 link = {http://doi.acm.org/10.1145/2451176.2451207},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {75--76},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Magnetic Marionette: Magnetically Driven Elastic Controller on Mobile Device},
 year = {2013}
}


@inproceedings{Schulz:2013:MIS:2451176.2451218,
 abstract = {In this paper we present an intelligent user interface which combines a speech-based interface with several other input modalities. The integration of multiple devices into a working environment should provide greater flexibility to the daily routine of medical experts for example. To this end, we will introduce a medical cyber-physical system that demonstrates the use of a bidirectional connection between a speech-based interface and a head-mounted see-through display. We will show examples of how we can exploit multiple input modalities and thus increase the usability of a speech-based interaction system.},
 acmid = {2451218},
 address = {New York, NY, USA},
 author = {Schulz, Christian and Sonntag, Daniel and Weber, Markus and Toyama, Takumi},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451218},
 isbn = {978-1-4503-1966-9},
 keyword = {interaction design, medical healthcare, multimodal interaction, natural language processing, pervasive computing},
 link = {http://doi.acm.org/10.1145/2451176.2451218},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {97--98},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Multimodal Interaction Strategies in a Multi-device Environment Around Natural Speech},
 year = {2013}
}


@inproceedings{Shen:2013:WPA:2451176.2451210,
 abstract = {Mobile phones have been widely used to access, retrieve and organize information. In this paper, we present the meshin system, an intelligent personal assistant that organizes messages, notifications and appointments for mobile phone users. To help users prepare for meetings, meshin automatically creates a profile for each meeting attendee. The meshin system searches the Internet with the attendee's name and the domain of the email address, then retrieves and aggregates information for this attendee. To get a better understanding of the attendee, it further estimates the personality profile based on the emails he/she wrote. Our experimental results show that our system can predict personality with reasonable accuracies (95%).},
 acmid = {2451210},
 address = {New York, NY, USA},
 author = {Shen, Jianqiang and Brdiczka, Oliver and Liu, Juan and Suzuki, Masafumi},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451210},
 isbn = {978-1-4503-1966-9},
 keyword = {email, personal assistant, personality, text processing},
 link = {http://doi.acm.org/10.1145/2451176.2451210},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {81--82},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {WhoAmi: Profiling Attendees Before Meetings},
 year = {2013}
}


@inproceedings{Perakakis:2013:AET:2451176.2451222,
 abstract = {We propose a new interface evaluation tool that incorporates affective metrics which are provided from the ElectroEncephaloGraphy (EEG) signals of the Emotiv EPOC neuro-headset device. The evaluation tool captures and analyzes information in real time from a multitude of sources such as EEG, affective metrics such as frustration, engagement and excitement and facial expression. The proposed tool has been used to gain detailed affective information of users interacting with a mobile multimodal (touch and speech) iPhone application, for which we investigated the effect of speech recognition errors and modality usage patterns.},
 acmid = {2451222},
 address = {New York, NY, USA},
 author = {Perakakis, Manolis and Potamianos, Alexandros},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451222},
 isbn = {978-1-4503-1966-9},
 keyword = {affective evaluation, brain signals, eeg, evaluation tool, iphone, usability research},
 link = {http://doi.acm.org/10.1145/2451176.2451222},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {105--106},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {An Affective Evaluation Tool Using Brain Signals},
 year = {2013}
}


@inproceedings{Gil:2013:IAS:2451176.2451224,
 abstract = {Semantic wikis augment wikis with semantic properties that can be used to aggregate and query data through reasoning. Semantic wikis are used by many communities, for widely varying purposes such as organizing genomic knowledge, coding software, and tracking environmental data. Although wikis have been analyzed extensively, there has been no published analysis of the use of semantic wikis. We carried out an initial analysis of twenty semantic wikis selected for their diverse characteristics and content. Based on the number of property edits per contributor, we identified several patterns to characterize community behaviors that are common to groups of wikis.},
 acmid = {2451224},
 address = {New York, NY, USA},
 author = {Gil, Yolanda and Knight, Angela and Zhang, Kevin and Zhang, Larry and Sethi, Ricky},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451224},
 isbn = {978-1-4503-1966-9},
 keyword = {rdf, semantic web, semantic wikis, social knowledge collection},
 link = {http://doi.acm.org/10.1145/2451176.2451224},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {109--110},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {An Initial Analysis of Semantic Wikis},
 year = {2013}
}


@inproceedings{Schwartz:2013:IWL:2451176.2451228,
 abstract = {This workshop explores the interactions between location awareness and Dual/Mixed/PolySocial Reality in smart (instrumented) environments and their impact on culture and society. The main scope of this workshop is to explore how a Dual/Mixed/PolySocial Reality paradigm can be used to improve applications in smart environments and, by extension, which new possibilities can be opened up by these paradigms. These may include positioning methods and location-based services using the DR paradigm, such as navigation services and group interaction services (location-based social signal processing) as well as agent based intermediaries to offset errant voluminous multiplexed communication messaging. The workshop is also open to discuss sensor and actuator technologies that are being developed to foster the growth of interaction possibilities in smart environments.},
 acmid = {2451228},
 address = {New York, NY, USA},
 author = {Schwartz, Tim and Kahl, Gerrit and Applin, Sally A. and Dim, Eyal},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451228},
 isbn = {978-1-4503-1966-9},
 keyword = {dual reality, location-based services, mixed reality, polysocial reality, positioning, social anthropology, social signal processing},
 link = {http://doi.acm.org/10.1145/2451176.2451228},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {115--118},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {IUI 2013 3rd Workshop on Location Awareness for Mixed and Dual Reality: (LAMDa'13)},
 year = {2013}
}


@inproceedings{Shirokura:2013:EEE:2451176.2451192,
 abstract = {We developed E3-player, a novel video player with three operation modes which enhances video experiences by using a user's physiological inputs. This system's purpose is to enhance the emotional excitement of the users by reinforcing their response to the videos they are watching. Users who use the E3-player need only to attach a physiological sensor to their own hand and wearing noise-cancelling headphones. Through our experiments, we ensure that the E3-player can indeed enhance video experience and provide new video experiences for viewers.},
 acmid = {2451192},
 address = {New York, NY, USA},
 author = {Shirokura, Takumi and Munekata, Nagisa and Ono, Tetsuo},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451192},
 isbn = {978-1-4503-1966-9},
 keyword = {entertainment computing, physiological input, skin conductance response, video player},
 link = {http://doi.acm.org/10.1145/2451176.2451192},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {47--48},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {E3-player: Emotional Excitement Enhancing Video Player Using Skin Conductance Response},
 year = {2013}
}


@inproceedings{Mancilla-Caceres:2013:AGR:2451176.2451183,
 abstract = {Peer influence in social networks has long been recognized as one of the key factors in many of the social health issues that affect young people. In order to study peer networks, scientists have relied on the use of self-report surveys that impose limitations on the types of issues than can be studied. On the other hand, the ever increasing use of computers for communication has given rise to new ways of studying group dynamics and, even more importantly, it has enabled a new way to affect those dynamics as they are detected. Our work is focused on designing and analyzing computer social games that can be used as data collection tools for social interactions, and that can also react and change accordingly in order to promote prosocial, rather than aggressive, behavior.},
 acmid = {2451183},
 address = {New York, NY, USA},
 author = {Mancilla-Caceres, Juan F. and Amir, Eyal and Espelage, Dorothy},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451183},
 isbn = {978-1-4503-1966-9},
 keyword = {bullying detection, computational social science, games with a purpose},
 link = {http://doi.acm.org/10.1145/2451176.2451183},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {21--24},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Adaptive Game for Reducing Aggressive Behavior},
 year = {2013}
}


@inproceedings{Glowacka:2013:SSB:2451176.2451199,
 abstract = {Techniques for both exploratory and known item search tend to direct only to more specific subtopics or individual documents, as opposed to allowing directing the exploration of the information space. We present SciNet, an interactive information retrieval system that combines Reinforcement Learning techniques along with a novel user interface design to allow active engagement of users in directing the search. Users can directly manipulate document features (keywords) to indicate their interests and Reinforcement Learning is used to model the user by allowing the system to trade off between exploration and exploitation. This gives users the opportunity to more effectively direct their search.},
 acmid = {2451199},
 address = {New York, NY, USA},
 author = {G\lowacka, Dorota and Ruotsalo, Tuukka and Konyushkova, Ksenia and Athukorala, Kumaripaba and Kaski, Samuel and Jacucci, Giulio},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451199},
 isbn = {978-1-4503-1966-9},
 keyword = {adaptive interfaces, datamining and machine learning, information retrieval, recommender/filtering systems},
 link = {http://doi.acm.org/10.1145/2451176.2451199},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {61--62},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {SciNet: A System for Browsing Scientific Literature Through Keyword Manipulation},
 year = {2013}
}


@inproceedings{Denoue:2013:RDM:2451176.2451190,
 abstract = {We describe direct video manipulation interactions applied to screen-based tutorials. In addition to using the video timeline, users of our system can quickly navigate into the video by mouse-wheel, double click over a rectangular region to zoom in and out, or drag a box over the video canvas to select text and scrub the video until the end of a text line even if not shown in the current frame. We describe the video processing techniques developed to implement these direct video manipulation techniques, and show how they are implemented to run in most modern web browsers using HTML5's CANVAS and Javascript.},
 acmid = {2451190},
 address = {New York, NY, USA},
 author = {Denoue, Laurent and Carter, Scott and Cooper, Matthew and Adcock, John},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451190},
 isbn = {978-1-4503-1966-9},
 keyword = {direct manipulation, html5, intelligent user interface, real-time, video processing, web browser},
 link = {http://doi.acm.org/10.1145/2451176.2451190},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {43--44},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Real-time Direct Manipulation of Screen-based Videos},
 year = {2013}
}


@inproceedings{Tamura:2013:HHP:2451176.2451220,
 abstract = {We propose a system called Haptic Pad for Impressive Text Communication for creating text messages with haptic stimuli using the SPIDAR-tablet haptic interface. This system helps users indicate emotion in text messages and actions of characters in storytelling by attaching physical feedback to words in text. We evaluated the effectiveness of the system experimentally in two scenarios: storytelling and text messaging. We found that effective use of haptic stimuli depends on each situation and participant.},
 acmid = {2451220},
 address = {New York, NY, USA},
 author = {Tamura, Ayano and Okada, Shogo and Nitta, Katsumi and Harada, Tetsuya and Sato, Makoto},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451220},
 isbn = {978-1-4503-1966-9},
 keyword = {affect, communication, e-mail application, haptic interface, haptics, text messaging, touch panel},
 link = {http://doi.acm.org/10.1145/2451176.2451220},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {101--102},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {HAPPIcom: Haptic Pad for Impressive Text Communication},
 year = {2013}
}


@inproceedings{Adams:2013:KWC:2451176.2451194,
 abstract = {Online resources known as wikis are commonly used for collection and distribution of information. We present a software implementation that assists wiki contributors with the task of keeping a wiki current. Our demonstration, built using English Wikipedia, enables wiki contributors to subscribe to sources of news, based on which it makes intelligent recommendations for pages within Wikipedia where the new content should be added. This tool is also potentially useful for helping new Wikipedia editors find material to contribute.},
 acmid = {2451194},
 address = {New York, NY, USA},
 author = {Adams, Rachel and Kuntz, Alex and Marks, Morgan and Martin, William and Musicant, David},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451194},
 isbn = {978-1-4503-1966-9},
 keyword = {news feeds, recommendations, wiki, workflow},
 link = {http://doi.acm.org/10.1145/2451176.2451194},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {51--52},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Keeping Wiki Content Current via News Sources},
 year = {2013}
}


@inproceedings{Shin:2013:SSS:2451176.2451217,
 abstract = {To enhance the incorrectness of keyword based search, we propose an efficient semantic search method based on a lightweight mobile ontology designed for smart mobile devices. In addition, we implement a prototype of semantic search engine working on Android smartphones and our prototype engine provides better user experience compared with keyword based search.},
 acmid = {2451217},
 address = {New York, NY, USA},
 author = {Shin, Sangjin and Ko, Jihoon and Shin, Dong-Hoon and Jung, Jooik and Lee, Kyong-Ho},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451217},
 isbn = {978-1-4503-1966-9},
 keyword = {mobile ontology, semantic search, smart phone},
 link = {http://doi.acm.org/10.1145/2451176.2451217},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {95--96},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Semantic Search for Smart Mobile Devices},
 year = {2013}
}


@inproceedings{Kuwabara:2013:GCP:2451176.2451212,
 abstract = {Ghost-Hunting (GH) is a new technique that improves pointing performance in a graphical user interface (GUI) by expanding targets to facilitate easier access. In GH, the effect of decreasing the movement distance of a cursor by expanding the size of onscreen targets is utilized to improve the GUI. GH shows the guides of the end point of the shortest movement path, called ghosts, inside expanded target areas. Users can optimize their cursor movements by only moving their cursor towards the ghosts in GH, unlike other techniques that use the invisible outline of an expanded target such as with Bubble Cursor. We conduct an experimental evaluation to clarify the effectiveness of GH in menu-item selection tasks. The result shows that GH's selection time was significantly faster than that of the ordinal cursor or Bubble Cursor. In particular, GH is faster than Bubble Cursor in environments with a high density of targets.},
 acmid = {2451212},
 address = {New York, NY, USA},
 author = {Kuwabara, Chihiro and Yamamoto, Keiko and Kuramoto, Itaru and Tsujino, Yoshihiro and Minakuchi, Mitsuru},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451212},
 isbn = {978-1-4503-1966-9},
 keyword = {area cursor, bubble cursor, ghost-hunting, pointing, target acquisition, voronoi diagram},
 link = {http://doi.acm.org/10.1145/2451176.2451212},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {85--86},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Ghost-hunting: A Cursor-based Pointing Technique with Picture Guide Indication of the Shortest Path},
 year = {2013}
}


@inproceedings{Schnelle-Walka:2013:SSW:2451176.2451227,
 abstract = {Smart objects are everyday objects that have computing capabilities and give rise to new ways of interaction with our environment. The increasing number of smart objects in our life shapes how we interact beyond the desktop. In this workshop we explore various aspects of the design, development and deployment of smart objects including how one can interact with smart objects.},
 acmid = {2451227},
 address = {New York, NY, USA},
 author = {Schnelle-Walka, Dirk and Huber, Jochen and Lissermann, Roman and Brdiczka, Oliver and Luyten, Kris and M\"{u}hlh\"{a}user, Max},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451227},
 isbn = {978-1-4503-1966-9},
 keyword = {context-aware computing, home, input and interaction technologies, interaction design, multi-modal interfaces, usability testing and evaluation, user experience design / experience design, user interface design, user studies},
 link = {http://doi.acm.org/10.1145/2451176.2451227},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {113--114},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {SmartObjects: Second Workshop on Interacting with Smart Objects},
 year = {2013}
}


@proceedings{Duarte:2012:2166966,
 abstract = {It is our great pleasure to welcome you to the 2012 ACM International Conference on Intelligent User Interfaces -- IUI'12 and to Lisboa, Portugal. Starting in 1993, IUI is now on its 17th edition and has established itself has the premier venue for reporting outstanding research and development on intelligent user interface. The IUI series continues to be the principal forum for the meeting of the Human-Computer Interaction (HCI) and the Artificial Intelligence (AI) communities. This gives rise to unique, creative, interdisciplinary contributions. This year's meeting showcases those topics, with works covering innovations in mobile interfaces, collaboration technology, affective interfaces, multimodal interfaces, pen interfaces, haptic and gesture interfaces, multi-touch interfaces, speech interfaces, gaze-based interfaces, tabletop interfaces, health applications, entertainment applications, adaptive narratives and theater, sports and in-vehicle applications, geographic applications, social media interfaces, educational interfaces, sketch recognition, human-robot interfaces, personalization and assistive technologies, end-user programming, ubiquitous and smart environments, locationaware interfaces, recommender interfaces, persuasive interfaces, web-based interfaces and agentbased interfaces. Building on previous years' success, the IUI 2012 call for papers attracted 134 full paper submissions and 78 short paper submissions. To ensure the highest possible quality we assembled a team of 48 senior program committee members and 367 reviewers. This guaranteed that every submission had at least three reviews plus one meta-review. This was followed by a rebuttal phase, keeping the procedure started two years ago. We believe that this process has guaranteed the highest quality possible for this year technical program and we would like to thank all the senior program committee members and reviewers for their hard work in making sure the most relevant works were selected. Through this very thorough review process we were able to accept 18 full papers, 15 short papers and 16 poster presentations, meaning an acceptance rate of 13% for full papers, 16% for oral presentations and 23% for combined oral and poster presentations. In addition to the full and short papers presentations and poster presentations, IUI will also feature a Demonstrations session for which 18 submissions were accepted from a total of 26 submissions. This year, the IUI programme includes three notable invited speakers sharing their innovative work and experiences with the conference participants: Alex 'Sandy' Pentland from the MIT Human Dynamic Lab, Christopher Bishop from Microsoft Research and Takeo Igarashi from the University of Tokyo. In order to foster the growth of the community, IUI 2012 will feature for the first time in the IUI series a Doctoral Consortium. Its success can be measured by the 12 high quality submissions received. Doctoral Consortium students will also be able to exhibit their work to the main conference audience in the poster session, thus promoting their insertion into the IUI community. We would also like to thank the conference sponsors and supporters that made it possible to provide financial support for Doctoral Consortium attendees and other students participating in the conference. Nine full-day workshops will take place at IUI 2012 covering diverse trending topics in the IUI area: Activity Context Representation: Techniques and Languages; Developing Intelligent User Interfaces for e-Accessibility and e-Inclusion; Context-awareness in Retrieval and Recommendation (CaRR 2012); 3rd Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS); Scent and Scensibility; User Modeling from Social Media; 2nd Workshop on Interacting with Smart Objects; 2nd Workshop on Location Awareness for Mixed and Dual Reality (LaMDa'12); 1st International Workshop on Ubiquitous Personalization (UP'2012). IUI 2012 continues and extends the cooperation with the ACM Transactions on Interactive Intelligent Systems (TiiS). Besides the streamlined processing of journal submissions based on IUI 2012 papers, IUI 2012 will feature a special session where authors of recently accepted articles for the ACM TiiS will spotlight key contributions of their work. It is our conviction that it will benefit greatly every member of the IUI community. We would like to thank Anthony Jameson and John Riedl, the Editors in Chief of TiiS, for their cooperation.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1048-2},
 location = {Lisbon, Portugal},
 note = {608120},
 publisher = {ACM},
 title = {IUI '12: Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 year = {2012}
}


@inproceedings{Ozbal:2013:NTS:2451176.2451196,
 abstract = {In this paper, we introduce a system that supports the naming process by exploiting natural language processing and linguistic creativity techniques in a completely unsupervised fashion. The system generates two types of neologisms based on the category of the service to be named and the properties to be underlined. While the first type consists of homophonic puns and metaphors, the second consists of neologisms that are produced by adding Latin suffixes to English words or homophonic puns. During this process, both semantic appropriateness and sound pleasantness of the generated names are taken into account.},
 acmid = {2451196},
 address = {New York, NY, USA},
 author = {\"{O}zbal, G\"{u}zde and Strapparava, Carlo},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451196},
 isbn = {978-1-4503-1966-9},
 keyword = {branding, computational creativity, natural language processing},
 link = {http://doi.acm.org/10.1145/2451176.2451196},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {55--56},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Namelette: A Tasteful Supporter for Creative Naming},
 year = {2013}
}


@inproceedings{Novacek:2013:SMS:2451176.2451198,
 abstract = {Unlike full reading, 'skim-reading' involves the process of looking quickly over information in an attempt to cover more material whilst still being able to retain a superficial view of the underlying content. Within this work, we specifically emulate this natural human activity by providing a dynamic graph-based view of entities automatically extracted from text using superficial text parsing / processing techniques. We provide a preliminary web-based tool (called 'SKIMMR') that generates a network of inter-related concepts from a set of documents. In SKIMMR, a user may browse the network to investigate the lexically-driven information space extracted from the documents. When a particular area of that space looks interesting to a user, the tool can then display the documents that are most relevant to the displayed concepts. We present this as a simple, viable methodology for browsing a document collection (such as a collection scientific research articles) in an attempt to limit the information overload of examining that document collection. This paper presents a motivation and overview of the approach, outlines technical details of the preliminary SKIMMR implementation, describes the tool from the user's perspective and summarises the related work.},
 acmid = {2451198},
 address = {New York, NY, USA},
 author = {Nov\'{a}\v{c}ek, V\'{\i}t and Burns, Gully},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451198},
 isbn = {978-1-4503-1966-9},
 keyword = {distributional semantics, information visualisation, knowledge extraction, text mining},
 link = {http://doi.acm.org/10.1145/2451176.2451198},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {59--60},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {SKIMMR: Machine-aided Skim-reading},
 year = {2013}
}


@inproceedings{Kahl:2013:VMM:2451176.2451216,
 abstract = {Smart spaces are equipped with a large number of sensors and actuators. Data measured by the sensors is sent to respective services, which can react on them and control actuators correspondingly. In order to improve the services and make them smarter, they can communicate with each other and exchange data. The more interferences between the services exist, the more complex is the monitoring and extension of such smart spaces. In this paper, we propose a monitoring tool for these environments, which consists of a real and a virtual component. The real component is the physical smart space itself and the virtual one consists of a three-dimensional model of the space. Sensor information is transmitted from the real to the virtual component and represented there, via an appropriate visualization. Additionally, the tool offers a communication channel from the virtual component to the real counterpart to control the physical actuators.},
 acmid = {2451216},
 address = {New York, NY, USA},
 author = {Kahl, Gerrit},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451216},
 isbn = {978-1-4503-1966-9},
 keyword = {dual reality, monitoring tool, smart spaces},
 link = {http://doi.acm.org/10.1145/2451176.2451216},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {93--94},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {A Visual Monitoring and Management Tool for Smart Environments},
 year = {2013}
}


@inproceedings{Amershi:2013:IWI:2451176.2451230,
 abstract = {Many applications of Machine Learning (ML) involve interactions with humans. Humans may provide input to a learning algorithm (in the form of labels, demonstrations, corrections, rankings or evaluations) while observing its outputs (in the form of feedback, predictions or executions). Although humans are an integral part of the learning process, traditional ML systems used in these applications are agnostic to the fact that inputs/outputs are from/for humans. However, a growing community of researchers at the intersection of ML and human-computer interaction are making interaction with humans a central part of developing ML systems. These efforts include applying interaction design principles to ML systems, using human-subject testing to evaluate ML systems and inspire new methods, and changing the input and output channels of ML systems to better leverage human capabilities. With this Interactive Machine Learning (IML) workshop at IUI 2013 we aim to bring this community together to share ideas, get up-to-date on recent advances, progress towards a common framework and terminology for the field, and discuss the open questions and challenges of IML.},
 acmid = {2451230},
 address = {New York, NY, USA},
 author = {Amershi, Saleema and Cakmak, Maya and Knox, W. Bradley and Kulesza, Todd and Lau, Tessa},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451230},
 isbn = {978-1-4503-1966-9},
 keyword = {active learning, democratizing machine learning, empirical studies and computational models of human teaching, end-user programming, feature labeling, human-in-the-loop intelligent systems, interactive clustering, programming by demonstration, reinforcement learning with human feedback or guidance, transparency and feedback in machine learning},
 link = {http://doi.acm.org/10.1145/2451176.2451230},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {121--124},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {IUI Workshop on Interactive Machine Learning},
 year = {2013}
}


@inproceedings{Vrzakova:2013:CAV:2451176.2451187,
 abstract = {Many aspects of interaction are hard to directly observe and measure. My research focuses on particular aspects of UX such as cognitive workload, problem solving or engagement, and establishes computational links between them and visual attention. Using machine learning and pattern recognition techniques, I aim to achieve automatic inferences for HCI and employ them as enhancements in gaze-aware interfaces.},
 acmid = {2451187},
 address = {New York, NY, USA},
 author = {Vrzakova, Hana},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451187},
 isbn = {978-1-4503-1966-9},
 keyword = {eye-tracking, interaction inference, machine learning},
 link = {http://doi.acm.org/10.1145/2451176.2451187},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {37--40},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Computational Approaches to Visual Attention for Interaction Inference},
 year = {2013}
}


@inproceedings{Mahmud:2013:IRI:2451176.2451204,
 abstract = {With changes of customer requirements, web development, especially developing Rich Internet Applications (RIA) with complex widgets and data-driven behavior can be a time-consuming task. In our previous work [3], we have presented a test-driven web development approach using ClearScript test cases as requirements to automatically generate widgets, and thus reduce the barrier of web development and testing. We extend on this work, and develop a machine learning based algorithm to identify RIA patterns [1] from requirements specified as test cases, and automatically instantiate them using simple rules. We also present performance of our algorithm and a user study which demonstrates the viability of our approach.},
 acmid = {2451204},
 address = {New York, NY, USA},
 author = {Mahmud, Jalal},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451204},
 isbn = {978-1-4503-1966-9},
 keyword = {data driven, pattern detection, ria},
 link = {http://doi.acm.org/10.1145/2451176.2451204},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {69--70},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Improving Rich Internet Application Development Using Patterns},
 year = {2013}
}


@inproceedings{Mace:2013:AHG:2451176.2451211,
 abstract = {Accelerometer-based gesture recognition is a major area of interest in human-computer interaction. In this paper, we compare two approaches: naïve Bayesian classification with feature separability weighting [1] and dynamic time warping [2]. Algorithms based on these two approaches are introduced and the results are compared. We evaluate both algorithms with four gesture types and five samples from five different people. The gesture identification accuracy for Bayesian classification and dynamic time warping are 97% and 95%, respectively.},
 acmid = {2451211},
 address = {New York, NY, USA},
 author = {Mace, David and Gao, Wei and Coskun, Ayse},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451211},
 isbn = {978-1-4503-1966-9},
 keyword = {accelerometer, bayesian classifier, dynamic time warping, feature separability weighting, gesture recognition;},
 link = {http://doi.acm.org/10.1145/2451176.2451211},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {83--84},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Accelerometer-based Hand Gesture Recognition Using Feature Weighted Na\"{\i}Ve Bayesian Classifiers and Dynamic Time Warping},
 year = {2013}
}


@inproceedings{Hwang:2013:VLP:2451176.2451206,
 abstract = {In this paper, we present a low-cost placement-aware technique, called VibroTactor, which allows mobile devices to determine where they are placed (e.g., in a pocket, on a phone holder, on the bed, or on the desk). This is achieved by filtering and analyzing the acoustic signal generated when the mobile device vibrates. The advantage of this technique is that it is inexpensive and easy to deploy because it uses a microphone, which already embedded in standard mobile devices. To verify this idea, we implemented a prototype and conducted a preliminary test. The results show that this system achieves an average success rate of 91% in 12 different real-world placement sets.},
 acmid = {2451206},
 address = {New York, NY, USA},
 author = {Hwang, Sungjae and Wohn, Kwangyun},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451206},
 isbn = {978-1-4503-1966-9},
 keyword = {context-aware, pattern recognition, placement detection, pseudo sensor, sensor repurposing, vibration echoes},
 link = {http://doi.acm.org/10.1145/2451176.2451206},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {73--74},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {VibroTactor: Low-cost Placement-aware Technique Using Vibration Echoes on Mobile Devices},
 year = {2013}
}


@inproceedings{Knox:2013:TAH:2451176.2451201,
 abstract = {Incorporating human interaction into agent learning yields two crucial benefits. First, human knowledge can greatly improve the speed and final result of learning compared to pure trial-and-error approaches like reinforcement learning. And second, human users are empowered to designate "correct" behavior. In this abstract, we present research on a system for learning from human interaction - the TAMER framework - then point to extensions to TAMER, and finally describe a demonstration of these systems.},
 acmid = {2451201},
 address = {New York, NY, USA},
 author = {Knox, W. Bradley and Stone, Peter and Breazeal, Cynthia},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451201},
 isbn = {978-1-4503-1966-9},
 keyword = {end-user programming, human-agent interaction, interactive machine learning, modeling and prediction of user behavior, reinforcement learning},
 link = {http://doi.acm.org/10.1145/2451176.2451201},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {65--66},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Teaching Agents with Human Feedback: A Demonstration of the TAMER Framework},
 year = {2013}
}


@inproceedings{Ehlen:2013:MDI:2451176.2451200,
 abstract = {Speak4itSM uses a multimodal interface to perform mobile search for local businesses. Users combine simultaneous speech and touch to input queries or commands, for example, by saying, "gas stations", while tracing a route on a touchscreen. This demonstration will exhibit an extension of our multimodal semantic processing architecture from a one-shot query system to a multimodal dialogue system that tracks dialogue state over multiple turns and resolves prior context using unification-based context resolution. We illustrate the capabilities and limitations of this approach to multimodal interpretation, describing the challenges of supporting true multimodal interaction in a deployed mobile service, while offering an interactive demonstration on tablets and smartphones.},
 acmid = {2451200},
 address = {New York, NY, USA},
 author = {Ehlen, Patrick and Johnston, Michael},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451200},
 isbn = {978-1-4503-1966-9},
 keyword = {dialog, multimodal interfaces,, search},
 link = {http://doi.acm.org/10.1145/2451176.2451200},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {63--64},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {A Multimodal Dialogue Interface for Mobile Local Search},
 year = {2013}
}


@inproceedings{Lee:2013:IDP:2451176.2451195,
 abstract = {In this paper, we introduce an interactive application for planar curve design in a real world based on spatial augmented reality (SAR). The key component is a projector-camera unit that recognizes physical control objects (i.e., key points of an intended curve) using a camera and displays a design result (i.e., a B-spline curve) directly on the real world surface using a projector. Usually, geometric design is performed with the aid of CAD software and traditional user interfaces of a computer system. The main contribution of this paper is application of spatial augmented reality techniques in the domain of computer-aided geometric design (CAGD) for more tangible and intuitive interaction in a real world. We describe the feature of the prototype system and demonstrate the working application with examples.},
 acmid = {2451195},
 address = {New York, NY, USA},
 author = {Lee, Ahyun and Suh, Jeong Dae and Lee, Joo-Haeng},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451195},
 isbn = {978-1-4503-1966-9},
 keyword = {cagd, calibration, projector-camera system, spatial augmented reality (sar), tangible interaction},
 link = {http://doi.acm.org/10.1145/2451176.2451195},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {53--54},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Interactive Design of Planar Curves Based on Spatial Augmented Reality},
 year = {2013}
}


@inproceedings{Hagiya:2013:APF:2451176.2451205,
 abstract = {To provide an accurate and user-adaptable software keyboard for touchscreens, we propose a probabilistic flick keyboard based on HMMs. This keyboard can reduce the input error by taking the time series of the actual touch position into consideration and by user adaptation. We evaluated performance of the HMM-based flick keyboard and MLLR adaptation. Experimental results showed that a user-dependent model reduced the error rate by 28.2%. In a practical setting, MLLR user adaptation with only 10 words reduced the error rate by 16.5% and increased typing speed by 10.5%.},
 acmid = {2451205},
 address = {New York, NY, USA},
 author = {Hagiya, Toshiyuki and Kato, Tsuneo},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451205},
 isbn = {978-1-4503-1966-9},
 keyword = {handheld devices, input technologies, personalization},
 link = {http://doi.acm.org/10.1145/2451176.2451205},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {71--72},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Adaptable Probabilistic Flick Keyboard Based on HMMs},
 year = {2013}
}


@inproceedings{Ahmed:2013:SFE:2451176.2451197,
 abstract = {In the emerging field of speech-to-speech translation, emphasis is currently placed on the linguistic content, while the significance of paralinguistic information conveyed by facial expression or tone of voice is typically neglected. We present a prototype system for multimodal speech-to-speech translation that is able to automatically recognize and translate spoken utterances from one language into another, with the output rendered by a speech synthesis system. The novelty of our system lies in the technique of generating the synthetic speech output in one of several expressive styles that is automatically determined using a camera to analyze the user's facial expression during speech.},
 acmid = {2451197},
 address = {New York, NY, USA},
 author = {Ahmed, Zeeshan and Steiner, Ingmar and Sz{\'e}kely, \'{E}va and Carson-Berndsen, Julie},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451197},
 isbn = {978-1-4503-1966-9},
 keyword = {emotion and affective user interface, multi-modal interfaces, speech i/o, video analysis},
 link = {http://doi.acm.org/10.1145/2451176.2451197},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {57--58},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {A System for Facial Expression-based Affective Speech Translation},
 year = {2013}
}


@inproceedings{Agarwal:2013:IWI:2451176.2451229,
 abstract = {Information Technology (IT) has had significant impact on the society and has touched all aspects of our lives. Up and until now computers and expensive devices have fueled this growth. It has resulted in several benefits to the society. The challenge now is to take this success to its next level where IT services can be accessed by users in developing regions. The first IUI4DR workshop was held at IUI 2008. This workshop focused on low cost interfaces, interfaces for illiterate people and on exploring different input mechanisms. The second workshop held at IUI 2011 focused on multimodal applications and collaborative interfaces in particular to aid effective navigation of content and access to services. So far we have concentrated on mobile devices as the primary method for people to access content and services. In particular we focused on low-end feature phones that are widely used. However the smart phone market is booming even in developing countries with touch phones available for as little as 50 USD. We want to explore how devices such as smart TVs, smart phones, and old desktop machines, radios, etc. can be used to provide novel interaction methods and interfaces for the low literate populations. We would also like to continue our focus on interaction modalities other than speech such as gestures, haptic inputs and touch interfaces. },
 acmid = {2451229},
 address = {New York, NY, USA},
 author = {Agarwal, Sheetal and Rajput, Nitendra and Kodagoda, Neesha and Wong, B.L. William and Oviatt, Sharon},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451229},
 isbn = {978-1-4503-1966-9},
 keyword = {developing regions, intelligent assistants, interaction design, multimodal interfaces},
 link = {http://doi.acm.org/10.1145/2451176.2451229},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {119--120},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {3rd International Workshop on Intelligent User Interfaces for Developing Regions: IUI4DR},
 year = {2013}
}


@inproceedings{O'Banion:2013:FLA:2451176.2451214,
 abstract = {Journalists often localize news stories that are not explicitly about the community they serve by investigating and describing how those stories affect that community. This is, in essence, a form of personalization based not on a reader's personal interests, but rather on their ties to a geographic location. In this paper we present The Local Angle, an approach for automating the process of finding national and international news stories that are locally relevant. The Local Angle associates the people, companies, and organizations mentioned in news stories with geographic locations using semantic analysis tools and online knowledge bases. We describe the design and implementation of our prototype system that helps content curators and consumers discover articles that are of local interest even if they do not originate locally.},
 acmid = {2451214},
 address = {New York, NY, USA},
 author = {O'Banion, Shawn and Birnbaum, Larry and Bradley, Scott},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451214},
 isbn = {978-1-4503-1966-9},
 keyword = {local news, personalization, recommendation system},
 link = {http://doi.acm.org/10.1145/2451176.2451214},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {89--90},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Finding the Local Angle in National News},
 year = {2013}
}


@inproceedings{Karasudani:2013:EDR:2451176.2451208,
 abstract = {In order to reduce people's workload of looking for valuable information from a large amount of available information, recommendation systems, task management systems, and so on are attracting considerable attention. Such systems are expected to allow easy access to information under the current work context. In the development of these systems, how to handle a user's current work context to know what information he wants to use is a key point. We have developed a novel method to extract relationships among documents as the work context by analyzing the user's activity history according to several viewpoints of a human being who memorizes and seeks information. We report the details of the proposed method, the evaluation result, and an application example.},
 acmid = {2451208},
 address = {New York, NY, USA},
 author = {Karasudani, Akira and Iwata, Satoshi and Matsumoto, Tatsuro and Aritake, Hirokazu},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451208},
 isbn = {978-1-4503-1966-9},
 keyword = {activity history, relationships between documents},
 link = {http://doi.acm.org/10.1145/2451176.2451208},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {77--78},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Extracting Document Relationships by Analyzing User's Activity History},
 year = {2013}
}


@inproceedings{Kahl:2013:PSS:2451176.2451223,
 abstract = {Providing private data is a highly controversial and widely debated topic. Not only the information about individuals but also about companies should be kept private. In order to satisfy the needs of both individuals and companies, corresponding privacy protection mechanisms have to be implemented. For example, systems which assist customers during their shopping process in a physical retail store require customer related information, such as the shopping list, allergy or bank account information as well as data from the retailer, like the product range and prices. In this paper, we introduce a concept for decoupling both information sources implemented in a shopping scenario, which amongst others allows Mobile Payment without the transmission of private data. The implemented prototype has been presented at a large fair to potential users in order to receive valuable feedback.},
 acmid = {2451223},
 address = {New York, NY, USA},
 author = {Kahl, Gerrit and Paradowski, Denise},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451223},
 isbn = {978-1-4503-1966-9},
 keyword = {mobile payment, nfc, smart shopping cart},
 link = {http://doi.acm.org/10.1145/2451176.2451223},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {107--108},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {A Privacy-aware Shopping Scenario},
 year = {2013}
}


@inproceedings{Seyed:2013:SSB:2451176.2451186,
 abstract = {Devices such as tablets, mobile phones, tabletops and wall displays all incorporate different sizes of screens, and are now commonplace in a variety of situations and environments. Environments that incorporate these devices, multi-display environments (MDEs) are highly interactive and innovative, but the interaction in these environments is not well understood. The research presented here investigates and explores interaction and users in MDEs. This exploration tries to understand the conceptual models of MDEs for users and then examine and validate interaction approaches that can be done to make them more usable. In addition to a brief literature review, the methodology, research goals and current research status are presented.},
 acmid = {2451186},
 address = {New York, NY, USA},
 author = {Seyed, Teddy and Burns, Chris and Costa Sousa, Mario and Maurer, Frank},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451186},
 isbn = {978-1-4503-1966-9},
 keyword = {cross-device interaction, mobile-devices, multi-display environments, multi-display interaction, multi-surface environments, tabletop, touch},
 link = {http://doi.acm.org/10.1145/2451176.2451186},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {33--36},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {From Small Screens to Big Displays: Understanding Interaction in Multi-display Environments},
 year = {2013}
}


@inproceedings{Wu:2013:PAP:2451176.2451221,
 abstract = {In many commercial environments understanding the user's intention can lead to more engaging and intelligent user interactions. We looked at theme park photo kiosks where many people use their camera phones to capture their ride photos on preview displays. We believe that by identifying people with photo-taking intention and engaging them through intelligent UI can help reduce the instances of people opting for low quality but free screen capture. We built a prototype system called PhotoAct, using depth camera to recognize human postures and in real time infer people's photo-taking intentions. In this paper, we describe the system components, the detection algorithm, and present preliminary lab study results.},
 acmid = {2451221},
 address = {New York, NY, USA},
 author = {Wu, Shuguang and Xiao, Jun and Reily, Ken},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451221},
 isbn = {978-1-4503-1966-9},
 keyword = {camera detection, photoware, posture analysis},
 link = {http://doi.acm.org/10.1145/2451176.2451221},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {103--104},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {PhotoAct: Act on Photo Taking},
 year = {2013}
}


@inproceedings{Kim:2013:CAT:2451176.2451215,
 abstract = {In this paper, we propose a novel CAT (Computerized Adaptive Testing) system based on Bayesian network. Our novel system makes good use of topology and probabilistic inference algorithm of Bayesian network to efficiently estimate proficiency of learner and also give an adaptive learning guide when needed. From several experiments, we identified that our system could considerably improve proficiency-estimation performance when compared with conventional CAT methods.},
 acmid = {2451215},
 address = {New York, NY, USA},
 author = {Kim, Kyung Soo and Choi, Yong Suk},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451215},
 isbn = {978-1-4503-1966-9},
 keyword = {adaptive learning guide, bayesian network, computerized adaptive testing},
 link = {http://doi.acm.org/10.1145/2451176.2451215},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {91--92},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Computerized Adaptive Testing and Learning Using Bayesian Network},
 year = {2013}
}


@inproceedings{Alexenko:2013:ASP:2451176.2451213,
 abstract = {A growing elderly population has created a need for innovative eldercare technologies. The use of a home robot to assist with daily tasks is one such example. In this paper we describe an interface for human-robot interaction, which uses built-in speech recognition in Android phones to control a mobile robot. We discuss benefits of using a smartphone for speech-based robot control and present speech recognition accuracy results for younger and older adults obtained with an Android smartphone.},
 acmid = {2451213},
 address = {New York, NY, USA},
 author = {Alexenko, Tatiana and Biondo, Megan and Banisakher, Deya and Skubic, Marjorie},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451213},
 isbn = {978-1-4503-1966-9},
 keyword = {android, eldercare, human-robot interaction, older adults, robotics, smartphones, speech recognition, user study},
 link = {http://doi.acm.org/10.1145/2451176.2451213},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {87--88},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Android-based Speech Processing for Eldercare Robotics},
 year = {2013}
}


@inproceedings{Pappu:2013:DSI:2451176.2451189,
 abstract = {Speech systems are typically deployed either over phones, e.g. IVR agents, or on embodied agents, e.g. domestic robots. Most of these systems are limited to a particular platform i.e., only accessible by phone or in situated interactions. This limits scalability and potential domain of operation. Our goal is to make speech interfaces more widely available, and we are proposing a new approach for deploying such interfaces on the internet along with traditional platforms. In this work, we describe a lightweight speech interface architecture built on top of Freeswitch, an open source softswitch platform. A softswitch enables us to provide users with access over several types of channels (phone, VOIP, etc.) as well as support multiple users at the same time. We demonstrate two dialog applications developed using this approach: 1) Virtual Chauffeur: a voice based virtual driving experience and 2) Talkie: a speech-based chat bot.},
 acmid = {2451189},
 address = {New York, NY, USA},
 author = {Pappu, Aasish and Rudnicky, Alexander},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451189},
 isbn = {978-1-4503-1966-9},
 keyword = {phone apps, speech interfaces, voip apps, web apps},
 link = {http://doi.acm.org/10.1145/2451176.2451189},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {41--42},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Deploying Speech Interfaces to the Masses},
 year = {2013}
}


@inproceedings{Picard:2013:ECD:2451176.2451209,
 abstract = {We introduce a robust and accurate eye corner detector. The purpose of this technology is to improve the robustness of natural user interfaces' inputs, such as eye movements, in real-life environments for various users. Our technology relies on the pupil centers and particularly the inter-pupil direction, to define simple features capturing the structural characteristics of the eye corners independently of the shape and appearance of their neighborhoods. Our method proved to be robust to different lighting environments, eye shapes and different patterns of reflection on glasses. We report an error below 2% of the inter-pupil distance for 98% of the images, and maintain processing time below 3ms for computation on both eyes.},
 acmid = {2451209},
 address = {New York, NY, USA},
 author = {Picard, S{\'e}bastien and Yu, Shanshan and Nakashima, Satoshi},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451209},
 isbn = {978-1-4503-1966-9},
 keyword = {detector, eye corners, robustness},
 link = {http://doi.acm.org/10.1145/2451176.2451209},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {79--80},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Eye Corner Detector Robust to Shape and Illumination Changes},
 year = {2013}
}


@inproceedings{Dostal:2013:DCD:2451176.2451178,
 abstract = {Display ecosystems encapsulate a number of independent and/or interconnected displays and their users. We are seeing the emergence of more complex display ecosystems, whether it is due to the number of collaborators, the number of devices or displays, the complexity of the user interface or increased information flow or a combination of all of all these factors. I hypothesise that interactions within display ecologies would benefit from awareness of the computational, physiological and environmental context. This paper presents a brief overview of related work as well as the research goals, relevant methodology and current research status.},
 acmid = {2451178},
 address = {New York, NY, USA},
 author = {Dostal, Jakub},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451178},
 isbn = {978-1-4503-1966-9},
 keyword = {context-aware, distance-aware, multi-display, multi-user, subtle interaction},
 link = {http://doi.acm.org/10.1145/2451176.2451178},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {1--4},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Designing Context-aware Display Ecosystems},
 year = {2013}
}


@inproceedings{Gou:2013:PVT:2451176.2451191,
 abstract = {This paper presents an interactive visualization tool, PersonalityViz, to help people understand their personality traits derived from social media. The system uses the Linguistic Inquiry and Word Count (LIWC) text analysis tool and LIWC/Big Five personality correlations to compute a person's Big Five personality from one's tweets. It provides an interactive visual interface that allows a user to explore her personality traits over time, and examine the visual evidence to understand how the personality traits are derived from the relevant tweets.},
 acmid = {2451191},
 address = {New York, NY, USA},
 author = {Gou, Liang and Mahmud, Jalal and Haber, Eben and Zhou, Michelle},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451191},
 isbn = {978-1-4503-1966-9},
 keyword = {big five, personality, personality changes, social media, visualization},
 link = {http://doi.acm.org/10.1145/2451176.2451191},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {45--46},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {PersonalityViz: A Visualization Tool to Analyze People's Personality with Social Media},
 year = {2013}
}


@inproceedings{Galatas:2013:MCA:2451176.2451180,
 abstract = {Context-awareness constitutes a fundamental attribute of a smart environment. Our research aims at advancing the context-awareness capabilities of ambient intelligence environments by combining multi-modal information from both stationary and moving sensors. The collected data enables us to perform person identification and 3-D localization and recognize activities. In addition, we explore closed-loop feedback by integrating autonomous robots interacting with the users.},
 acmid = {2451180},
 address = {New York, NY, USA},
 author = {Galatas, Georgios and Makedon, Fillia},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451180},
 isbn = {978-1-4503-1966-9},
 keyword = {3-d interaction, autonomous interactive robots, context-awareness, localization, multi-modal input, smart environments, speech processing},
 link = {http://doi.acm.org/10.1145/2451176.2451180},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {9--12},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Multi-modal Context-awareness for Ambient Intelligence Environments},
 year = {2013}
}


@inproceedings{Huang:2013:LCC:2451176.2451182,
 abstract = {The use of mobile device is becoming more popular than before. There are many designers entering the area of mobile app design and development. However, due to the limitation of the screen size and context of use, it becomes extremely difficult for non-experienced designers or developers to make a good mobile application design. This paper introduces a wireframe-based matching technique to help people seek relevant mobile UI design examples for inspirations. We leveraged the wisdom of the crowd for creating coherent mappings between wireframes and design examples. Furthermore, we constructed a mobile UI design gallery for designers to explore inspiring examples in the wireframing stage.},
 acmid = {2451182},
 address = {New York, NY, USA},
 author = {Huang, Yi-Ching and Wang, Chun-I and Hsu, Jane},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451182},
 isbn = {978-1-4503-1966-9},
 keyword = {crowdsourcing, design, examples, mobile design, wireframe},
 link = {http://doi.acm.org/10.1145/2451176.2451182},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {17--20},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Leveraging the Crowd for Creating Wireframe-based Exploration of Mobile Design Pattern Gallery},
 year = {2013}
}


@inproceedings{Khayyamian:2013:IWI:2451176.2451202,
 abstract = {In this demonstration, we introduce a novel web-based intelligent interface which automatically detects and highlights programming content (programming code and messages) in Q&A programming forums. We expect our interface helps enhancing visual presentation of such forum content and enhance effective participation. We solve this problem using several alternative approaches: a dictionary-based baseline method, a non-sequential Naïve Bayes classification algorithm, and Conditional Random Fields (CRF) which is a sequential labeling framework. The best results are produced by CRF method with an F1-Score of 86.9%. We also experimentally validate how robust our classifier is by testing the constructed CRF model built on a C++ forum against a Python and a Java dataset. The results indicate the classifier works quite well across different domains. To demonstrate detection results, a web-based graphical user interface is developed that accepts a user input programming forum message and processes it using trained CRF model and then displays the programming content snippets in a different font to the user.},
 acmid = {2451202},
 address = {New York, NY, USA},
 author = {Khayyamian, Mahdy and Kim, Jihie},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451202},
 isbn = {978-1-4503-1966-9},
 keyword = {conditional random fields, q\&\#38;a forums, text classification, web-based intelligent interface},
 link = {http://doi.acm.org/10.1145/2451176.2451202},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {67--68},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {An Intelligent Web-based Interface for Programming Content Detection in Q\&\#38;a Forums},
 year = {2013}
}


@inproceedings{Gardner:2013:RCD:2451176.2451181,
 abstract = {In this paper we describe plans for a dynamic hand gesture recognition system based on motion capture cameras with unlabeled markers. The intended classifier is an extension of previous work on static hand gesture recognition in the same environment. The static gestures are to form the basis of a vocabulary that will allow precise descriptions of various expressive hand gestures when combined with inferred motion and temporal data. Hidden Markov Models and dynamic time warping are expected to be useful tools in achieving this goal.},
 acmid = {2451181},
 address = {New York, NY, USA},
 author = {Gardner, Andrew and Duncan, Christian A. and Selmic, Rastko and Kanno, Jinko},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451181},
 isbn = {978-1-4503-1966-9},
 keyword = {dynamic time warping, gesture recognition, hidden markov models, motion capture},
 link = {http://doi.acm.org/10.1145/2451176.2451181},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {13--16},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Real-time Classification of Dynamic Hand Gestures from Marker-based Position Data},
 year = {2013}
}


@inproceedings{Eivazi:2013:MSA:2451176.2451179,
 abstract = {Micro-neurosurgery is performed with high power microscope. The microscope provides a precise perception of operative neurosurgical anatomy. The surgery is conducted using miniaturized instruments through a small hole in the skull and spin channel. Although there are predefined routine procedures in the micro-neurosurgery, still surgeons have to maintain a high level of situation awareness (SA) to operate safely. In this paper I discuss about my PhD research that focuses on relationship between eye movement pattern and level of SA.},
 acmid = {2451179},
 address = {New York, NY, USA},
 author = {Eivazi, Shahram},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451179},
 isbn = {978-1-4503-1966-9},
 keyword = {eye tracking, micro-neurosurgeons, situation awareness},
 link = {http://doi.acm.org/10.1145/2451176.2451179},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {5--8},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Measuring Situation Awareness of Micro-neurosurgeons},
 year = {2013}
}


@inproceedings{Leidinger:2013:MMU:2451176.2451193,
 abstract = {The availability of food ingredient information in digital form is a major factor in modern information systems related to diet management and health issues. Although ingredient information is printed on food product labels, corresponding digital data is rarely available for the public. In this demo, we present the Mobile Food Information Scanner (MoFIS), a mobile user interface designed to enable users to semi-automatically extract ingredient lists from food product packaging.},
 acmid = {2451193},
 address = {New York, NY, USA},
 author = {Leidinger, Tobias and Spassova, L\"{u}bomira and Arens, Andreas and R\"{o}sch, Norbert},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451193},
 isbn = {978-1-4503-1966-9},
 keyword = {information extraction, mobile user interface},
 link = {http://doi.acm.org/10.1145/2451176.2451193},
 location = {Santa Monica, California, USA},
 numpages = {2},
 pages = {49--50},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {MoFIS: A Mobile User Interface for Semi-automatic Extraction of Food Product Ingredient Lists},
 year = {2013}
}


@inproceedings{Papangelis:2013:TAD:2451176.2451185,
 abstract = {Adaptive Dialogue Systems can be seen as smart interfaces that typically use natural language (spoken or written) as a means of communication. They are being used in many applications, such as customer service, in-car interfaces, even in rehabilitation, and therefore it is essential that these systems are robust, scalable and quickly adaptable in order to cope with changing user or system needs or environmental conditions. Making Dialogue Systems adaptive means overcoming several challenges, such as scalability or lack of training data. Achieving adaptation online has thus been an even greater challenge. We propose to build such a system, that will operate in an Assistive Living Environment and provide its services as a coach to patients that need to perform rehabilitative exercises. We are currently in the process of developing it, using Robot Operating System on a robotic platform.},
 acmid = {2451185},
 address = {New York, NY, USA},
 author = {Papangelis, Alexandros and Karkaletsis, Vangelis and Huang, Heng},
 booktitle = {Proceedings of the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/2451176.2451185},
 isbn = {978-1-4503-1966-9},
 keyword = {adaptive dialogue systems, dialogue management, personalization, reinforcement learning},
 link = {http://doi.acm.org/10.1145/2451176.2451185},
 location = {Santa Monica, California, USA},
 numpages = {4},
 pages = {29--32},
 publisher = {ACM},
 series = {IUI '13 Companion},
 title = {Towards Adaptive Dialogue Systems for Assistive Living Environments},
 year = {2013}
}


