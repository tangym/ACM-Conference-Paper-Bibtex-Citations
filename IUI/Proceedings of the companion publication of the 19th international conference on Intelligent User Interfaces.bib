@proceedings{Kuflik:2014:2559184,
 abstract = {It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round. The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles "From Touch through Air to Brain" "Learning and Skills", "Intelligent Visual Interaction", "Users and Motion", "Leveraging Social Competencies", "Adaptive User Interfaces" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on "Multiadaptive Interfaces to Cyber-Physical Environments", Professor Noam Tractinsky's second day keynote is on "Visual Aesthetics of Interactive Technologies" and the last day keynote, by Professor Mark Billinghurst is on "Using AR to Create Empathic Experiences". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: "Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-2729-9},
 location = {Haifa, Israel},
 publisher = {ACM},
 title = {IUI Companion '14: Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 year = {2014}
}


@inproceedings{Unuma:2014:SMA:2559184.2559198,
 abstract = {In this paper, we propose an interaction system which displays see-through images on the mobile display and that allows a user to interact with virtual objects overlaid on the see-through image using the user's hand. In this system, the camera which tracks the user's viewpoint is attached to the front of the mobile display and the depth camera which captures color and depth images of the user's hand and the background scene is attached to the back of the mobile display. Natural interaction with virtual objects using the user's hand is realized by displaying images so that the appearance of a space through the mobile display is consistent with that of the real space from the user's viewpoint. We implemented two applications to the system and showed the usefulness of this system in various AR applications.},
 acmid = {2559198},
 address = {New York, NY, USA},
 author = {Unuma, Yuko and Niikura, Takehiro and Komuro, Takashi},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559198},
 isbn = {978-1-4503-2729-9},
 keyword = {augmented reality, depth camera, geometric consistency, mobile device},
 link = {http://doi.acm.org/10.1145/2559184.2559198},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {17--20},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {See-through Mobile AR System for Natural 3D Interaction},
 year = {2014}
}


@inproceedings{Gu:2014:RSI:2559184.2559189,
 abstract = {This paper introduces a novel method for detecting and modeling intentions of students performing training tasks in a Virtual Reality (VR) environment enhanced with intelligent tutoring capabilities. Our VR-setup provides students with an immersive user interface, but produces noisy and low-level input, from which we need to recognize higher-level cognitive information about the student. The complexity of this task is amplified by the requirements of the target domain (child pedestrian safety), where students need to train complex skills in dynamic settings. We present an approach for this task, which combines the logic-based Event Calculus (EC) and probabilistic modeling.},
 acmid = {2559189},
 address = {New York, NY, USA},
 author = {Gu, Yecheng and Sosnovsky, Sergey},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559189},
 isbn = {978-1-4503-2729-9},
 keyword = {intelligent tutoring systems, intention recognition, student modeling, virtual reality},
 link = {http://doi.acm.org/10.1145/2559184.2559189},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {69--72},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Recognition of Student Intentions in a Virtual Reality Training Environment},
 year = {2014}
}


@proceedings{Kim:2013:2449396,
 abstract = {It is our great pleasure to welcome you to the 2013 International Conference on Intelligent User Interfaces (IUI'13). This year marks the eighteenth meeting of this conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, increasing the intelligence of both in the process. The call for papers attracted 195 submissions from Asia, Canada, Europe, Africa, and the United States. The program committee accepted 43 papers covering a diverse set of topics, including brain-computer interaction, social media analysis, automated design, and crowdsourcing. The program opens with a keynote by Professor Luis von Ahn on "Duolingo: Learn a Language for Free while Helping to Translate the Web," and closes with a keynote by Professor Monica S. Lam on "How Mobile Disrupts Social As We Know it." We also have an excellent poster and demonstration program consisting of 14 demos and 22 posters selected from a pool of 64 total submissions. In addition, the conference provides two exciting tutorials and four interesting workshops. The tutorials feature an introduction to Human Computation by Edith Law and an introduction to knowledge acquisition from the web and social media by Zornitsa Kozareva. The workshops cover topics ranging from interactive machine learning to IUI for developing worlds. No conference of this size could be organized without the help of a large number of individuals who volunteer an enormous amount of their own time. Their names can be found in the following pages and each and every one of these extraordinary volunteers deserve our thanks. We want to especially recognize all of the members of the organizing committee, who put in countless hours over nearly a year to make the conference happen. If you see one of them in the hotel bar at the conference, please buy them a beverage of their choice. We must also thank our senior program committee for coordinating the review process and all 654 members of the program committee for providing high quality reviews that exceeded even our lofty expectations. Last, but certainly not least, we must thank the authors for providing the content for the program that is the foundation of any successful conference. We look forward to your presentations!},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1965-2},
 location = {Santa Monica, California, USA},
 publisher = {ACM},
 title = {IUI '13: Proceedings of the 2013 International Conference on Intelligent User Interfaces},
 year = {2013}
}


@inproceedings{Paletta:2014:IIW:2559184.2559943,
 abstract = {Digital Games for Empowerment and Inclusion have the potential to improve our society by preparing particular groups of people to meet social challenges in their everyday lives, and to do so in an enjoyable way through games. These games are developing rapidly to exploit new algorithms for computational intelligence supported by increasing availability of computing power to help analyze players' behavior, monitor their motivation and interest, and to adapt the progress of the games accordingly. Intelligent Digital Games for Empowerment and Inclusion (IDGEI) explore the use of machine intelligence in serious digital games. In this introduction and in this context, we summarize the second international workshop on IDGEI held at the International Conference on Intelligent User Interfaces (IUI) 2014.},
 acmid = {2559943},
 address = {New York, NY, USA},
 author = {Paletta, Lucas and Schuller, Bjoern W. and Robinson, Peter and Sabouret, Nicolas},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559943},
 isbn = {978-1-4503-2729-9},
 keyword = {affective computing, digital games for empowerment and inclusion, machine intelligence, serious games},
 link = {http://doi.acm.org/10.1145/2559184.2559943},
 location = {Haifa, Israel},
 numpages = {2},
 pages = {49--50},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {IDGEI 2014: 2Nd International Workshop on Intelligent Digital Games for Empowerment and Inclusion},
 year = {2014}
}


@inproceedings{deRooij:2014:TER:2559184.2559186,
 abstract = {Emotions can be regulated to fit a task in order to enhance task performance. Motor expressions can help regulate emotion. This paper briefly reports ongoing work on the design of physical interactions based on motor expressions that can help regulate emotion to fit a task. We argue that to be effective, such interactions must be made meaningful in relation to ongoing appraisal processes, and that such interactions can help regulate emotion via congruence, suppression, or incompatibility. We present previous work on the validation of these arguments within the context of supporting idea generation, and develop a roadmap for research that aims to translate these results to the design of physical interactions under device constraints. The research will enable designers of interactive technology to develop physical interactions that help regulate emotion with the aim to help people get the most out of their own capabilities.},
 acmid = {2559186},
 address = {New York, NY, USA},
 author = {de Rooij, Alwin},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559186},
 isbn = {978-1-4503-2729-9},
 keyword = {affective computing, embodied interaction, emotion elicitation, emotion regulation, motor expression},
 link = {http://doi.acm.org/10.1145/2559184.2559186},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {57--60},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Toward Emotion Regulation via Physical Interaction},
 year = {2014}
}


@inproceedings{Paraskevopoulos:2014:CUC:2559184.2559201,
 abstract = {The demo paper describes the Creative User Centric Inspirational Search, which aims to leverage user inspiration in information seeking activities. CRUISE is an interactive exploratory search tool that combines diversification of content and sources with a user interface design that visualizes cues from the social chatter generated with microblogging services such as Twitter and lets users interactively explore the available information space. The tool is based on the observation that users often use the social chatter to follow links and initiate information seeking activities which can lead to unexpected discoveries which can in turn inspire them.},
 acmid = {2559201},
 address = {New York, NY, USA},
 author = {Paraskevopoulos, Fotis and Taramigkou, Maria and Bothos, Efthimios and Apostolou, Dimitris and Mentzas, Gregoris},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559201},
 isbn = {978-1-4503-2729-9},
 keyword = {exploratory search, inspirational systems, social information filtering},
 link = {http://doi.acm.org/10.1145/2559184.2559201},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {25--28},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Creative User Centric Inspirational Search},
 year = {2014}
}


@inproceedings{Sagara:2014:MAT:2559184.2559197,
 abstract = {In this paper, we propose a user interface that enables multi-finger typing in the space behind a mobile device. By using the augmented reality (AR) technology, a virtual keyboard is superimposed on the rear camera image, and a hand region of the camera image is again superimposed on that image, which makes it possible to perform input operation as if there were a real keyboard. The system recognizes only key pressing actions and does not recognize a hand or fingers, which enables stable recognition and multi-finger input. Further, key typing at any place on a plane and in the air is possible. Demonstration using an experimental device showed that multi-finger input using a virtual keyboard displayed on the screen was realized.},
 acmid = {2559197},
 address = {New York, NY, USA},
 author = {Sagara, Satoshi and Higuchi, Masakazu and Komuro, Takashi},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559197},
 isbn = {978-1-4503-2729-9},
 keyword = {augmented reality, multi-finger input, virtual keyboard},
 link = {http://doi.acm.org/10.1145/2559184.2559197},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {13--16},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Multi-finger AR Typing Interface for Mobile Devices},
 year = {2014}
}


@inproceedings{Impett:2014:FAM:2559184.2559203,
 abstract = {Facial expressions play a crucial role in human interaction. Interactive digital games can help teaching people to both express and recognise them. Such interactive games can benefit from the ability to alter user expressions dynamically and in real-time. In this demonstration, we present the Facial Affect Mapping Engine (FAME), a framework for mapping and manipulating facial expressions across images and video streams. Our system is fully automatic runs in real-time and does not require any specialist hardware. FAME presents new possibilities for the designers of intelligent interactive digital games.},
 acmid = {2559203},
 address = {New York, NY, USA},
 author = {Impett, Leonardo and Robinson, Peter and Baltrusaitis, Tadas},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559203},
 isbn = {978-1-4503-2729-9},
 keyword = {augmented reality, face swapping, face tracking, facial affect, facial puppetry, intelligent games.},
 link = {http://doi.acm.org/10.1145/2559184.2559203},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {33--36},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {A Facial Affect Mapping Engine},
 year = {2014}
}


@inproceedings{Taele:2014:DSR:2559184.2559185,
 abstract = {As commercial motion-tracking sensors achieve greater reliability and ubiquity, intelligent sketching user interfaces can expand beyond traditional surface environments for richer surfaceless sketching interactions. However, relevant techniques for automatically recognizing sketches in surfaceless interaction spaces are either largely constrained, due to limited gesture input vocabularies from existing gesture recognition techniques; or unexplored, due to being adapted specifically for surface environments by existing sketch recognition techniques. This dissertation research therefore proposes to investigate techniques for developing intelligent surfaceless sketching user interfaces. The core research work will focus on investigating automated recognition techniques for better understanding the content of surfaceless sketches, and determining optimal interaction techniques for improving related intuitive sketching cues in those surfaceless interaction spaces.},
 acmid = {2559185},
 address = {New York, NY, USA},
 author = {Taele, Paul and Hammond, Tracy},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559185},
 isbn = {978-1-4503-2729-9},
 keyword = {natural user interfaces, sketch recognition, surfaceless interaction},
 link = {http://doi.acm.org/10.1145/2559184.2559185},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {53--56},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Developing Sketch Recognition and Interaction Techniques for Intelligent Surfaceless Sketching User Interfaces},
 year = {2014}
}


@inproceedings{Smith:2014:SCT:2559184.2559192,
 abstract = {Informal carers lack adequate practical and emotional support. This PhD investigates how a software agent could be used to help maintain a carer's personal social network by mediating communication and facilitating the provision of emotional and practical support. The agent should use features of the carer and their social network to provide a personalized support interface.},
 acmid = {2559192},
 address = {New York, NY, USA},
 author = {Smith, Kirsten},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559192},
 isbn = {978-1-4503-2729-9},
 keyword = {agents, ehealth, emotional support, social networks},
 link = {http://doi.acm.org/10.1145/2559184.2559192},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {81--84},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Supporting Carers Through Intelligent Technology},
 year = {2014}
}


@inproceedings{Lopez-Tovar:2014:NIA:2559184.2559191,
 abstract = {This research presents the concept of a non-command interface for a smart room to automatically detect when people talk about a document and whether it is present or not, as a fundamental prerequisite for missing document provision that doesn't require explicit requests, avoiding distraction from the main discourse. A study on how observers judge document usage in meetings is presented as a baseline and the conceptual framework is briefly explained. Finally, an exploratory experiment is reported. These elements demonstrate the research feasibility and define the techniques needed to build the agent.},
 acmid = {2559191},
 address = {New York, NY, USA},
 author = {Lopez-Tovar, Hugo and Dowell, John},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559191},
 isbn = {978-1-4503-2729-9},
 keyword = {ambient intelligence, computer supported cooperative work, intelligent user interfaces, meetings, proactive and agent-based paradigms for user interaction},
 link = {http://doi.acm.org/10.1145/2559184.2559191},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {77--80},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {A Non-command Interface for Automatic Document Provision During Meetings},
 year = {2014}
}


@inproceedings{Schiavo:2014:SIS:2559184.2559188,
 abstract = {Ambient intelligence refers to a vision of technology where physical environments are sensitive and responsive to people. One of the challenges to realize this vision is to leverage information available in the social context. My doctoral research focuses on how to design interfaces that support co-located multi-user interactions taking into account individual and group nonverbal behavior, such as proxemics, gaze direction and body movements. In particular, the research activities are twofold: to understand which nonverbal cues and social signals reflect engagement, cooperation and cohesion in co-located group activities and to design systems that can handle and manage this social information. I present an integrated research approach for designing multi-user interactions based on social signal processing and I discuss the progress-to-date toward the development of systems that can sense and respond to social context.},
 acmid = {2559188},
 address = {New York, NY, USA},
 author = {Schiavo, Gianluca},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559188},
 isbn = {978-1-4503-2729-9},
 keyword = {co-located interaction, context-awareness, multi-user interfaces, nonverbal behavior, social context},
 link = {http://doi.acm.org/10.1145/2559184.2559188},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {65--68},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Socially-aware Interfaces for Supporting Co-located Interaction},
 year = {2014}
}


@inproceedings{BenShimon:2014:DRS:2559184.2559194,
 abstract = {Many small and mid-sized e-businesses wish to integrate a recommender system into their website. Integrating an existing recommender system to a website often requires certain expertise and programming efforts, thus incurs substantial investments and may not be justified by the added value of the recommender system. This demo presents a solution for integrating a recommender system as a service to an existing e-business without any programming efforts. The integration method is analogue to the way of the Google AdSense integration and the business model is adapted from the advertisements world. Initial feedback from real website owners indicates that such integration has a great benefit for both sides; the website owner and the Recommender System (RS) provider.},
 acmid = {2559194},
 address = {New York, NY, USA},
 author = {Ben Shimon, David and Friedman, Michael and Hoerle, Johannes and Tsikinovsky, Alexander and Gude, Roland and Aluchanov, Rodion},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559194},
 isbn = {978-1-4503-2729-9},
 keyword = {collaborative filtering, integration, recommender system as a service},
 link = {http://doi.acm.org/10.1145/2559184.2559194},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {1--4},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Deploying Recommender System for the Masses},
 year = {2014}
}


@inproceedings{Wecker:2014:VSY:2559184.2559204,
 abstract = {Many tools exist for extracting and visualizing key information from a corpus of text documents. However often, one would like to assess the sentiment and feelings that arise from a single document. This paper describes an interactive service that visualizes the sentiment of a specific document. The service enables the user to visualize the sentimental polarity of each paragraph to get a detailed impression; to quickly detect the polarity of emotional words; to identify subjective sentences within the text, and the grade level of language used in each sentence. Participants in an initial qualitative evaluation found the service fast and useful.},
 acmid = {2559204},
 address = {New York, NY, USA},
 author = {Wecker, Alan J. and Minkov, Einat and Mokryn, Osnat and Lanir, Joel and Kuflik, Tsvi},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559204},
 isbn = {978-1-4503-2729-9},
 keyword = {emotion polarity, sentiment analysis, subjectivity, user interface, visualize},
 link = {http://doi.acm.org/10.1145/2559184.2559204},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {37--40},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Visualizing Sentiment: Do You See What I Mean?},
 year = {2014}
}


@inproceedings{Schnelle-Walka:2014:STW:2559184.2559940,
 abstract = {The increasing number of smart objects in our everyday life shapes how we interact beyond the desktop. In this workshop we discuss how interaction with these smart objects should be designed from various perspectives. \},
 acmid = {2559940},
 address = {New York, NY, USA},
 author = {Schnelle-Walka, Dirk and Huber, Jochen and Radomski, Stefan and Brdiczka, Oliver and Luyten, Kris and M\"{u}hlh\"{a}user, Max},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559940},
 isbn = {978-1-4503-2729-9},
 keyword = {context-awareness, embodied interaction, enabling techologies, hci, multimodal and adapter interaction, novel interaction, smart objects, tangible interaction},
 link = {http://doi.acm.org/10.1145/2559184.2559940},
 location = {Haifa, Israel},
 numpages = {2},
 pages = {45--46},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {SmartObjects: Third Workshop on Interacting with Smart Objects},
 year = {2014}
}


@inproceedings{Tintarev:2014:DMP:2559184.2559202,
 abstract = {Autonomous systems perform tasks without human guidance. Techniques for making autonomous systems scrutable and, hence, more transparent are required in order to support humans working with such systems. The Scrutable Autonomous Systems (SAsSy) demo shows a novel way of combining argumentation and natural language to generate a human understandable explanation dialogue. By interacting with SAsSy users are able to ask why a certain plan was selected for execution, why other alternatives were not selected, also allowing users to modify information in the system.},
 acmid = {2559202},
 address = {New York, NY, USA},
 author = {Tintarev, Nava and Kutlak, Roman},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559202},
 isbn = {978-1-4503-2729-9},
 keyword = {agents, argumentation, explanations, natural language},
 link = {http://doi.acm.org/10.1145/2559184.2559202},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {29--32},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Demo: Making Plans Scrutable with Argumentation and Natural Language Generation},
 year = {2014}
}


@inproceedings{Gatti:2014:SMA:2559184.2559205,
 abstract = {As advertisements on posters in the street get more and more aggressive, our basic cognitive defense -aimed at not perceiving those messages- is not enough. One advanced defensive technique is based on transforming the perceived message into something different from what was originally meant in the message. The demo is based on an application for smartphones that creatively modifies the linguistic expression in a virtual copy of a poster. The mobile system is inspired by the counter-cultural art practice of "subvertising", and aims at experiencing aesthetic pleasure that relaxes the cognitive tension of the user.},
 acmid = {2559205},
 address = {New York, NY, USA},
 author = {Gatti, Lorenzo and Guerini, Marco and Stock, Oliviero and Strapparava, Carlo},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559205},
 isbn = {978-1-4503-2729-9},
 keyword = {affective nlp, computational humour, mobile apps},
 link = {http://doi.acm.org/10.1145/2559184.2559205},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {41--44},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {SUBVERTISER: Mocking Ads Through Mobile Phones},
 year = {2014}
}


@inproceedings{Matsumoto:2014:SSD:2559184.2559190,
 abstract = {We investigated a classification method using brain computer interfaces (BCIs) for silent speech. Event-related potentials (ERPs) obtained when four subjects imagined the vocalization of two Japanese vowels while they remained silent and immobilized were recorded. We used an adaptive collection (AC) that adaptively selects suitable output signals of common spatial patterns (CSP) filters and its time duration for classification. The classification accuracies (CAs) were 73-92% for the pairwise classification /a/ vs. /u/ in the use of 63 channels and significantly better than previous study.},
 acmid = {2559190},
 address = {New York, NY, USA},
 author = {Matsumoto, Mariko},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559190},
 isbn = {978-1-4503-2729-9},
 keyword = {adaptive collection, brain computer interface (bci), common spatial patter (csp), eeg, silent speech, support vector machine (svm)},
 link = {http://doi.acm.org/10.1145/2559184.2559190},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {73--76},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Silent Speech Decoder Using Adaptive Collection},
 year = {2014}
}


@inproceedings{Jain:2014:WAJ:2559184.2559193,
 abstract = {By replacing the hand-written 'thought records', used by Cognitive behavioral therapy (CBT) patients, with a Wearable audio journal that works in tandem with a smartphone, we can help patients capture their automatic thoughts at the moment of its occurrence and facilitate in the posterior analysis of the data along with the therapist. Speech provides richer clues about the emotional state of mind of the patient and thus could possibly help in better therapy.},
 acmid = {2559193},
 address = {New York, NY, USA},
 author = {Jain, Devyani and Hariharan Kala, Manikandan},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559193},
 isbn = {978-1-4503-2729-9},
 keyword = {aids for cognitive behavioral therapy, mindfulness, reflective journalism, technology facilitated self-awareness, wearable technology},
 link = {http://doi.acm.org/10.1145/2559184.2559193},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {85--88},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Wearable Audio Journal and Mobile Application to Capture Automatic Thoughts in Patients Undergoing Cognitive Behavioral Therapy},
 year = {2014}
}


@inproceedings{Oomen:2014:PAC:2559184.2559941,
 abstract = {Since 2007, the PATCH workshop series have been gathering successfully researchers and professionals from various countries and institutions to discuss the topics of digital access to cultural heritage and specifically the personalization aspects in this process. Due to this rich history, the reach of the PATCH workshop in various research communities is extensive.},
 acmid = {2559941},
 address = {New York, NY, USA},
 author = {Oomen, Johan and Aroyo, Lora and Gena, Cristina and Wecker, Alan},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559941},
 isbn = {978-1-4503-2729-9},
 keyword = {mobile, personalized},
 link = {http://doi.acm.org/10.1145/2559184.2559941},
 location = {Haifa, Israel},
 numpages = {2},
 pages = {47--48},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Personalized Access to Cultural Heritage (PATCH2014): The Future of Experiencing Cultural Heritage},
 year = {2014}
}


@inproceedings{Leuski:2014:MPH:2559184.2559200,
 abstract = {We demonstrate Ally -- a prototype interface for a consumer-level medical diagnostic device. It is an interactive virtual character, -- Virtual Human (VH), -- that listens to user's concern, collects and processes sensor data, offers advice, guides the user through a self-administered medical tests, and answers the user's questions. The primary focus of this demo is on the VH, we describe and demonstrate the technologies for language analysis, dialogue management, response generation and presentation. The sensing and medical decision making components are simulated in the current system, but possible applications and extensions are discussed.},
 acmid = {2559200},
 address = {New York, NY, USA},
 author = {Leuski, Anton and Gowrisankar, Rasiga and Richmond, Todd and Shapiro, Ari and Xu, Yuyu and Feng, Andrew},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559200},
 isbn = {978-1-4503-2729-9},
 keyword = {interface for healthcare, mobile, virtual human},
 link = {http://doi.acm.org/10.1145/2559184.2559200},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {21--24},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Mobile Personal Healthcare Mediated by Virtual Humans},
 year = {2014}
}


@inproceedings{Roitman:2014:MVD:2559184.2559195,
 abstract = {Social communities play an important role in many domains. While a lot of attention has been given to developing efficient methods for detecting and analyzing social communities, it still remains a great challenge to provide intuitive search interfaces for end-users who wish to discover and explore such communities. Trying to fill the gaps, in this demonstration we present Microcosm: a holistic solution for visual discovery, exploration and analysis of social communities.},
 acmid = {2559195},
 address = {New York, NY, USA},
 author = {Roitman, Haggai and Raviv, Ariel and Hummel, Shay and Erera, Shai and Konopniki, David},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559195},
 isbn = {978-1-4503-2729-9},
 keyword = {discovery, exploration, social communities, visualization},
 link = {http://doi.acm.org/10.1145/2559184.2559195},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {5--8},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Microcosm: Visual Discovery, Exploration and Analysis of Social Communities},
 year = {2014}
}


@inproceedings{AlTarawneh:2014:EUS:2559184.2559196,
 abstract = {In this work, we present a demonstration of a visual interactive tool called ESSAVis that helps different engineers in collaborating together for understanding the failure mechanisms in complex embedded systems. ESSAVis provides a 2Dplus3D visual user interface that integrates intuitively between different data sets related with embedded systems failure mechanisms. The tool accepts a CFT model describing a specific hazard in the underlying system, and a CAD model describing the geometry of system components. In this paper, we present different interaction options of ESSAVis that are used for intuitively extracting safety aspects of the underlying embedded system.},
 acmid = {2559196},
 address = {New York, NY, USA},
 author = {AlTarawneh, Ragaad and Bauer, Jens and Humayoun, Shah Rukh and Ebert, Achim and Liggesmeyer, Peter},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559196},
 isbn = {978-1-4503-2729-9},
 keyword = {collaborative environment, embedded systems, essavis, immersive environment, safety aspects visualization},
 link = {http://doi.acm.org/10.1145/2559184.2559196},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {9--12},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Enhancing Understanding of Safety Aspects in Embedded Systems Through an Interactive Visual Tool},
 year = {2014}
}


@inproceedings{Yogev:2014:ESI:2559184.2559187,
 abstract = {Exploratory search of scientific literature plays an essential part of a researcher's work. Efforts to provide interfaces supporting this task accomplished significant progress, but the field is open for further evolution. In this paper I present four basic design concepts identified in exploratory search interfaces: relevance, diversity, relationships and categories, and propose a novel browsing layout featuring a unique combination of these concepts.},
 acmid = {2559187},
 address = {New York, NY, USA},
 author = {Yogev, Sivan},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559187},
 isbn = {978-1-4503-2729-9},
 keyword = {citation networks, exploratory search interfaces},
 link = {http://doi.acm.org/10.1145/2559184.2559187},
 location = {Haifa, Israel},
 numpages = {4},
 pages = {61--64},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Exploratory Search Interfaces: Blending Relevance, Diversity, Relationships and Categories},
 year = {2014}
}


@proceedings{Kuflik:2014:2557500,
 abstract = {It is our great pleasure to welcome you to the 2014 International Conference on Intelligent User Interfaces (IUI'14). It is the nineteenth IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and also delves into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather then the other way round. The call for papers attracted 191 submissions from Asia, America Europe, Africa, and Australia. The program committee accepted 46 papers, covering a diverse set of topics, reflected in the session titles "From Touch through Air to Brain" "Learning and Skills", "Intelligent Visual Interaction", "Users and Motion", "Leveraging Social Competencies", "Adaptive User Interfaces" and a special session with papers that honor the memory of John Riedl, who left us too early. A great attraction of the conference is provided by the scientific keynotes: Professor Wolfgang Wahlster opens the conference program with a keynote on "Multiadaptive Interfaces to Cyber-Physical Environments", Professor Noam Tractinsky's second day keynote is on "Visual Aesthetics of Interactive Technologies" and the last day keynote, by Professor Mark Billinghurst is on "Using AR to Create Empathic Experiences". In addition we are pleased to offer an invited talk by a relevant industry speaker, Yanki Margalit: "Startup nation and the Makers revolution. Intelligent user interfaces and the future of the Israeli hi-tech". We also have 11 posters and an excellent demonstration program consisting of 27 demos. In addition, the conference provides four very interesting workshops and a student consortium.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-2184-6},
 location = {Haifa, Israel},
 note = {608140},
 publisher = {ACM},
 title = {IUI '14: Proceedings of the 19th International Conference on Intelligent User Interfaces},
 year = {2014}
}


@inproceedings{Davis:2014:SPT:2559184.2559944,
 abstract = {Sketch recognition has technically been around for 40 years, but it has come and gone several times due to the difficulty of the problem. With the rise of touch and pen enabled phones and tablets, sketch recognition is regaining popularity and public presence, and more people are becoming aware of and interested in this difficult, but valuable, problem. It is important to harness the Sketch Recognition community at this time to encourage the flourishing of this topic.},
 acmid = {2559944},
 address = {New York, NY, USA},
 author = {Davis, Richard C. and Adler, Aaron},
 booktitle = {Proceedings of the Companion Publication of the 19th International Conference on Intelligent User Interfaces},
 doi = {10.1145/2559184.2559944},
 isbn = {978-1-4503-2729-9},
 keyword = {pen, recognition, sketch, touch},
 link = {http://doi.acm.org/10.1145/2559184.2559944},
 location = {Haifa, Israel},
 numpages = {2},
 pages = {51--52},
 publisher = {ACM},
 series = {IUI Companion '14},
 title = {Sketch: Pen and Touch Recognition},
 year = {2014}
}


