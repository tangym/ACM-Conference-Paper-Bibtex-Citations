@inproceedings{Theocharous:2017:IPI:3030024.3040983,
 abstract = {In this paper we propose an intelligent user interface for a Point-of-Interest (POI) recommendation system. Our approach solves many challenges, such as learning from passive data, sequential real-time recommendations, Inferring the user's propensity to listen to a recommendation, and minimizing recommendation fatigue. We demonstrate our approach on a real world POI data set from Flicker.},
 acmid = {3040983},
 address = {New York, NY, USA},
 author = {Theocharous, Georgios and Vlassis, Nikos and Wen, Zheng},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040983},
 isbn = {978-1-4503-4893-5},
 keyword = {MDPs, POIs, Thompson sampling, personalization},
 link = {http://doi.acm.org/10.1145/3030024.3040983},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {49--52},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {An Interactive Points of Interest Guidance System},
 year = {2017}
}


@proceedings{Papadopoulos:2017:3030024,
 abstract = {It is our great pleasure to welcome you to the 2017 International Conference on Intelligent User Interfaces (IUI'17). It is the twenty-second IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and delves also into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather than the other way around. The call for papers attracted 272 submissions from Africa, America, Asia, Australia and Europe, a record number for the IUI series, 58 submissions of posters and demos and 25 submissions to the students' consortium. The program committee accepted 63 papers, covering a diverse set of topics, reflected in the session titles "Recommender Systems", "Multimodal and Augmented Interaction", "Understanding Users", "Information Visualization", "Personalization", "Interactive Programming and Automation", "Trust", "Intelligent Training and Educational Interfaces", "Intelligent Systems", "Gestural and Haptic Interaction", "Analytics", "Interactive Machine Learning and Explanation", "Machine Learning", and "Information Retrieval". We also have 19 posters and 13 demos and 16 doctoral consortium papers. Following the tradition of collaboration with TiiS journal, 5 papers that were published during 2016 are presented at IUI 2017 and selected papers will be invited to submit extended versions to the journal. In addition, the conference provides six workshops and three tutorials. One of the main attractions of the conference is provided by the scientific keynotes: Dr. Shumin Zhai opens the conference program with a keynote on "Modern Touchscreen Keyboards as Intelligent User Interfaces: A Research Review", Professor George Samaras' second day keynote is on "Utilizing Human Cognitive and Emotional Factors for User-Centered Computing" and the last day keynote, by Professor Panos Markopoulos, is on "Interaction Design for Rehabilitation". The conference program is available for IUI participants on Conference Navigator. IUI 2017 has a few novelties: For the first time, IUI introduced parallel sessions throughout the conference. The doctoral consortium papers were integrated into the main program for the first time in IUI. Another novelty of IUI 2017 is the introduction of the "most impactful IUI paper" award.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4893-5},
 location = {Limassol, Cyprus},
 publisher = {ACM},
 title = {IUI '17 Companion: Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 year = {2017}
}


@inproceedings{Sararit:2017:EMI:3030024.3038288,
 abstract = {We present the design and prototype implementation of a virtual reality simulator for teaching emergency management decision-making in endodontic surgery. The simulator aims to teach how to correctly respond to a variety of emergency situations and teach students the situation awareness skills required to rapidly recognize and respond to emergencies. We present results of an initial evaluation of face and content validity of the prototype and describe the design of a more comprehensive evaluation including evaluating the knowledge gain in emergency management of students trained with the system as well as the effectiveness of simulator in inducing a feeling of stress in students.},
 acmid = {3038288},
 address = {New York, NY, USA},
 author = {Sararit, Nat},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038288},
 isbn = {978-1-4503-4893-5},
 keyword = {decision making, emergency management, endodontics, root canal treatment, virtual reality},
 link = {http://doi.acm.org/10.1145/3030024.3038288},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {205--208},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Emergency Management Integration in an Endodontic Surgery VR Simulator},
 year = {2017}
}


@inproceedings{Mouzouras:2017:DSC:3030024.3038271,
 abstract = {Although, one in five humans living in high risk areas will develop skin cancer during a lifetime, there is currently no mechanism to help humans track the development of skin moles. DermaTrack, the application described in this paper offers an innovative mechanism, using a mobile application, for i) tracking skin cancer over time, and ii) share the data recorded with a specialized doctor. In this paper, we are providing an evaluation of the prototype mobile application interface developed.},
 acmid = {3038271},
 address = {New York, NY, USA},
 author = {Mouzouras, Nikos and Pogiatzis, Andreas and Kleanthous, Styliani and Samaras, George},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038271},
 isbn = {978-1-4503-4893-5},
 keyword = {interface evaluation, mobile application evaluation, usability evaluation},
 link = {http://doi.acm.org/10.1145/3030024.3038271},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {85--88},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {DermaTrack: A Skin Cancer Tracking Intelligent Application},
 year = {2017}
}


@inproceedings{JosekuttyThomas:2017:PHE:3030024.3040986,
 abstract = {We examine how persuasive messages can be used to promote and encourage healthy eating based on personality. After a personality assessment, participants assessed the persuasiveness of messages designed using Cialdini's principles of persuasion. The results of our study indicate that 'Authority' messages were most influential. In addition, we observed that positively framed messages were significantly more persuasive than negatively framed ones. Furthermore, personality had a significant influence on the best message type, with agreeable subjects being more inclined to persuasion than others.},
 acmid = {3040986},
 address = {New York, NY, USA},
 author = {Josekutty Thomas, Rosemary and Masthoff, Judith and Oren, Nir},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040986},
 isbn = {978-1-4503-4893-5},
 keyword = {age, framing, gender, healthy eating, personalisation, personality, persuasion, virtual agent},
 link = {http://doi.acm.org/10.1145/3030024.3040986},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {81--84},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Personalising Healthy Eating Messages to Age, Gender and Personality: Using Cialdini's Principles and Framing},
 year = {2017}
}


@inproceedings{Afyouni:2017:MSG:3030024.3040977,
 abstract = {Cerebral Palsy, trauma, and strokes are common causes for the loss of hand movements and the decrease in muscle strength for both children and adults. Improving fine motor skills usually involves the synchronization of wrists and fingers by performing appropriate tasks and activities. This demo introduces a novel patient-centered framework for the gamification of hand therapies in order to facilitate and encourage the rehabilitation process. This framework consists of an adaptive therapy-driven 3D environment augmented with our motion-based natural user interface. An intelligent game generator is developed, which translates the patient's gestures into navigational movements with therapy-driven goals, while adapting the level of difficulty based on the patient profile and real-time performance. A comprehensive evaluation and clinical-based assessments were conducted in a local children disability center, and highlights of the results are presented.},
 acmid = {3040977},
 address = {New York, NY, USA},
 author = {Afyouni, Imad and Qamar, Ahmad Muaz and Hussain, Syed Osama and Ur Rehman, Faizan and Sadiq, Bilal and Murad, Abdullah},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040977},
 isbn = {978-1-4503-4893-5},
 keyword = {gesture recognition, hand therapy, leap motion, serious games},
 link = {http://doi.acm.org/10.1145/3030024.3040977},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {133--136},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Motion-Based Serious Games for Hand Assistive Rehabilitation},
 year = {2017}
}


@inproceedings{Carcangiu:2017:GRT:3030024.3038283,
 abstract = {Now, users can easily provide input relying on body movements through the newest tracking devices. The available solutions have a mismatch: on one hand, classifiers offer a high precision, but their structure is difficult to inspect for providing feedback and feedforward. On the other hand, compositional approaches for gesture definition support decomposition, but with a low recognition precision. We introduce DEICTIC, a compositional and declarative gesture description that allows creating Hidden Markov Models (HMMs) for recognizing a gesture precisely, while providing information on its sub-components.},
 acmid = {3038283},
 address = {New York, NY, USA},
 author = {Carcangiu, Alessandro},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038283},
 isbn = {978-1-4503-4893-5},
 keyword = {classification, compositional, declarative, gestures, hidden Markov models},
 link = {http://doi.acm.org/10.1145/3030024.3038283},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {185--188},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Gesture Recognition Through Declarative and Classifier Approach},
 year = {2017}
}


@inproceedings{Peltonen:2017:ISR:3030024.3038263,
 abstract = {We introduce topic-relevance map, an interactive search result visualization that assists rapid information comprehension across a large ranked set of results. The topic-relevance map visualizes a topical overview of the search result space as keywords with respect to two essential information retrieval measures: relevance and topical similarity. Non-linear dimensionality reduction is used to embed high-dimensional keyword representations of search result data into angles on a radial layout. Relevance of keywords is estimated by a ranking method and visualized as radiuses on the layout. Similar keywords are modeled by nearby points and more relevant keywords are closer to the center of the radial display. We evaluated the effect of the topic-relevance map in a search result comprehension task where 24 participants were summarizing search results and produced a conceptualization of the result space. Topic-relevance map significantly improves participants' comprehension capability compared to a ranked list.},
 acmid = {3038263},
 address = {New York, NY, USA},
 author = {Peltonen, Jaakko and Belorustceva, Kseniia and Ruotsalo, Tuukka},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038263},
 isbn = {978-1-4503-4893-5},
 keyword = {exploratory search, sense-making, visualization},
 link = {http://doi.acm.org/10.1145/3030024.3038263},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {149--152},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Improving Search Result Comprehension by Topic-Relevance Map Visualization},
 year = {2017}
}


@inproceedings{Callaway:2017:CCW:3030024.3030028,
 abstract = {Wearables offer an attractive platform for interacting intelligently with our environment and ourselves. Commercially available wearables are not aimed at the academic/research environment. They have proprietary protocols, do not willingly share recorded data or information on how it was processed and filtered, and do not have the right combinations of sensors or actuators in the desired positions or sensitivity. Given the scarce resources that academic groups have, their wearables have rarely progressed past a very bulky prototype stage. But it is now possible to create a complete custom wearable within a month at very low cost. This tutorial will teach the skills necessary to design and fabricate a Bluetooth based wrist or ring wearable that can wirelessly send sensor data to a smartphone or computer for data analysis and receive wireless commands to actuate sensors. Given the basic schematics for a circuit, you will learn how to choose and source components, lay out and route a circuit board, send the design off to a local fabrication house, and create the finished device when the printed circuit boards return a week later. I will introduce helpful open source software, teach basic industry standards and the properties of various sensors and actuators, and describe features that are especially useful for wearables.},
 acmid = {3030028},
 address = {New York, NY, USA},
 author = {Callaway, Charles B.},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3030028},
 isbn = {978-1-4503-4893-5},
 keyword = {hardware design, hardware fabrication, sensors},
 link = {http://doi.acm.org/10.1145/3030024.3030028},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {29--31},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Creating Custom Wearable Electronics: From Design to Fabrication to Experimentation},
 year = {2017}
}


@inproceedings{Costales:2017:SGT:3030024.3040988,
 abstract = {In the context of Medicine, technology facilitates the design and development of prostheses that make it possible for patients to recover specific movements. Myoelectric prostheses connect to the patient nerves directly and allow limb movements via electric impulses generated by the nervous system. However, the use of these prostheses requires intensive training, which can be hard and tiring, especially for children. The use of games can make training much more enjoyable. In this paper, we describe SilverTouch, an application to help children to train the use of myoelectric prostheses by means of three different types of multi-touch games. The games are dynamically generated for each user according to his needs and performance at runtime. We have designed them following the advice of experts in Medicine, Physiotherapy, Therapy and Education. The results are promising: the final users agreed that SilverTouch is a good tool for training the use of prostheses, while the experts confirmed its potential to be widely utilized for that purpose.},
 acmid = {3040988},
 address = {New York, NY, USA},
 author = {Costales, Fernando G. and Carro, Rosa M.},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040988},
 isbn = {978-1-4503-4893-5},
 keyword = {children, game-based training, multi-touch surfaces, myoelectric prostheses},
 link = {http://doi.acm.org/10.1145/3030024.3040988},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {93--96},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {SilverTouch: Game-based Training for Children with Myoelectric Prostheses},
 year = {2017}
}


@inproceedings{Jahani-Fariman:2017:DUI:3030024.3038277,
 abstract = {Despite the recent developments in gesture-driven technologies facilitating multi-touch and mid-air gesture recognition, there has been little formal user evaluation and analysis of these systems for in-vehicle interfaces. Mid-air gesture-based interfaces can provide a less cumbersome in-vehicle interface for safer driving. Recent developments in gesture-driven technologies have facilitated multi-touch and mid-air gesture recognition. However, for in-vehicle interfaces, research needs to be conducted on the most efficient gesture vocabulary for performing secondary tasks. Following the Interaction Design process user requirements need to be explored, followed by evaluation of characteristics and functions. Then, the outcomes of user evaluation study can be used to develop an efficient in-vehicle gestural interface.},
 acmid = {3038277},
 address = {New York, NY, USA},
 author = {Jahani-Fariman, Hessam},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038277},
 isbn = {978-1-4503-4893-5},
 keyword = {driving simulator, gestural interface, gesture recognition, in-vehicle interface, user-elicitation},
 link = {http://doi.acm.org/10.1145/3030024.3038277},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {165--168},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Developing a User-defined Interface for In-vehicle Mid-air Gestural Interactions},
 year = {2017}
}


@inproceedings{Yao:2017:GIP:3030024.3038265,
 abstract = {We present a novel gestural interface for an educational 3D construction game that helps children practice and learn spatial reasoning skills. Previous research shows that having well-developed spatial reasoning skills is crucial to the success in the STEM fields. Our game requires the player to create a number of 3D target objects by moving, rotating, and assembling smaller pieces in the right way through a gestural interface. The gestures were designed with enhancing the user experience and effectiveness of learning in mind, by having a congruent mapping between hand gestures and spatial operations. The initial results of the preliminary study we conducted with the children show that the interface has the potential to be used for practicing spatial reasoning skills with the game. We also discuss how the study can lead to the development of a theoretical framework for designing gestural interfaces for educational games that leverage the benefit of embodied interactions.},
 acmid = {3038265},
 address = {New York, NY, USA},
 author = {Yao, Yuan and Chiu, Po-Tsung and Fu, Wai-Tat},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038265},
 isbn = {978-1-4503-4893-5},
 keyword = {3D interaction, children, gestural interface, spatial reasoning, video game},
 link = {http://doi.acm.org/10.1145/3030024.3038265},
 location = {Limassol, Cyprus},
 numpages = {5},
 pages = {43--47},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {A Gestural Interface for Practicing Children's Spatial Skills},
 year = {2017}
}


@inproceedings{Salo:2017:MAS:3030024.3040975,
 abstract = {Museums are seeking different ways to attract and engage audiences. Digital stories in various forms have been utilized as one approach to increase audience experience. This paper presents how to bring audio stories as a part of museum?s activities by developing a modular audio story platform. Most of the functionality is included in Android applications, which allow visitors to attach stories with emotions to artifacts, share stories with other visitors and enrich existing stories with sounds. All the audio files, linking of the artifacts and related audio files are managed by audio digital asset management system. Our platform supports curated audio stories, but the main emphasis is in the visitors? audio stories. We differentiate from the other digital storytelling systems by attaching emotions onto the visitor stories, and combining the soundscapes and audio stories as visitor modified audio stories.},
 acmid = {3040975},
 address = {New York, NY, USA},
 author = {Salo, Kari and Zinin, Vallo and Bauters, Merja and Mikkonen, Tommi},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040975},
 isbn = {978-1-4503-4893-5},
 keyword = {android, audio story, emotions, mobile sound mixing, museum, soundscape, user generated content},
 link = {http://doi.acm.org/10.1145/3030024.3040975},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {113--116},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Modular Audio Story Platform for Museums},
 year = {2017}
}


@inproceedings{Wauck:2017:GFI:3030024.3038286,
 abstract = {This document gives an overview of my current research project investigating how children develop spatial reasoning skills through video game training. I describe the motivation and goals of the project and the progress made so far.},
 acmid = {3038286},
 address = {New York, NY, USA},
 author = {Wauck, Helen},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038286},
 isbn = {978-1-4503-4893-5},
 keyword = {children, cognitive science, education, learning, spatial reasoning, video games},
 link = {http://doi.acm.org/10.1145/3030024.3038286},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {197--200},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Game Features and Individual Differences: What Makes a Spatial Skill Training Video Game Effective?},
 year = {2017}
}


@inproceedings{Haim:2017:VIT:3030024.3038264,
 abstract = {With the ever-growing volume of cyber-attacks on organizations, security analysts require effective visual interfaces and interaction techniques to detect security breaches and, equally importantly, to efficiently share threat information. To support this need, we present a tool called ?User Behavior Analytics? (UBA) that conducts continuous analysis of individuals' usage of their organizational IT networks, and effectively visualizes the associated security exposures of the organization. The UBA tool was developed as an extension of IBM?s security analytics environment, and incorporates a risk-focused dashboard that highlights anomalous user behaviors and the aggregated risk levels associated with individual users, user groups, and overall system security state. Moreover, the tool?s dashboard has been designed to facilitate rapid review of security incidents and correlate them with data from various sources such as user directory and HR systems. In doing so, the tool presents busy security analysts with an effective means to visually identify and respond to cyber threats on the organization's crown jewels.},
 acmid = {3038264},
 address = {New York, NY, USA},
 author = {Haim, Bar and Menahem, Eitan and Wolfsthal, Yaron and Meenan, Christopher},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038264},
 isbn = {978-1-4503-4893-5},
 keyword = {anomaly detection, insider threat, user behavior analytics},
 link = {http://doi.acm.org/10.1145/3030024.3038264},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {39--42},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Visualizing Insider Threats: An Effective Interface for Security Analytics},
 year = {2017}
}


@inproceedings{Wecker:2017:ACI:3030024.3040980,
 abstract = {The following discusses a demo for an application that serves as a museum guide, which after the visit gives advice on additional cultural heritage sites to visit. The demo simulates the implementation at the Tower of David in Jerusalem. The system uses behavior to determine both preferences and characteristics.},
 acmid = {3040980},
 address = {New York, NY, USA},
 author = {Wecker, Alan J. and Kuflik, Tsvi and Stock, Oliviero},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040980},
 isbn = {978-1-4503-4893-5},
 keyword = {connecting indoor and outdoor, cultural heritage experience, mobile museum guide},
 link = {http://doi.acm.org/10.1145/3030024.3040980},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {153--156},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {AMuse: Connecting Indoor and Outdoor Cultural Heritage Experiences},
 year = {2017}
}


@inproceedings{Madaan:2017:VEU:3030024.3038261,
 abstract = {Governmental authorities publish rules and directives that govern the operations of an industry. These documents, called regulations, are meant to safeguard the interests of consumers. With increasing number, size and complexity of such documents, companies face an uphill task to comply with them. We present a cognitive system, called Cogpliance, for exploring and understanding regulatory documents with the goal of assisting compliance officers in attaining regulatory compliance. Cogpliance automatically reads natural language regulatory documents, extracts key concepts and presents an interactive information exploration user interface for answering compliance officers queries.},
 acmid = {3038261},
 address = {New York, NY, USA},
 author = {Madaan, Nishtha and Karanam, Hima and Gupta, Ankush and Jain, Nitisha and Kumar, Arun and Tamilselvam, Srikanth},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038261},
 isbn = {978-1-4503-4893-5},
 keyword = {SOLR, SQL, none, user interfaces},
 link = {http://doi.acm.org/10.1145/3030024.3038261},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {129--132},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Visual Exploration of Unstructured Regulatory Documents},
 year = {2017}
}


@inproceedings{Eivazi:2017:TIS:3030024.3038269,
 abstract = {After many decades of research, the presence of intelligent user interfaces is unquestionable in any modern operating room (OR). For the first time, we aim to bring proactive intelligent systems into microsurgery OR. The first step towards an intelligent surgical microscope is to design an activity-aware microscope. In this paper, we present a novel system that we have built to record both eyes and instruments movements of surgeons while operating with a surgical microscope. We present a case study in micro-neurosurgery to show how the system monitors the surgeon's activities. We achieved about 1 mm accuracy for gaze and instrument tracking. Now real-time ecologically valid data can be used to design, for example, a self-adjustable microscope.},
 acmid = {3038269},
 address = {New York, NY, USA},
 author = {Eivazi, Shahram and Fuhl, Wolfgang and Kasneci, Enkelejda},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038269},
 isbn = {978-1-4503-4893-5},
 keyword = {eye tracking, hands-free, intelligent surgical microscope},
 link = {http://doi.acm.org/10.1145/3030024.3038269},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {69--72},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Towards Intelligent Surgical Microscope: Micro-surgeons' Gaze and Instrument Tracking},
 year = {2017}
}


@inproceedings{Sandbank:2017:EME:3030024.3038260,
 abstract = {Building conversational agents is becoming easier thanks to the profusion of designated platforms. Integrating emotional intelligence in such agents contributes to positive user satisfaction. Currently, this integration is implemented using calls to an emotion analysis service. In this demonstration we present EHCTool that aims to detect and notify the conversation designer about problematic conversation states where emotions are likely to be expressed by the user. Using its exploration view, the tool assists the designer to manage and define appropriate responses in these cases.},
 acmid = {3038260},
 address = {New York, NY, USA},
 author = {Sandbank, Tommy and Shmueli-Scheuer, Michal and Herzig, Jonathan and Konopnicki, David and Shaul, Rottem},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038260},
 isbn = {978-1-4503-4893-5},
 keyword = {conversational agent, emotions, tooling},
 link = {http://doi.acm.org/10.1145/3030024.3038260},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {125--128},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {EHCTool: Managing Emotional Hotspots for Conversational Agents},
 year = {2017}
}


@inproceedings{Donoso-Guzman:2017:EII:3030024.3038281,
 abstract = {Evidence-based health care (EBHC) is an important practice of medicine which provides systematic scientific evidence to answer clinical questions. Epistemonikos is one of the most important online systems in the field. Currently, many tasks within this system require a large amount of manual effort, which could be improved by leveraging human-in-the-loop machine learning techniques. In this article we propose a system called EpistAid, which combines machine learning, relevance feedback and an interactive user interface to support Epistemonikos users' on EBHC information filtering tasks.},
 acmid = {3038281},
 address = {New York, NY, USA},
 author = {Donoso-Guzm\'{a}n, Ivania},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038281},
 isbn = {978-1-4503-4893-5},
 keyword = {evidence-based health care, information filtering, intelligent user interfaces, visualization},
 link = {http://doi.acm.org/10.1145/3030024.3038281},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {177--180},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {EpistAid: An Interactive Intelligent System for Evidence-based Health Care},
 year = {2017}
}


@inproceedings{Oraby:2017:CML:3030024.3038284,
 abstract = {With increasing interest in the development of intelligent agents capable of learning, proficiently automating tasks, and gaining world knowledge, the importance of integrating the ability to converse naturally with users is more crucial now than ever before. This thesis aims to understand and characterize different aspects of social language to facilitate the development of intelligent agents that are socially aware and able to engage users to a level that was not previously possible with language generation systems. Using various machine learning algorithms and data-driven approaches to model the nuances of social language in dialogue, such as factual and emotional expression, sarcasm and humor and the related subclasses of rhetorical questions and hyperbole, we can come closer to modeling the characteristics of the social language that allows us to express emotion and knowledge, and thereby exhibit these styles in the agents we develop.},
 acmid = {3038284},
 address = {New York, NY, USA},
 author = {Oraby, Shereen},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038284},
 isbn = {978-1-4503-4893-5},
 keyword = {argument, dialogue, intelligent agents, sarcasm},
 link = {http://doi.acm.org/10.1145/3030024.3038284},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {189--192},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Characterizing and Modeling Linguistic Style in Dialogue for Intelligent Social Agents},
 year = {2017}
}


@inproceedings{Dugan:2017:AWA:3030024.3030026,
 abstract = {Awareness is a key user interface and interaction paradigm. Choosing what to make the user aware of, at what time, and how, has a critical impact on system usage and overall perception. In this workshop, we will bring together those from academia and industry to share their own work in this area, debate key topics, and brainstorm possible future collaborations or papers.},
 acmid = {3030026},
 address = {New York, NY, USA},
 author = {Dugan, Casey and Brusilovsky, Peter and Daly, Elizabeth and O'Donovan, John},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3030026},
 isbn = {978-1-4503-4893-5},
 keyword = {alerts, awareness, information overload, recommender systems, visualizations},
 link = {http://doi.acm.org/10.1145/3030024.3030026},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {1--3},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {AWARE: Workshop on Awareness Interfaces and Interactions},
 year = {2017}
}


@inproceedings{Zamora:2017:RCF:3030024.3040201,
 abstract = {This research study explores how chatbots can find a place in routine daily lives. Chatbot development has increased while in many cases its purpose still remains loosely defined. Due to its novel and relatively new technology, there is an opportunity to create meaningful experiences with chatbots in a typical person?s life. Qualitative insights were collected from 54 participants in India and the US over the course of two weeks. To identify opportunities for chatbots, we must understand how these programs are perceived and what needs exist for people. The research objectives include understanding the following: 1) anticipations for chatbots 2) preferred input modalities 3) opportunities for chatbots based on user needs.},
 acmid = {3040201},
 address = {New York, NY, USA},
 author = {Zamora, Jennifer},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040201},
 isbn = {978-1-4503-4893-5},
 keyword = {India, artificial intelligence, chatbots, input, mobile},
 link = {http://doi.acm.org/10.1145/3030024.3040201},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {109--112},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Rise of the Chatbots: Finding A Place for Artificial Intelligence in India and US},
 year = {2017}
}


@inproceedings{Dragunova:2017:MVS:3030024.3038272,
 abstract = {Findability belongs to key aspects of a webpage usability. When testing findability, the measured task times result not only from the design of a web page, but are influenced also by the individual differences in the participants? abilities, such as their visual search ability. In order to measure this ability, we designed a calibration procedure consisting of a visual search task containing Web icons. In this poster paper, we present results of a quantitative eye tracking study with 45 participants comparing the designed visual search task to the standard conjunction search with respect to the reaction time, number of fixations as well as the used search strategies. The results show that searching for icons is a harder task eliciting more fixations and longer reaction times. In addition, it allows us to differentiate the visual search ability of the users as indicated by the differences in reaction times and search strategies.},
 acmid = {3038272},
 address = {New York, NY, USA},
 author = {Dragunova, Maria and Moro, Robert and Bielikova, Maria},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038272},
 isbn = {978-1-4503-4893-5},
 keyword = {eye tracking, findability, personalization, usability, user experience, user study, visual search, web},
 link = {http://doi.acm.org/10.1145/3030024.3038272},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {97--100},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Measuring Visual Search Ability on the Web},
 year = {2017}
}


@inproceedings{Vijayaraghavan:2017:TAI:3030024.3040979,
 abstract = {We present TweetVista, an interactive web-based tool for mapping the conversation landscapes on Twitter. TweetVista is an intelligent and interactive desktop web application for exploring the conversation landscapes on Twitter. Given a dataset of tweets, the tool uses advanced NLP techniques using deep neural networks and a scalable clustering algorithm to map out coherent conversation clusters. The interactive visualization engine then enables the users to explore these clusters. We ran three case studies using datasets about the 2016 US presidential election and the summer 2016 Orlando shooting. Despite the enormous size of these datasets, using TweetVista users were able to quickly and clearly make sense of the various conversation topics around these datasets.},
 acmid = {3040979},
 address = {New York, NY, USA},
 author = {Vijayaraghavan, Prashanth and Vosoughi, Soroush and Yuan, Ann and Roy, Deb},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040979},
 isbn = {978-1-4503-4893-5},
 keyword = {conversation clusters, interactive tool, semantic clusters, tweet2vec, twitter},
 link = {http://doi.acm.org/10.1145/3030024.3040979},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {145--148},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {TweetVista: An AI-Powered Interactive Tool for Exploring Conversations on Twitter},
 year = {2017}
}


@inproceedings{Gao:2017:FHI:3030024.3038290,
 abstract = {Aging populations have a huge demand of searching health information online. However, for their relatively worse physical ability and cognitive ability, normal searching interface may not be able to fulfill aging people's special demands. In our work, we point out the problem which aging populations are facing when they use the normal online searching system. Then, we propose our interactive health information retrieval framework for aging populations using actual pages from the WebMD.com, a popular website where people search for health information. There are three phases in our proposed framework: the retrieval model design, the interface design and the evaluation design. We hope our interface could help aging users obtain better experience when they search for healthcare information online.},
 acmid = {3038290},
 address = {New York, NY, USA},
 author = {Gao, Mingkun},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038290},
 isbn = {978-1-4503-4893-5},
 keyword = {aging population, healthcare information, information retrieval},
 link = {http://doi.acm.org/10.1145/3030024.3038290},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {213--216},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {A Framework of Health Information Retrieval for Aging Population},
 year = {2017}
}


@inproceedings{Renner:2017:EAG:3030024.3040987,
 abstract = {Intelligent personal assistance systems for manual tasks may support users on multiple levels. A general function is guiding the visual attention of the user towards the item relevant for the next action. This is a challenging task, as the user may be in arbitrary positions and orientations relative to the target. Optical see-through head-mounted-displays (HMDs) present an additional challenge, as the target may be already visible for the user but lie outside the field-of-view of the augmented reality (AR) display. In the context of a smart glasses-based assistance system for a manual assembly station, we evaluated five different visual attention guidance techniques for optical see-through devices. We found that combined directional and positional in-situ guidance performs best overall, but that performance depends on target location. The study is our first realization of a simulated AR methodology in which we create a repeatable and highly-controlled experimental design using a virtual reality (VR) HMD setup.},
 acmid = {3040987},
 address = {New York, NY, USA},
 author = {Renner, Patrick and Pfeiffer, Thies},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040987},
 isbn = {978-1-4503-4893-5},
 keyword = {augmented reality, prompting, visual search, visualizations},
 link = {http://doi.acm.org/10.1145/3030024.3040987},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {89--92},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Evaluation of Attention Guiding Techniques for Augmented Reality-based Assistance in Picking and Assembly Tasks},
 year = {2017}
}


@inproceedings{Schneider:2017:ARE:3030024.3038280,
 abstract = {Personal health and fitness technologies, such as activity trackers, bear the potential to impact health behaviors globally. However, most users abandon these technology quickly. Possible reasons are that provided feedback (often consisting of raw data) is not actionable, not relevant, or the provided advice is not easy to integrate into people's lives. One approach to tackle this problem, is to develop personalized or adaptive digital coaches that take users' individual differences and situation into account. Even though the first prototypes of personalized coaches have been presented and evaluated, this research is still in its infancy. In my thesis, I want to extend this research by (a) investigating the influences of individual differences on behaviors and motivations to use a digital fitness coach, (2) mapping and conceptually exploring the design space of personalized digital fitness coaches, (3) and iteratively prototyping and testing adaptations of personalized fitness coaches in a user-centered design process.},
 acmid = {3038280},
 address = {New York, NY, USA},
 author = {Schneider, Hanna},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038280},
 isbn = {978-1-4503-4893-5},
 keyword = {design space, fitness coach, personalization},
 link = {http://doi.acm.org/10.1145/3030024.3038280},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {173--176},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Adapting at Run-time: Exploring the Design Space of Personalized Fitness Coaches},
 year = {2017}
}


@inproceedings{SuYin:2017:AFF:3030024.3038285,
 abstract = {Fine motor skill is indispensable for a dentist. As in many other medical fields of study, the traditional surgical master apprentice model is widely adopted in dental education. Recently, virtual reality (VR) simulators have been employed as supplementary components to the traditional skill-training curriculum, and numerous dental VR systems have been developed academically and commercially. However, the full promise of such systems has yet to be realized due to the lack of sufficient support for formative feedback. Without such a mechanism, evaluation still demands dedicated time of experts in scarce supply. With the aim to fill the gap of formative assessment using VR simulators in skill training in dentistry, we propose a framework to objectively assess the surgical skill and generate feedback automatically. The core concept of the framework is to generate the feedback by correlating the portion of the procedure responsible with the error in the outcome. Assessment of outcome and the procedure, pedagogical models, and multiple modalities to provide feedback are the integral components of this research.},
 acmid = {3038285},
 address = {New York, NY, USA},
 author = {Su Yin, Myat},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038285},
 isbn = {978-1-4503-4893-5},
 keyword = {formative assessment, intelligent tutoring system, multimodal feedback, surgical simulation, virtual reality},
 link = {http://doi.acm.org/10.1145/3030024.3038285},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {193--196},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Automated Formative Feedback in a Virtual Reality (VR) Dental Surgery Simulator},
 year = {2017}
}


@inproceedings{Barria-Pineda:2017:CKV:3030024.3038262,
 abstract = {Mastery Grids is an intelligent interface that provides access to different kinds of practice content for an introductory programming course. A distinctive feature of the interface is a parallel topic-level visualization of student progress and the progress of their peers. This contribution presents an extended version of the original system that features a fine-grained visualization of student knowledge on the level of the detailed concepts that are associated with the course. The student model is based on a Bayesian-network which is built using students performance history in the learning activities.},
 acmid = {3038262},
 address = {New York, NY, USA},
 author = {Barria-Pineda, Jordan and Guerra, Julio and Huang, Yun and Brusilovsky, Peter},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038262},
 isbn = {978-1-4503-4893-5},
 keyword = {competency visualization, information visualization, open student model, social comparison, student modeling},
 link = {http://doi.acm.org/10.1145/3030024.3038262},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {141--144},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Concept-Level Knowledge Visualization For Supporting Self-Regulated Learning},
 year = {2017}
}


@inproceedings{Dwivedi:2017:VAV:3030024.3040989,
 abstract = {Math word problems are difficult for students to start with since they involve understanding the problem?s context and abstracting out its underlying mathematical operations. A visual understanding of the problem at hand can be very useful for the comprehension of the problem. We present a system VisualMath that uses machine learning tools and crafted visual logic to automatically generate appropriate visualizations from the text of the word-problems and solve it. We demonstrate the improvements in the understanding of math word-problems by conducting a user study and learning of meaning of relevant new words by students.},
 acmid = {3040989},
 address = {New York, NY, USA},
 author = {Dwivedi, Utkarsh and Rajput, Nitendra and Dey, Prasenjit and Varkey, Blessin},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040989},
 isbn = {978-1-4503-4893-5},
 keyword = {automated visualization, natural language processing},
 link = {http://doi.acm.org/10.1145/3030024.3040989},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {105--108},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {VisualMath: An Automated Visualization System for Understanding Math Word-Problems},
 year = {2017}
}


@inproceedings{Friedman:2017:BAA:3030024.3040245,
 abstract = {In principle, brain-computer interfaces (BCIs) hold the promise for being the ultimate intelligent interfaces ? what could surpass an interface that is able to interpret your thoughts and preferences, in real time, and behave accordingly? In practice, it is still not quite clear if and how BCIs can contribute to or replace existing interaction paradigms. In the last 10- 20 years BCI research focused on providing patients who lost their ability to communicate through the usual channels (speech) with ways of communication that are directly based on brain signals. While a lot of progress has been made, very few patients actually use BCI in their daily life. Moreover, it is not clear whether BCI has any advantage for non-clinical applications and for able-bodied individuals.},
 acmid = {3040245},
 address = {New York, NY, USA},
 author = {Friedman, Doron and Brouwer, Anne-Marie and Nijholt, Anton},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040245},
 isbn = {978-1-4503-4893-5},
 keyword = {EEG, FNIRs, brain computer interface},
 link = {http://doi.acm.org/10.1145/3030024.3040245},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {5--7},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {BCIforReal: An application-Oriented Approach to BCI Out of the Laboratory},
 year = {2017}
}


@inproceedings{Glowacka:2017:ESI:3030024.3040246,
 abstract = {In recent years there has been a growing interest in developing new methods and systems that allow users to interactively explore large volumes of data, such as document collections, multimedia collections or biomedical datasets. There are various approaches to support users in this interactive environment ranging from the development of new algorithms through visualisation methods to specialised interfaces. The overarching goal of this workshop is to bring together a group of researchers spanning across multiple facets of exploratory search and data analytics to discuss, and outline research challenges for this novel area.},
 acmid = {3040246},
 address = {New York, NY, USA},
 author = {Glowacka, Dorota and Milios, Evangelos and Soto, Axel J. and Paulovich, Fernando},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040246},
 isbn = {978-1-4503-4893-5},
 keyword = {data analytics, exploratory search, interactive information retrieval},
 link = {http://doi.acm.org/10.1145/3030024.3040246},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {9--11},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Exploratory Search and Interactive Data Analytics},
 year = {2017}
}


@inproceedings{Wu:2017:IAU:3030024.3038287,
 abstract = {In recent years, user personality has been increasingly recognized as a valuable resource being incorporated into the process of generating recommendations. However, the effort of explicitly acquiring users' personality traits via psychological questionnaire is unavoidably high, which may impede the application of personality-based recommenders in real life. My PhD research aims to investigate how to derive users' personality from their implicit behavior and further improve the existing recommender systems. For this purpose, we first identify significant features through experimental validation. We then build inference model to unify these features for determining users' Big-Five personality traits. We further develop personalized recommender systems by incorporating the inferred personality. Our study would indicate an effective solution to boost the applicability of personality-based recommender systems in the online environment.},
 acmid = {3038287},
 address = {New York, NY, USA},
 author = {Wu, Wen},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038287},
 isbn = {978-1-4503-4893-5},
 keyword = {implicit acquisition, recommender systems, user personality},
 link = {http://doi.acm.org/10.1145/3030024.3038287},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {201--204},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Implicit Acquisition of User Personality for Augmenting Recommender Systems},
 year = {2017}
}


@inproceedings{Celik:2017:IWS:3030024.3040248,
 abstract = {New technologies are changing the way we learn and teach. Emerging technologies such as social semantic web, cloud computing, and the growing popularity of mobile devices, embedded devices and adaptive context-aware technologies are leading to a paradigm shift in the way educational services are provided. Through technologies and approaches such as ubiquitous and adaptive learning, learning becomes personalized, flexible, and suitable to meet diverse and rapidly changing technologies, environments and learner needs, while opening unprecedented possibilities for education. The aim of the "Intelligent Interfaces for Ubiquitous and Smart Learning" workshop has been to bring together researchers from industry and academia to address the challenges of the intelligent user interfaces and smart learning fields, discuss new ideas and present their research to the scientific community in order to enhance the methodologies and techniques for intelligent learning environments for the 21st century. The workshop program, program committee and further details are available on the website (http://smartlearn.dibris.unige.it/).},
 acmid = {3040248},
 address = {New York, NY, USA},
 author = {Celik, Ilknur and Torre, Ilaria},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040248},
 isbn = {978-1-4503-4893-5},
 keyword = {cloud technologies, intelligent interfaces, intelligent tutoring systems, interactive learning environments, mobile learning, personalized interaction, recommender systems, smart educational interfaces, social and semantic technologies, technology-enhanced learning, ubiquitous learning, user modelling, user-adapted systems, workshop},
 link = {http://doi.acm.org/10.1145/3030024.3040248},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {17--19},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {IUI'17 Workshop Summary for SmartLearn: Intelligent Interfaces for Ubiquitous and Smart Learning},
 year = {2017}
}


@inproceedings{Sararit:2017:VSE:3030024.3040976,
 abstract = {We present a virtual reality simulator for teaching emergency management decision-making in endodontic surgery. Objectives of the simulator are to 1) teach how to correctly respond to a variety of emergency situations, 2) acclimate students to making decisions in stressful emergency situations and 3) teach students the situation awareness skills required to rapidly recognize and respond to emergencies. To meet these objectives, we present a simulator that permits emergency situations to be dynamically inserted at various points in the procedure and that is immersive. The simulator also allows a teacher to observe and review a session in real-time or post session. Preliminary evaluation of face and content validity shows that the simulation is sufficiently realistic and the system is a promising teaching tool.},
 acmid = {3040976},
 address = {New York, NY, USA},
 author = {Sararit, Nat and Haddawy, Peter and Suebnukarn, Siriwan},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040976},
 isbn = {978-1-4503-4893-5},
 keyword = {decision making, emergency management, endodontic, root canal treatment, virtual reality},
 link = {http://doi.acm.org/10.1145/3030024.3040976},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {117--120},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {A VR Simulator for Emergency Management in Endodontic Surgery},
 year = {2017}
}


@inproceedings{Jannach:2017:IRS:3030024.3030027,
 abstract = {Automated recommendations have become a common feature of modern online services and mobile apps. In many practical applications, the means provided for users to interact with recommender systems (e.g., to state explicit preferences or to provide feedback on the recommendations) are, however, very limited. In order to improve such systems and consequently user satisfaction, much research work has been done over the years to build richer and more intelligent user interfaces for recommender systems. In this tutorial, we provide a comprehensive overview of existing approaches to user interaction aspects of recommender systems, with a special focus on explanation interfaces. We also provide examples of real-world systems that implement advanced interaction mechanisms and discuss open challenges in the field.},
 acmid = {3030027},
 address = {New York, NY, USA},
 author = {Jannach, Dietmar and Nunes, Ingrid and Jugovac, Michael},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3030027},
 isbn = {978-1-4503-4893-5},
 keyword = {interaction design, recommender systems},
 link = {http://doi.acm.org/10.1145/3030024.3030027},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {25--27},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Interacting with Recommender Systems},
 year = {2017}
}


@inproceedings{Chen:2017:SEO:3030024.3040978,
 abstract = {Entity search and exploration can enrich search user interfaces by presenting relevant information instantly and offering relevant exploration pointers to users. Previous research has demonstrated that large Knowledge Graphs allow exploitation and recommendation of explicit links between the entities and other information to improve information access and ranking. However, less attention has been devoted to user interfaces for effectively presenting results, recommending related entities and explaining relations between entities. We introduce a system called SEED which is designed to support entity search and exploration in large Knowledge Graphs. We demonstrate SEED using a dataset of hundreds of thousands of movie related entities from the DBpedia Knowledge Graph. The system utilizes a graph embedding model for ranking entities and their relations, recommending related entities, and explaining their interrelations.},
 acmid = {3040978},
 address = {New York, NY, USA},
 author = {Chen, Jun and Jacucci, Giulio and Chen, Yueguo and Ruotsalo, Tuukka},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040978},
 isbn = {978-1-4503-4893-5},
 keyword = {embedding model, exploratory search, knowledge graph, knowledge representation},
 link = {http://doi.acm.org/10.1145/3030024.3040978},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {137--140},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {SEED: Entity Oriented Information Search and Exploration},
 year = {2017}
}


@inproceedings{Graus:2017:ICS:3030024.3040247,
 abstract = {The first workshop on Theory-Informed User Modeling for Tailoring and Personalizing Interfaces (HUMANIZE) took place in conjunction with the 22nd annual meeting of the intelligent user interfaces (IUI) community in Limassol, Cyprus on March 13, 2017. The goal of the workshop was to attract researchers from different fields by accepting contributions on the intersection of practical data mining methods and theoretical knowledge for personalization. A total of six papers were accepted for this edition of the workshop.},
 acmid = {3040247},
 address = {New York, NY, USA},
 author = {Graus, Mark and Ferwerda, Bruce and Schedl, Markus and Tkalcic, Marko and Willemsen, Martijn and Germanakos, Panagiotis},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040247},
 isbn = {978-1-4503-4893-5},
 keyword = {data mining, personalization, psychological theories, user interfaces, workshop summary},
 link = {http://doi.acm.org/10.1145/3030024.3040247},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {13--15},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {IUI'17 Companion-Workshop Summary for HUMANIZE'17},
 year = {2017}
}


@proceedings{Papadopoulos:2017:3025171,
 abstract = {It is our great pleasure to welcome you to the 2017 International Conference on Intelligent User Interfaces (IUI'17). It is the twenty-second IUI conference, continuing its tradition of being the principal international forum for reporting outstanding research at the intersection of Human Computer Interaction (HCI) and Artificial Intelligence (AI). The work that appears at IUI bridges these two fields and delves also into related fields, such as psychology, cognitive science, computer graphics, the arts, and many others. Members of the IUI community are interested in improving the symbiosis between humans and computers, and in making systems adapt to humans rather than the other way around. The call for papers attracted 272 submissions from Africa, America, Asia, Australia and Europe, a record number for the IUI series, 58 submissions of posters and demos and 25 submissions to the students' consortium. The program committee accepted 63 papers, covering a diverse set of topics, reflected in the session titles "Recommender Systems", "Multimodal and Augmented Interaction", "Understanding Users", "Information Visualization", "Personalization", "Interactive Programming and Automation", "Trust", "Intelligent Training and Educational Interfaces", "Intelligent Systems", "Gestural and Haptic Interaction", "Analytics", "Interactive Machine Learning and Explanation", "Machine Learning", and "Information Retrieval". We also have 19 posters and 13 demos and 16 doctoral consortium papers. Following the tradition of collaboration with TiiS journal, 5 papers that were published during 2016 are presented at IUI 2017 and selected papers will be invited to submit extended versions to the journal. In addition, the conference provides six workshops and three tutorials. One of the main attractions of the conference is provided by the scientific keynotes: Dr. Shumin Zhai opens the conference program with a keynote on "Modern Touchscreen Keyboards as Intelligent User Interfaces: A Research Review", Professor George Samaras' second day keynote is on "Utilizing Human Cognitive and Emotional Factors for User-Centered Computing" and the last day keynote, by Professor Panos Markopoulos, is on "Interaction Design for Rehabilitation". The conference program is available for IUI participants on Conference Navigator. IUI 2017 has a few novelties: For the first time, IUI introduced parallel sessions throughout the conference. The doctoral consortium papers were integrated into the main program for the first time in IUI. Another novelty of IUI 2017 is the introduction of the "most impactful IUI paper" award.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4348-0},
 location = {Limassol, Cyprus},
 publisher = {ACM},
 title = {IUI '17: Proceedings of the 22Nd International Conference on Intelligent User Interfaces},
 year = {2017}
}


@inproceedings{Sengupta:2017:GIK:3030024.3038259,
 abstract = {In the conventional keyboard interfaces for eye typing, the functionalities of the virtual keys are static, i.e., user?s gaze at a particular key simply translates the associated letter as user's input. In this work we argue the keys to be more dynamic and embed intelligent predictions to support gaze-based text entry. In this regard, we demonstrate a novel "GazeTheKey" interface where a key not only signifies the input character, but also predict the relevant words that could be selected by user's gaze utilizing a two-step dwell time.},
 acmid = {3038259},
 address = {New York, NY, USA},
 author = {Sengupta, Korok and Menges, Raphael and Kumar, Chandan and Staab, Steffen},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038259},
 isbn = {978-1-4503-4893-5},
 keyword = {dwell time, eye tracking, eye typing, gaze input, text entry, visual feedback},
 link = {http://doi.acm.org/10.1145/3030024.3038259},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {121--124},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {GazeTheKey: Interactive Keys to Integrate Word Predictions for Gaze-based Text Entry},
 year = {2017}
}


@inproceedings{VerganiDambros:2017:MRQ:3030024.3038268,
 abstract = {In a variety of use-cases, deriving information on user's fatigue is an important step for content adaptation. In this work, we investigate which eye tracking related measures can predict the error rate (as a proxy of subject's fatigue)during a visual experiment. Data was collected during a 40 minutes campimetric task, where the user has to detect visual stimuli (i.e., dots) of different contrast. We found that eye-tracking measures can be used to train a machine learning model to predict the error rate of a user with an average correlation of 0.72±0.17. The results show that this method can be used to measure the user?s response quality.},
 acmid = {3038268},
 address = {New York, NY, USA},
 author = {Vergani Dambros, Gustavo and Ungewiss, Judith and K\"{u}bler, Thomas and Kasneci, Enkelejda and Sp\"{u}ler, Martin},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038268},
 isbn = {978-1-4503-4893-5},
 keyword = {blink rate, campimetry, eye-tracking, fatigue, pupil diameter, vigilance},
 link = {http://doi.acm.org/10.1145/3030024.3038268},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {61--64},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Monitoring Response Quality During Campimetry Via Eye-Tracking},
 year = {2017}
}


@inproceedings{Harteveld:2017:DPA:3030024.3040981,
 abstract = {Playful environments are increasingly being used for conducting research. This makes a game platform for authoring research studies and teaching about how to conduct research a necessary progression. In this paper, we discuss Mad Science, a playful platform that is being created to allow users to create behavioral experiments. We discuss iterations of the authoring tools, including lessons learned, and the need for AI assistance to guide and teach users.},
 acmid = {3040981},
 address = {New York, NY, USA},
 author = {Harteveld, Casper and Manning, Nolan and Abu-Arja, Farah and Menasce, Rick and Thurston, Dean and Smith, Gillian and Sutherland, Steven C.},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040981},
 isbn = {978-1-4503-4893-5},
 keyword = {authoring tools, experiments, interface design, playful},
 link = {http://doi.acm.org/10.1145/3030024.3040981},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {157--160},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Design of Playful Authoring Tools for Social and Behavioral Science},
 year = {2017}
}


@inproceedings{Tresser:2017:PVG:3030024.3038289,
 abstract = {The purpose of the current work is to explore the potential of a personalized virtual gaming system capable of dynamically adjusting game parameters in accordance with the abilities and therapeutic needs of children with Cerebral Palsy (CP). The study includes three stages: Defining user characteristics and identifying user requirements of children with CP in order to create a user model via interviews and focus groups; Developing a prototype of a personalized virtual gaming system for rehabilitation of children with CP and; Evaluating the prototype with typically developing children and children with CP. Initial results from the first stage identified the benefits and potential of personalized virtual gaming for treating children with CP from both the therapist?s and child?s viewpoints. Iterative prototyping and testing of the personalization algorithm are currently in progress.},
 acmid = {3038289},
 address = {New York, NY, USA},
 author = {Tresser, Sarit},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038289},
 isbn = {978-1-4503-4893-5},
 keyword = {cerebral palsy (CP), personalization, rehabilitation, user modeling, video games, virtual reality (VR)},
 link = {http://doi.acm.org/10.1145/3030024.3038289},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {209--212},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Personalization of Virtual Games for Children with Cerebral Palsy},
 year = {2017}
}


@inproceedings{diSciascio:2017:AUI:3030024.3038291,
 abstract = {Exploring large volumes of data with learning or investigative purposes is often regarded as exploratory search. Rather than plain question answering, exploratory search is an iterative process of information seeking and sensemaking. My focus is the development of an interactive intelligent tool that assists the search task and the study of user behavior and experience. More specifically, I combine recommender systems with advanced user interfaces to maximize what Hearst calls "recognition over recall".},
 acmid = {3038291},
 address = {New York, NY, USA},
 author = {di Sciascio, Cecilia},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038291},
 isbn = {978-1-4503-4893-5},
 keyword = {advanced user interfaces, exploratory search, recommender systems, user experience},
 link = {http://doi.acm.org/10.1145/3030024.3038291},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {221--224},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Advanced User Interfaces and Hybrid Recommendations for Exploratory Search},
 year = {2017}
}


@inproceedings{Tsai:2017:III:3030024.3038292,
 abstract = {Offering diversity in the output of a recommender system is an active research question. Most of the current approaches focus on Top-N optimization, which results in poor user insight and accuracy trade-off. However, little is known about how an interactive interface can help with this issue. This pilot study shows that a multidimensional visualization promotes diversity among the recommended items. This finding motivated future work to provide diversity in recommender system by visualizing multivariate data through an interpretable and interactive interface.},
 acmid = {3038292},
 address = {New York, NY, USA},
 author = {Tsai, Chun-Hua},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038292},
 isbn = {978-1-4503-4893-5},
 keyword = {HCI, diversity, recommender system},
 link = {http://doi.acm.org/10.1145/3030024.3038292},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {225--228},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {An Interactive and Interpretable Interface for Diversity in Recommender Systems},
 year = {2017}
}


@inproceedings{Eivazi:2017:TAS:3030024.3040985,
 abstract = {In the past decade, eye tracking has emerged as a promising answer to the increasing needs of understanding surgical expertise. The implicit desire is to design an intelligent user interface (IUI) to monitor and assess the competency of surgical trainees. In this paper, for the first time in microsurgery, we explore the potential for a surgical automatic skill assessment through a combination of machine learning techniques, computational modeling, and eye tracking. We present primary findings from a random forest classification method where we achieved about 70% recognition rate for the detection of expert and novice group. This leads us to a conclusion that prediction of the micro-surgeon performance is possible, can be automated, and that the eye movement data carry important information about the skills of micro-surgeons.},
 acmid = {3040985},
 address = {New York, NY, USA},
 author = {Eivazi, Shahram and Slupina, Michael and Fuhl, Wolfgang and Afkari, Hoorieh and Hafez, Ahmad and Kasneci, Enkelejda},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040985},
 isbn = {978-1-4503-4893-5},
 keyword = {eye tracking, machine learning, micro-neurosurgery, skill assessment},
 link = {http://doi.acm.org/10.1145/3030024.3040985},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {73--76},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Towards Automatic Skill Evaluation in Microsurgery},
 year = {2017}
}


@inproceedings{Mauro:2017:IPC:3030024.3038282,
 abstract = {My PhD project focuses on Participatory GIS (PGIS). In the project I analyze two methodologies to offer personalized search results in community maps and a natural interaction with the system. The first consists of automatically gathering the terms according to which the users express their information needs, in order to enrich the domain conceptualization of a PGIS, giving common definitions for places. The second concerns the creation of ontology-based user models that reflect the interests, lexicon and modality of expression adopted by each person, mapped to the domain ontology adopted by the PGIS. In the project I also analyze how these techniques may be jointly used during the query expansion process to retrieve more accurate and relevant search results.},
 acmid = {3038282},
 address = {New York, NY, USA},
 author = {Mauro, Noemi},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038282},
 isbn = {978-1-4503-4893-5},
 keyword = {linked data, ontologies, ontology-based user model, participatory GIS, personalization, semantic search},
 link = {http://doi.acm.org/10.1145/3030024.3038282},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {181--184},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Intelligent and Personalized Community Maps},
 year = {2017}
}


@inproceedings{Do:2017:IIS:3030024.3040991,
 abstract = {Despite the explosive growth of online social media where people can easily share their thoughts, our current society is more divided than before, gridlocked over society, culture, race, and gender issues. Selective exposure, a confirmatory bias of individuals that favors preexisting opinions while avoiding attitude-inconsistent views, impedes the balanced insight of a controversial issue, which thereby would account for the societal division. In this research proposal, we introduce an intelligent interface that automatically clusters and visualizes diverse opinions about a controversial topic. First, we collect controversial posts from Facebook and its comments. Then, the comments are automatically clustered using a machine-learning algorithm based on features that reflect its contents and the writer's stance. Lastly, we propose an intelligent user interface with controversial posts and opinion clusters where users would be motivated to hunt for opinion groups that are different from their own perspective.},
 acmid = {3040991},
 address = {New York, NY, USA},
 author = {Do, Hyo Jin},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040991},
 isbn = {978-1-4503-4893-5},
 keyword = {intelligent user interface, machine-learning, social opinion},
 link = {http://doi.acm.org/10.1145/3030024.3040991},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {217--220},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Intelligent Interface for Seeing the World Through Different Lenses},
 year = {2017}
}


@inproceedings{Bader:2017:EEO:3030024.3040982,
 abstract = {A restaurant review is a reflection of the reviewer?s experience and attitude towards the restaurant. The same applies to a review of a new phone or a review on any other online merchandize. Films, however, are created with the intended purpose to evoke an emotional response in the viewer. This emotional response does not necessarily correspond with the viewer's attitude towards the film. Thus, the question we try to address is, would the emotions expressed in a film?s online reviews also reflect the emotions elicited during the film? In this work, we take a first step in the investigation of this question, by studying the role of emotions in movie reviews as expressed in a large dataset of millions of online reviews for over 9000 movies, that appeared in IMDb from 1972 to 2015. Our results show that we can extract emotions elicited by the film from its reviews, and create an emotional signature of a film, and of a genre. This is a first step towards an Emotion-based Film Browser UI system that will enable users to browse films according to the emotions they evoke.},
 acmid = {3040982},
 address = {New York, NY, USA},
 author = {Bader, Nadeem and Mokryn, Osnat and Lanir, Joel},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040982},
 isbn = {978-1-4503-4893-5},
 keyword = {emotional signature, emotions, movie reviews},
 link = {http://doi.acm.org/10.1145/3030024.3040982},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {35--38},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Exploring Emotions in Online Movie Reviews for Online Browsing},
 year = {2017}
}


@inproceedings{Dwivedi:2017:EIG:3030024.3038266,
 abstract = {This paper introduces {it EyamKayo}, a first-of-its-kind interactive CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart), using eye gaze and facial expression based human interactions, to better distinguish humans from software robots. Our system generates a sequence of instructions, asking the user to follow a controlled sequence of gaze points, and generate a controlled sequence of facial expressions. We evaluate user comfort and system usability, and validate using usability tests.},
 acmid = {3038266},
 address = {New York, NY, USA},
 author = {Dwivedi, Utkarsh and Ahuja, Karan and Islam, Rahul and Barbhuiya, Ferdous A. and Nagar, Seema and Dey, Kuntal},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038266},
 isbn = {978-1-4503-4893-5},
 keyword = {emotion, facial expression, gaze, interactive captcha},
 link = {http://doi.acm.org/10.1145/3030024.3038266},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {53--56},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {EyamKayo: Interactive Gaze and Facial Expression Captcha},
 year = {2017}
}


@inproceedings{Augstein:2017:AMF:3030024.3038267,
 abstract = {Personalization has been discussed in a number of domains and it also plays an important role in the area of human-computer interaction as users' interaction abilities and preferences vary drastically. Considering these individual characteristics can contribute to better user experience and also accessibility of interactive settings. This extended abstract describes a framework that enables personalized interaction based on analyzing and modeling users' interaction abilities.},
 acmid = {3038267},
 address = {New York, NY, USA},
 author = {Augstein, Mirjam and Neumayr, Thomas and Kern, Daniel and Kurschl, Werner and Altmann, Josef and Burger, Thomas},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038267},
 isbn = {978-1-4503-4893-5},
 keyword = {interaction analysis, personalization, user modeling},
 link = {http://doi.acm.org/10.1145/3030024.3038267},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {57--60},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {An Analysis and Modeling Framework for Personalized Interaction},
 year = {2017}
}


@inproceedings{Constantinou:2017:UVR:3030024.3038270,
 abstract = {An investigation in the use of Virtual Reality as a means of training designers to design interfaces accessible to achromatic vision patients is presented. Within this context virtual environments incorporating real life environments are visualised through the eyes of achromatic vision patients and designers are given the opportunity to navigate and interact with the virtual environment using different types of interaction schemes. Through the process designers assess the applicability of different interaction methods adjusted to the needs of achromatic vision patients. According to the results of an experimental investigation, the idea of using Virtual Reality-based training is deemed effective.},
 acmid = {3038270},
 address = {New York, NY, USA},
 author = {Constantinou, Vaso and Lanitis, Andreas and Ioannou, Andri},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038270},
 isbn = {978-1-4503-4893-5},
 keyword = {accessibility, achomatic vision, deuteranopia, protanopia, tritanopia, virtual reality},
 link = {http://doi.acm.org/10.1145/3030024.3038270},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {77--80},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Using Virtual Reality to Train Designers to Develop Friendly Interfaces for Achromatic Vision Patients},
 year = {2017}
}


@inproceedings{Kalloori:2017:PPR:3030024.3038278,
 abstract = {Most of the present research and application of Recommender Systems is based on the usage of preferences derived from absolute evaluations, such as user ratings or clicks. However, this type of preferences has few disadvantages, e.g., if most of the user rated items are 5 stars, then it is difficult to understand which item the user prefers among them. In this research work, we focus on pairwise preferences as an alternative way for modeling user preferences and compute recommendations. In our scenario, users provide pair scores for a set of item pairs, indicating which item, and to what extent, is preferred. In this Ph.D research, we aim at developing intelligent user interfaces that optimally combine ratings with pairwise preferences. Furthermore, we aim at identifying specific conditions/situations where pairwise preferences elicitation is meaningful and beneficial.},
 acmid = {3038278},
 address = {New York, NY, USA},
 author = {Kalloori, Saikishore},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038278},
 isbn = {978-1-4503-4893-5},
 keyword = {pairwise preferences, ratings, recommender systems},
 link = {http://doi.acm.org/10.1145/3030024.3038278},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {169--172},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Pairwise Preferences and Recommender Systems},
 year = {2017}
}


@inproceedings{Schnelle-Walka:2017:SFW:3030024.3040249,
 abstract = {The increasing number of smart objects in our everyday life radically changes how we interact with everyday objects. In this workshop, we discuss how the interaction with these smart objects should be designed from various perspectives.},
 acmid = {3040249},
 address = {New York, NY, USA},
 author = {Schnelle-Walka, Dirk and M\"{u}ller, Florian and Grosse-Puppendahl, Tobias and Luyten, Kris and M\"{u}hlh\"{a}user, Max and Brdiczka, Oliver},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040249},
 isbn = {978-1-4503-4893-5},
 keyword = {HCI, context-awareness, embodied interaction, enabling techologies, multimodal and adapter interaction, novel interaction, smart objects, tangible interaction},
 link = {http://doi.acm.org/10.1145/3030024.3040249},
 location = {Limassol, Cyprus},
 numpages = {3},
 pages = {21--23},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {SmartObjects: Fifth Workshop on Interacting with Smart Objects},
 year = {2017}
}


@inproceedings{Ko:2017:SSI:3030024.3038274,
 abstract = {In this paper, we propose the selection of representative images based on human affects. For this, the images are first transformed into the affective space using convolutional neural network (CNN). Thereafter, images are clustered on affective space and then the resulting clusters are ranked based on the proposed three properties ? coverage, affective coherence and distinctiveness. Finally, some representative images are selected from top-ranked clusters. The experiments conducted on Flickr images showed the effectiveness of the proposed method.},
 acmid = {3038274},
 address = {New York, NY, USA},
 author = {Ko, Eunjeong and Kim, Eun Yi and Yu, Yaohui},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038274},
 isbn = {978-1-4503-4893-5},
 keyword = {convolutional neural network, human affects, image summarization, ranking model, social image},
 link = {http://doi.acm.org/10.1145/3030024.3038274},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {101--104},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Summarizing Social Image Search Results Using Human Affects},
 year = {2017}
}


@inproceedings{Karpouzis:2017:AGI:3030024.3030029,
 abstract = {The advent of ubiquitous and wearable sensors and computing power and, especially, natural interfaces in the form of speech-based commands or hand-held devices enables users to interact with computers, gaming consoles, and portable devices in a human-like fashion, surpassing the conventional paradigm of keyboards, mice and hand-held controllers. This emerging paradigm opens up new means of non-verbal communication: users can shrug their shoulders to indicate indifference to the options presented to them, nod when agreeing or shout when angry, thus producing feedback which computing systems can take advantage of to provide a truly natural and personalized experience. In addition to this, both seasoned gamers and casual users can interact with computer and console games in the same manner as they would when playing a conventional physical or mental game. In the framework of human-computer interaction, this opens up an opportunity to explore those games as a research medium: the Flow Theory of Optimal Experience, developed by Csikszentmihalyi, gets its name from the way so many people have described a peculiar state of extreme happiness and satisfaction, being so engaged and absorbed by certain activities that they seem to 'flow' along with them in a spontaneous and almost automatic manner, being ?carried by the flow? of the activity. As a result, play becomes not the opposite of work, as is sometimes considered, but is actually sometimes synonymous to it: for instance, children seem to learn infinitely easier when the learning objectives are achieved through play than when forced into the conventional study paradigms. This tutorial aims to introduce games not as a leisure or entertainment activity, but as a means to educate children and adults. Natural interaction and expressivity, personalization (starting from the user interface, all the way down to producing individual content based on what players enjoy), along with accessible computing and aesthetic emotions constitute concepts which can benefit from studying user behaviour and expressivity when playing games. It order to bridge the gap from low-level observed signals (audio, video or even biosignals) to affective and behavioural cues, one needs to map extracted features or cues to user characteristics, taking into account background information or user and environment context, e.g. a smile from the user may be interpreted as positive feedback by a gaming environment, while a frown may indicate that the user did not get what he/she expected to or has a hard time with the particular game stage. Knowledge technologies can be of great assistance here, offering useful qualities, such as alignment and consistency checking, while concepts from cognitive theories, e.g. Theory of Mind, can prove valuable when trying to reason about the beliefs, desires and intentions of the user. As a result, research and development of games are not confined to one single discipline, but instead compose an exciting and challenging inter-disciplinary field.},
 acmid = {3030029},
 address = {New York, NY, USA},
 author = {Karpouzis, Kostas},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3030029},
 isbn = {978-1-4503-4893-5},
 keyword = {affective computing, computational intelligence, games research, human-machine interaction, machine learning, natural interfaces},
 link = {http://doi.acm.org/10.1145/3030024.3030029},
 location = {Limassol, Cyprus},
 numpages = {2},
 pages = {33--34},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Affective and Gameful Interfaces},
 year = {2017}
}


@proceedings{Nichols:2016:2856767,
 abstract = {It is with great pleasure that we welcome you to beautiful Sonoma, California and the 21st edition of ACM International Conference on Intelligent User Interfaces -- ACM IUI 2016. ACM IUI is "where HCI meets AI," or where the academic research communities of Human-Computer Interaction (HCI) and Artificial Intelligence (AI) intersect. As the premier international forum for reporting outstanding research and development on intelligent user interfaces, the conference welcomes submissions describing work at the cross-section of these two fields and other related fields, such as psychology, behavioral science, cognitive science, computer graphics, design, the arts, and many others. Members of the ACM IUI community are interested in improving the symbiosis between humans and computers, increasing the intelligence of both in the process. The call for papers attracted 194 long and short paper submissions, 31 poster paper submissions, 11 demo paper submissions, and 17 student consortium submissions. The final program of the conference includes 2 keynotes, 49 long and short papers (25.3% acceptance rate), 15 posters, 6 demos, 2 workshops, 1 tutorial, and 12 student consortium papers. We are particularly excited for the keynotes by two distinguished speakers that will open the first and third days of the conference. The opening keynote will be given by Xavier Amatriain, VP of Engineering at Quora, on the topic of the "Past, Present, and Future of Recommender Systems: An Industry Perspective." The closing keynote will be given by Professor Elisabeth André, from Augsburg University and a long-time member of the ACM IUI community, on the topic of "Socially-Sensitive Interfaces: From Offline Studies to Interactive Experiences." The conference could not be organized without the help of a large number of individuals who generously volunteered much of their own time. Their names can be found on the following pages. All of the members of the organizing committee have done a fantastic job of coordinating the many moving parts that go into putting on a great conference. We must also particularly thank our 34 senior program committee members for coordinating the papers review process and the 91 members of the program committee for providing high quality reviews. And, most important, we must thank the authors for their diligent work that resulted in so many great submissions. These have allowed us to develop the excellent program that is the enduring heart of the conference. Another key for any great conference is a collection of strong sponsor organizations and generous corporate supporters. Our sponsors ACM, SIGAI, and SIGCHI are instrumental in making the conference happen year in and year out. This year, SIGCHI and SIGAI were particularly generous in providing financial support for our student travel grants, which have enabled 19 students to attend the conference that might not have otherwise. Our corporate supporters, Microsoft, IBM, Google, and Tableau have been supremely generous and the conference would be weaker without their contributions. We hope you will find the program engaging and the mix of academic disciplines broadens your perspective on computing. We also hope the conference will provide you with a valuable opportunity to share ideas with other researchers and practitioners from around the world, whether through presenting your own work formally or through informal discussions during the banquet or coffee breaks. With luck, those shared ideas will manifest themselves in exciting papers at next year's conference and ultimately have impact far beyond the conference! If you have any suggestions for how to improve the conference either this year or in the future, please do not hesitate to let us know.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4137-0},
 location = {Sonoma, California, USA},
 publisher = {ACM},
 title = {IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces},
 year = {2016}
}


@inproceedings{Verbert:2017:SCA:3030024.3038273,
 abstract = {Recent efforts in recommender systems research focus increasingly on human factors affecting recommendation acceptance, such as transparency and user control. In this paper, we present IntersectionExplorer, a scalable visualization to interleave the output of several recommender engines with user-contributed relevance information, such as bookmarks and tags. Two user studies at conferences indicate that this approach is well suited for technical audiences in smaller venues, and allowed the identification of applicability limitations for less technical audiences attending larger events.},
 acmid = {3038273},
 address = {New York, NY, USA},
 author = {Verbert, Katrien and Brusilovsky, Peter and Wongchokprasitti, Chirayu and Parra, Denis and Cardoso, Bruno},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3038273},
 isbn = {978-1-4503-4893-5},
 keyword = {interactive visualization, recommender systems, set visualization},
 link = {http://doi.acm.org/10.1145/3030024.3038273},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {161--164},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Supporting Conference Attendees with Visual Decision Making Interfaces},
 year = {2017}
}


@inproceedings{Sheidin:2017:VSE:3030024.3040984,
 abstract = {News today are generated and distributed online by a multitude of sources all over the world. Easy and efficient monitoring and analysis of news stories is of interest to both professional analysts and the general public. One interesting aspect is the magnitude and impact of a story as well as its evolution over time. In this work we introduce an idea and a system that presents temporal and spatial evolution of news world-wide, in two different levels, to help users quickly understand and act upon the large amount of data. An overview option shows a general split of the reported news, and a more detailed view provides interactive options for deeper analysis of a single news episode. We demonstrate our system on data from news events generated by the Europe Media Monitor (EMM), an online news aggregator platform.},
 acmid = {3040984},
 address = {New York, NY, USA},
 author = {Sheidin, Julia and Lanir, Joel and Kuflik, Tsvi and Bak, Peter},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces Companion},
 doi = {10.1145/3030024.3040984},
 isbn = {978-1-4503-4893-5},
 keyword = {news, news visualization, spatio-temporal visualization},
 link = {http://doi.acm.org/10.1145/3030024.3040984},
 location = {Limassol, Cyprus},
 numpages = {4},
 pages = {65--68},
 publisher = {ACM},
 series = {IUI '17 Companion},
 title = {Visualizing Spatial-Temporal Evaluation of News Stories},
 year = {2017}
}


