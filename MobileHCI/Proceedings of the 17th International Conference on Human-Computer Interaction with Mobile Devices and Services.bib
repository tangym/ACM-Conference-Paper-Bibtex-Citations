@inproceedings{McMillan:2015:WVV:2785830.2785883,
 abstract = {The explosion of mobile applications and services presents challenges for evaluation and user study. One successful approach has been to deploy instrumented applications, logging their use over long periods of time. We present an expansion of this by remotely recording video and audio of use, while also capturing device and app context. In vivo combines five data collection techniques -- screen recording, ambient audio recording, wearable cameras, data logging and distributed remote uploads. This data provides a range of insights and we discuss examples from previous work which reveal interaction design issues where interface confusions or task mismatches occur. We see how apps are integrated into ongoing activity and environment (such as how maps are used in situ), and how recorded conversations around and about apps may be used for evaluation purposes. We conclude by arguing that this combinative method helps us to move from considering app use in isolation, to studying app use in interaction.},
 acmid = {2785883},
 address = {New York, NY, USA},
 author = {McMillan, Donald and McGregor, Moira and Brown, Barry},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785883},
 isbn = {978-1-4503-3652-9},
 keyword = {Evaluation, Logging, Screen Recording, Video Analysis},
 link = {http://doi.acm.org/10.1145/2785830.2785883},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {494--503},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {From in the Wild to in Vivo: Video Analysis of Mobile Device Use},
 year = {2015}
}


@inproceedings{Ismair:2015:MTM:2785830.2785854,
 abstract = {Mid-air gestures are initial hand poses with a subsequent movement. Existing gesture guides reveal this dynamic part of a gesture. Initial poses, however, are either revealed by space-consuming cheat sheets or time-consuming demonstration videos. Mime is a novel interaction concept that (1) reveals how to form complex hand poses and (2) teaches pose-command mappings: Mime reduces hand poses to space-efficient line figures that users mime with their hands; these abstract lines are embedded into command icons or names to create a mnemonic. We present several applications of the Mime concept, and implemented a prototype based on mid-air back-of-device interaction on off-the-shelf mobile phones. We compared both mnemonics, iconic and textual, to a baseline without embedding to test learnability and memorability of a 12-item vocabulary. Users in the iconic condition required significantly less training than both other conditions and recalled significantly more items after one week compared to the no-cue baseline.},
 acmid = {2785854},
 address = {New York, NY, USA},
 author = {Ismair, Simon and Wagner, Julie and Selker, Ted and Butz, Andreas},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785854},
 isbn = {978-1-4503-3652-9},
 keyword = {Mid-air gesture, back-of-device interaction, feedforward, hand pose, mnemonic, pose-command mapping},
 link = {http://doi.acm.org/10.1145/2785830.2785854},
 location = {Copenhagen, Denmark},
 numpages = {8},
 pages = {199--206},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {MIME: Teaching Mid-Air Pose-Command Mappings},
 year = {2015}
}


@inproceedings{Church:2015:UCM:2785830.2785891,
 abstract = {Driven by curiosity and our own three diverse smartphone application usage datasets, we sought to unpack the nuances of mobile device use by revisiting two recent Mobile HCI studies [1, 17]. Our goal was to add to our broader understanding of smartphone usage by investigating if differences in mobile device usage occurred not only across our three datasets, but also in relation to prior work. We found differences in the top-10 apps in each dataset, in the durations and types of interactions as well as in micro-usage patterns. However, it proved very challenging to attribute such differences to a specific factor or set of factors: was it the time frame in which the studies were executed? The recruitment procedure? The experimental method? Using our somewhat troubled analysis, we discuss the challenges and issues of conducting mobile research of this nature and reflect on caveats related to the replicability and generalizability of such work.},
 acmid = {2785891},
 address = {New York, NY, USA},
 author = {Church, Karen and Ferreira, Denzil and Banovic, Nikola and Lyons, Kent},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785891},
 isbn = {978-1-4503-3652-9},
 keyword = {Device usage, Evaluation, Generalizability, Methodology, Micro-usage, Mobile HCI, Mobile usage, Replication, Smartphone usage, User Studies},
 link = {http://doi.acm.org/10.1145/2785830.2785891},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {504--514},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Understanding the Challenges of Mobile Phone Usage Data},
 year = {2015}
}


@inproceedings{Matthies:2015:BLO:2785830.2785859,
 abstract = {We present Botential, an on-body interaction method for a wearable input device that can identify the location of on-body tapping gestures, using the entire human body as an interactive surface to expand the usually limited interaction space in the context of mobility. When the sensor is being touched, Botential identifies a body part's unique electric signature, which depends on its physiological and anatomical compositions. This input method exhibits a number of advantages over previous approaches, which include: 1) utilizing the existing signal the human body already emits, to accomplish input with various body parts, 2) the ability to also sense soft and long touches, 3) an increased sensing range that covers the whole body, and 4) the ability to detect taps and hovering through clothes.},
 acmid = {2785859},
 address = {New York, NY, USA},
 author = {Matthies, Denys J. C. and Perrault, Simon T. and Urban, Bodo and Zhao, Shengdong},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785859},
 isbn = {978-1-4503-3652-9},
 keyword = {Capacitive Sensing, EMG, Embodied Interaction, Eyes-free, Hands-free, On-Body Interaction, User Interface},
 link = {http://doi.acm.org/10.1145/2785830.2785859},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {207--216},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Botential: Localizing On-Body Gestures by Measuring Electrical Signatures on the Human Skin},
 year = {2015}
}


@inproceedings{Wohn:2015:AAI:2785830.2785865,
 abstract = {Ubiquitous mobile usage provides more opportunities to interact with more people than ever, but with the constraint that people's capacity for attention to others is limited. People manage demands on their attention by limiting their availability to others, and this may cause failure in attempts to reach others. In today's always-connected world, we know very little about how people manage their own availability, maintain awareness of others, and adapt their strategies for reaching others in the face of failure. This paper draws on results from a qualitative field study to present an integrative, joint action approach to attention management. Results suggest that mobile devices play a large part in assessing ambient awareness of others and signaling availability, but are rarely used in isolation. Attention is a continuum that spans multiple devices and channels involving actions and choices learned over time.},
 acmid = {2785865},
 address = {New York, NY, USA},
 author = {Wohn, Donghee Yvette and Birnholtz, Jeremy},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785865},
 isbn = {978-1-4503-3652-9},
 keyword = {Attention, CMC, ambient attention, awareness, channel sequencing},
 link = {http://doi.acm.org/10.1145/2785830.2785865},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {26--35},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {From Ambient to Adaptation: Interpersonal Attention Management Among Young Adults},
 year = {2015}
}


@inproceedings{Wang:2015:PUP:2785830.2785886,
 abstract = {We present PalmType, which uses palms as interactive keyboards for smart wearable displays, such as Google Glass. PalmType leverages users' innate ability to pinpoint specific areas of their palms and fingers without visual attention (i.e. proprioception), and provides visual feedback via the wearable displays. With wrist-worn sensors and wearable displays, PalmType enables typing without requiring users to hold any devices and does not require visual attention to their hands. We conducted design sessions with 6 participants to see how users map QWERTY layout to their hands based on their proprioception. To evaluate typing performance and preference, we conducted a 12-person user study using Google Glass and Vicon motion tracking system, which showed that PalmType with optimized QWERTY layout is 39% faster than current touchpad-based keyboards. In addition, PalmType is preferred by 92% of the participants. We demonstrate the feasibility of wearable PalmType by building a prototype that uses a wrist-worn array of 15 infrared sensors to detect users' finger position and taps, and provides visual feedback via Google Glass.},
 acmid = {2785886},
 address = {New York, NY, USA},
 author = {Wang, Cheng-Yao and Chu, Wei-Chen and Chiu, Po-Tsung and Hsiu, Min-Chieh and Chiang, Yih-Harn and Chen, Mike Y.},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785886},
 isbn = {978-1-4503-3652-9},
 keyword = {Palm-based interaction, QWERTY keyboard, Smart glass, Text input, Wearable},
 link = {http://doi.acm.org/10.1145/2785830.2785886},
 location = {Copenhagen, Denmark},
 numpages = {8},
 pages = {153--160},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {PalmType: Using Palms As Keyboards for Smart Glasses},
 year = {2015}
}


@inproceedings{Kleinman:2015:EMD:2785830.2785833,
 abstract = {We present design research on personal public displays: mobile and wearable displays that direct user designated content towards other collocated individuals. We built display software that projects text and image on the outer facing side of a two-screen laptop and used this prototype as a design probe with three different groups: (1) attendees at a 300-person conference, (2) eight office workers, and (3)twenty design students. We analyze how users crafted content for the displays, identifying that in close-knit groups, the social pressure to appear witty with text postsled to a preference for using images. The mobility afforded by the display allowed users to explore new relationships between physical location and digital content, and we also discuss how by standers observed the displays and re-purposed the messages for use with other outsiders. We conclude with a discussion of potential applications for future design and research work.},
 acmid = {2785833},
 address = {New York, NY, USA},
 author = {Kleinman, Lisa and Hirsch, Tad and Yurdana, Matt},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785833},
 isbn = {978-1-4503-3652-9},
 keyword = {dual-screens, groupware, identity projection, personal public displays, semi-public displays, urban screens, wearable displays},
 link = {http://doi.acm.org/10.1145/2785830.2785833},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {233--243},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Exploring Mobile Devices As Personal Public Displays},
 year = {2015}
}


@inproceedings{McLachlan:2015:BIT:2785830.2785878,
 abstract = {In this paper we present the results of a study investigating the control of simultaneous non-dominant hand (NDH) pressure input and dominant hand (DH) pinch, swipe and rotate gesture input on a touchscreen tablet device. We investigate the effect of NDH pressure input on DH gesture accuracy, and vice versa, to support the design of bimanual interaction techniques for tablet devices. Our results suggest that pressure negatively affects DH touchscreen gesture performance; however, pressure targeting accuracy for each gesture was still high (86% overall). Our results show that participants were able to achieve high levels of accuracy using DH swipe gestures (the simplest gesture in the study) suggesting that the ability to perform a simultaneous combination of pressure and touchscreen gesture input depends on the complexity of the dominant hand action involved.},
 acmid = {2785878},
 address = {New York, NY, USA},
 author = {McLachlan, Ross and Brewster, Stephen},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785878},
 isbn = {978-1-4503-3652-9},
 keyword = {Non-Dominant Hand, Pressure input, Transience, bimanual interaction, touchscreen gestures},
 link = {http://doi.acm.org/10.1145/2785830.2785878},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {547--556},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Bimanual Input for Tablet Devices with Pressure and Multi-Touch Gestures},
 year = {2015}
}


@inproceedings{Cheng:2015:CRC:2785830.2785851,
 abstract = {With the use of several tablet devices and a shared large display, CozyMaps is a multi-display system that supports real-time collocated collaboration on a shared map. This paper builds on existing works and introduces rich user interactions by proposing awareness, notification, and view sharing techniques, to enable seamless information sharing and integration in map-based applications. Based on our exploratory study, we demonstrated that participants are satisfied with these new proposed interactions. We found that view sharing techniques should be location-focused rather than user-focused. Our results provide implications for the design of interactive techniques in collaborative multi-display map systems.},
 acmid = {2785851},
 address = {New York, NY, USA},
 author = {Cheng, Kelvin and He, Liang and Meng, Xiaojun and Shamma, David A. and Nguyen, Dung and Thangapalam, Anbarasan},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785851},
 isbn = {978-1-4503-3652-9},
 keyword = {Collaboration, Multi-touch tablets, Overview\&plus;Detail, Share large display, Viewport, Workspace awareness},
 link = {http://doi.acm.org/10.1145/2785830.2785851},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {46--51},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {CozyMaps: Real-time Collaboration on a Shared Map with Multiple Displays},
 year = {2015}
}


@inproceedings{Birnholtz:2015:FAI:2785830.2785857,
 abstract = {Providing the initiator of a conversation with awareness information about their target's availability can improve interruption timing. Providing this information, however, can be particularly challenging with mobile devices, which are carried by users in a range contexts and have limited audible and visual display possibilities due to possible background noise and small screen size. Haptic or tactile displays present a potentially useful alternative, as interaction with mobile devices is often by touch. This paper reports on a dual-task comparison of awareness information usage on a mobile variable-friction tactile display vs. a visual display under conditions that varied in task type and task workload. Participants using the tactile display performed marginally better on the primary task, but were less accurate and slower on the awareness task. However, there is evidence that some of the awareness task differences dissipated over time. Self-report data also suggests that people's experience with the tactile display was generally positive and improved over time.},
 acmid = {2785857},
 address = {New York, NY, USA},
 author = {Birnholtz, Jeremy and Gergle, Darren and Liebman, Noah and Sinclair, Sarah},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785857},
 isbn = {978-1-4503-3652-9},
 keyword = {Awareness displays, CSCW, availability, interruption, tactile, variable friction},
 link = {http://doi.acm.org/10.1145/2785830.2785857},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {16--25},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Feeling Aware: Investigating the Use of a Mobile Variable-Friction Tactile Display for Awareness Information},
 year = {2015}
}


@inproceedings{Wozniak:2015:RRS:2785830.2785893,
 abstract = {This paper explores remote cheering during amateur races through a formative design inquiry. Friends and family of advanced amateur runners are part of their running experience. Runners rely on support during the race day and it is usually provided in the form of co-located cheers. RUFUS -- a prototype remote ambient runner support system -- was developed. The system enables supporters to send three types of signals to runners during a race and runners can send signals back to supporters. Input from supporters is sent through a webpage and received by runners through a device designed to lower distraction. An in situ study was conducted to evaluate the prototype during an organized race. Results show that two-way communication between runners and supporters was achieved. We also found that our system reflected varying user needs correctly. Runners and supporters reported increased motivation and enhanced race experience through feeling connected.},
 acmid = {2785893},
 address = {New York, NY, USA},
 author = {Wo\'{z}niak, Pawe\l and Knaving, Kristina and Bj\"{o}rk, Staffan and Fjeld, Morten},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785893},
 isbn = {978-1-4503-3652-9},
 keyword = {HCI for sports, Running, engagement, events, support system},
 link = {http://doi.acm.org/10.1145/2785830.2785893},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {115--124},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {RUFUS: Remote Supporter Feedback for Long-Distance Runners},
 year = {2015}
}


@inproceedings{Paay:2015:QUS:2785830.2785877,
 abstract = {We present the design and evaluation of a smartphone app, QuittyLink, designed to help smokers reduce or stop smoking. Smoking cigarettes is a serious health risk and people who wish to quit often struggle to do so. It is well known that the most effective method of assisting smoking cessation is personal face-to-face counseling. However, this approach is only used by very few people wishing to quit for reasons such as inconvenience and personal shyness. In response to this we have created an app that provides personal counseling to users on their smartphone. The counseling content is authored by smoking cessation experts and is based on the user's personal data and recent actual smoking behaviors collected through the smartphone. We deployed the QuittyLink app with people in their everyday lives to study how personal counseling on mobile phones would influence their smoking behaviors. We found that both the personal counseling and the ability to visualize and reflect on their own self-tracked smoking behaviors helped them form strategies to improve their ability to quit.},
 acmid = {2785877},
 address = {New York, NY, USA},
 author = {Paay, Jeni and Kjeldskov, Jesper and Skov, Mikael B. and Srikandarajah, Nirojan and Brinthaparan, Umachanger},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785877},
 isbn = {978-1-4503-3652-9},
 keyword = {Smoking cessation, health behavior change, interaction design, mobile apps, personal counseling, self-tracking},
 link = {http://doi.acm.org/10.1145/2785830.2785877},
 location = {Copenhagen, Denmark},
 numpages = {7},
 pages = {98--104},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {QuittyLink: Using Smartphones for Personal Counseling to Help People Quit Smoking},
 year = {2015}
}


@inproceedings{Constantinides:2015:EMN:2785830.2785860,
 abstract = {As news is increasingly accessed on smartphones and tablets, the need for personalising news app interactions is apparent. We report a series of three studies addressing key issues in the development of adaptive news app interfaces. We first surveyed users' news reading preferences and behaviours; analysis revealed three primary types of reader. We then implemented and deployed an Android news app that logs users' interactions with the app. We used the logs to train a classifier and showed that it is able to reliably recognise a user according to their reader type. Finally we evaluated alternative, adaptive user interfaces for each reader type. The evaluation demonstrates the differential benefit of the adaptation for different users of the news app and the feasibility of adaptive interfaces for news apps.},
 acmid = {2785860},
 address = {New York, NY, USA},
 author = {Constantinides, Marios and Dowell, John and Johnson, David and Malacria, Sylvain},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785860},
 isbn = {978-1-4503-3652-9},
 keyword = {Adaptive mobile User Interfaces, Implicit sampling, Mobile news reading, Personalisation},
 link = {http://doi.acm.org/10.1145/2785830.2785860},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {457--462},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Exploring Mobile News Reading Interactions for News App Personalisation},
 year = {2015}
}


@inproceedings{Gugenheimer:2015:CUC:2785830.2785834,
 abstract = {In this paper we present ColorSnakes, a PIN-based authentication mechanism for smartphones which uses fake paths on a grid of numbers to disguise user input. In a lab study (n=24),we evaluated variations of ColorSnakes in terms of usability and security. In comparison to direct input, indirect input significantly reduced the risk of shoulder surfing (10.5%) without increasing the input time. In a follow up real-world study (n=12), we compared ColorSnakes with PIN entry and Android's Pattern Unlock over the course of three weeks. Although authentication time for ColorSnakes was higher than for the other two mechanisms, participants valued the security benefit over its slightly higher error rate and increased authentication time. We argue that ColorSnakes could be used as an additional authentication mechanism alongside current mechanisms, thus providing the user with the choice of changing to ColorSnakes for certain applications or when there is an observer.},
 acmid = {2785834},
 address = {New York, NY, USA},
 author = {Gugenheimer, Jan and De Luca, Alexander and Hess, Hayato and Karg, Stefan and Wolf, Dennis and Rukzio, Enrico},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785834},
 isbn = {978-1-4503-3652-9},
 keyword = {Authentication, security, shoulder surfing, smartphone},
 link = {http://doi.acm.org/10.1145/2785830.2785834},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {274--283},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {ColorSnakes: Using Colored Decoys to Secure Authentication in Sensitive Contexts},
 year = {2015}
}


@inproceedings{Klamka:2015:EEC:2785830.2785849,
 abstract = {We explore the high potential of elastic controllers for casual interaction in mobile and ubiquitous computing scenarios. While several remote interaction techniques with handheld or body-worn devices have been proposed, the usage of string-based, elastic interaction is still underexplored. Therefore, we first introduce a systematic design space along the axes reference system, interaction dimensions, sensing methods and haptic feedback. Our main contribution is Elasticcon, a versatile, wearable device with a retractable string and a set of exchangeable traction knobs. This elastic controller provides several degrees of freedom and allows rich interaction techniques. As a result of an iterative design process, we also contribute two working prototypes for belt-worn and handheld use. To demonstrate their versatility, we implemented several promising application scenarios. We tested Elasticcon in three smaller user studies investigating qualitative usability aspects and found initial evidence for elastic controllers as being comfortable, casual and yet accurate interaction devices.},
 acmid = {2785849},
 address = {New York, NY, USA},
 author = {Klamka, Konstantin and Dachselt, Raimund},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785849},
 isbn = {978-1-4503-3652-9},
 keyword = {casual interaction, elastic input, mobile input device, mobile interaction, multi-modal, string-based interaction, wearable},
 link = {http://doi.acm.org/10.1145/2785830.2785849},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {410--419},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Elasticcon: Elastic Controllers for Casual Interaction},
 year = {2015}
}


@inproceedings{Wang:2015:IEC:2785830.2785845,
 abstract = {Through a controlled online experiment with 447 Android phone users using their own devices, we investigated how empowering users with information-disclosure control and enhancing their ads awareness affect their installation behaviors, information disclosure, and privacy perceptions toward different mobile apps. In the 3 (control: no, low, high) x 2 (ads awareness: absent, present) x 3 (app context: Wallpaper, BusTracker, Flashlight) fractional factorial between-subjects experiment, we designed privacy notice dialogs that simulate real Android app pre-installation privacy-setting interfaces to implement and manipulate control and ads awareness. Our findings suggest that empowering users with control over information disclosure and enhancing their ads awareness before installation effectively help them make better privacy decisions, increase their likelihood of installing an app, and improve their perceptions of the app. Implications for designing mobile apps' privacy notice dialogs and potential separate-ads-control solutions are discussed.},
 acmid = {2785845},
 address = {New York, NY, USA},
 author = {Wang, Na and Zhang, Bo and Liu, Bin and Jin, Hongxia},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785845},
 isbn = {978-1-4503-3652-9},
 keyword = {Ads Awareness, Android, Control, Mobile, Notice and Consent, Privacy, Third-Party Applications (Apps)},
 link = {http://doi.acm.org/10.1145/2785830.2785845},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {373--382},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Investigating Effects of Control and Ads Awareness on Android Users' Privacy Behaviors and Perceptions},
 year = {2015}
}


@inproceedings{Dingler:2015:IYQ:2785830.2785840,
 abstract = {Social norm has it that people are expected to respond to mobile phone messages quickly. We investigate how attentive people really are and how timely they actually check and triage new messages throughout the day. By collecting more than 55,000 messages from 42 mobile phone users over the course of two weeks, we were able to predict people's attentiveness through their mobile phone usage with close to 80% accuracy. We found that people were attentive to messages 12.1 hours a day, i.e. 84.8 hours per week, and provide statistical evidence how very short people's inattentiveness lasts: in 75% of the cases mobile phone users return to their attentive state within 5 minutes. In this paper, we present a comprehensive analysis of attentiveness throughout each hour of the day and show that intelligent notification delivery services, such as bounded deferral, can assume that inattentiveness will be rare and subside quickly.},
 acmid = {2785840},
 address = {New York, NY, USA},
 author = {Dingler, Tilman and Pielot, Martin},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785840},
 isbn = {978-1-4503-3652-9},
 keyword = {Attentiveness, Availability, Bounded Deferral, Interruptibility, Mobile Devices, Responsiveness},
 link = {http://doi.acm.org/10.1145/2785830.2785840},
 location = {Copenhagen, Denmark},
 numpages = {5},
 pages = {1--5},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {I'Ll Be There for You: Quantifying Attentiveness Towards Mobile Messaging},
 year = {2015}
}


@inproceedings{Ho:2015:EEH:2785830.2785836,
 abstract = {With the advent of the technological era, Computer Vision Syndrome (CVS) has become a common problem. Due to the small hand-held form of smartphones, many users are not aware of the distance between eyes and the device. This habit may lead to negative impacts on ocular health. Always keeping a safe distance prevents the user from CVS. In this paper, we present a mobile application that utilizes the front camera to estimate the distance between the phone and the user. Once this distance is too short, the system alerts the user. We explore four different types of warnings: Blur, Flashing Border, Spot, and Push Notification. We conducted user studies to measure satisfaction, effectiveness, and distraction of these warning methods. Our results show that our system is effective in reminding users to keep a safe distance.},
 acmid = {2785836},
 address = {New York, NY, USA},
 author = {Ho, Jimmy and Pointner, Reinhard and Shih, Huai-Chun and Lin, Yu-Chih and Chen, Hsuan-Yu and Tseng, Wei-Luan and Chen, Mike Y.},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785836},
 isbn = {978-1-4503-3652-9},
 keyword = {CVS, Face detection, Harmon Distance, Warnings},
 link = {http://doi.acm.org/10.1145/2785830.2785836},
 location = {Copenhagen, Denmark},
 numpages = {9},
 pages = {77--85},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {EyeProtector: Encouraging a Healthy Viewing Distance when Using Smartphones},
 year = {2015}
}


@inproceedings{Buschek:2015:MTS:2785830.2785844,
 abstract = {Typing is a common task on mobile devices and has been widely addressed in HCI research, mostly regarding quantitative factors such as error rates and speed. Qualitative aspects, like personal expressiveness, have received less attention. This paper makes individual typing behaviour visible to the users to render mobile typing more personal and expressive in varying contexts: We introduce a dynamic font personalisation framework, TapScript, which adapts a finger-drawn font according to user behaviour and context, such as finger placement, device orientation and movements - resulting in a handwritten-looking font. We implemented TapScript for evaluation with an online survey (N=91) and a field study with a chat app (N=11). Looking at resulting fonts, survey participants distinguished pairs of typists with 84.5% accuracy and walking/sitting with 94.8%. Study participants perceived fonts as individual and the chat experience as personal. They also made creative explicit use of font adaptations.},
 acmid = {2785844},
 address = {New York, NY, USA},
 author = {Buschek, Daniel and De Luca, Alexander and Alt, Florian},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785844},
 isbn = {978-1-4503-3652-9},
 keyword = {Font Personalisation, Mobile, Touch Typing},
 link = {http://doi.acm.org/10.1145/2785830.2785844},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {125--130},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {There is More to Typing Than Speed: Expressive Mobile Touch Keyboards via Dynamic Font Personalisation},
 year = {2015}
}


@inproceedings{Matthews:2015:SDM:2785830.2785866,
 abstract = {In this paper, we argue that atypical cognitive, perceptual and behavioral characteristics associated with serious mental illnesses should be taken into consideration when designing health technologies. While applications have been developed to assist in the treatment of these illnesses, the specific psychological characteristics of these disorders have rarely been considered extensively in the design process. Here, we explore how an understanding of the low-level characteristics of bipolar disorder, combined with a clinically-validated treatment and patients' lived experience, can inform mHealth design. We present a novel method -- in situ design -- to support ecologically valid design, and demonstrate its use through the co-development with 9 individuals with bipolar disorder of MoodRhythm, a mobile application designed to track and stabilize daily routines. We provide evidence that mHealth design elements tailored to the characteristics and needs of individuals with bipolar disorder can result in engaging interactions.},
 acmid = {2785866},
 address = {New York, NY, USA},
 author = {Matthews, Mark and Voida, Stephen and Abdullah, Saeed and Doherty, Gavin and Choudhury, Tanzeem and Im, Sangha and Gay, Geri},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785866},
 isbn = {978-1-4503-3652-9},
 keyword = {Mental health technology, bipolar disorder, mHealth, mobile health, participatory design},
 link = {http://doi.acm.org/10.1145/2785830.2785866},
 location = {Copenhagen, Denmark},
 numpages = {12},
 pages = {86--97},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {In Situ Design for Mental Illness: Considering the Pathology of Bipolar Disorder in mHealth Design},
 year = {2015}
}


@proceedings{Paterno:2016:2957265,
 abstract = {MobileHCI brings together people from diverse backgrounds and areas of expertise to provide a truly multidisciplinary forum. Academics, hardware and software developers, designers and practitioners alike can discuss challenges encountered on different frontiers of mobility, as well as potential solutions that will advance the field. The conference covers both academic and industry research, ranging from fundamental interaction models and techniques to social and cultural aspects of everyday life with mobile technologies.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4413-5},
 location = {Florence, Italy},
 publisher = {ACM},
 title = {MobileHCI '16: Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 year = {2016}
}


@inproceedings{Burgbacher:2015:MHP:2785830.2785858,
 abstract = {Gesture typing is a popular stroke-based text input method for mobile devices. Instead of tapping, the user enters a word with a single continuous stroke by gesturing through all the letters. In this paper, we introduce a quantitative motor control model to predict the human performance of gesture typing in terms of production times. Based on a model of cursive handwriting, it can be applied to predict the influence of the keyboard layout on gesture typing performance. In contrast to previous approaches, the "chunking" of multiple movements into a single action, which is observed for expert users, is a natural characteristic of the proposed model that avoids over-estimation of the production times. Data collected from gesture keyboard users is evaluated to assess the performance of the model in comparison to previous models.},
 acmid = {2785858},
 address = {New York, NY, USA},
 author = {Burgbacher, Ulrich and Hinrichs, Klaus},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785858},
 isbn = {978-1-4503-3652-9},
 keyword = {Gesture keyboards, experimental study, movement time, shape writing, text input},
 link = {http://doi.acm.org/10.1145/2785830.2785858},
 location = {Copenhagen, Denmark},
 numpages = {7},
 pages = {137--143},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Modeling Human Performance of Stroke-Based Text Entry},
 year = {2015}
}


@inproceedings{Grossman:2015:TGA:2785830.2785867,
 abstract = {Text entry for smart eyewear is generally limited to speech-based input due to constraints of the input channels. However, many smart eyewear devices are now including a side touchpad making gesture-based text entry feasible. The Swipeboard technique, recently proposed for ultra-small touch screens such as smart watches, may be particularly suitable for smart eyewear: unlike other recent text-entry techniques for small devices, it supports eyes-free input. We investigate the limitations and feasibility of implementing Swipeboard on smart eyewear, using the side touch pad for input. Our first study reveals usability and recognition problems of using the side touch pad to perform the required gestures. To address these problems, we propose SwipeZone, which replaces diagonal gestures with zone-specific swipes. In a text entry study, we show that our redesign achieved a WPM rate of 8.73, 15.2% higher than Swipeboard, with a statistically significant improvement in the last half of the study blocks.},
 acmid = {2785867},
 address = {New York, NY, USA},
 author = {Grossman, Tovi and Chen, Xiang Anthony and Fitzmaurice, George},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785867},
 isbn = {978-1-4503-3652-9},
 link = {http://doi.acm.org/10.1145/2785830.2785867},
 location = {Copenhagen, Denmark},
 numpages = {9},
 pages = {144--152},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Typing on Glasses: Adapting Text Entry to Smart Eyewear},
 year = {2015}
}


@inproceedings{Jokela:2015:CMM:2785830.2785841,
 abstract = {As people increasingly own multiple mobile and portable devices (such as smartphones, tablets, and laptops), situations where several devices are used together have become more common. A frequent problem in such situations is how to move virtual visual objects (such as content items or application windows) between device displays. We present a comparative evaluation of three methods for moving objects between personal mobile devices: Tray, Transfer Mode, and Device Touch. The participants' preferences of the methods in different real-life scenarios were found to strongly depend on the task and the context of use, making the design of a single optimal cross-display object movement method a challenging task. We identify several clusters of contextual factors that influenced the users' preferences. We also report more detailed differences in efficiency, novelty, learnability, physical device handling, and task completion strategies between the three methods included in the evaluation.},
 acmid = {2785841},
 address = {New York, NY, USA},
 author = {Jokela, Tero and Ojala, Jarno and Grassel, Guido and Piippo, Petri and Olsson, Thomas},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785841},
 isbn = {978-1-4503-3652-9},
 keyword = {Multi-device interaction, cross-display object movement, laptops, mobile devices, smartphones, tablets},
 link = {http://doi.acm.org/10.1145/2785830.2785841},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {172--181},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {A Comparison of Methods to Move Visual Objects Between Personal Mobile Devices in Different Contexts of Use},
 year = {2015}
}


@inproceedings{Jarusriboonchai:2015:SDM:2785830.2785863,
 abstract = {Activities that have traditionally been performed with tangible artifacts, e.g. reading the newspaper and browsing printed photos, have increasingly moved to mobile devices. This has made it harder for the surrounding people to become aware of the activities a person is performing with the device. As a result, the possibilities for serendipitous social interactions between the user and the collocated people have diminished. We introduce social displays, additional displays on mobile devices providing social cues about the activities of device user's activities for surrounding people. We conducted five focus groups with in total 23 participants, each discussing four scenarios and co-designing the presentation of cues on the display. The results suggest that the display has potential to break the private bubble of mobile device activities, as well as to provide tickets-to-talk to enhance social interaction, especially between acquaintances. We discuss social opportunities and challenges as well as possible design directions for social displays.},
 acmid = {2785863},
 address = {New York, NY, USA},
 author = {Jarusriboonchai, Pradthana and Olsson, Thomas and V\"{a}\"{a}n\"{a}nen-Vainio-Mattila, Kaisa},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785863},
 isbn = {978-1-4503-3652-9},
 keyword = {Collocated interaction, activity awareness, backside display, mobile device, social display, social interaction},
 link = {http://doi.acm.org/10.1145/2785830.2785863},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {254--263},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Social Displays on Mobile Devices: Increasing Collocated People's Awareness of the User's Activities},
 year = {2015}
}


@inproceedings{McGookin:2015:ENR:2785830.2785879,
 abstract = {Navigation when running is exploratory, characterised by both starting and ending in the same location, and iteratively foraging the environment to find areas with the most suitable running conditions. Runners do not wish to be explicitly directed, or refer to navigation aids that cause them to stop running, such as maps. Such undirected navigation is also common in other 'on-foot' scenarios, but how to support it is under-investigated. We contribute a novel method that uses crowd-sourced venue databases to rate a geographical area on its suitability to run in using linear regression. Our regression model is able to accurately predict the suitability of an area to run in (Pearson r=0.74) with a low mean error (RMSE=1.0). We outline how our method can support runners, and can be applied to other undirected navigation scenarios.},
 acmid = {2785879},
 address = {New York, NY, USA},
 author = {McGookin, David and Gkatzia, Dimitra and Hastie, Helen},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785879},
 isbn = {978-1-4503-3652-9},
 keyword = {Exploratory Navigation, Foursquare, Machine Learning, OpenStreetMap, Pedestrian Navigation, Regression Analysis, Running},
 link = {http://doi.acm.org/10.1145/2785830.2785879},
 location = {Copenhagen, Denmark},
 numpages = {5},
 pages = {357--361},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Exploratory Navigation for Runners Through Geographic Area Classification with Crowd-Sourced Data},
 year = {2015}
}


@proceedings{Boring:2015:2785830,
 abstract = {
                  An abstract is not available.
              },
 address = {New York, NY, USA},
 isbn = {978-1-4503-3652-9},
 location = {Copenhagen, Denmark},
 publisher = {ACM},
 title = {MobileHCI '15: Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 year = {2015}
}


@inproceedings{Shimon:2015:EUB:2785830.2785890,
 abstract = {Many studies have highlighted the advantages of expanding the input space of mobile devices by utilizing the back of the device. We extend this work by performing an elicitation study to explore users' mapping of gestures to smartphone commands and identify their criteria for using back-of-device gestures. Using the data collected from our study, we present elicited gestures and highlight common user motivations, both of which inform the design of back-of-device gestures for mobile interaction.},
 acmid = {2785890},
 address = {New York, NY, USA},
 author = {Shimon, Shaikh Shawon Arefin and Morrison-Smith, Sarah and John, Noah and Fahimi, Ghazal and Ruiz, Jaime},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785890},
 isbn = {978-1-4503-3652-9},
 keyword = {Smartphones, back-of-device interaction, eyes-free interaction, gestures, hybrid input, mobile},
 link = {http://doi.acm.org/10.1145/2785830.2785890},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {227--232},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Exploring User-Defined Back-Of-Device Gestures for Mobile Devices},
 year = {2015}
}


@inproceedings{Wang:2015:PUP:2785830.2785885,
 abstract = {In this paper, we explored eyes-free gesture interactions on palms, which enables users to interact with devices by drawing stroke gestures on palms without looking at palms. We conducted a 24-person user study to understand how users draw gestures on the palm with varying characteristics including regions, orientation and starting points. Based on the findings, we proposed two new interaction techniques for palm-based gesture interface. To explore and demonstrate the feasibility of the interaction, we implemented EyeWrist, a wrist-mounted prototype which detects gestures on palms by using an IR camera and laser-line projector. The preliminary evaluation revealed that EyeWrist enabled users to draw graffiti letter and multi-stroke gestures with above 90% accuracy and that both the concept of using palms as gesture interfaces for eyes-free input and the proposed two interaction techniques were appealing to users.},
 acmid = {2785885},
 address = {New York, NY, USA},
 author = {Wang, Cheng-Yao and Hsiu, Min-Chieh and Chiu, Po-Tsung and Chang, Chiao-Hui and Chan, Liwei and Chen, Bing-Yu and Chen, Mike Y.},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785885},
 isbn = {978-1-4503-3652-9},
 keyword = {Eyes-free input, Gesture input, Palm-based interaction, Stroke gestures, Wearable},
 link = {http://doi.acm.org/10.1145/2785830.2785885},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {217--226},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {PalmGesture: Using Palms As Gesture Interfaces for Eyes-free Input},
 year = {2015}
}


@inproceedings{Wenig:2015:SIM:2785830.2785862,
 abstract = {Map applications for smartwatches present new challenges in cartography, a domain in which large display sizes have significant advantages. In this paper, we introduce StripeMaps, a system that adapts the mobile web design technique of linearization for displaying maps on the small screens of smartwatches. Just as web designers simplify multiple column desktop websites into a single column for easier navigation on mobile devices, StripeMaps transforms any two-dimensional route map into a one-dimensional "stripe". Through a user study, we show that this simplification allows StripeMaps to outperform both traditional mobile map interfaces and turn-by-turn directions for pedestrian navigation using smartwatches. In addition to introducing StripeMaps, this paper also has a secondary contribution. It contains the first empirical comparison of different approaches for pedestrian smartwatch navigation and illuminates their pros and cons.},
 acmid = {2785862},
 address = {New York, NY, USA},
 author = {Wenig, Dirk and Sch\"{o}ning, Johannes and Hecht, Brent and Malaka, Rainer},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785862},
 isbn = {978-1-4503-3652-9},
 keyword = {Cartography, Mobile Maps, Pedestrian Navigation, Smartwatches},
 link = {http://doi.acm.org/10.1145/2785830.2785862},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {52--62},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {StripeMaps: Improving Map-based Pedestrian Navigation for Smartwatches},
 year = {2015}
}


@inproceedings{Dancu:2015:MNU:2785830.2785876,
 abstract = {Advances in display technologies could soon make wearable mid-air displays---devices that present dynamic images floating in mid-air relative to a mobile user---available. Such devices may enable new input and output modalities compared to current mobile devices, and seamlessly offer information on the go. This paper presents a functional prototype for the purpose of understanding these modalities in more detail, including suitable applications and device placement. We first collected results from an online survey identified map navigation as one of the most desirable applications and suggested placement preferences. Based on these rankings, we built a wearable mid-air display mockup consisting of mobile phone, pico projector, and a holder frame, mountable in two alternative ways: wrist and chest. We then designed an experiment, asking participants to navigate different urban routes using map navigation displayed in mid-air. For map navigation, participants ranked wrist-mount safer than chest-mount. The experiment results validate the use of a wearable mid-air display for map navigation. Based on our online survey and experiment, we offer insights and recommendations for the design of wearable mid-air displays.},
 acmid = {2785876},
 address = {New York, NY, USA},
 author = {Dancu, Alexandru and Fourgeaud, Micka\"{e}l and Obaid, Mohammad and Fjeld, Morten and Elmqvist, Niklas},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785876},
 isbn = {978-1-4503-3652-9},
 keyword = {Mid-air displays, navigation, prototyping, wearable displays},
 link = {http://doi.acm.org/10.1145/2785830.2785876},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {71--76},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Map Navigation Using a Wearable Mid-air Display},
 year = {2015}
}


@inproceedings{Zuckerman:2015:LMT:2785830.2785870,
 abstract = {College students in the social sciences are required to learn quantitative research methods and statistics. Unfortunately, many fail to see the relevance of these courses, and are often anxious about them. In an effort to increase students' engagement in the research process, we developed Ruzo -- a mobile scientific inquiry platform. Ruzo enables instructors and students to create research projects as custom mobile apps, collect data on the go, and visualize the data using a web-based interactive tool. Ruzo was designed based on five guidelines, derived from interviews with domain experts: guide students through all stages of research; reduce anxiousness; encourage active learning; connect to students' everyday lives; and adapt the system to the needs of the instructor. A user study showed that Ruzo was easy to use, and students expressed interest in research, thereby demonstrating the potential of mobile technology to scaffold scientific inquiry.},
 acmid = {2785870},
 address = {New York, NY, USA},
 author = {Zuckerman, Oren and Gal-Oz, Ayelet and Peretz, Oran and Weisberg, Orad and Tarrasch, Ricardo},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785870},
 isbn = {978-1-4503-3652-9},
 keyword = {Higher Education, Mobile Learning, Research Methods, Scientific Inquiry},
 link = {http://doi.acm.org/10.1145/2785830.2785870},
 location = {Copenhagen, Denmark},
 numpages = {8},
 pages = {470--477},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Leveraging Mobile Technology to Engage College Students in Scientific Research},
 year = {2015}
}


@inproceedings{Alharbi:2015:CDE:2785830.2785892,
 abstract = {Mobile user interface design patterns have been widely used across different mobile platforms. UI design patterns have evolved and changed significantly as new trends emerge and fade at different times. This paper presents a data-mining approach to analyzing design pattern changes in Android apps. Over a period of 18 months, we tracked 24,436 apps and collected their versions. In total, our sample consists of 56,349 unique app versions, more than 5 million source files, and more than 25 million UI elements. We developed a dedicated infrastructure based on modern big data technologies to support our differential analyses regarding design pattern changes. Some highlights of our findings include a) some apps would switch to a design pattern even after it was deprecated, b) the adoption rate of newly introduced design patterns (e.g., Fragment) is relatively low, c) some apps would update their listing details to reflect changes in design patterns.},
 acmid = {2785892},
 address = {New York, NY, USA},
 author = {Alharbi, Khalid and Yeh, Tom},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785892},
 isbn = {978-1-4503-3652-9},
 keyword = {Android, UI, analysis, apps, design, pattern},
 link = {http://doi.acm.org/10.1145/2785830.2785892},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {515--524},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Collect, Decompile, Extract, Stats, and Diff: Mining Design Pattern Changes in Android Apps},
 year = {2015}
}


@inproceedings{Ng:2015:EEM:2785830.2785853,
 abstract = {In this paper, we investigate the effects of mobility and encumbrance (holding objects such as shopping bags) on standard gestures commonly performed on touchscreens: tapping, dragging, spreading & pinching and rotating clockwise & anticlockwise when completed using a two-handed input posture. These one- and two- finger on-screen gesture inputs have become common but previous research has only examined tapping performance in everyday walking and encumbered situations. Therefore, a series of Fitts' Law style targeting tasks was designed to measure the performance of each gesture with users walking only and walking while carrying bags. The results showed that encumbrance and walking had a negative impact on each gesture in terms of accuracy except for rotational actions, which were performed well. Tapping and dragging both performed poorly which shows the input difficulties of single finger interactions when encumbered and on the move. Our findings will help designers choose the appropriate input techniques for future mobile user interfaces and apps in physically demanding contexts.},
 acmid = {2785853},
 address = {New York, NY, USA},
 author = {Ng, Alexander and Williamson, John and Brewster, Stephen},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785853},
 isbn = {978-1-4503-3652-9},
 keyword = {Encumbrance, Fitts' Law, Mobile interactions, Touch-based gestures, Walking},
 link = {http://doi.acm.org/10.1145/2785830.2785853},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {536--546},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {The Effects of Encumbrance and Mobility on Touch-Based Gesture Interactions for Mobile Phones},
 year = {2015}
}


@inproceedings{Bae:2015:GVI:2785830.2785872,
 abstract = {Although mobile devices are generating a rapidly increasing proportion of search queries, search interfaces have not changed significantly to accommodate mobile constraints. In particular, imprecise search exists in the no-man's land between specific fact-finding and general browsing, and can be especially challenging on mobile devices, when user input is difficult and environmental distractions make remembering related information difficult. We examined the prevalence of these mobile search use cases in a two-week diary study, finding that imprecise and general search accounted for the large majority of difficulty with search. Hypothesizing that the ability to view a link neighborhood around the search result could be quite helpful in these cases, we designed GraphTiles, a visual interface for mobile search that exploits the structured entity relationships present in a significant portion of online datasets (e.g. IMDb [5] and LinkedIn [6]). In an experimental evaluation, users performed imprecise searches more quickly with GraphTiles than with a standard mobile site.},
 acmid = {2785872},
 address = {New York, NY, USA},
 author = {Bae, Juhee and Setlur, Vidya and Watson, Benjamin},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785872},
 isbn = {978-1-4503-3652-9},
 keyword = {Mobile search, browsing, entity-relationship, fact-finding, imprecise search},
 link = {http://doi.acm.org/10.1145/2785830.2785872},
 location = {Copenhagen, Denmark},
 numpages = {8},
 pages = {63--70},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {GraphTiles: A Visual Interface Supporting Browsing and Imprecise Mobile Search},
 year = {2015}
}


@inproceedings{Micallef:2015:WAU:2785830.2785835,
 abstract = {One of the main reasons why smartphone users do not adopt screen locking mechanisms is due to the inefficiency of entering a PIN/pattern each time they use their phone. To address this problem we designed a context-sensitive screen locking application which asked participants to enter a PIN/pattern only when necessary, and evaluated its impact on efficiency and satisfaction. Both groups of participants, who prior to the study either locked or did not lock their phone, adopted our application and felt that unlocking their phone only when necessary was more efficient, did not annoy them and offered a reasonable level of security. Participants responded positively to the option of choosing when a PIN/pattern is required in different contexts. Therefore, we recommend that designers of smartphone locking mechanisms should consider ceding a reasonable level of control over security settings to users to increase adoption and convenience, while keeping smartphones reasonably secure.},
 acmid = {2785835},
 address = {New York, NY, USA},
 author = {Micallef, Nicholas and Just, Mike and Baillie, Lynne and Halvey, Martin and Kayacik, Hilmi G\"{u}ne\c{s}},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785835},
 isbn = {978-1-4503-3652-9},
 keyword = {Adoption, Authentication, Mobile HCI, Usability, User Experience},
 link = {http://doi.acm.org/10.1145/2785830.2785835},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {284--294},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Why Aren'T Users Using Protection? Investigating the Usability of Smartphone Locking},
 year = {2015}
}


@inproceedings{Robinson:2015:QCE:2785830.2785855,
 abstract = {Digital markers such as barcodes and QR codes are ubiquitous. However, these codes are normally used only for retrieving a small amount of information, such as a product identifier or a web link. Much previous work has investigated the value of associating digital content with physical objects in everyday scenarios, but has so far relied primarily on adding new markers to existing items, or studied only short-term usage. In this paper, we explore the benefits of "commandeering" existing object labels to support this interaction. We add a social layer to existing digital codes, allowing users to "tag" any marker in their environment with their own messages, which can then be viewed by any other user. The core contribution of this work is the findings and insights that were collected in user studies. We explored the use of our design via two deployments that demonstrate the potential of such a system beyond its playful starting point. We conclude the work by drawing out a number of key design elements for future appropriation designs.},
 acmid = {2785855},
 address = {New York, NY, USA},
 author = {Robinson, Simon and Pearson, Jennifer and Jones, Matt},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785855},
 isbn = {978-1-4503-3652-9},
 keyword = {Appropriation, QR codes, barcodes, tagging},
 link = {http://doi.acm.org/10.1145/2785830.2785855},
 location = {Copenhagen, Denmark},
 numpages = {5},
 pages = {182--186},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Q-arrgh!: Commandeering Everyday Digital Codes},
 year = {2015}
}


@inproceedings{Chen:2015:SMC:2785830.2785868,
 abstract = {Today's smartphones enable rich, media-enhanced conversations. Millions of photos and billions of messages are shared each day on smartphones. But how, exactly, are images and web links being used in mobile conversations? And what does this mean for the design of new mobile communications applications? We set out to learn how people currently share and discuss mobile media by performing a detailed content analysis of 109 photos and links that were shared in 2,779 messages using a mobile messaging application deployed in the United State and Taiwan. Through our analysis of these conversations, we show how mobile media is used to experience the moment together, to fill in the visual details, to provide background context, and to exchange information. We then discuss our results and provide two designs inspired by our findings.},
 acmid = {2785868},
 address = {New York, NY, USA},
 author = {Chen, Ying-Yu and Bentley, Frank and Holz, Christian and Xu, Cheng},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785868},
 isbn = {978-1-4503-3652-9},
 keyword = {Messaging, communication, mobile, photo sharing},
 link = {http://doi.acm.org/10.1145/2785830.2785868},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {264--273},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Sharing (and Discussing) the Moment: The Conversations That Occur Around Shared Mobile Media},
 year = {2015}
}


@inproceedings{Hohlfeld:2015:ACV:2785830.2785869,
 abstract = {Gaze tracking is a common technique to study user interaction but is also increasingly used as input modality. In this regard, computer vision based systems provide a promising low-cost realization of gaze tracking on mobile devices. This paper complements related work focusing on algorithmic designs by conducting two users studies aiming to i) independently evaluate EyeTab as promising gaze tracking approach and ii) by providing the first independent use case driven evaluation of its applicability in mobile scenarios. Our evaluation elucidates the current state of mobile computer vision based gaze tracking and aims to pave the way for improved algorithms. In this regard, we aim to further foster the development by releasing our source data as reference database open to the public.},
 acmid = {2785869},
 address = {New York, NY, USA},
 author = {Hohlfeld, Oliver and Pomp, Andr{\'e} and Link, J\'{o} \'{A}gila Bitsch and Guse, Dennis},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785869},
 isbn = {978-1-4503-3652-9},
 keyword = {Gaze tracking, Quality of Experience, user study},
 link = {http://doi.acm.org/10.1145/2785830.2785869},
 location = {Copenhagen, Denmark},
 numpages = {8},
 pages = {427--434},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {On the Applicability of Computer Vision Based Gaze Tracking in Mobile Scenarios},
 year = {2015}
}


@inproceedings{Gomes:2015:DTK:2785830.2785843,
 abstract = {Tablet computers aim to bridge the gap between portability and productivity, reducing the need for users to carry multiple devices. However, despite increases in resolution, their displays are limited in size. This commonly results in sequential rather than parallel options for screen navigation, a significant drawback when multitasking. In this paper, we present DisplayCover, a tablet cover that integrates a physical keyboard as well as a touch and stylus sensitive thin-film e-ink display. We developed example applications to demonstrate the ability to dynamically alter the cover display content based on usage context, as well as concurrent access to multiple applications, stylus annotation, gestures and trackpad interactions.},
 acmid = {2785843},
 address = {New York, NY, USA},
 author = {Gomes, Antonio and Trutna, Tristan and Vertegaal, Roel},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785843},
 isbn = {978-1-4503-3652-9},
 keyword = {Context-Aware, Input Devices, Keyboard, Peripheral Hardware, Secondary Display, Stylus Annotation, Tablet},
 link = {http://doi.acm.org/10.1145/2785830.2785843},
 location = {Copenhagen, Denmark},
 numpages = {5},
 pages = {531--535},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {DisplayCover: A Tablet Keyboard with an Embedded Thin-Film Touchscreen Display},
 year = {2015}
}


@inproceedings{Serrano:2015:GDH:2785830.2785838,
 abstract = {Distributed display environments (DDEs) allow use of various specialized devices but challenge designers to provide a clean flow of data across multiple displays. Upcoming consumer-ready head-worn displays (HWDs) can play a central role in unifying the interaction experience in such ecosystems. In this paper, we report on the design and development of Gluey, a user interface that acts as a 'glue' to facilitate seamless input transitions and data movement across displays. Based on requirements we refine for such an interface, Gluey leverages inherent headworn display attributes such as field-of-view tracking and an always-available canvas to redirect input and migrate content across multiple displays, while minimizing device switching costs. We implemented a functional prototype integrating Gluey's numerous interaction possibilities. From our experience in this integration and from user evaluation results, we identify the open challenges in using HWDs to unify the interaction experience in DDEs.},
 acmid = {2785838},
 address = {New York, NY, USA},
 author = {Serrano, Marcos and Ens, Barrett and Yang, Xing-Dong and Irani, Pourang},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785838},
 isbn = {978-1-4503-3652-9},
 keyword = {Content migration, Distributed displays, Head-Worn Display, Input redirection, Multi-display environments},
 link = {http://doi.acm.org/10.1145/2785830.2785838},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {161--171},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Gluey: Developing a Head-Worn Display Interface to Unify the Interaction Experience in Distributed Display Environments},
 year = {2015}
}


@inproceedings{Owen:2015:CDE:2785830.2785881,
 abstract = {The world is faced with a growing number of people who live with chronic medical conditions. There have been numerous digital interventions into personal management of these diseases in recent years, yet gaps remain in the HCI literature. In particular, we lack a systematic understanding of user requirements in tools that support independent management while away from external influences. This paper presents a first investigation into low-intervention support for self-management. A mobile application enabled individuals to capture contextual information related to their health in the form of photographs. Through a month-long user study, we identify four management trends amongst our participants and describe their influence on mobile application adoption.},
 acmid = {2785881},
 address = {New York, NY, USA},
 author = {Owen, Tom and Pearson, Jennifer and Thimbleby, Harold and Buchanan, George},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785881},
 isbn = {978-1-4503-3652-9},
 keyword = {Health care, chronic disease management, deployment studies, diabetes, ubiquitous computing},
 link = {http://doi.acm.org/10.1145/2785830.2785881},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {105--114},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {ConCap: Designing to Empower Individual Reflection on Chronic Conditions Using Mobile Apps},
 year = {2015}
}


@inproceedings{Sun:2015:PMA:2785830.2785880,
 abstract = {Existing graphical passwords require users to proactively memorize their secrets and meanwhile these schemes are vulnerable to shoulder surfing attacks. We propose a novel graphical password scheme, PassApp, which utilizes users' everyday memory about installed apps on mobile devices as shared secrets. As the registration stage is no longer needed, PassApp exempts users from additional memory burden and greatly enhances user experience. Additionally, PassApp owns a large password set and only a small part of passwords may be exposed during a login. Therefore, PassApp has a natural advance on effectively resisting guessing attacks and shoulder surfing attacks. Our user studies demonstrate that PassApp performs well with a reasonable login time (7.27s) and a high success rate (95.48%). Our security analysis shows PassApp can effectively withstand one-time shoulder surfing attacks and on average 30 times of shoulder surfing are necessary to expose all passwords.},
 acmid = {2785880},
 address = {New York, NY, USA},
 author = {Sun, Huiping and Wang, Ke and Li, Xu and Qin, Nan and Chen, Zhong},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785880},
 isbn = {978-1-4503-3652-9},
 keyword = {PassApp, graphic password, installed app, shoulder surfing},
 link = {http://doi.acm.org/10.1145/2785830.2785880},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {306--315},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {PassApp: My App is My Password!},
 year = {2015}
}


@inproceedings{Zeng:2015:PSC:2785830.2785875,
 abstract = {Due to inaccurate GPS data and complex environment close to buildings, for blind people it is often hard to find entrances in unknown areas. In this paper, we propose an enhance method that combines crowd-sourcing technology and location-based services, in order to help blind pedestrians find entrances independently in unknown regions. Besides collecting environmental accessibility information collaboratively, within this method a reference point has to be created for each entrance. Users are guided to a reference point by current GPS-based navigation systems, and rely on the environmental accessibility information walking from the reference point to the target entrance finally. A pilot study with 10 subjects (5 blind and 5 blindfolded) indicated that, the proposed method would help blind people find entrances in unfamiliar areas, and we found the blind and blindfolded individuals performed differently due to their different levels of orientation and mobility skills. Overall, it is promising to integrate the proposed approach into existing navigation systems for blind and visually impaired people.},
 acmid = {2785875},
 address = {New York, NY, USA},
 author = {Zeng, Limin and Weber, Gerhard},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785875},
 isbn = {978-1-4503-3652-9},
 keyword = {Blind user, collaborative approach, entrance, environmental accessibility, mobility skill, navigation},
 link = {http://doi.acm.org/10.1145/2785830.2785875},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {347--356},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {A Pilot Study of Collaborative Accessibility: How Blind People Find an Entrance},
 year = {2015}
}


@inproceedings{Takashima:2015:EBS:2785830.2785884,
 abstract = {This paper explores the Boundless Scroll interface that extends the motor space for finger drag motions into the off-screen space using a tracking system around the screen. Seamlessly extended motor spaces enable continuous scroll actions across the on- and off-screens, reducing the chance of clutching and preserving content visibility during long-distance and smooth scrolling actions. We empirically evaluate our new technique, the Boundless Scroll and compare it to ordinary scroll interfaces (Drag and Flick) in two dominant screen devices. The first screen condition uses a large flat touch screen where users manipulate a non-full-screen window while using the surrounding space as an extended motor space. The second condition is a mobile device to examine mid-air finger scroll motions in the off-screen space using a 3D motion sensor. An empirically controlled study demonstrates our Boundless Scroll's many benefits, such as fewer clutching actions, occlusion-less content observations, and efficient and effortless off-screen acquisitions and also provided further design factors, implementations of the Boundless Scroll, and around-device interfaces.},
 acmid = {2785884},
 address = {New York, NY, USA},
 author = {Takashima, Kazuki and Shinshi, Nana and Kitamura, Yoshifumi},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785884},
 isbn = {978-1-4503-3652-9},
 keyword = {Around-device interaction, Interaction technique, Touch device},
 link = {http://doi.acm.org/10.1145/2785830.2785884},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {557--566},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Exploring Boundless Scroll by Extending Motor Space},
 year = {2015}
}


@inproceedings{Boland:2015:EMM:2785830.2785846,
 abstract = {This paper contributes novel measures of user engagement in mobile music retrieval, linking these to work in music psychology, and illustrating resulting design guidelines in a demonstrator system. The large music collections available to users today can be overwhelming in mobile settings, they offer 'too-much-choice' to users, who often resort to shuffle-based playback. Work in music psychology has introduced the concept of music engagement -- listeners vary in their desired control over their music listening, and engagement varies with listening context. We develop a series of metrics to capture music listening behaviour from users' interaction logs. In a survey of 94 music listeners, we show significant correlations between music engagement from questionnaires and the presented quantitative metrics. We show how music retrieval can adapt to this engagement, developing a tablet-based demonstrator system, with an exploratory evaluation.},
 acmid = {2785846},
 address = {New York, NY, USA},
 author = {Boland, Daniel and McLachlan, Ross and Murray-Smith, Roderick},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785846},
 isbn = {978-1-4503-3652-9},
 keyword = {Adaptation, Engagement, Music, Retrieval},
 link = {http://doi.acm.org/10.1145/2785830.2785846},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {484--493},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Engaging with Mobile Music Retrieval},
 year = {2015}
}


@inproceedings{Odell:2015:OKP:2785830.2785848,
 abstract = {Physical keyboards provide feedback and tactile landmarks that are not present on on-screen keyboards (OSKs). Similarly, physical keyboards provide faster typing speed than OSKs. The present study was designed to address the lack of research into the direct application of different types of feedback and tactile landmarks to on-screen typing with the intent of improving tablet OSK performance. Fourteen participants performed typing tasks using 6 tablet OSK variants: no feedback (the benchmark), audio feedback, visual feedback, haptic feedback, key-shaped tactile landmarks, and inverse tactile landmarks with ridges over the key gaps. Typing performance was not statistically different across the conditions, except for the key-shaped landmarks, which performed worse. This was largely due to the overlay affecting the sensitivity of the keys. The conclusion is that, without additional changes, feedback and tactile landmarks alone do not offer the opportunity to improve the performance of OSKs.},
 acmid = {2785848},
 address = {New York, NY, USA},
 author = {Odell, Dan},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785848},
 isbn = {978-1-4503-3652-9},
 keyword = {Typing, tablet computers, tablets, text input, touchscreens},
 link = {http://doi.acm.org/10.1145/2785830.2785848},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {131--136},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {On-screen Keyboards: Does the Presence of Feedback or Tactile Landmarks Improve Typing Performance?},
 year = {2015}
}


@inproceedings{Schirmer:2015:SMW:2785830.2785832,
 abstract = {We present Shoe me the Way, a novel tactile interface for eyes-free pedestrian navigation in urban environments. Our prototypical implementation can be fully integrated into users' own, regular shoes without permanent modifications. Interface use does not distract users from their surroundings. It thereby adds to users' safety and enables them to explore their environments more freely than is possible with prevailing mobile map-based pedestrian navigation systems. We evaluated our prototype using two different navigation modes in a study with 21 participants and report on significant differences in user performance and preferences between the modes. Study results also show that even our prototypical implementation is already stable, functional and has high usability.},
 acmid = {2785832},
 address = {New York, NY, USA},
 author = {Schirmer, Maximilian and Hartmann, Johannes and Bertel, Sven and Echtler, Florian},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785832},
 isbn = {978-1-4503-3652-9},
 keyword = {eyes-free interface, mobile device, navigation, tactile interface, wearable},
 link = {http://doi.acm.org/10.1145/2785830.2785832},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {327--336},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Shoe Me the Way: A Shoe-Based Tactile Interface for Eyes-Free Urban Navigation},
 year = {2015}
}


@inproceedings{Alcaidinho:2015:LMT:2785830.2785861,
 abstract = {We present the results of an 8-week pilot study with 55 dogs investigating whether using quantimetric monitors and a companion smartphone application can reduce returns and increase the perceived strength of bonds between newly adopted dogs from the Humane Society of Silicon Valley and their adopters. Through this pilot study, we developed guidelines for future research and discovered promising results indicating that providing dog quantimetric data to adopters through the use of a smartphone application could yield reduced rates of re-relinquishment. Additionally, respondents indicated that they felt using the smartphone application helped them to better meet the activity needs of their dog and increased the bond between themselves and their newly adopted dog.},
 acmid = {2785861},
 address = {New York, NY, USA},
 author = {Alcaidinho, Joelle and Valentin, Giancarlo and Tai, Stephanie and Nguyen, Brian and Sanders, Krista and Jackson, Melody and Gilbert, Eric and Starner, Thad},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785861},
 isbn = {978-1-4503-3652-9},
 keyword = {adoption, animal-computer interaction, quantimetrics},
 link = {http://doi.acm.org/10.1145/2785830.2785861},
 location = {Copenhagen, Denmark},
 numpages = {7},
 pages = {463--469},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Leveraging Mobile Technology to Increase the Permanent Adoption of Shelter Dogs},
 year = {2015}
}


@inproceedings{Chang:2015:IMU:2785830.2785852,
 abstract = {Smartphones are considered to be "always on, always connected" but mobile users are not always attentive and responsive to incoming communication. We present a mixed methods study investigating how mobile users use ringer modes for managing interruption by and awareness of incoming communication, and how these practices and locales affect their attentiveness and responsiveness. We show that mobile users have diverse ringer mode usage, but they switch ringer modes mainly for three purposes: avoiding interruption, preventing the phone from disrupting the environment, and noticing important notifications. In addition, without signals of notifications, users are less likely to immediately attend to notifications, but they are not less responsive to those they have attended. Finally, ringer mode switches, attentiveness, and responsiveness are all correlated with certain locales. We discuss implications from these findings, and suggest how future CMC tools and notification services take different purposes for using ringer modes and locales into consideration.},
 acmid = {2785852},
 address = {New York, NY, USA},
 author = {Chang, Yung-Ju and Tang, John C.},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785852},
 isbn = {978-1-4503-3652-9},
 keyword = {Mobile, SMS, availability, awareness, computer-mediated communication, notification, responsiveness, ringer mode},
 link = {http://doi.acm.org/10.1145/2785830.2785852},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {6--15},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Investigating Mobile Users' Ringer Mode Usage and Attentiveness and Responsiveness to Communication},
 year = {2015}
}


@inproceedings{Ferreira:2015:CBM:2785830.2785864,
 abstract = {This paper advances the study of batteries in everyday life. We provide a situated understanding of smartphone battery care based on a qualitative user study involving device logging and behavioral tracking to support our inquiry. Our findings depict how caring for batteries fits into everyday routines, the work that is done to prepare and maintain an infrastructure that supports mobile energy needs, and the ways in which batteries are monitored and preserved. Moreover, they illustrate what happens when everyday routines are disrupted and when planning or infrastructure fails, causing flat batteries and the need to apply mechanisms for coping. We build on these insights to propose shifting the research focus from user and device centric approaches towards more contextualized understandings of situated practices. We conclude by discussing the implications of our findings for two increasingly important topics within HCI, personal informatics and the Internet of Things (IoT).},
 acmid = {2785864},
 address = {New York, NY, USA},
 author = {Ferreira, Pedro and McGregor, Moira and Lampinen, Airi},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785864},
 isbn = {978-1-4503-3652-9},
 keyword = {Battery care, Ethno-mining, HBI, Infrastructure},
 link = {http://doi.acm.org/10.1145/2785830.2785864},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {383--392},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Caring for Batteries: Maintaining Infrastructures and Mobile Social Contexts},
 year = {2015}
}


@inproceedings{Alt:2015:GPW:2785830.2785882,
 abstract = {Common user authentication methods on smartphones, such as lock patterns, PINs, or passwords, impose a trade-off between security and password memorability. Image-based passwords were proposed as a secure and usable alternative. As of today, however, it remains unclear how such schemes are used in the wild. We present the first study to investigate how image-based passwords are used over long periods of time in the real world. Our analyses are based on data from 2318 unique devices collected over more than one year using a custom application released in the Android Play store. We present an in-depth analysis of what kind of images users select, how they define their passwords, and how secure these passwords are. Our findings provide valuable insights into real-world use of image-based passwords and inform the design of future graphical authentication schemes.},
 acmid = {2785882},
 address = {New York, NY, USA},
 author = {Alt, Florian and Schneegass, Stefan and Shirazi, Alireza Sahami and Hassib, Mariam and Bulling, Andreas},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785882},
 isbn = {978-1-4503-3652-9},
 keyword = {Graphical passwords, images, security},
 link = {http://doi.acm.org/10.1145/2785830.2785882},
 location = {Copenhagen, Denmark},
 numpages = {7},
 pages = {316--322},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Graphical Passwords in the Wild: Understanding How Users Choose Pictures and Passwords in Image-based Authentication Schemes},
 year = {2015}
}


@inproceedings{Santani:2015:CCR:2785830.2785837,
 abstract = {Nairobi is one of the fastest growing metropolitan cities and a major business and technology powerhouse in Africa. However, Nairobi currently lacks monitoring technologies to obtain reliable data on traffic and road infrastructure conditions. In this paper, we investigate the use of mobile crowdsourcing as means to gather and document Nairobi's road quality information. We first present the key findings of a city-wide road quality survey about the perception of existing road quality conditions in Nairobi. Based on the survey's findings, we then developed a mobile crowdsourcing application, called CommuniSense, to collect road quality data. The application serves as a tool for users to locate, describe, and photograph road hazards. We tested our application through a two-week field study amongst 30 participants to document various forms of road hazards from different areas in Nairobi. To verify the authenticity of user-contributed reports from our field study, we proposed to use online crowdsourcing using Amazon's Mechanical Turk (MTurk) to verify whether submitted reports indeed depict road hazards. We found 92% of user-submitted reports to match the MTurkers judgements. While our prototype was designed and tested on a specific city, our methodology is applicable to other developing cities},
 acmid = {2785837},
 address = {New York, NY, USA},
 author = {Santani, Darshan and Njuguna, Jidraph and Bills, Tierra and Bryant, Aisha W. and Bryant, Reginald and Ledgard, Jonathan and Gatica-Perez, Daniel},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785837},
 isbn = {978-1-4503-3652-9},
 keyword = {ICTD, Kenya, Mobile Crowdsourcing, Road Hazards, Urban Computing},
 link = {http://doi.acm.org/10.1145/2785830.2785837},
 location = {Copenhagen, Denmark},
 numpages = {12},
 pages = {445--456},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {CommuniSense: Crowdsourcing Road Hazards in Nairobi},
 year = {2015}
}


@inproceedings{Venolia:2015:SIS:2785830.2785847,
 abstract = {We developed a prototype called SeeSaw that explored using reaction video and auto reply to create an engaging video messaging experience. When viewing a video message, reaction video captures a video of the viewer's reaction to share back with the message sender. After finishing viewing the video message, auto reply immediately begins recording the viewer's response. A pilot study found that SeeSaw evoked conversational and authentic interactions, even though the messages were captured remotely and asynchronously. A follow-up comparative lab study found that reaction video encouraged a more conversational exchange, while both features together enhanced the authenticity of the experience. Although participants preferred the reaction video only condition, they perceived that the reaction video plus auto reply condition combined the conversationality of a video call with the flexibility of asynchronous messaging.},
 acmid = {2785847},
 address = {New York, NY, USA},
 author = {Venolia, Gina and Tang, John C. and Inkpen, Kori},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785847},
 isbn = {978-1-4503-3652-9},
 keyword = {Mobile messaging, asynchronous communication, video messaging},
 link = {http://doi.acm.org/10.1145/2785830.2785847},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {244--253},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {SeeSaw: I See You Saw My Video Message},
 year = {2015}
}


@proceedings{Boring:2015:2786567,
 abstract = {
                  An abstract is not available.
              },
 address = {New York, NY, USA},
 isbn = {978-1-4503-3653-6},
 location = {Copenhagen, Denmark},
 publisher = {ACM},
 title = {MobileHCI '15: Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 year = {2015}
}


@inproceedings{Mujibiya:2015:CIB:2785830.2785888,
 abstract = {We present Corona, a wearable device that allows constant high-voltage electrostatic charge to be continuously accumulated in the human body. We propose the usages of Corona for three basic functions; generating haptic sensations, generating electric power from body static charge and near-body electric field, and inducing physical force near the body. We describe detailed principle of operation, analysis of produced energy and force, discussion on safety issues, as well as demonstration of proof-of-concept applications for aforementioned basic functions. We conclude with discussion of our experiments using the prototype and applications, which also involves a study to gather user feedbacks. To the best of our knowledge, Corona is the first work to exploit continuous high-voltage static charge on the human body for Human-Computer Interaction purposes.},
 acmid = {2785888},
 address = {New York, NY, USA},
 author = {Mujibiya, Adiyan},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785888},
 isbn = {978-1-4503-3652-9},
 keyword = {Body electrostatics, energy harvesting, haptic, highvoltage generator, power distribution, static charge and discharge, touch-less object manipulation, wearable device},
 link = {http://doi.acm.org/10.1145/2785830.2785888},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {435--444},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Corona: Interactivity of Body Electrostatics in Mobile Scenarios Using Wearable High-Voltage Static Charger},
 year = {2015}
}


@inproceedings{Koelle:2015:DLM:2785830.2785842,
 abstract = {Data glasses do carry promising potential for hands-free interaction, but also raise various concerns amongst their potential users. In order to gain insights into the nature of those concerns, we investigate how potential usage scenarios are perceived by device users and their peers. We present results of a two-step approach: a focus group discussion with 7 participants, and a user study with 38 participants. In particular, we look into differences between the usage of data glasses and more established devices such as smart phones. We provide quantitative measures for scenario-related social acceptability and point out factors that can influence user attitudes. Based on our quantitative and qualitative results, we derive design implications that might support the development of head-worn devices and applications with an improved social acceptability.},
 acmid = {2785842},
 address = {New York, NY, USA},
 author = {Koelle, Marion and Kranz, Matthias and M\"{o}ller, Andreas},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785842},
 isbn = {978-1-4503-3652-9},
 keyword = {Data glasses, privacy, social acceptability, user attitudes},
 link = {http://doi.acm.org/10.1145/2785830.2785842},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {362--372},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Don'T Look at Me That Way!: Understanding User Attitudes Towards Data Glasses Usage},
 year = {2015}
}


@inproceedings{Huang:2015:MSD:2785830.2785889,
 abstract = {Current campus communication regarding safety-related issues can be improved for both efficiency and accessibility. We observed a unique opportunity to develop a mobile crowdsourcing system, which allows university community members to report safety related incidents to the campus police department and to share their reports with other users of the system. To better inform the design of such a system, we applied drift-diffusion models in cognitive psychology to model the effect of various factors on users' sharing tendency. We conducted a laboratory experiment with 30 participants. We also ran an MTurk study with 230 participants to explore the feature of anonymous sharing in the application design. In this paper we report various results, including the findings that the time of day, location, and type of crime each affects the likelihood and timeliness of sharing safety reports in several different ways. We also discuss the implications for design of mobile crowdsourcing systems for public safety in general.},
 acmid = {2785889},
 address = {New York, NY, USA},
 author = {Huang, Yun and White, Corey and Xia, Huichuan and Wang, Yang},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785889},
 isbn = {978-1-4503-3652-9},
 keyword = {Decision Model, Mobile Crowdsourcing, Public Safety},
 link = {http://doi.acm.org/10.1145/2785830.2785889},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {400--409},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Modeling Sharing Decision of Campus Safety Reports and Its Design Implications to Mobile Crowdsourcing for Safety},
 year = {2015}
}


@inproceedings{Hasan:2015:SSM:2785830.2785850,
 abstract = {Motivated by a rise in the variety and number of mobile devices that users carry, we investigate scenarios when operating these devices in a spatially interlinked manner can lead to interfaces that generate new advantages. Our exploration is focused on the design of SAMMI, a spatially-aware multi-device interface to assist with analytic map navigation tasks, where, in addition to browsing the workspace, the user has to make a decision based on the content embedded in the map. We focus primarily on the design space for spatially interlinking a smartphone with a smartwatch. As both smart devices are spatially tracked, the user can browse information by moving either device in the workspace. We identify several design factors for SAMMI and through a first study we explore how best to combine these for efficient map navigation. In a second study we compare SAMMI to the common Flick-&-Pinch gestures for an analytic map navigation task. Our results reveal that SAMMI is an efficient spatial navigation interface, and by means of an additional spatially tracked display, can facilitate quick information retrieval and comparisons. We finally demonstrate other potential use cases for SAMMI that extend beyond map navigation to facilitate interaction with spatial workspaces.},
 acmid = {2785850},
 address = {New York, NY, USA},
 author = {Hasan, Khalad and Ahlstr\"{o}m, David and Irani, Pourang},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785850},
 isbn = {978-1-4503-3652-9},
 keyword = {Around-Device Interaction, Peephole Interaction, Spatial interaction, Ubiquitous Analytic Interfaces},
 link = {http://doi.acm.org/10.1145/2785830.2785850},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {36--45},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {SAMMI: A Spatially-Aware Multi-Mobile Interface for Analytic Map Navigation Tasks},
 year = {2015}
}


@inproceedings{Hang:2015:LYP:2785830.2785839,
 abstract = {We describe three scenarios in which fallback authentication on smartphones can occur and evaluate their real-life occurrences in an online survey (n=244) and complementing interviews (n=12). The results provide first insights into frequencies, reasons, countermeasures taken and problems of lockout experiences. Overall, study participants were satisfied with current fallback schemes, but at the same time, fallback authentication was aggravated when special circumstances applied and thus, leave room for improvements. Based on this, we propose an alternative concept for fallback authentication that quizzes users about installed and not installed apps on their device. Authentication succeeds, when users identify a certain number of apps correctly. Our evaluation showed that the concept yields an overall accuracy of 95%.},
 acmid = {2785839},
 address = {New York, NY, USA},
 author = {Hang, Alina and De Luca, Alexander and von Zezschwitz, Emanuel and Demmler, Manuel and Hussmann, Heinrich},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785839},
 isbn = {978-1-4503-3652-9},
 keyword = {Apps, Fallback Authentication, Smartphones, Survey},
 link = {http://doi.acm.org/10.1145/2785830.2785839},
 location = {Copenhagen, Denmark},
 numpages = {11},
 pages = {295--305},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Locked Your Phone? Buy a New One? From Tales of Fallback Authentication on Smartphones to Actual Concepts},
 year = {2015}
}


@inproceedings{Kim:2015:CCC:2785830.2785887,
 abstract = {Providing accurate color information to online shopping customers is important for their purchase decisions. However, due to the multiple imaging processes that product photos undergo, end-users often experience a color mismatch between the color of the photo online and the product received. Therefore, we use a crowdsourcing approach to generate what we term CrowdColor, which is the collective color reported by individuals using a mobile color picker. CrowdColor serves as a color review application from the customers' perspectives in the form of a color palette that represents the product color. We perform controlled experiments to evaluate the accuracy of CrowdColor and to understand how the effects of the device and lighting conditions may influence the crowd's color perception and input tasks. The quantitative results reveal that CrowdColor achieves high accuracy and is positively rated overall. Based on experimental analyses, we present design guidelines for crowdsourcing color perception tasks.},
 acmid = {2785887},
 address = {New York, NY, USA},
 author = {Kim, Jaejeung and Leksikov, Sergey and Thamjamrassri, Punyotai and Lee, Uichin and Suk, Hyeon-Jeong},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785887},
 isbn = {978-1-4503-3652-9},
 keyword = {Crowdsourcing, color perception, graphical perception, mobile shopping},
 link = {http://doi.acm.org/10.1145/2785830.2785887},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {478--483},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {CrowdColor: Crowdsourcing Color Perceptions Using Mobile Devices},
 year = {2015}
}


@inproceedings{Tollmar:2015:BME:2785830.2785894,
 abstract = {This paper describes a study of how social media could be integrated and used in Mobile Experience Sampling. As addressed in previous studies, Experience Sampling Method relies on high response frequency. However participants may experience it as a burden which may cause delay or even suspension of data collection. We have developed a system that allows participants in Mobile Experience Sampling studies to share their questions and answers on social media. We tested our system in a group of 40 participants. The study shows that enabled sharing of ESM questions significantly increased response and participation rates, in our test by &plus;43%, which also indicates its influence on participants' compliance and motivation levels. This paper presents the study and discusses some further use and influence of social media in Experience Sampling.},
 acmid = {2785894},
 address = {New York, NY, USA},
 author = {Tollmar, Konrad and Huang, Chengcheng},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785894},
 isbn = {978-1-4503-3652-9},
 keyword = {Android, ESM, Mobile Experience Sampling, Social media},
 link = {http://doi.acm.org/10.1145/2785830.2785894},
 location = {Copenhagen, Denmark},
 numpages = {6},
 pages = {525--530},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Boosting Mobile Experience Sampling with Social Media},
 year = {2015}
}


@inproceedings{Yuksel:2015:UEI:2785830.2785856,
 abstract = {Multiple researchers recently proposed the use of the digital compass embedded in mobile devices for touchless interaction in the 3D space around them. These methods overcome several limits imposed by other interaction techniques and were evaluated for a variety of uses. However, they do not support collaborative settings and are prone to dynamic noise caused by external conditions, as with most other sensor-based interaction techniques. In this paper, we propose the use of frequency-modulated electromagnets as an input medium for magnetic interaction to overcome its various constraints and further enable multi-user and two-handed input. Furthermore, we demonstrated the hardware design specifications of a novel input device, referred to as electromagnetic stylus, which is prototyped to conduct a user-study on the proposed method. Experimental results indicate that gestures performed simultaneously by four electromagnetic styli can accurately be recognized using a single magnetic field sensor, and dynamic noises can be substantially reduced.},
 acmid = {2785856},
 address = {New York, NY, USA},
 author = {Yuksel, Kamer Ali and Baz, Ipek and Ozduman, Haluk},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785856},
 isbn = {978-1-4503-3652-9},
 keyword = {Around device interaction, electromagnetic stylus, magnetic field sensor, mobile devices, solenoid driver circuit},
 link = {http://doi.acm.org/10.1145/2785830.2785856},
 location = {Copenhagen, Denmark},
 numpages = {7},
 pages = {420--426},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Using Electromagnetic Input for Multi-User or Two-Handed Spatial Gestural Interaction Based on the Digital Compass},
 year = {2015}
}


@inproceedings{Tseng:2015:LUL:2785830.2785831,
 abstract = {This work presents LEaD, a helmet-based visual guidance system utilizing light movement in scooter drivers' peripheral vision for turn-by-turn navigation. A linear light strip mounted on a helmet navigates for scooter drivers using simple 1D light movement, which can be easily acquired and identified by peripheral vision with the on-going foveal vision task. User studies suggest that this novel system can effectively direct scooter drivers without introducing visual distractions in route-guided experiences.},
 acmid = {2785831},
 address = {New York, NY, USA},
 author = {Tseng, Hung-Yu and Liang, Rong-Hao and Chan, Liwei and Chen, Bing-Yu},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785831},
 isbn = {978-1-4503-3652-9},
 keyword = {Navigation, Peripheral Visualization, Wearable Display},
 link = {http://doi.acm.org/10.1145/2785830.2785831},
 location = {Copenhagen, Denmark},
 numpages = {4},
 pages = {323--326},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {LEaD: Utilizing Light Movement As Peripheral Visual Guidance for Scooter Navigation},
 year = {2015}
}


@inproceedings{Giannopoulos:2015:GGP:2785830.2785873,
 abstract = {Pedestrian navigation systems help us make a series of decisions that lead us to a destination. Most current pedestrian navigation systems communicate using map-based turn-by-turn instructions. This interaction mode suffers from ambiguity, its user's ability to match the instruction with the environment, and it requires a redirection of visual attention from the environment to the screen. In this paper we present GazeNav, a novel gaze-based approach for pedestrian navigation. GazeNav communicates the route to take based on the user's gaze at a decision point. We evaluate GazeNav against the map-based turn-by-turn instructions. Based on an experiment conducted in a virtual environment with 32 participants we found a significantly improved user experience of GazeNav, compared to map-based instructions, and showed the effectiveness of GazeNav as well as evidence for better local spatial learning. We provide a complete comparison of navigation efficiency and effectiveness between the two approaches.},
 acmid = {2785873},
 address = {New York, NY, USA},
 author = {Giannopoulos, Ioannis and Kiefer, Peter and Raubal, Martin},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785873},
 isbn = {978-1-4503-3652-9},
 keyword = {Eye Tracking, Gaze-Based Interaction, Pedestrian Navigation, Wayfinding},
 link = {http://doi.acm.org/10.1145/2785830.2785873},
 location = {Copenhagen, Denmark},
 numpages = {10},
 pages = {337--346},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {GazeNav: Gaze-Based Pedestrian Navigation},
 year = {2015}
}


@inproceedings{Ledo:2015:PCD:2785830.2785871,
 abstract = {Remote controls facilitate interactions at-a-distance with appliances. However, the complexity, diversity, and increasing number of digital appliances in ubiquitous computing ecologies make it increasingly difficult to: (1) discover which appliances are controllable; (2) select a particular appliance from the large number available; (3) view information about its status; and (4) control the appliance in a pertinent manner. To mitigate these problems we contribute proxemic-aware controls, which exploit the spatial relationships between a person's handheld device and all surrounding appliances to create a dynamic appliance control interface. Specifically, a person can discover and select an appliance by the way one orients a mobile device around the room, and then progressively view the appliance's status and control its features in increasing detail by simply moving towards it. We illustrate proxemic-aware controls of assorted appliances through various scenarios. We then provide a generalized conceptual framework that informs future designs of proxemic-aware controls.},
 acmid = {2785871},
 address = {New York, NY, USA},
 author = {Ledo, David and Greenberg, Saul and Marquardt, Nicolai and Boring, Sebastian},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785871},
 isbn = {978-1-4503-3652-9},
 keyword = {Mobile Interaction, control of appliances, proxemic-interaction, ubiquitous computing},
 link = {http://doi.acm.org/10.1145/2785830.2785871},
 location = {Copenhagen, Denmark},
 numpages = {12},
 pages = {187--198},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Proxemic-Aware Controls: Designing Remote Controls for Ubiquitous Computing Ecologies},
 year = {2015}
}


@inproceedings{Moroni:2015:AFN:2785830.2785874,
 abstract = {Mobile payment represents a promising emerging market. Nevertheless, especially for Mobile Proximity Payment (MPP), neither users nor merchants have largely adopted this innovation so far. This study aims to identify the adoption factors of MPP by developing a user model, tested through an in-lab experimentation involving 50 users in Italy. We then compared our results with those obtained through a remote survey that involved 1001 subjects who have never used a MPP system before. Compatibility with users' needs, habits and lifestyle has been found to be the dominating factor for adoption. Surprisingly, we found that a previous use of e-payment systems does not influence the user's perception of compatibility. While perceived security is a concern for prospective users who have never used MPP, it does not affect the intention to adopt for users who tried the system at least once. Cost considerations do not influence MPP adoption intention. Based on these findings we expect that MPP systems have a high chance to be widely adopted if optimized for compatibility.},
 acmid = {2785874},
 address = {New York, NY, USA},
 author = {Moroni, Alice and Talamo, Maurizio and Dimitri, Andrea},
 booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/2785830.2785874},
 isbn = {978-1-4503-3652-9},
 keyword = {M-payments, Risk, Security, User Experience},
 link = {http://doi.acm.org/10.1145/2785830.2785874},
 location = {Copenhagen, Denmark},
 numpages = {7},
 pages = {393--399},
 publisher = {ACM},
 series = {MobileHCI '15},
 title = {Adoption Factors of NFC Mobile Proximity Payments in Italy},
 year = {2015}
}


