@inproceedings{Orzechowski:2010:IMP:1851600.1851714,
 abstract = {While shopping online for textiles from a mobile device, we face the perceptual gap between qualities we can perceive via the interface and those we sense when handling the real textile product. In this research I first investigate the qualities that people look for when interacting with textiles. Further, I examine the gestures people commonly use to handle fabrics, and I propose a way to imitate them on a mobile device. Finally, I prototype touch-screen interactive-video interfaces and assess best practice.},
 acmid = {1851714},
 address = {New York, NY, USA},
 author = {Orzechowski, Pawel M.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851714},
 isbn = {978-1-60558-835-3},
 keyword = {gestures, interactive video, mobile interface, perception, textiles},
 link = {http://doi.acm.org/10.1145/1851600.1851714},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {477--478},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Interactive Mobile Presentation of Textiles},
 year = {2010}
}


@inproceedings{Chittaro:2010:SBU:1851600.1851607,
 abstract = {Searching for an item in a long ordered list that does not fit the screen is a frequent task when using mobile devices. This paper explores four different interfaces to support blind users in carrying out this task. Two of them are based on the idea of tree-augmentation of a list, proposed by Furnas [3], and differ in their depth versus breadth ratio. The other two interfaces adopt the more traditional technique of list scrolling based respectively on standard multitap and T9 keyboard entry. The paper reports also on the results of a pilot study of the four interfaces conducted on two blind users.},
 acmid = {1851607},
 address = {New York, NY, USA},
 author = {Chittaro, Luca and Marassi, Alessandro},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851607},
 isbn = {978-1-60558-835-3},
 keyword = {blind users, long lists, menu selection, mobile devices},
 link = {http://doi.acm.org/10.1145/1851600.1851607},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {27--30},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Supporting Blind Users in Selecting from Very Long Lists of Items on Mobile Phones},
 year = {2010}
}


@inproceedings{AlMahmud:2010:DCS:1851600.1851680,
 abstract = {In this paper we present the design of an image capturing device for persons with aphasia. The early concepts were validated with one speech therapist and the usability of the camera was tested with one aphasic person. Our semi-autonomous hand-held camera, tapered to meet specific interaction and ergonomic needs of expressive aphasics. This camera is able to capture daily experiences by creating photographs that receives significant, automatically added tags. We present the design case study with early evaluation results by proxy users.},
 acmid = {1851680},
 address = {New York, NY, USA},
 author = {Al Mahmud, Abdullah and Braun, Jeffrey and Martens, Jean-Bernard},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851680},
 isbn = {978-1-60558-835-3},
 keyword = {aphasia, capturing, life-logging, prototyping},
 link = {http://doi.acm.org/10.1145/1851600.1851680},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {391--392},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Designing to Capture and Share Life Experiences for Persons with Aphasia},
 year = {2010}
}


@inproceedings{Dorflinger:2010:MHT:1851600.1851732,
 abstract = {Technical Information and Communication Technologies for Development (ICTD) research lacks appropriate research methods along the entire development lifecycle spanning design, development, deployment, evaluation and monitoring. Mobile HCI has a great set of research methods that have proven their suitability in mobile research. However, applying Mobile HCI research methods unchanged in technical ICTD will fail due to the specific cultural, infrastructural and governmental context of developing countries. In this workshop we want to bring together people who are active in Mobile HCI and ICTD research to elaborate on Mobile HCI methods and discuss their application for technical ICTD.},
 acmid = {1851732},
 address = {New York, NY, USA},
 author = {D\"{o}rflinger, J\"{o}rg and Gross, Tom},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851732},
 isbn = {978-1-60558-835-3},
 keyword = {mobile human computer interaction, research methodologies, technical ICTD},
 link = {http://doi.acm.org/10.1145/1851600.1851732},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {517--520},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile HCI and Technical ICTD: A Methodological Perspective},
 year = {2010}
}


@inproceedings{Tintarev:2010:OBT:1851600.1851636,
 abstract = {This paper presents a field study of a framework for personalized mobile recommendations in the tourism domain, of sight-seeing Points of Interest (POI). We evaluate the effectiveness, satisfaction and divergence from popularity of a knowledge-based personalization strategy comparing it to recommending most popular sites. We found that participants visited more of the recommended POIs for lists with popular but non-personalized recommendations. In contrast, the personalized recommendations led participants to visit more POIs overall and visit places "off the beaten track". The level of satisfaction between the two conditions was comparable and high, suggesting that our participants were just as happy with the rarer, "off the beaten track" recommendations and their overall experience. We conclude that personalized recommendations set tourists into a discovery mode with an increased chance for serendipitous findings, in particular for returning tourists.},
 acmid = {1851636},
 address = {New York, NY, USA},
 author = {Tintarev, Nava and Flores, Ana and Amatriain, Xavier},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851636},
 isbn = {978-1-60558-835-3},
 keyword = {field studies, mobile applications, recommender systems, user-centered design},
 link = {http://doi.acm.org/10.1145/1851600.1851636},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {209--218},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Off the Beaten Track: A Mobile Field Study Exploring the Long Tail of Tourist Recommendations},
 year = {2010}
}


@inproceedings{Wenig:2010:ICM:1851600.1851673,
 abstract = {While studies have shown the advantages of map-image-combinations for pedestrian navigation, none of them concentrated on interaction. We suggest to combine an intuitive pitch gesture with the natural peephole metaphor not only for pedestrian navigation but also for virtual exploration with mobile devices and present a first prototype implementing our ideas.},
 acmid = {1851673},
 address = {New York, NY, USA},
 author = {Wenig, Dirk and Malaka, Rainer},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851673},
 isbn = {978-1-60558-835-3},
 keyword = {image-based navigation, maps, mobile devices, pedestrian navigation, virtual exploration},
 link = {http://doi.acm.org/10.1145/1851600.1851673},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {377--378},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Interaction with Combinations of Maps and Images for Pedestrian Navigation and Virtual Exploration},
 year = {2010}
}


@inproceedings{Ouilhet:2010:GSM:1851600.1851695,
 abstract = {Google Sky Map, an application for Android mobile phones, allows the user to discover and browse the sky by simply pointing the phone to space. Using the Android phone's orientation sensors, Sky Map shows a particular stellar map specific for each user's location. This paper describes the design principle used for Sky Map: the use of the mobile device as the main interface and the GUI as a secondary guidance. The GUI in Google Sky Map is kept as minimal as possible. The search GUI is an example of how an on-screen GUI and the physical movement of the phone can work in harmony to provide an accurate user experience. Google Sky Map was developed by five Google Engineers and one User Experience Designer.},
 acmid = {1851695},
 address = {New York, NY, USA},
 author = {Ouilhet, Hector},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851695},
 isbn = {978-1-60558-835-3},
 keyword = {GUI, interaction style, mobile, planetarium, sensors, space},
 link = {http://doi.acm.org/10.1145/1851600.1851695},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {419--422},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Google Sky Map: Using Your Phone As an Interface},
 year = {2010}
}


@inproceedings{Broll:2010:TPM:1851600.1851706,
 abstract = {Mobile devices can take advantage of physical interaction with their environment and its objects to compensate their constrained input and output capabilities. For that purpose, dynamic NFC-displays combine the physical interaction with NFC-tagged user interfaces and the output capabilities of public displays. We have adopted this technology for the Whack-a-Mole game to show how it can improve the accessibility and usability of mobile games. This paper describes the design of the game and explores how physical interaction with dynamic NFC-displays can compensate the constraints of mobile games and enrich their gameplay.},
 acmid = {1851706},
 address = {New York, NY, USA},
 author = {Broll, Gregor and Graebsch, Roman and Holleis, Paul and Wagner, Matthias},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851706},
 isbn = {978-1-60558-835-3},
 keyword = {dynamic NFC-displays, mobile gaming, near field communication (NFC), physical user interfaces},
 link = {http://doi.acm.org/10.1145/1851600.1851706},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {459--462},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Touch to Play: Mobile Gaming with Dynamic, NFC-based Physical User Interfaces},
 year = {2010}
}


@inproceedings{Henze:2010:EOV:1851600.1851632,
 abstract = {Map navigation is often limited due to the inherent size restrictions of mobile devices' displays. Using a magic lens to interact with physical objects has been proposed as a way to reduce this limitation. The dynamic peephole interface is an alternative approach where a device is moved across a virtual surface. In this paper we study the effect of an additional visualization of objects beyond the screen on magic lens and dynamic peephole interfaces. In the conducted experiment the participants had to select points of interest shown on a map. We show that an additional visualization of off-screen objects decreases the task completion time and reduces the perceived task load. The advantage of an off-screen visualization is much higher than the difference between using a magic lens instead of a dynamic peephole interface.},
 acmid = {1851632},
 address = {New York, NY, USA},
 author = {Henze, Niels and Boll, Susanne},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851632},
 isbn = {978-1-60558-835-3},
 keyword = {augmented reality, dynamic peephole, magic lens, map navigation, mobile interaction},
 link = {http://doi.acm.org/10.1145/1851600.1851632},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {191--194},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Evaluation of an Off-screen Visualization for Magic Lens and Dynamic Peephole Interfaces},
 year = {2010}
}


@inproceedings{Aslan:2010:TMP:1851600.1851727,
 abstract = {We are interested in all sorts of tool-support, which help the designer of a pervasive application in different stages of the development process, such as task and requirements analysis, conceptual design, prototyping and evaluation. We are looking for contributions that will help to address the following questions: What are the past experiences and future expectations of designers and developers that use tools for support?; What exactly are the benefits and the shortcomings of available tools?; What are the open issues and challenges for the next few years? The workshop will feature presentations of research results, experiences of past and ongoing work, and a forum for participants to address a predefined set of focus questions.},
 acmid = {1851727},
 address = {New York, NY, USA},
 author = {Aslan, Ilhan and Leichtenstern, Karin and Holleis, Paul and Wasinger, Rainer and Stahl, Christoph},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851727},
 isbn = {978-1-60558-835-3},
 keyword = {design process, mobile application, pervasive application, tool-support},
 link = {http://doi.acm.org/10.1145/1851600.1851727},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {499--502},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Tool-support for Mobile and Pervasive Application Development - Issues and Challenges},
 year = {2010}
}


@inproceedings{Seebode:2010:IFQ:1851600.1851717,
 abstract = {Aim of this research is to investigate the influence of system feedback in different modalities like nonverbal auditory information as well as speech, tactile and graphical feedback on perceived quality. As a first step experiments are conducted for different kinds of unimodal feedback to establish a suitable experimental paradigm. Based on these experiments certain feedback messages are selected and implemented in a multimodal mobile prototype to study the influence of those feedback messages on the interaction and the perceived quality. The developed approach will serve as a generic experimental set-up to collect user ratings and interaction data. These measures can than be used to evaluate the quality and usability of multimodal systems in mobile contexts and for quality prediction.},
 acmid = {1851717},
 address = {New York, NY, USA},
 author = {Seebode, Julia},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851717},
 isbn = {978-1-60558-835-3},
 keyword = {auditory, multimodal interaction, tactile feedback, visual},
 link = {http://doi.acm.org/10.1145/1851600.1851717},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {483--484},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Influence of Feedback on the Quality of Multimodal Systems},
 year = {2010}
}


@inproceedings{Liu:2010:DLP:1851600.1851650,
 abstract = {Many field study methods such as usability test in fields, contextual inquiry, and ethnographic interview can be applied to evaluate user experience of concepts in trials; however, most of such traditional field study methods suffer from weaknesses like resource demanding, time consuming, lack of measurement for longitudinal usage or lack of channels to collect user feedbacks in real time. In this paper, we propose an approach to combine data logging with e-diary for user experience evaluation in field trials. An evaluation case on a mobile service concept is also presented to show this approach.},
 acmid = {1851650},
 address = {New York, NY, USA},
 author = {Liu, Ning and Liu, Ying and Wang, Xia},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851650},
 isbn = {978-1-60558-835-3},
 keyword = {data log, diary, evaluation, field trial},
 link = {http://doi.acm.org/10.1145/1851600.1851650},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {287--290},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Data Logging Plus e-Diary: Towards an Online Evaluation Approach of Mobile Service Field Trial},
 year = {2010}
}


@inproceedings{McAdam:2010:NID:1851600.1851625,
 abstract = {Camera phones are now very common but there are some usability issues that affect their use. These can occur because the users look through the LCD to frame the image and can often miss the icons displayed around the edges that present important information about the status of the camera. This may lead to shots being missed or poorly exposed. Most camera phones do not take full advantage of the features of the underlying phone platform to enhance their interfaces. We created a camera application for the Nokia N95 that featured novel interface elements and made use of the features of the platform to provide a rich variety of information in more usable forms, such as: sonifications of the luminance histogram to ensure better exposure before a picture is taken; phone orientation to give a level indicator to ensure the camera is straight; measuring phone movement to ensure the phone is being held steady; and the detection of image motion to support panning We also present a scenario for how these features could be used in conjunction with each other during the photo taking process.},
 acmid = {1851625},
 address = {New York, NY, USA},
 author = {McAdam, Christopher and Pinkerton, Craig and Brewster, Stephen A.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851625},
 isbn = {978-1-60558-835-3},
 keyword = {camera phone, luminance histogram, motion, orientation, panning, sonification, tactile},
 link = {http://doi.acm.org/10.1145/1851600.1851625},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {143--152},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Novel Interfaces for Digital Cameras and Camera Phones},
 year = {2010}
}


@inproceedings{Nanavati:2010:SWS:1851600.1851733,
 abstract = {With the proliferation of pervasive devices and the increase in their processing capabilities, client-side speech processing has been emerging as a viable alternative. The SiMPE workshop series started in 2006 [5] with the goal of enabling speech processing on mobile and embedded devices to meet the challenges of pervasive environments (such as noise) and leveraging the context they offer (such as location). SiMPE 2010, the 5th in the series, will continue to explore issues, possibilities, and approaches for enabling speech processing as well as convenient and effective speech and multimodal user interfaces. Over the years, SiMPE has been evolving too, and since last year, one of our major goals has been to increase the participation of speech/multimodal HCI designers, and increase their interactions with speech processing experts. Multimodality got more attention in SiMPE 2008 than it has received in the previous years. In SiMPE 2007 [4], the focus was on developing regions. Given the importance of speech in developing regions, SiMPE 2008 had "SiMPE for developing regions" as a topic of interest. Speech User interaction in cars was a focus area in 2009 [2]. Given the multi-disciplinary nature of our goal, we hope that SiMPE will become the prime meeting ground for experts in these varied fields to bring to fruition, novel, useful and usable mobile speech applications.},
 acmid = {1851733},
 address = {New York, NY, USA},
 author = {Nanavati, Amit Anil and Rajput, Nitendra and Rudnicky, Alexandar I. and Turunen, Markku and Kun, Andrew L. and Paek, Tim and Tashev, Ivan},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851733},
 isbn = {978-1-60558-835-3},
 keyword = {mobile computing, pervasive computing, speech processing},
 link = {http://doi.acm.org/10.1145/1851600.1851733},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {521--524},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {SiMPE: 5th Workshop on Speech in Mobile and Pervasive Environments},
 year = {2010}
}


@inproceedings{Ladstaetter:2010:MDF:1851600.1851682,
 abstract = {Analysis of human geographical orientation is a crucial issue to understand the user's actual demand on context based information. As the limitations in accuracy of satellite based positioning especially in urban environments and network based positioning are well known, a novel framework concept based on data fusion of multiple sensors build-in handsets will enable to characterize the user's situation and allow automated analysis with semantic mapping functionality. In this paper, the first approach for high accuracy multi sensor orientation tracking by the use of a mobile phone is discussed.},
 acmid = {1851682},
 address = {New York, NY, USA},
 author = {Ladstaetter, Stefan and Luley, Patrick and Almer, Alexander and Paletta, Lucas},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851682},
 isbn = {978-1-60558-835-3},
 keyword = {data fusion, dead reckoning, inertial measurement, kalman filter, multisensor positioning, pedestrian navigation},
 link = {http://doi.acm.org/10.1145/1851600.1851682},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {395--396},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Multisensor Data Fusion for High Accuracy Positioning on Mobile Phones},
 year = {2010}
}


@inproceedings{delaGuia:2010:CTN:1851600.1851702,
 abstract = {Co-Interactive Table is a client-server system designed to facilitate collaborative tasks in any kind of meeting such as sharing information and files among the participants using simple, natural and intuitive gestures. We have used technology based on mobile devices and RFID to implement the system. The system is composed of panels (one per user) forming the interactive table. A projector connected to a PC updates instantly the information generated in the meeting such as notes, ideas and the specific information of each participant. All devices used in the meeting room are connected via Wi-Fi to the Co-Interactive Table server. This server is responsible for providing important web services that coordinate and control the system performance. Besides, the system offers the possibility of performing remote meetings without losing functionality. The Co-interactive table client application runs on mobile devices with RFID reader. The system can recognize the service required by the user with a gesture as simple and natural as bringing the mobile device near the interactive table to select the desired action.},
 acmid = {1851702},
 address = {New York, NY, USA},
 author = {de la Gu\'{\i}a, Elena and Gallud, Jose A. A. and Tesoriero, Ricardo and Lozano, Mar\'{\i}a D. and Penichet, V\'{\i}ctor},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851702},
 isbn = {978-1-60558-835-3},
 keyword = {RFID, collaboration, interactive meetings, interactive table, mobile devices},
 link = {http://doi.acm.org/10.1145/1851600.1851702},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {447--450},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Co-interactive Table: A New Facility to Improve Collaborative Meetings},
 year = {2010}
}


@inproceedings{Scott:2010:RTE:1851600.1851630,
 abstract = {RearType is a text input system for mobile devices such as Tablet PCs, using normal keyboard keys but on the reverse side of the device. The standard QWERTY layout is split and rotated so that hands gripping the device from either side have the usual keys under the fingers. This frees up the front of the device, maximizing the use of the display for visual output, eliminating the need for an onscreen keyboard and the resulting hand occlusion, and providing tactile and multi-finger text entry - with potential for knowledge transfer from QWERTY. Using a prototype implementation which includes software visualization of the keys to assist with learning, we conducted a study to explore the initial learning curve for RearType. With one hour's training, RearType typing speed was an average 15 WPM, and was not statistically different to a touchscreen keyboard.},
 acmid = {1851630},
 address = {New York, NY, USA},
 author = {Scott, James and Izadi, Shahram and Rezai, Leila Sadat and Ruszkowski, Dominika and Bi, Xiaojun and Balakrishnan, Ravin},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851630},
 isbn = {978-1-60558-835-3},
 keyword = {keyboard, mobile devices, tablet pc, text entry},
 link = {http://doi.acm.org/10.1145/1851600.1851630},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {171--180},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {RearType: Text Entry Using Keys on the Back of a Device},
 year = {2010}
}


@inproceedings{Benedito:2010:KRT:1851600.1851674,
 abstract = {Mobile devices are designed mostly to fit users with no particular disability. Tactile affordances are neglected at the expense of more attractive stylish interfaces and assistive solutions are stereotypical, also facing disabilities with a narrow perspective. A blind user is presented with screen reading software to overcome the inability to receive feedback from the device. However, these solutions go only half-way. In the absence of sight other capabilities stand up. Above all, the sense of touch plays an essential role while interacting with physical keypads. To empower these users, a deeper understanding of their capabilities and how they relate with technology is mandatory. We propose a user-product compatibility approach, taking in account that blind users have different tactile attributes. We expect to correlate the user's tactile sensitivity and keypad demands, enabling informed keypad design and selection.},
 acmid = {1851674},
 address = {New York, NY, USA},
 author = {Benedito, Jo\~{a}o and Guerreiro, Tiago and Nicolau, Hugo and Gon\c{c}alves, Daniel},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851674},
 isbn = {978-1-60558-835-3},
 keyword = {assessment, blind, mobile accessibility, tactile sensitivity},
 link = {http://doi.acm.org/10.1145/1851600.1851674},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {379--380},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {The Key Role of Touch in Non-visual Mobile Interaction},
 year = {2010}
}


@inproceedings{Blommaert:2010:DPD:1851600.1851711,
 abstract = {Most people suffering from autism have a desperate need for clarity and structure in their lives. There are various applications (agendas, daily planners, pictograms, etc.) that support autistic individuals in their living. However, not many applications out there make it possible for a person with autism to live a structured life on his own, in a variety of contexts, with minimum human guidance. Day Pad is an application that helps individuals, especially children and early teenagers, to organize their lives independently. This application can support the lives of individuals in a variety of contexts (home, daycare, market, school, etc.) and run on variety of mobile devices (PDA, tablet PC, etc.) depending on the context.},
 acmid = {1851711},
 address = {New York, NY, USA},
 author = {Blommaert, Anne and Philippart, Pieter and Rassaerts, Chris and Theunissen, Erik and Widdershoven, Svenja and Shahid, Suleman},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851711},
 isbn = {978-1-60558-835-3},
 keyword = {autism, children, contextual user interface, design},
 link = {http://doi.acm.org/10.1145/1851600.1851711},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {473--474},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Day Pad: A Daily Life Assistant for Autistic Children},
 year = {2010}
}


@inproceedings{Chong:2010:GUD:1851600.1851644,
 abstract = {Mobile devices with wireless network capabilities can be associated to form ad hoc networks to share resources; however, such an association of devices requires authentication. At present, PIN is the common authentication method, but in many cases, small devices may not have input interfaces to accommodate PIN entry. We therefore design a gesture-based authentication scheme, called GesturePIN, for associating multiple mobile devices; our solution provides the advantage of being adaptable to any PIN authentication systems. We have also conducted a quantitative user study to understand the speed and accuracy of people using our gesture-based system compared to using PIN.},
 acmid = {1851644},
 address = {New York, NY, USA},
 author = {Chong, Ming Ki and Marsden, Gary and Gellersen, Hans},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851644},
 isbn = {978-1-60558-835-3},
 keyword = {device association, device authentication, gesture password, spontaneous interaction},
 link = {http://doi.acm.org/10.1145/1851600.1851644},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {261--264},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {GesturePIN: Using Discrete Gestures for Associating Mobile Devices},
 year = {2010}
}


@inproceedings{Music:2010:VHT:1851600.1851654,
 abstract = {The paper demonstrates the feasibility of using mobile phones for fitness and rehabilitation purposes by training them to recognise a user's hula-hooping movements. It also proposes several parameters which can be used as a measure of rhythmic movement quality. Experimental measurements were achieved with two test subjects performing two sets of steady hula-hooping. The paper compares algorithm performance with accelerometer, gyroscope and magnetometer sensor readings. Analysis of the recorded data indicated that magnetometers had some advantages over accelerometers for reliable phase extraction. Hilbert transforms were used to extract the phase information, and a Dynamic Rhythmic Primitive Model was identified for the hula-hooping movement. Together these tools allow the creation of hula-hooping performance metrics which can be used in wellness, rehabilitation or entertainment applications for mobile devices. We outline open technical challenges and possible future research directions.},
 acmid = {1851654},
 address = {New York, NY, USA},
 author = {Music, Josip and Murray-Smith, Roderick},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851654},
 isbn = {978-1-60558-835-3},
 keyword = {dynamic movement primitives, fitness, hilbert transform, hula hoop, magnetometer, phase angle},
 link = {http://doi.acm.org/10.1145/1851600.1851654},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {309--312},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Virtual Hooping: Teaching a Phone About Hula-hooping for Fitness, Fun and Rehabilitation},
 year = {2010}
}


@inproceedings{Setlur:2010:SCB:1851600.1851689,
 abstract = {Typical web navigation techniques tend to support undirected web browsing, a depth-first search of information pages. This search strategy often results in the unintentional behavior of 'web surfing', where a user starts in search of information, but is sidetracked by tangential links. A mobile user in particular, would prefer to extract the desired information quickly and with minimal mental effort. In this paper, we introduce 'SemantiLynx' to visually augment hyperlinks on web pages for better supporting the task of directed searches on small-screen ubiquitous platforms. Our algorithm comprises four parts: establishing the context of information related to a hyperlink, retrieving relevant imagery based on this context, applying image simplification, and finally compositing a visual icon for the given hyperlink.},
 acmid = {1851689},
 address = {New York, NY, USA},
 author = {Setlur, Vidya},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851689},
 isbn = {978-1-60558-835-3},
 keyword = {directed search, hyperlinks, icons, mobile device, ubiquitous web},
 link = {http://doi.acm.org/10.1145/1851600.1851689},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {409--410},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {SemantiLynx: Context Based Icons for Mobile Web Navigation and Directed Search Tasks},
 year = {2010}
}


@inproceedings{Villanueva:2010:MCS:1851600.1851699,
 abstract = {We introduce a new system to improve the collaboration possibilities among the participants in face-to-face meetings and working groups, called WallShare. WallShare is a new interaction device and a new platform to develop collaborative applications. The proposed system provides a shared zone that is displayed by a projector over a wall. Users can collaborate through the shared zone using their own mobile devices, such as mobile phones, PDAs, laptops and so on. To use the shared zone, users have their own cursors that allow them to share any kind of files, such as images, or documents. WallShare has been proved helpful to support distributed user interfaces. The usability evaluation also showed us that WallShare users' can perform a set of tasks with effectiveness, productivity and satisfaction.},
 acmid = {1851699},
 address = {New York, NY, USA},
 author = {Villanueva, Pedro Gonz\'{a}lez and Tesoriero, Ricardo and Gallud, Jose A.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851699},
 isbn = {978-1-60558-835-3},
 keyword = {HCI, UI distribution, interaction resources, mobile devices},
 link = {http://doi.acm.org/10.1145/1851600.1851699},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {435--438},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Multi-pointer and Collaborative System for Mobile Devices},
 year = {2010}
}


@inproceedings{Dekel:2010:DEI:1851600.1851681,
 abstract = {We present an ongoing series of tests that explore the capabilities of un-augmented smart phones to serve as indoor navigation devices. We developed and tested a dead reckoning navigation application on an IPhone 3GS. It was found that the DRec application can count steps with more than 97% accuracy. This parameter, when multiplied with the user's personal step distance can be used to compute distance traveled. In initial tests DRec was able to compute the distance traveled with more than 90% accuracy. A dead reckoning test was also run, and initial results are promising.},
 acmid = {1851681},
 address = {New York, NY, USA},
 author = {Dekel, Amnon and Schiller, Elad},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851681},
 isbn = {978-1-60558-835-3},
 keyword = {accelerometer, compass, dead reckoning, navigation},
 link = {http://doi.acm.org/10.1145/1851600.1851681},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {393--394},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {DRec: Exploring Indoor Navigation with an Un-augmented Smart Phone},
 year = {2010}
}


@inproceedings{Lynggaard:2010:MCD:1851600.1851720,
 abstract = {This paper is a summary of the Ph.D. project about home and mobility. The project concerns design for mobile life and through various prototypes it is an investigation of how to support the act of home making away from the primary home.},
 acmid = {1851720},
 address = {New York, NY, USA},
 author = {Lynggaard, Aviaja Borup},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851720},
 isbn = {978-1-60558-835-3},
 keyword = {design research, home, interaction design, mobility, modern nomads},
 link = {http://doi.acm.org/10.1145/1851600.1851720},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {489--490},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {On the Move: Creating Domesticity Through Experience Design},
 year = {2010}
}


@inproceedings{Jedrzejczyk:2010:PHI:1851600.1851690,
 abstract = {We describe the "Privacy-Shake", a novel interface for managing coarse grained privacy settings. We built a prototype that enables users of Buddy Tracker, an example location sharing application, to change their privacy preferences by shaking their phone. Users can enable or disable location sharing and change the level of granularity of disclosed location by shaking and sweeping their phone. In this poster we present and motivate our work on Privacy-Shake and report on a lab-based evaluation of the interface with 16 participants.},
 acmid = {1851690},
 address = {New York, NY, USA},
 author = {Jedrzejczyk, Lukasz and Price, Blaine A. and Bandara, Arosha and Nuseibeh, Bashar},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851690},
 isbn = {978-1-60558-835-3},
 keyword = {haptics, location sharing, mobile computing, privacy management},
 link = {http://doi.acm.org/10.1145/1851600.1851690},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {411--412},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {"Privacy-shake",: A Haptic Interface for Managing Privacy Settings in Mobile Location Sharing Applications},
 year = {2010}
}


@inproceedings{Vyas:2010:CCO:1851600.1851692,
 abstract = {Physical design objects such as sketches, drawings, collages, storyboards and models play an important role in supporting communication and coordination in design studios. CAM (Cooperative Artefact Memory) is a mobile-tagging based messaging system that allows designers to collaboratively store relevant information onto their design objects in the form of messages, annotations and external web links. We studied the use of CAM in a Product Design studio over three weeks, involving three different design teams. In this paper, we briefly describe CAM and show how it serves as 'object memory'.},
 acmid = {1851692},
 address = {New York, NY, USA},
 author = {Vyas, Dhaval and Nijholt, Anton and Kr\"{o}ner, Alexander},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851692},
 isbn = {978-1-60558-835-3},
 keyword = {design objects, design studio, mobile-tagging, object memory},
 link = {http://doi.acm.org/10.1145/1851600.1851692},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {415--416},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {CAM: A Collaborative Object Memory System},
 year = {2010}
}


@inproceedings{Guerreiro:2010:SFF:1851600.1851677,
 abstract = {The proliferation of personal devices and their constant awareness of our interactions have generated an enormous amount of data that can be useful to help the user obtaining relevant information when needed. Our approach uses the personal information on users' devices, together with public online sources, to provide relevant information from the user point of view. The information from the users' devices, due to its personal and credible character, works as a filter to the retrieved from other less trustable and structured sources. A preliminary evaluation, suggested that we can provide the user with inter-connected relevant information from heterogeneous sources. However, we found some limitations that led us to our current research challenges.},
 acmid = {1851677},
 address = {New York, NY, USA},
 author = {Guerreiro, Jo\~{a}o and Guerreiro, Tiago and Gon\c{c}alves, Daniel},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851677},
 isbn = {978-1-60558-835-3},
 keyword = {information filtering, mobile, personal information, public information},
 link = {http://doi.acm.org/10.1145/1851600.1851677},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {385--386},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Surpassing Farley Files: Opportunities and Challenges on Obtaining Personally Relevant Information},
 year = {2010}
}


@proceedings{Bylund:2011:2037373,
 abstract = {We are proud to present the proceedings of the 13th International Conference on Human-Computer Interaction with Mobile Devices and Services-colloquially known as 'Mobile HCI'. Reflecting research conducted both in Universities and Industry, Mobile HCI focuses on next generation, meaningful interaction techniques and services for mobile devices. Research areas include technical, interactional, social and cultural aspects, as well as studies of social life with mobile devices. Mobile human-computer-interaction is one of the most rapidly growing areas in computing. The proliferation of smartphones, and the resultant expansion of mobile Internet access, underscore that this is a cardinal area of invention and innovation for both consumers and industry. There is a growing desire and a need for meaningful and useful applications, and a call for innovative content selection and presentation techniques and novel interaction models. The ever-increasing importance of this area for business, for social and for technical innovation is reflected in the growing interest in the Mobile HCI conference. With 276 valid submissions the number of technical papers and notes was at a record high, increasing by over 20% from the previous year, 2010. This growth has further fueled the longstanding commitment from the research community to continue to improve on the quality of the conference. This year we have made effort to improve the quality of the reviewing process. The papers and notes chairs broadened the group of peer reviewers and added a meta-reviewing step. The Senior Program Committee, over 35 people, met in person---across two locations connected by video and audio connections-to decide on the selection of papers and notes. A rigorous process of discussion and reflection was conducted wherein each paper was addressed and considered for inclusion. We instituted a shepherding process of revise-and-resubmit for papers and notes that showed great promise; all shepherded papers were ultimately accepted. As a result of this process, 63 papers and notes (an acceptance rate of 23%) of the submissions to the conference were selected for presentations in Stockholm at the end of August 2011. These proceedings contain the accepted papers and notes that resulted from our review process. The research topics herein reflect our ambition to provide cutting edge research that considers the challenges and potential solutions for effective and meaningful interaction with mobile systems and services. Research presented here covers the design, evaluation and application of techniques for all mobile and wearable computing devices and services. Topics include: next generation touch and gesture-based interaction, including more extended vibro - tactile solutions; the design of video-based interaction on-the go; projections and visualizations from small 'pica-projectors'; technical and social issues around mobile data security and privacy; and case studies of relationship management through mobile devices and location-based services. The global penetration and impact of mobile interaction is reflected. Examples range from interaction to social fabric, from research into various alphabets, such as handling Indian text input to phone use among workers in China. The conference also focuses on understanding various contexts where mobile technologies and services are having an impact on everyday recreational life-see for example the design and evaluation of mobile services for hedonic parts of life such as shopping and fashion. The Mobile HCI conference promises to be a vibrant and fast-paced event. Given the increasing number of selected papers, we have chosen to include more content-17 papers and notes sessions-in the program. We have thus reduced the time for each presentation, allowing the audience to enjoy a richer variety of research and demonstrations and encouraging broader debate. The audience will be diverse. The conference has traditionally provided a meeting ground for researchers from both industry and academia-this is also a hallmark of MobileHCI2011 in Stockholm. This combination is visible in the selection of technical contributions within these proceedings, with authors and projects hailing from industry research organizations and from universities from around the globe.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-0541-9},
 location = {Stockholm, Sweden},
 publisher = {ACM},
 title = {MobileHCI '11: Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services},
 year = {2011}
}


@inproceedings{vonReischach:2010:EPR:1851600.1851635,
 abstract = {Research has shown that product reviews on the Internet not only support consumers when shopping, but also lead to increased sales for retailers. Recent approaches successfully use smart phones to directly relate products (e.g. via barcode or RFID) to corresponding reviews, making these available to consumers on the go. However, it is unknown what modality (star ratings/text/video) users consider useful for creating reviews and using reviews on their mobile phone, and how the preferred modalities are different from those on the Web. To shed light on this we conduct two experiments, one of them in a quasi-realistic shopping environment. The results indicate that, in contrast to the known approaches, stars and pre-structured text blocks should be implemented on mobile phones rather than long texts and videos. Users prefer less and rather well-aggregated product information while on the go. This accounts both for entering and, surprisingly, also for using product reviews.},
 acmid = {1851635},
 address = {New York, NY, USA},
 author = {von Reischach, Felix and Dubach, Erica and Michahelles, Florian and Schmidt, Albrecht},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851635},
 isbn = {978-1-60558-835-3},
 keyword = {mobile applications, mobile interaction, product ratings, product recommendations, product reviews, user interfaces},
 link = {http://doi.acm.org/10.1145/1851600.1851635},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {199--208},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {An Evaluation of Product Review Modalities for Mobile Phones},
 year = {2010}
}


@inproceedings{Duarte:2010:IAT:1851600.1851721,
 abstract = {
                  An abstract is not available.
              },
 acmid = {1851721},
 address = {New York, NY, USA},
 author = {Duarte, Lu\'{\i}s},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851721},
 isbn = {978-1-60558-835-3},
 keyword = {mobile environments, physiological interaction, usability assessment},
 link = {http://doi.acm.org/10.1145/1851600.1851721},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {491--492},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Interaction Assessment Through Physiological Interfaces in Collaborative \&\#38; Mobile Environments},
 year = {2010}
}


@proceedings{Oppermann:2009:1613858,
 abstract = {The 11th International Conference International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI 2009) provides a forum for academics and practitioners to discuss the challenges and potential solutions for effective interaction with mobile systems and services. It covers the design, evaluation and application of techniques for all mobile and wearable computing devices and services. The conference series developed since 1998 from a workshop format into a symposium and is held since 2004 as an international conference. It has been held in cooperation with the ACM at places such as Amsterdam, Singapore, Helsinki, Salzburg, or Pisa. In 2009 the conferences is organized for the first time in Germany, jointly by Fraunhofer FIT, Sankt Augustin, and the University of Siegen. In these proceedings, we document the selected full and short Papers. We received this year 176 submissions, 95 full and 81 short Papers. We were able to accept 23 full papers (at a 24.2% acceptance rate) and 15 short Papers (at a 18.5% acceptance rate). The overall acceptance rate is 21.6%. Full and short Papers were chosen in a severe and quality-oriented selection process in which each contribution was evaluated by at least three reviewers. After the completion of the reviews, some 30 reviewers came together in Sankt Augustin for a two days meeting to evaluate the reviews and make final decisions on acceptance. These reviewers are highlighted by an * in the list of reviewers. We paid specific attention to the scientific value of the contribution, the methods used and the fit with the main stream of the conference. We have been very selective. This highly qualityoriented selection process will strengthen the reputation of MobileHCI as the primary international meeting in our field. Please note that the acceptance rates were clearly lower than in this year's ACM-CHI conference.},
 address = {New York, NY, USA},
 isbn = {978-1-60558-281-8},
 location = {Bonn, Germany},
 publisher = {ACM},
 title = {MobileHCI '09: Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 year = {2009}
}


@inproceedings{Kray:2010:UGC:1851600.1851640,
 abstract = {Gestures can offer an intuitive way to interact with a computer. In this paper, we investigate the question whether gesturing with a mobile phone can help to perform complex tasks involving two devices. We present results from a user study, where we asked participants to spontaneously produce gestures with their phone to trigger a set of different activities. We investigated three conditions (device configurations): phone-to-phone, phone-to-tabletop, and phone to public display. We report on the kinds of gestures we observed as well as on feedback from the participants, and provide an initial assessment of which sensors might facilitate gesture recognition in a phone. The results suggest that phone gestures have the potential to be easily understood by end users and that certain device configurations and activities may be well suited for gesture control.},
 acmid = {1851640},
 address = {New York, NY, USA},
 author = {Kray, Christian and Nesbitt, Daniel and Dawson, John and Rohs, Michael},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851640},
 isbn = {978-1-60558-835-3},
 keyword = {device pairing, gesture, large display, mobile phone, multi-device interaction, tabletop, user-defined gesture},
 link = {http://doi.acm.org/10.1145/1851600.1851640},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {239--248},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {User-defined Gestures for Connecting Mobile Phones, Public Displays, and Tabletops},
 year = {2010}
}


@inproceedings{Fischer:2010:ECT:1851600.1851620,
 abstract = {In this paper we investigate effects of the content of interruptions and of the time of interruption delivery on mobile phones. We review related work and report on a naturalistic quasi-experiment using experience-sampling that showed that the receptivity to an interruption is influenced by its content rather than by its time of delivery in the employed modality of delivery - SMS. We also examined the underlying variables that increase the perceived quality of content and found that the factors interest, entertainment, relevance and actionability influence people's receptivity significantly. Our findings inform system design that seeks to provide context-sensitive information or to predict interruptibility and suggest the consideration of receptivity as an extension to the way we think and reason about interruptibility.},
 acmid = {1851620},
 address = {New York, NY, USA},
 author = {Fischer, Joel E. and Yee, Nick and Bellotti, Victoria and Good, Nathan and Benford, Steve and Greenhalgh, Chris},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851620},
 isbn = {978-1-60558-835-3},
 keyword = {content, context, empirical study, experience-sampling, interruption, mobile, push vs. pull, quasi-experiment, receptivity, sms},
 link = {http://doi.acm.org/10.1145/1851600.1851620},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {103--112},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Effects of Content and Time of Delivery on Receptivity to Mobile Interruptions},
 year = {2010}
}


@inproceedings{Zhang:2010:CSG:1851600.1851665,
 abstract = {Mobile devices are ubiquitously used to access web applications. Multimodal mobile interfaces can offer advantages over less flexible approaches, in both usability and range of features. In this study we consider applying speech input to a web-based network management service. The key issue we are interested in is how to perform suitable multidimensional search through web-based interface on mobile devices. We present results from a pilot user evaluation, focusing on the comparison of a novel speech input method with the existing manual (GUI, Graphical User Interface) input for AT&T's Visualizer management service, on an iPhone. Speech input was experimentally shown to be as effective, more efficient, and preferred over GUI input by most users. We foresee that a multimodal approach may be preferable for many applications on mobile devices.},
 acmid = {1851665},
 address = {New York, NY, USA},
 author = {Zhang, Rui and North, Stephen and Koutsofios, Eleftherios},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851665},
 isbn = {978-1-60558-835-3},
 keyword = {modality, multimodal, speech input, visualizer, web service},
 link = {http://doi.acm.org/10.1145/1851600.1851665},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {357--360},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {A Comparison of Speech and GUI Input for Navigation in Complex Visualizations on Mobile Devices},
 year = {2010}
}


@inproceedings{Pombinho:2010:IVM:1851600.1851722,
 abstract = {The reduced display size of handheld mobile devices imposes severe usability and visualization problems. Adaptation to specific usage context is a key feature to overcome usability and display limitations on mobile devices. I intend to explore adaptive mobile visualization and develop a framework that can efficiently manage the adaptation methods used in the adaptation objects, according to the different contexts dimensions present.},
 acmid = {1851722},
 address = {New York, NY, USA},
 author = {Pombinho, Paulo},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851722},
 isbn = {978-1-60558-835-3},
 keyword = {geo referenced information visualization, mobile devices},
 link = {http://doi.acm.org/10.1145/1851600.1851722},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {493--494},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Information Visualization on Mobile Environments},
 year = {2010}
}


@proceedings{deSa:2010:1851600,
 abstract = {It is our great pleasure to welcome you to Mobile HCI2010, the 12th International Conference on Human-Computer Interaction with Mobile Devices and Services, and to Lisboa, Portugal. For the first time MobileHCI takes place in Portugal and is organised by the University of Lisboa, with the collaboration of the New University of Lisboa and the research centres LaSIGE and CITI, and in cooperation with ACM SIGCHI and ACM SIGMOBILE. Starting in 1998 in Glasgow, MobileHCI is now on its 12th edition and it is the leading conference in the field of Human Computer Interaction with Mobile Devices and Services. The MobileHCI series provides a forum for academics and practitioners to discuss the challenges and potential solutions for effective interaction with mobile systems and services. It covers the design, evaluation and application of techniques and approaches for mobile and wearable computing devices and services. MobileHCI 2010 call for papers attracted many researchers and practitioners in the area receiving a total of 111 full papers and 114 short papers. Through a very thorough review process, we were able to accept 26 full papers and 20 short papers in a very competitive process. The acceptance rate for full papers was 23.4% and for short papers was 17.5%. In addition to the full and short papers, MobileHCI 2010 includes other submission categories that promote different types of interactions among the participants (workshops, panels, industrial case studies, a design competition, future innovations, posters, demos and experiences, and a doctoral consortium). This year, the programme includes three notable invited speakers, Patrick Baudish from the Hasso Plattner Institute, Josh Ulm from Vodafone UK, and Scott Jenson from Google USA, with mixed industry and academic backgrounds sharing their innovative work and experiences with the conference participants. The Programme Committee was fundamental in reaching the final high quality programme. As a new approach, the rigorous review process included Associate Chairs and Programme Committee members. Each paper was reviewed by at least three PC members (most of the papers by four or five) and was assigned to an Associate Chair that moderated online discussions to reach a final set of reviews for each paper. The Programme Chair and the Associate Chairs met in Lisboa in March 2010 to make the final decisions for the conference. In total, more than 1100 reviews were generated over the several categories of the programme.},
 address = {New York, NY, USA},
 isbn = {978-1-60558-835-3},
 location = {Lisbon, Portugal},
 publisher = {ACM},
 title = {MobileHCI '10: Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 year = {2010}
}


@inproceedings{Kriesten:2010:CAI:1851600.1851687,
 abstract = {In this work we present a method to intuitively issue control over devices in smart environments, to display data that smart objects and sensors provide, and to create and manipulate flows of information in smart environments. This makes it easy to customize smart environments by linking arbitrary data sources to various display modalities on the fly. Touchscreen smartphones - as readily available multi-purpose devices - are used to overlay real objects with virtual controls. We evaluated this system with a first qualitative user study.},
 acmid = {1851687},
 address = {New York, NY, USA},
 author = {Kriesten, Bastian and T\"{u}nnermann, Ren{\'e} and Mertes, Christian and Hermann, Thomas},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851687},
 isbn = {978-1-60558-835-3},
 keyword = {ambient data streams, augmented reality, home automation, mixed reality, mobile devices, mobile interaction},
 link = {http://doi.acm.org/10.1145/1851600.1851687},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {405--406},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Controlling Ambient Information Flow Between Smart Objects with a Mobile Mixed-reality Interface},
 year = {2010}
}


@inproceedings{Weinberg:2010:CPS:1851600.1851621,
 abstract = {We present a driving simulator-based evaluation of a new technique for simplifying in-vehicle device interactions and thereby improving driver safety. We show that the use of multiple, contextually linked push-to-talk buttons (Multi-PTT) shortens voice dialog duration versus the use of a conventional, single push-to-talk button (Single-PTT). This benefit comes without detriment to driving performance or visual attention to the forward roadway. Test subjects also preferred the Multi-PTT approach over the conventional approach, and reported that it imposed a lower cognitive workload.},
 acmid = {1851621},
 address = {New York, NY, USA},
 author = {Weinberg, Garrett and Harsham, Bret and Forlines, Clifton and Medenica, Zeljko},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851621},
 isbn = {978-1-60558-835-3},
 keyword = {driving simulation, listen button, multimodality, push-to-talk, speech recognition, voice dialogs},
 link = {http://doi.acm.org/10.1145/1851600.1851621},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {113--122},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Contextual Push-to-talk: Shortening Voice Dialogs to Improve Driving Performance},
 year = {2010}
}


@inproceedings{Kaufmann:2010:ATR:1851600.1851652,
 abstract = {Ubicomp applications increasingly involve smart phones that control or communicate with embedded systems. Compelling examples in this space include tangible interfaces, environmental sensor networks, game controllers and automated homes. Across research, design, and hobbyist communities there is clearly a desire to build applications that involve combinations of mobile and non-mobile technologies. However, constructing these applications is a laborious process that requires considerable breadth and depth of expertise in programming, electronics, industrial and interaction design. Amarino is a toolkit that enables the rapid prototyping of such applications by connecting the Android operating system to the Arduino microcontroller platform. It consists of an Android application, an Arduino library, and a collection of documentation and examples. This suite of tools allows users to: 1) access Android events (ie: compass orientation, accelerometer data, and text messages received) and send them to Arduino microcontrollers without doing any Android programming, and 2) quickly develop Android applications that receive data (ie: environmental sensor data) from (and send data to) Arduino microcontrollers. This paper introduces Amarino and presents the results of a preliminary user study.},
 acmid = {1851652},
 address = {New York, NY, USA},
 author = {Kaufmann, Bonifaz and Buechley, Leah},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851652},
 isbn = {978-1-60558-835-3},
 keyword = {Arduino, android, communication, interfaces, microcontroller, mobile computing, mobile devices, mobile phones, smart phones, tangible, toolkit, wearables},
 link = {http://doi.acm.org/10.1145/1851600.1851652},
 location = {Lisbon, Portugal},
 numpages = {8},
 pages = {291--298},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Amarino: A Toolkit for the Rapid Prototyping of Mobile Ubiquitous Computing},
 year = {2010}
}


@inproceedings{Vinciarelli:2010:MSS:1851600.1851731,
 abstract = {This paper introduces the First International Workshop on Mobile Social Signal Processing (SSP). The Workshop aims at bringing together the Mobile HCI and Social Signal Processing research communities. The former investigates approaches for effective interaction with mobile and wearable devices, while the latter focuses on modeling, analysis and synthesis of nonverbal behavior in human{human and human-machine interactions. While dealing with similar problems, the two domains have different goals and methodologies. However, mutual exchange of expertise is likely to raise new research questions as well as to improve approaches in both domains. After providing a brief survey of Mobile HCI and SSP, the paper introduces general aspects of the workshop (including topics, keynote speakers and dissemination means).},
 acmid = {1851731},
 address = {New York, NY, USA},
 author = {Vinciarelli, Alessandro and Murray-Smith, Roderick and Bourlard, Herv{\'e}},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851731},
 isbn = {978-1-60558-835-3},
 keyword = {mobile HCI, social signal processing},
 link = {http://doi.acm.org/10.1145/1851600.1851731},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {513--516},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile Social Signal Processing: Vision and Research Issues},
 year = {2010}
}


@inproceedings{Acharya:2010:EUR:1851600.1851688,
 abstract = {Energy consumption that takes place because of industrial sheltered living through amenities such as lighting, heat, ventilation and air conditioning is not fully deciphered by the users when in use, especially in shared public spaces. Here we describe a design intervention, where users in a shared workspace are made aware of the energy consumption and its pattern of use due to ambient lighting through text messages on their personal mobile devices. The text messages contained specially treated information about the energy consumption. This poster describes the design intervention through the prototype description of a 'Usage Responsive Space'.},
 acmid = {1851688},
 address = {New York, NY, USA},
 author = {Acharya, Karthikeya and Mikkonen, Jussi},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851688},
 isbn = {978-1-60558-835-3},
 keyword = {collective feedback, design intervention, energy 2.0, physical resource usage, shared spaces, usage responsive environment},
 link = {http://doi.acm.org/10.1145/1851600.1851688},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {407--408},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Energy Usage Responsive Space and Personal Mobile Devices},
 year = {2010}
}


@inproceedings{Kratz:2010:SZM:1851600.1851615,
 abstract = {In this paper we present a novel interface for mobile map navigation based on Semi-Automatic Zooming (SAZ). SAZ gives the user the ability to manually control the zoom level of an SDAZ interface, while retaining the automatic zooming characteristics of that interface at times when the user is not explicitly controlling the zoom level. In a user study conducted using a realistic mobile map with a wide scale space, we compare SAZ with existing map interface techniques, multi-touch and Speed-Dependent Automatic Zooming (SDAZ). We extend a dynamic state-space model for Speed-Dependent Automatic Zooming (SDAZ) to accept 2D tilt input for scroll rate and zoom level control and implement a dynamically zoomable map view with access to high-resolution map material for use in our study. The study reveals that SAZ performs significantly better than SDAZ and that SAZ is comparable in performance and usability to a standard multi-touch map interface. Furthermore, the study shows that SAZ could serve as an alternative to multi-touch as input technique for mobile map interfaces.},
 acmid = {1851615},
 address = {New York, NY, USA},
 author = {Kratz, Sven and Brodien, Ivo and Rohs, Michael},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851615},
 isbn = {978-1-60558-835-3},
 keyword = {SDAZ, automatic zoom, dynamics, mobile devices, tilt input, zooming-scrolling ui},
 link = {http://doi.acm.org/10.1145/1851600.1851615},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {63--72},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Semi-automatic Zooming for Mobile Map Navigation},
 year = {2010}
}


@inproceedings{Anastassova:2010:UAH:1851600.1851734,
 abstract = {The goal of this full-day workshop is to initiate a discussion on the design and presentation of audio and haptic spatial information on mobile devices. We would like to invite researchers working in the fields of human-computer interaction, computer science, cognitive sciences, psychology, psychophysics, and mechatronics to submit a position paper and/or a demo presentation dealing with topics such as methodologies for representing multisensory spatial information on mobile devices, new interaction techniques, specific evaluation methods.},
 acmid = {1851734},
 address = {New York, NY, USA},
 author = {Anastassova, Margarita and Magnusson, Charlotte and Pielot, Martin and Randall, Gary and Claassen, Ginger B.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851734},
 isbn = {978-1-60558-835-3},
 keyword = {audio, design, evaluation, geospatial information, haptics, metaphors},
 link = {http://doi.acm.org/10.1145/1851600.1851734},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {525--526},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Using Audio and Haptics for Delivering Spatial Information via Mobile Devices},
 year = {2010}
}


@inproceedings{Nguyen:2010:UNS:1851600.1851678,
 abstract = {In this paper we describe our research toward improving the current mobile contacts applications, which we found to lack important features that are essential to a fully satisfactory user experience. We identify the needs for a better user experience for organizing and searching, as well as looking for information from one's social network. We present the results of a user study that identified the problems with the current mobile contacts applications and propose tagging contacts and social network information sharing as the mechanism for improving their usability and usefulness.},
 acmid = {1851678},
 address = {New York, NY, USA},
 author = {Nguyen, Trung Van and Oh, Alice Hae Yun},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851678},
 isbn = {978-1-60558-835-3},
 keyword = {mobile contacts application design, mobile recommendation system, mobile tagging, user study},
 link = {http://doi.acm.org/10.1145/1851600.1851678},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {387--388},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Users' Needs for Social Tagging and Sharing on Mobile Contacts},
 year = {2010}
}


@inproceedings{Koskela:2010:SUP:1851600.1851700,
 abstract = {The use of Voice over IP (VoIP) applications involves a number of security threats and usability issues, leading to possible breaches of security and privacy. With the adoption of future peer-to-peer communication systems, the challenges grow even more as we rely on untrusted peers to access the service. We are developing a peer-to-peer VoIP system which features techniques for improving the security and privacy of users in future networks. However, as the threats are seldom well understood, presenting them in a usable manner is problematic. Implemented on a mobile device, the small user interface provides additional challenges for the end user. Via interviews, a questionnaire and usability testing, we seek to improve both the usability of managing and understanding the additional security, as well as the overall user experience of the emerging application.},
 acmid = {1851700},
 address = {New York, NY, USA},
 author = {Koskela, Joakim and Karvonen, Kristiina and Kilinkaridis, Theofanis and Gurtov, Andrei},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851700},
 isbn = {978-1-60558-835-3},
 keyword = {VoIP, peer-to-peer, usable security, user study},
 link = {http://doi.acm.org/10.1145/1851600.1851700},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {439--442},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Secure and Usable P2P VoIP for Mobile Devices},
 year = {2010}
}


@inproceedings{Ketabdar:2010:TUE:1851600.1851626,
 abstract = {We present a new technique based on using embedded compass (magnetic) sensor for efficient use of 3D space around a mobile device for interaction with the device. Around Device Interaction (ADI) enables extending interaction space of small mobile and tangible devices beyond their physical boundary. Our proposed method is based on using compass (magnetic field) sensor integrated in new mobile devices (e.g. iPhone 3GS, G1/2 Android). In this method, a properly shaped permanent magnet (e.g. a rod, pen or a ring) is used for interaction. The user makes coarse gestures in 3D space around the device using the magnet. Movement of the magnet affects magnetic field sensed by the compass sensor integrated in the device. The temporal pattern of the gesture is then used as a basis for sending different interaction commands to the mobile device. The proposed method does not impose changes in hardware and physical specifications of the mobile device, and unlike optical methods is not limited by occlusion problems. Therefore, it allows for efficient use of 3D space around device, including back of device. Zooming, turning pages, accepting/rejecting calls, clicking items, controlling a music player, and mobile game interaction are some example use cases. Initial evaluation of our algorithm using a prototype application developed for iPhone shows convincing gesture classification results.},
 acmid = {1851626},
 address = {New York, NY, USA},
 author = {Ketabdar, Hamed and Roshandel, Mehran and Y\"{u}ksel, Kamer Ali},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851626},
 isbn = {978-1-60558-835-3},
 keyword = {around device 3D interaction, embedded compass (magnetic) sensor, mobile devices, movement-based gestures, properly shaped magnet},
 link = {http://doi.acm.org/10.1145/1851600.1851626},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {153--156},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Towards Using Embedded Magnetic Field Sensor for Around Mobile Device 3D Interaction},
 year = {2010}
}


@inproceedings{Schildbach:2010:ISR:1851600.1851619,
 abstract = {More and more people interact with their mobile phone while walking. The presented research analyzes; firstly, the negative effect of walking when considering reading and target selection tasks, such as weaker performance and higher workload. Here, we focused on one-handed interaction with a touch screen whereby the thumb is used as the input device. Secondly, we analyze how these negative effects can be compensated by increasing the text size and the size of the targets to select on the mobile phone. A comparative user study was conducted with 16 participants who performed target acquisition and reading tasks while standing and walking. The results show that whilst performance decreases, cognitive load increases significantly when reading and selecting targets when walking. Furthermore, the results show that the negative effect regarding target selection can be compensated by increasing the target size, but the text reading task did not yield better performance results for a larger text size due to the increased demand for scrolling. These results can be used to inform future designs of mobile user interfaces which might provide a dedicated walking mode.},
 acmid = {1851619},
 address = {New York, NY, USA},
 author = {Schildbach, Bastian and Rukzio, Enrico},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851619},
 isbn = {978-1-60558-835-3},
 keyword = {mobile interaction, reading, target selection, walking},
 link = {http://doi.acm.org/10.1145/1851600.1851619},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {93--102},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Investigating Selection and Reading Performance on a Mobile Phone While Walking},
 year = {2010}
}


@inproceedings{Lang:2010:SPM:1851600.1851613,
 abstract = {To explore opportunities for technology adoption in emerging markets, we conducted ethnographic studies to understand the social practices and technology use of young migrant workers in China. In total twenty-six young migrant workers, aged 19-28, were interviewed and/or shadowed in three cities (Beijing, Hangzhou, and Xi'an). We found that social practices play a significant role in the life of the research participants, who live in stressful and "unfriendly" urban environments and have a lower social status than urban residents. Moreover, we found that these social practices act as a primary driver for mobile phones adoption and use. Personal mobile phones were quickly adopted and frequently used to initiate, maintain and enhance social connections, as well as the quality of social practices. Based on the research findings, we discuss several design directions for making mobile phones play a greater role in social practices.},
 acmid = {1851613},
 address = {New York, NY, USA},
 author = {Lang, Xueming and Oreglia, Elisa and Thomas, Suzanne},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851613},
 isbn = {978-1-60558-835-3},
 keyword = {emerging markets, mobile phone, social practices, young migrant workers},
 link = {http://doi.acm.org/10.1145/1851600.1851613},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {59--62},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Social Practices and Mobile Phone Use of Young Migrant Workers},
 year = {2010}
}


@inproceedings{Hinze:2010:CQE:1851600.1851658,
 abstract = {The users of mobile devices increasingly use networked services to address their information needs. Questions asked by mobile users are strongly influenced by contextual factors such as location, conversation and activity. We report on a diary study performed to better understand mobile information needs. We find that the type of questions recorded by participants varies across their locations, with differences between home, shopping and in-car contexts. These variations occur both in the query terms and in the form of desired answers. Both the location of queries and the participants' activities affected participants' questions. When information needs were affected by both location and activity, they tended to be strongly affected by both factors. The overall picture that emerges is one of multiple contextual influences interacting to shape mobile information needs. Mobile devices that attempt to adapt to users' context will need to account for a rich variety of situational factors.},
 acmid = {1851658},
 address = {New York, NY, USA},
 author = {Hinze, Annika M. and Chang, Carole and Nichols, David M.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851658},
 isbn = {978-1-60558-835-3},
 keyword = {context, diary study, location, mobile information needs, user requirements},
 link = {http://doi.acm.org/10.1145/1851600.1851658},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {327--336},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Contextual Queries Express Mobile Information Needs},
 year = {2010}
}


@inproceedings{Feige:2010:ICR:1851600.1851669,
 abstract = {Current planning tools for cycling trips do not sufficiently support the often explorative, spontaneous nature of cycling as route creation is not provided in a way suitable for usage on typical mobile devices in situ. In close cooperation with the target group, we developed and evaluated an approach where cycling routes based on selected images of points of interest can be generated on-the-fly.},
 acmid = {1851669},
 address = {New York, NY, USA},
 author = {Feige, Sebastian and Wenig, Dirk and Pantel, Christoph and Malaka, Rainer},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851669},
 isbn = {978-1-60558-835-3},
 keyword = {cycling, mobile applications, route generation, trip planning},
 link = {http://doi.acm.org/10.1145/1851600.1851669},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {369--370},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Image-based Cycle Route Generation on Mobile Devices},
 year = {2010}
}


@inproceedings{Vazquez-Alvarez:2010:DSA:1851600.1851716,
 abstract = {Audio interfaces are becoming more important due to the increasing functionality of today's mobile devices. As a result, more complex audio-driven eyes-free interactions are required when mobile. The aim of my work is to evaluate 3D audio techniques used to implement auditory displays that support multitasking and access to context information in interactive mobile environments.},
 acmid = {1851716},
 address = {New York, NY, USA},
 author = {Vazquez-Alvarez, Yolanda},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851716},
 isbn = {978-1-60558-835-3},
 keyword = {3D audio, audio interfaces, context information, mobile devices, multitasking},
 link = {http://doi.acm.org/10.1145/1851600.1851716},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {481--482},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Designing Spatial Audio Interfaces for Mobile Devices: Supporting Multitasking and Context Information},
 year = {2010}
}


@inproceedings{Reitmaier:2010:FTM:1851600.1851649,
 abstract = {We describe and reflect on a method we used to evaluate usability and give insights on situated use of a mobile digital storytelling prototype. We report on rich data we gained by implementing this method and argue that we were able to learn more about our prototype, users, their needs, and their context, than we would have through other evaluation methods. We look at the usability problems we uncovered and discuss how our flexibility in field-testing allowed us to observe unanticipated usage, from which we were able to motivate future design directions. Finally, we reflect on the importance of spending time in-situ during all stages of design, especially when designing across cultures.},
 acmid = {1851649},
 address = {New York, NY, USA},
 author = {Reitmaier, Thomas and Bidwell, Nicola J. and Marsden, Gary},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851649},
 isbn = {978-1-60558-835-3},
 keyword = {HCI4D, digital storytelling, evaluation, probe, rural},
 link = {http://doi.acm.org/10.1145/1851600.1851649},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {283--286},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Field Testing Mobile Digital Storytelling Software in Rural Kenya},
 year = {2010}
}


@inproceedings{Schmid:2010:SLG:1851600.1851617,
 abstract = {This paper presents a novel solution to the focus-and-context problem of mobile maps provided for local and global orientation. Our solution is inspired by the design principles of static You-Are-Here maps and realizes principles of human spatial cognition to enable efficient communication of location information. We further propose selective interaction with the presented information to improve the speed and accuracy of interpretation of the geographic information. Tests show strong evidence for the cognitive and interaction efficiency of the resulting maps, as users were faster and more accurate than with conventional mobile maps.},
 acmid = {1851617},
 address = {New York, NY, USA},
 author = {Schmid, Falko and Kuntzsch, Colin and Winter, Stephan and Kazerani, Aisan and Preisig, Benjamin},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851617},
 isbn = {978-1-60558-835-3},
 keyword = {detail-in-context, focus and context, localization, location-based services, spatial awareness, spatial cognition, you-are-here maps},
 link = {http://doi.acm.org/10.1145/1851600.1851617},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {83--92},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Situated Local and Global Orientation in Mobile You-are-here Maps},
 year = {2010}
}


@inproceedings{VazquezAlvarez:2010:DSA:1851600.1851642,
 abstract = {Auditory interfaces offer a solution to the problem of effective eyes-free mobile interactions. However, a problem with audio, as opposed to visual displays, is dealing with multiple simultaneous outputs. Any audio interface needs to consider: 1) simultaneous versus sequential presentation of multiple audio streams, 2) 3D audio techniques to place sounds in different spatial locations versus a single point of presentation, 3) dynamic movement versus fixed locations of audio sources. We present an experiment using a divided-attention task where a continuous podcast and an audio menu compete for attention. A sequential presentation baseline assessed the impact of cognitive load, and as expected, dividing attention had a significant effect on overall performance. However, spatial audio still increased the users' ability to attend to two streams, while dynamic movement of streams led to higher perceived workload. These results will provide guidelines for designers when building eyes-free auditory interfaces for mobile applications.},
 acmid = {1851642},
 address = {New York, NY, USA},
 author = {Vazquez Alvarez, Yolanda and Brewster, Stephen A.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851642},
 isbn = {978-1-60558-835-3},
 keyword = {auditory interfaces, divided-attention task, mobile systems, multiple audio streams, spatial audio},
 link = {http://doi.acm.org/10.1145/1851600.1851642},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {253--256},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Designing Spatial Audio Interfaces to Support Multiple Audio Streams},
 year = {2010}
}


@inproceedings{Pielot:2010:PVW:1851600.1851696,
 abstract = {Pedestrian navigation systems are becoming popular but the currently dominant audio-visual interaction can have drawbacks. Tactile feedback is studied as a solution, but currently only available as research prototypes. With the PocketNavigator we propose a demonstrator that adds tactile feedback to a simple but robust map-based navigation system that runs on any Android Smartphone. Users can leave the device in the pocket, while being guided non-visually through vibration cues. Like a compass we "point at" the next waypoint by encoding its direction and distance in vibration patterns. As an advantage over previous approaches it allows giving continuous feedback instead of isolated turning instructions and it can be realized without custom-built tactile displays. Preliminary results from a field study show that pedestrian can effectively use this Tactile Compass to reach a destination without turn-by-turn instructions. Integrated into the PocketNavigator we can now deploy it at the Android Market to evaluate the Tactile Compass with a wide range of users.},
 acmid = {1851696},
 address = {New York, NY, USA},
 author = {Pielot, Martin and Poppinga, Benjamin and Boll, Susanne},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851696},
 isbn = {978-1-60558-835-3},
 keyword = {pedestrian navigation, tactile displays},
 link = {http://doi.acm.org/10.1145/1851600.1851696},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {423--426},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {PocketNavigator: Vibro-tactile Waypoint Navigation for Everyday Mobile Devices},
 year = {2010}
}


@inproceedings{Wilson:2010:PMS:1851600.1851631,
 abstract = {Despite many successes in desktop applications, little work has looked at the use of pressure input on mobile devices and the different issues associated with mobile interactions e.g. non-visual feedback. This study examined pressure input on a mobile device using a single Force Sensing Resistor (FSR) with linearised output as a means of target selection within a menu, where target menu items varied in size and location along the z-axis. Comparing visual and audio feedback, results showed that, overall, eyes-free pressure interaction reached a mean level of 74% accuracy. With visual feedback mean accuracy reached 85%. Participants could accurately distinguish up to 10 pressure levels when given adequate feedback indicating a high level of control.},
 acmid = {1851631},
 address = {New York, NY, USA},
 author = {Wilson, Graham and Stewart, Craig and Brewster, Stephen A.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851631},
 isbn = {978-1-60558-835-3},
 keyword = {mobile interaction, non-visual feedback, pressure input},
 link = {http://doi.acm.org/10.1145/1851600.1851631},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {181--190},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Pressure-based Menu Selection for Mobile Devices},
 year = {2010}
}


@inproceedings{Gupta:2010:PTT:1851600.1851710,
 abstract = {Pulse Tangible Touch is a concept demonstrating the possibilities with touch-based interfaces. The concept can be universally applied to any product that uses a touch-based interface as the input method. The interface is made up of a screen that is flexible in nature. This flexible screen rises in the form of a button when it senses the proximity of a finger},
 acmid = {1851710},
 address = {New York, NY, USA},
 author = {Gupta, Gaurang},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851710},
 isbn = {978-1-60558-835-3},
 keyword = {tactile, tactile feedback},
 link = {http://doi.acm.org/10.1145/1851600.1851710},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {471--472},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Pulse: Tangible Touch},
 year = {2010}
}


@inproceedings{Wagner:2010:HSL:1851600.1851612,
 abstract = {This paper presents a multi-pronged study of users' location-sharing practices in the context of online social networks. The contribution of this study is two-fold: first it presents a series of insights relating to location-sharing practices, and second it highlights the use of third-person scenarios as a useful method for eliciting privacy concerns and potentially educating users.},
 acmid = {1851612},
 address = {New York, NY, USA},
 author = {Wagner, Daniel and Lopez, Mariana and Doria, Andre and Pavlyshak, Iryna and Kostakos, Vassilis and Oakley, Ian and Spiliotopoulos, Tasos},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851612},
 isbn = {978-1-60558-835-3},
 keyword = {location sharing, privacy, social network},
 link = {http://doi.acm.org/10.1145/1851600.1851612},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {55--58},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Hide and Seek: Location Sharing Practices with Social Media},
 year = {2010}
}


@inproceedings{Lee:2010:UEB:1851600.1851662,
 abstract = {Radio Frequency Identification (RFID) provides various opportunities to increase the productivity of retail business. In this paper, we describe a usability evaluation study for an RFID-based location tracking application, called Beep-To-The-Box (BTTB). The experiment was conducted in a simulated retail store to gain in-depth understanding of the usefulness and usability of the prototype in determining visual and audio user interface features. We describe the features of the BTTB, report the experimental results, and discuss insights gained to provide design recommendations for the final product design.},
 acmid = {1851662},
 address = {New York, NY, USA},
 author = {Lee, Young Seok and Basapur, Santosh and Zhang, Harry and Guerrero, Claudia and Massey, Noel},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851662},
 isbn = {978-1-60558-835-3},
 keyword = {RFID, indoor location tracking, usability, visual and auditory UI design},
 link = {http://doi.acm.org/10.1145/1851600.1851662},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {345--348},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Usability Evaluation of Beep-to-the-box},
 year = {2010}
}


@inproceedings{Broll:2010:MPU:1851600.1851624,
 abstract = {Near Field Communication (NFC) is an emerging technology for mobile interaction with everyday objects and associated digital resources. Apart from simple interactions with single tags, NFC has the potential for more elaborate interactions with physical objects that comprise multiple tags and serve as physical user interfaces (UI). This paper investigates the design of mobile and physical UIs for the interaction with multiple NFC-tags. It focuses on three basic interactions that qualify for multi-tag interaction - the navigation between parts of an application, the selection of items and the combination of items. Two user studies compare different configurations of mobile and physical UIs for these interactions in order to evaluate the allocation of application features and UI elements to mobile devices and tagged objects. The results advocate the continuous interaction on the latter, instead of splitting interactions between mobile and physical UIs.},
 acmid = {1851624},
 address = {New York, NY, USA},
 author = {Broll, Gregor and Hausen, Doris},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851624},
 isbn = {978-1-60558-835-3},
 keyword = {NFC, evaluation, multi-tag interaction, near field communication, physical user interface, single-tag interaction, usability},
 link = {http://doi.acm.org/10.1145/1851600.1851624},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {133--142},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile and Physical User Interfaces for NFC-based Mobile Interaction with Multiple Tags},
 year = {2010}
}


@inproceedings{Baudisch:2010:MNP:1851600.1851601,
 abstract = {Neither desktop computers nor the hundred-dollar laptop are the new mass computation platform of this world - mobile phones are. 4 Billion of them. So how come we still use PCs? Mobile devices have a major limitation: mobility requires smallness. Initially, miniaturization of hardware drove miniaturization at a fast pace, but limitations are not primarily technical anymore: today, it is almost exclusively human factors. Screens need to be large enough to be seen, keyboards large enough to be typed on. These factors, however, are practically invariant. In this presentation, I take a closer look at the research that emerges from the tension between the desire to perform complex tasks and the desire for mobility. Is it possible for mobile users to perform those complex tasks that today's users still perform on "large screen" desktop computers? What range of applications can we adapt by visually compressing them? What applications resist such an adaptation and why? In the second half of the talk, I am trying to look into the future of mobile device hardware, devices ten times smaller than today's devices.},
 acmid = {1851601},
 address = {New York, NY, USA},
 author = {Baudisch, Patrick},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851601},
 isbn = {978-1-60558-835-3},
 keyword = {mobile applications, user interface design},
 link = {http://doi.acm.org/10.1145/1851600.1851601},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {1--2},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {My New Pc is a Mobile Phone: Techniques and Technology for the New Smallness},
 year = {2010}
}


@inproceedings{Bergman:2010:IF:1851600.1851641,
 abstract = {Mobile devices offer challenges for UI design. Limited screen space leads to deep menus, complex navigation and loss of position. We introduce a new user interface concept that reverses the traditional navigation paradigm. By utilizing context awareness and allowing the user to control the UI via filters, objects of interest navigate past the user instead of the user navigating to the object. The user operates on a single view without the need for deep menu navigation. The new UI is also easy to configure. We implemented the concept on the Nokia S60 5th edition touch platform and conducted user testing with 16 users. Initially, users felt confused because of new ways of accessing things. However, after a short period of usage, majority of the users found it easy to use. Most of the users felt the system to be fun and playful.},
 acmid = {1851641},
 address = {New York, NY, USA},
 author = {Bergman, Janne and Vainio, Janne},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851641},
 isbn = {978-1-60558-835-3},
 keyword = {content agnostic, context awareness, flowing objects, mobile user interfaces, new user interface concept},
 link = {http://doi.acm.org/10.1145/1851600.1851641},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {249--252},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Interacting with the Flow},
 year = {2010}
}


@inproceedings{Niu:2010:SHC:1851600.1851675,
 abstract = {In this paper we present Stroke++, a novel hybrid Chinese input method for touch screen mobile phones that leverages hieroglyphic properties of Chinese characters to enable faster and easier input of Chinese characters on mobile phones. By using a special keypad layout, a friendly user interface and an adaptive radical selection algorithm, we achieved a competitive inputting performance compared with currently prevalent mobile Chinese input methods, while keeping a low entry barrier for Chineseinput novices. An extensive evaluation results show that Stroke++ out-performs the state-of-the-art keystroke-based or handwriting recognition-based Chinese character inputting methods, as far as the input speed and convenience are concerned.},
 acmid = {1851675},
 address = {New York, NY, USA},
 author = {Niu, Jianwei and Zhu, Like and Yan, Qifeng and Liu, Yingfei and Wang, Kongqiao},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851675},
 isbn = {978-1-60558-835-3},
 keyword = {chinese input, chinese radicals, mobile devices, touch screen, virtual keyboard},
 link = {http://doi.acm.org/10.1145/1851600.1851675},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {381--382},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Stroke++: A Hybrid Chinese Input Method for Touch Screen Mobile Phones},
 year = {2010}
}


@inproceedings{Mangold:2010:SVM:1851600.1851686,
 abstract = {The paper presents and discusses a prototype for the tracking and visualization of mobile user experience using the example of emergency management and response. The tracking prototype consists of GPS-devices and mini video cameras. The approach is based on time-geographic methods of visualization. It represents user interactions, mobile communication and media use in its locative and temporal dimensions. Using a spatiotemporal approach to mobile communities allows insights about the structure of mobile interactions, mobile communities and mobile user contexts.},
 acmid = {1851686},
 address = {New York, NY, USA},
 author = {Mangold, Benjamin},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851686},
 isbn = {978-1-60558-835-3},
 keyword = {human centered design, mobile communities, mobile social networks, mobile user experience, spatiotemporal dynamics, time geography, tracking, visualization},
 link = {http://doi.acm.org/10.1145/1851600.1851686},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {403--404},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Spatiotemporal Visualization of Mobile User Experience},
 year = {2010}
}


@inproceedings{Guerreiro:2010:AMI:1851600.1851718,
 abstract = {Every human is different. This diversity has not been given enough attention in mobile UI design. Disabled groups, with specific individual differences, face difficulties with traditional or stereotypical interfaces. My goal is to identify the individual features that influence mobile interaction, considering the blind, and match them with mobile interaction modalities in a comprehensive and extensible design space.},
 acmid = {1851718},
 address = {New York, NY, USA},
 author = {Guerreiro, Tiago},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851718},
 isbn = {978-1-60558-835-3},
 keyword = {assessment, blind, individual differences, mobile accessibility},
 link = {http://doi.acm.org/10.1145/1851600.1851718},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {485--486},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Assessing Mobile-wise Individual Differences in the Blind},
 year = {2010}
}


@inproceedings{deSa:2010:GCP:1851600.1851693,
 abstract = {Social competency training, as part of psychotherapy, for children and teenagers, requires them to engage on outdoor activities in which they have to complete tasks such as talking to someone or visiting a specific place. Currently, the inability for therapists to monitor their patients, to promote collaborative efforts and to reinforce positive attitudes is a major issue that affects both the therapy process and its results. In this paper we present an evaluation experience of a mobile prototype for a geo-referenced collaborative system that supports in-situ group therapy. We describe the concept, our initial low-fi prototypes and the experiments that were undertaken to validate them. Initial results are discussed and future work is defined.},
 acmid = {1851693},
 address = {New York, NY, USA},
 author = {de S\'{a}, Marco and Carri\c{c}o, Lu\'{\i}s and Faria, Jo\~{a}o and S\'{a}, Isabel and Baloian, Nelson and Zurita, Gustavo},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851693},
 isbn = {978-1-60558-835-3},
 keyword = {geo-referenced collaboration, mobile devices, psychotherapy},
 link = {http://doi.acm.org/10.1145/1851600.1851693},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {417--418},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Geo-referenced Collaborative Psychotherapy: Design and Evaluation of a Low-fidelity Prototype},
 year = {2010}
}


@inproceedings{vonNiman:2010:GV:1851600.1851725,
 abstract = {Gurus' Views 2010 is the sixth edition of the expert panel, addressing some of the hottest, most current and important user experience topics in an open interaction between experts and with the conference audience. The previous panels held at Mobile HCI 2003 in Udine, CHI 2004 in Vienna, Mobile HCI 2005 in Salzburg, HFT 2006 in Sophia Antipolis, and HFT 2008 in Kuala Lumpur, organized by Bruno von Niman in collaboration with and always populated by senior, professional authorities have provided useful insight into some areas and have been appreciated by a global audience. Some topics addressed by the experts are identified and prepared well ahead of the event, while others may be added late or even brought up during the panel, even by the audience. Some experts are pre-invited, while others may be added late, in order to provide the most relevant coverage of the issues discussed. Not all opinions expressed by the experts during the panel debate will necessarily reflect corporate positions but may be consisting of individual viewpoints based on experience, best practices or any other empirical evidence or gut feeling. The following pages may provide some further insight.},
 acmid = {1851725},
 address = {New York, NY, USA},
 author = {von Niman, Bruno and Fonseca, Jos{\'e} Manuel Cantera},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851725},
 isbn = {978-1-60558-835-3},
 keyword = {ICT, accessibility, mobile, usability, user experience, user interfaces},
 link = {http://doi.acm.org/10.1145/1851600.1851725},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {497--498},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {The Gurus' Views 2010},
 year = {2010}
}


@inproceedings{Juhlin:2010:MBW:1851600.1851610,
 abstract = {A new type of social medium, which allows users to broadcast live video from mobile devices to websites on the internet, is becoming increasingly popular. We provide a qualitative content analysis of a sample from four such services. The analysis specifically focuses on the topics presented, camerawork, and coordination, in order to investigate the possibilities and barriers to wider adoption of this new social medium. Although the services are growing in numbers of users, the study reveals an immature application area. People struggle to find interesting topics to broadcast and to manage the camera in a way that presents them in an appealing form. But there are also examples of topics such as artistic performances and tours, as well as ways to conduct live transitions and coordination, that point to a more medium-specific way of using these services. The results indicate that providing the opportunity to broadcast live video is not enough, and that there is now a need to design for amateurs' appropriation of camera handling techniques.},
 acmid = {1851610},
 address = {New York, NY, USA},
 author = {Juhlin, Oskar and Engstr\"{o}m, Arvid and Reponen, Erika},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851610},
 isbn = {978-1-60558-835-3},
 keyword = {content analysis, live broadcast, mobile, social media, video, webcast},
 link = {http://doi.acm.org/10.1145/1851600.1851610},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {35--44},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile Broadcasting: The Whats and Hows of Live Video As a Social Medium},
 year = {2010}
}


@inproceedings{Battestini:2010:LSS:1851600.1851638,
 abstract = {Text messaging has become a popular form of communication with mobile phones worldwide. We present findings from a large scale text messaging study of 70 university students in the United States. We collected almost 60, 000 text messages over a period of 4 months using a custom logging tool on our participants' phones. Our re- sults suggest that students communicate with a large number of contacts for extended periods of time, engage in simultaneous conversations with as many as 9 contacts, and often use text messaging as a method to switch between a variety of communication mediums. We also explore the content of text messages, and ways text message habits have changed over the last decade as it has become more popular. Finally, we offer design suggestions for future mobile communication tools.},
 acmid = {1851638},
 address = {New York, NY, USA},
 author = {Battestini, Agathe and Setlur, Vidya and Sohn, Timothy},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851638},
 isbn = {978-1-60558-835-3},
 keyword = {large-scale study, mobile device, short message service, sms, text messaging, texting},
 link = {http://doi.acm.org/10.1145/1851600.1851638},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {229--238},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {A Large Scale Study of Text-messaging Use},
 year = {2010}
}


@inproceedings{Verma:2010:FIH:1851600.1851708,
 abstract = {We propose "Find It," a set of two features to improve the browsing experience for screen reader users, particularly individuals living with vision loss or blindness. The two features, Tagging and Quick Scrolling, enable users to organize information and focus on relevant details to efficiently and rapidly access their element of interest in lists. Tagging allows users to annotate any message, contact, or file using either a typed or a spoken word for efficient retrieval. Quick Scrolling is a touch-screen based feature that allows users to listen to selected fields of a list at a time and skip sections irrelevant to the search. This combination of tagging and scrolling has the potential to expedite list searching when using screen readers with mobile devices.},
 acmid = {1851708},
 address = {New York, NY, USA},
 author = {Verma, Namrata and Shetye, Priyanka and Gangopadhyay, Diya and Bisht, Mukul and Pavlyshak, Iryna},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851708},
 isbn = {978-1-60558-835-3},
 keyword = {assistive technologies, information search and retrieval, mobile search, multi-scrolling, screen readers, tagging, visually impaired},
 link = {http://doi.acm.org/10.1145/1851600.1851708},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {467--470},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Find It: Information at Hand},
 year = {2010}
}


@inproceedings{Petersen:2010:THM:1851600.1851646,
 abstract = {For many people home making is an activity, which extends beyond a single house. We introduce the terminology of Homing as the act of home making, when in a primary home, secondary home or more temporary spaces. By point of departure in existing literature on home making and through ethnographic studies of extremely mobile people we identify general tactics for homing. We present the identified tactics and show how people deploy not only one but several tactics in their intention of making a homely feeling despite not being in their primary home. We review the mobile technologies currently in use and argue that several of the tactics identified are currently not well supported. We discuss how technology design can learn from this study through pointing to the potential in designing mobile technologies to better support these unsupported tactics. We consider the tactics as a tool for deeper understanding of mobile practices and thus informing the design of more relevant future technologies for people engaged in a mobile lifestyle.},
 acmid = {1851646},
 address = {New York, NY, USA},
 author = {Petersen, Marianne Graves and Lynggaard, Aviaja Borup and Krogh, Peter Gall and Winther, Ida Wentzel},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851646},
 isbn = {978-1-60558-835-3},
 keyword = {deleuze, design, ethnography, home, making home, mobility, tactics},
 link = {http://doi.acm.org/10.1145/1851600.1851646},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {265--274},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Tactics for Homing in Mobile Life: A Fieldwalk Study of Extremely Mobile People},
 year = {2010}
}


@inproceedings{Munteanu:2010:AML:1851600.1851697,
 abstract = {Basic literacy skills are fundamental building blocks of education, yet for a very large number of adults tasks such as understanding and using everyday items is a challenge. While research, industry, and policy-making is looking at improving access to textual information for low-literacy adults, the literacy-based demands of today's society are continually increasing. Although many community-based organizations offer resources and support to adults with limited literacy skills, current programs have difficulties reaching and retaining those that would benefit most from them. To address these challenges, the National Research Council of Canada is proposing a technological solution to support literacy programs and to assist low-literacy adults in today's information-centric society: ALEX© - Adult Literacy support application for EXperiential learning. ALEX© has been created together with low-literacy adults, following guidelines for inclusive design of mobile assistive tools. It is a mobile language assistant that is designed to be used both in the classroom and in daily life, in order to help low-literacy adults become increasingly literate and independent.},
 acmid = {1851697},
 address = {New York, NY, USA},
 author = {Munteanu, Cosmin and Lumsden, Joanna and Fournier, H{\'e}l\`{e}ne and Leung, Rock and D'Amours, Danny and McDonald, Daniel and Maitland, Julie},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851697},
 isbn = {978-1-60558-835-3},
 keyword = {assistive technology, educational interfaces, interface design, mobile computing, mobile learning},
 link = {http://doi.acm.org/10.1145/1851600.1851697},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {427--430},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {ALEX: Mobile Language Assistant for Low-literacy Adults},
 year = {2010}
}


@inproceedings{Eslambolchilar:2010:NIT:1851600.1851735,
 abstract = {The aim of this workshop is to provide a focal point for research and technology dedicated to persuasion and influence on mobile platforms. We aspire to establish a scientific network and community dedicated to emerging technologies for persuasion using mobile devices. This workshop would be a unique opportunity for interaction designers and researchers in this area to share their latest research and technologies on 'nudge' methods with the scientific communities. Patterns of consumption such as drinking and smoking are shaped by the taken-for-granted practices of everyday life. However, these practices are not fixed and 'immensely malleable'. Consequently, it is important to understand how the habits of everyday life change and evolve. Our decisions are inevitably influenced by how the choices are presented. Therefore, it is legitimate to deliberately 'nudge' people's behaviour in order to improve their lives. Mobile devices can play a significant role in shaping normal practices in three distinct ways: (1) they facilitate the capture of information at the right time and place; (2) they provide non-invasive and cost effective methods for communicating personalised data that compare individual performance with relevant social group performance; and (3) social network sites running on the device facilitate communication of personalised data that relate to the participant's self-defined community. Among the issues the workshop will take on are:(a) What opportunities do mobile interventions provide? (b) How far the intervention should go? (c) Is persuasion ethical? and (d) How can we extend the scale of intervention in a society using mobile devices? Participants will contribute to the workshop with examples of nudge and persuasive technologies, and we will work together to create novel ideas, interactive applications on the phone, and discuss future opportunities.},
 acmid = {1851735},
 address = {New York, NY, USA},
 author = {Eslambolchilar, Parisa and Wilson, Max L. and Komninos, Andreas},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851735},
 isbn = {978-1-60558-835-3},
 keyword = {behavioral wedge, influence, mobile devices, mobile phones, nudge, social norms},
 link = {http://doi.acm.org/10.1145/1851600.1851735},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {527--530},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Nudge \&\#38; Influence Through Mobile Devices},
 year = {2010}
}


@inproceedings{Sarmento:2010:MSE:1851600.1851691,
 abstract = {The increasing usage of mobile technologies for service provision has created the need to understand customer mobile service experiences and to integrate designer's and technology's perspectives for the design of successful mobile services. This paper presents the results of a qualitative study with 44 mobile service customers, providing an in-depth understanding of the experience factors that contribute to design improved mobile services. The study' results indicate that traditional interface factors, such as usefulness and ease of use, continue to be important. However, the study reveals that contextual factors, such as the social environment and service atmosphere, are very important for the mobile service experience. These results reinforce the need to adopt a broader view of the experience factors for the effective design of mobile services.},
 acmid = {1851691},
 address = {New York, NY, USA},
 author = {Sarmento, Teresa and Patr\'{\i}cio, Lia},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851691},
 isbn = {978-1-60558-835-3},
 keyword = {mobile services, service experience, service innovation},
 link = {http://doi.acm.org/10.1145/1851600.1851691},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {413--414},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile Service Experiences: Qualitative Study with a Broader Perspective},
 year = {2010}
}


@inproceedings{Hardy:2010:MIS:1851600.1851623,
 abstract = {This paper reports on a development framework, two prototypes, and a comparative study in the area of multi-tag Near-Field Communication (NFC) interaction. By combining NFC with static and dynamic displays, such as posters and projections, services are made more visible and allow users to interact with them easily by interacting directly with the display with their phone. In this paper, we explore such interactions, in particular, the combination of the phone display and large NFC displays. We also compare static displays and dynamic displays, and present a list of deciding factors for a particular deployment situation. We discuss one prototype for each display type and developed a corresponding framework which can be used to accelerate the development of such prototypes whilst supporting a high level of versatility. The findings of a controlled comparative study indicate, among other things, that all participants preferred the dynamic display, although the static display has advantages, e.g. with respect to privacy and portability.},
 acmid = {1851623},
 address = {New York, NY, USA},
 author = {Hardy, Robert and Rukzio, Enrico and Holleis, Paul and Wagner, Matthias},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851623},
 isbn = {978-1-60558-835-3},
 keyword = {dynamic display, mobile interaction, near field communication (NFC), static display},
 link = {http://doi.acm.org/10.1145/1851600.1851623},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {123--132},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile Interaction with Static and Dynamic NFC-based Displays},
 year = {2010}
}


@inproceedings{Nicolau:2010:PMC:1851600.1851670,
 abstract = {We are moving towards a future where people will be ever more surrounded by technology and multiple appliances, bringing about the promise of truly intelligent environments. However, this multitude of devices raises several issues to HCI practitioners. Indeed, our preliminary studies confirm that blind people experience difficulties with most appliances, due to inadequate interfaces. The research described here approaches this problem by moving the user interface away from appliances to an intermediary device, which blind people are familiar with and can fully control. Additionally, we propose an automatic generation algorithm, which provides a consistent user interface to all appliances in the environment.},
 acmid = {1851670},
 address = {New York, NY, USA},
 author = {Nicolau, Hugo and Nunes, Renato and Jorge, Joaquim},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851670},
 isbn = {978-1-60558-835-3},
 keyword = {blind, controller, interface generation, mobile device},
 link = {http://doi.acm.org/10.1145/1851600.1851670},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {371--372},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Personal Mobile Controller for Blind People},
 year = {2010}
}


@inproceedings{Ryu:2010:IVP:1851600.1851643,
 abstract = {At present, vibration feedback is widely used to improve the limited user interface of a mobile device. Despite recent advances of miniature actuator technology, a vibration motor is still a dominant actuator for commercial mobile devices. In this paper, we present a new vibration rendering method which can enhance the identification of mobile device vibrations produced by a vibration motor. Whereas the traditional method separates vibrations in voltage applied to the motor, we partition vibrations in their perceived intensity using perceptually transparent rendering. An empirical evaluation using absolute identification showed that our rendering method can improve perception performance in terms of correct identification rate and the amount of information transfer. The results suggest that perceptually transparent rendering can contribute to increasing the number of discrete vibrations that can be used for information delivery via a mobile device, e.g., for the priorities of phone calls.},
 acmid = {1851643},
 address = {New York, NY, USA},
 author = {Ryu, Jonghyun and Lee, Chil-Woo and Choi, Seungmoon},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851643},
 isbn = {978-1-60558-835-3},
 keyword = {identification, mobile device, perceived intensity, vibration},
 link = {http://doi.acm.org/10.1145/1851600.1851643},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {257--260},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Improving Vibrotactile Pattern Identification for Mobile Devices Using Perceptually Transparent Rendering},
 year = {2010}
}


@inproceedings{Schinke:2010:VOO:1851600.1851655,
 abstract = {An emerging technology for tourism information systems is mobile Augmented Reality using the position and orientation sensors of recent smartphones. State-of-the-art mobile Augmented Reality application accompanies the Augmented Reality visualization with a small mini-map to provide an overview of nearby points of interest (POIs). In this paper we develop an alternative visualization for nearby POIs based on off-screen visualization techniques for digital maps. The off-screen visualization uses arrows directly embedded into the Augmented Reality scene which point at the POIs. In the conducted study 26 participants explored nearby POIs and had to interpret their position. We show that participants are faster and can interpret the position of POIs more precisely with the developed visualization technique.},
 acmid = {1851655},
 address = {New York, NY, USA},
 author = {Schinke, Torben and Henze, Niels and Boll, Susanne},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851655},
 isbn = {978-1-60558-835-3},
 keyword = {augmented reality, mobile phone, orientation},
 link = {http://doi.acm.org/10.1145/1851600.1851655},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {313--316},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Visualization of Off-screen Objects in Mobile Augmented Reality},
 year = {2010}
}


@inproceedings{Ashbrook:2010:EOD:1851600.1851728,
 abstract = {With the continuing miniaturization of powerful computation into mobile devices, there exists an opportunity for re-envisioning how we interact with our personal technology.In addition to a core computational/interaction component such as a mobile phone, there could be substantial benefit to a user by offering an ensemble of multiple mobile devices that can be used together. Such devices could provide novel input or output capabilities, or distribute user interactions in a more effective way. Our goal with this proposed workshop is to foster discussion about what possibilities such collections of devices might offer.},
 acmid = {1851728},
 address = {New York, NY, USA},
 author = {Ashbrook, Daninel and Lyons, Kent},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851728},
 isbn = {978-1-60558-835-3},
 keyword = {ecologies, ensembles, mobile, systems, wearables},
 link = {http://doi.acm.org/10.1145/1851600.1851728},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {503--504},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Ensembles of On-body Devices},
 year = {2010}
}


@inproceedings{Ulm:2010:SNS:1851600.1851602,
 abstract = {The iPhone has brought about massive change to the way we do interaction design, to application development and marketplaces, and has overturned the mobile industry at large. However, it has also become the unsung poster child for another radical shift, the reinvention of the corporate Brand. The days of businesses buying their identity with big budget marketing, snapping slogans, and iconic logos have moved aside to make room for a new and persuasive, ownable property - the interface. Today's consumers are aligning to Brands based on the experience - may the best UI win. This session will explore the increasing importance of the user experience to differentiate products and services and it's role in establishing trust and affinity for Brands in the mobile and online marketplace.},
 acmid = {1851602},
 address = {New York, NY, USA},
 author = {Ulm, Josh},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851602},
 isbn = {978-1-60558-835-3},
 keyword = {affinity, apple, applications, brand, design, development, identity, interaction, logo, loyalty, marketing, mobile, pinch, swipe, user interface},
 link = {http://doi.acm.org/10.1145/1851600.1851602},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {3--4},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Swipe is the New Swoosh: How Interaction Design is Changing the Role of Brand},
 year = {2010}
}


@inproceedings{Fernaeus:2010:PEW:1851600.1851729,
 abstract = {This workshop aims to explore different approaches and challenges in studying playfulness as a mode of interacting with mobile technology. Researchers, designers and developers with interest in this theme are welcome to participate in a full day activity of demos, presentations and discussions. In particular, our emphasis is on how to introduce, explore and understand playful interaction in mobile applications used in the wild.},
 acmid = {1851729},
 address = {New York, NY, USA},
 author = {Fernaeus, Ylva and Cramer, Henriette and Korhonen, Hannu and Kaye, Jofish},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851729},
 isbn = {978-1-60558-835-3},
 keyword = {mobile interaction, playful interaction},
 link = {http://doi.acm.org/10.1145/1851600.1851729},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {505--508},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Please Enjoy!: Workshop on Playful Experiences in Mobile HCI},
 year = {2010}
}


@inproceedings{Church:2010:MWS:1851600.1851730,
 abstract = {The mobile space is evolving at an astonishing rate with over 4.1 billion subscribers in existence. The world is also witnessing an explosion in social web services with more users seeking novel ways of interacting with friends and family. We are interested in the combination of these two exciting research spaces: the social web and the mobile web. We believe that the social mobile web is going to be a highly influential research area in the near future and given the huge growth that both these fields have experienced in recent times we feel that now is an excellent time to discuss this nascent research space. This workshop continues the successful social mobile web workshop held as part of SocialCom in 2009. The workshop explores the current state of the social mobile web and combines technical presentations, demos and position papers to drive interaction and discussion among participants.},
 acmid = {1851730},
 address = {New York, NY, USA},
 author = {Church, Karen and Pujol, Josep M. and Smyth, Barry and Contractor, Noshir},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851730},
 isbn = {978-1-60558-835-3},
 keyword = {HCI, collaboration, interfaces, mobile content distribution, mobile content sharing, mobile context, mobile web, social browsing, social networks, social search, social web},
 link = {http://doi.acm.org/10.1145/1851600.1851730},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {509--512},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {MobileHCI'10 Workshop Summary: Social Mobile Web},
 year = {2010}
}


@inproceedings{Ghiani:2010:OCI:1851600.1851653,
 abstract = {Ubiquitous environments call for innovative uses of existing applications. In this paper we present our solution for partial Web migration: it allows users to interactively select parts of existing interfaces and have them migrate to a target device. The underlying supporting platform exploits logical user interface descriptions and a set of transformations. This environment is particularly useful for supporting mobile users accessing complex Web applications, such as various emerging mash-ups. We also show an example of use of our solution in a widespread Web application, and report on a user test.},
 acmid = {1851653},
 address = {New York, NY, USA},
 author = {Ghiani, Giuseppe and Patern\`{o}, Fabio and Santoro, Carmen},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851653},
 isbn = {978-1-60558-835-3},
 keyword = {migratory interfaces, partial migration, ubiquitous environments},
 link = {http://doi.acm.org/10.1145/1851600.1851653},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {299--308},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {On-demand Cross-device Interface Components Migration},
 year = {2010}
}


@inproceedings{Brush:2010:UEA:1851600.1851616,
 abstract = {We introduce activity-based navigation, which uses human activities derived from sensor data to help people navigate, in particular to retrace a "trail" previously taken by that person or another person. Such trails may include step counts, walking up/down stairs or taking elevators, compass directions, and photos taken along a user's path, in addition to absolute positioning (GPS and maps) when available. To explore the user experience of activity-based navigation, we built Greenfield, a mobile device interface for finding a car. We conducted a ten participant user study comparing users' ability to find cars across three different presentations of activity-based information as well as verbal instructions. Our results show that activity-based navigation can be used for car finding and suggest its promise more generally for supporting navigation tasks. We present lessons for future activity-based navigation interfaces, and motivate further work in this space, particularly in the area of robust activity inference.},
 acmid = {1851616},
 address = {New York, NY, USA},
 author = {Brush, A.J. Bernheim and Karlson, Amy K. and Scott, James and Sarin, Raman and Jacobs, Andy and Bond, Barry and Murillo, Oscar and Hunt, Galen and Sinclair, Mike and Hammil, Kerry and Levi, Steven},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851616},
 isbn = {978-1-60558-835-3},
 keyword = {activity inference, mobile applications, mobile user interfaces, navigation, sensor fusion},
 link = {http://doi.acm.org/10.1145/1851600.1851616},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {73--82},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {User Experiences with Activity-based Navigation on Mobile Devices},
 year = {2010}
}


@inproceedings{Kauko:2010:SSG:1851600.1851657,
 abstract = {Mobile phones are designed as personal devices, and thus mobile games often lack the social element present in other game platforms, e.g., in console games. In this paper, we present an interaction method for social gaming with portable devices. The interaction method combines displays of multiple devices to form a shared screen visible to all players. We conducted an experiment with 40 participants to compare the social setting between our method and a typical console game environment. The results show that the amount of oral communication was significantly higher in the mobile device setup. The results on subjective experience were inconclusive, but revealed that players' perceptions of a social situation were affected by various factors such as ergonomics, distance, support for spectators, and symbolic meanings of the seating arrangement. Our findings help to understand the design space of social co-located gaming, and show that mobile phones are a potential platform for such games.},
 acmid = {1851657},
 address = {New York, NY, USA},
 author = {Kauko, Jarmo and H\"{a}kkil\"{a}, Jonna},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851657},
 isbn = {978-1-60558-835-3},
 keyword = {game experience, mobile games, social interaction},
 link = {http://doi.acm.org/10.1145/1851600.1851657},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {317--326},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Shared-screen Social Gaming with Portable Devices},
 year = {2010}
}


@inproceedings{Naumann:2010:BII:1851600.1851685,
 abstract = {The QUESI (Questionnaire for the subjective consequences of intuitive use), a specific measure of the satisfaction of users interacting with a product, is presented. In addition, first benchmark values for mobile devices and applications are provided.},
 acmid = {1851685},
 address = {New York, NY, USA},
 author = {Naumann, Anja and Hurtienne, J\"{o}rn},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851685},
 isbn = {978-1-60558-835-3},
 keyword = {design for intuitive use, evaluation, questionnaire, usability},
 link = {http://doi.acm.org/10.1145/1851600.1851685},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {401--402},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Benchmarks for Intuitive Interaction with Mobile Devices},
 year = {2010}
}


@inproceedings{Lucero:2010:CUM:1851600.1851659,
 abstract = {Mobile phones have traditionally been utilized for personal and individual use. In this paper we explore shared co-located interactions with mobile phones. We introduce a phone-based application that supports ad hoc brainstorming sessions. The prototype allows a workgroup to create, edit and view virtual mind-map notes on any table surface. The prototype encourages people to use the devices interchangeably and thus engage in social interactions. Evaluations show that participants were able to easily create mind maps and that the prototype supports different strategies in mind-map creation.},
 acmid = {1851659},
 address = {New York, NY, USA},
 author = {Lucero, Andr{\'e}s and Ker\"{a}nen, Jaakko and Korhonen, Hannu},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851659},
 isbn = {978-1-60558-835-3},
 keyword = {co-located interaction, mobile devices, tangible user interface},
 link = {http://doi.acm.org/10.1145/1851600.1851659},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {337--340},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Collaborative Use of Mobile Phones for Brainstorming},
 year = {2010}
}


@inproceedings{Su:2010:TEV:1851600.1851606,
 abstract = {Mapping applications on mobile devices have gained widespread popularity as a means for enhancing user mobility and ability to explore new locations and venues. Visually impaired users currently rely on computer text-to-speech or human-spoken descriptions of maps and indoor spaces. Unfortunately, speech-based descriptions are limited in their ability to succinctly convey complex layouts or spacial positioning. This paper presents Timbremap, a sonification interface enabling visually impaired users to explore complex indoor layouts using off-the-shelf touch-screen mobile devices. This is achieved using audio feedback to guide the user's finger on the device's touch interface to convey geometry. Our user-study evaluation shows Timbremap is effective in conveying non-trivial geometry and enabling visually impaired users to explore indoor layouts.},
 acmid = {1851606},
 address = {New York, NY, USA},
 author = {Su, Jing and Rosenzweig, Alyssa and Goel, Ashvin and de Lara, Eyal and Truong, Khai N.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851606},
 isbn = {978-1-60558-835-3},
 keyword = {assistive, sonification, touch device, user interface},
 link = {http://doi.acm.org/10.1145/1851600.1851606},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {17--26},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Timbremap: Enabling the Visually-impaired to Use Maps on Touch-enabled Devices},
 year = {2010}
}


@inproceedings{Rebaque-Rivas:2010:MLS:1851600.1851679,
 abstract = {This article presents a study carried out from a user-centered design (UCD) perspective to define mobile learning scenarios. Student user profiles were defined and personas created. There were 4 focus groups with 7 students. 7 in-depth interviews with commuting students were carried out. The information collected allowed for the definition of 2 potential scenarios for mobile learning. These 2 scenarios helped identify specific devices, functionalities and applications. They highlighted the enormous potential for m-learning by commuting students. These 2 scenarios can act as the basis for the design and development of new applications linked to m-learning.},
 acmid = {1851679},
 address = {New York, NY, USA},
 author = {Rebaque-Rivas, Pablo and Gil-Rodr\'{\i}guez, Eva Patricia and Manresa-Mallol, Irene},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851679},
 isbn = {978-1-60558-835-3},
 keyword = {UCD, commuting, contextual inquiry, focus group, m-learning, personas, scenarios, user studies},
 link = {http://doi.acm.org/10.1145/1851600.1851679},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {389--390},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile Learning Scenarios from a UCD Perspective},
 year = {2010}
}


@inproceedings{Buttussi:2010:UMD:1851600.1851605,
 abstract = {Fast and effective communication is crucial during medical emergencies, but patients' disabilities can make it a challenging task for emergency medical responders. This paper proposes a mobile system to deal with the communication barrier between medical responders and deaf patients. The system allows medical responders to quickly browse a collection of emergency-related sentences, and show videos of the corresponding translations in sign language to the deaf patients. The design process involved experts in emergency medicine as well as experts from the deaf community. The evaluation carried out on ten emergency medical responders and ten deaf subjects showed that the system is useful to support communication with deaf people during medical emergencies.},
 acmid = {1851605},
 address = {New York, NY, USA},
 author = {Buttussi, Fabio and Chittaro, Luca and Carchietti, Elio and Coppo, Marco},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851605},
 isbn = {978-1-60558-835-3},
 keyword = {computer-mediated communication, deaf people, first responders, medical emergencies, mobile devices, sign languages},
 link = {http://doi.acm.org/10.1145/1851600.1851605},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {7--16},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Using Mobile Devices to Support Communication Between Emergency Medical Responders and Deaf People},
 year = {2010}
}


@inproceedings{Cui:2010:LIU:1851600.1851611,
 abstract = {This paper presents the Linked Internet UI Concept, or LinkedUI for short, as a holistic user interface concept to facilitate social interaction on mobile devices. It aggregates social events from social networking services and communication channels and uses hypertext navigation for presentation and interaction. We describe the concept design principles, highlights of the design, and the prototype implementation. We conducted a user study to compare LinkedUI with the benchmark of web applications running in a web browser to follow their friends' activities in Twitter and Flickr and two other optional services on mobile devices. The study results reveal that the users performed tasks faster in LinkedUI and also liked it more than the benchmark. These findings support the design principles of LinkedUI in facilitating social interaction via mobile devices.},
 acmid = {1851611},
 address = {New York, NY, USA},
 author = {Cui, Yanqing and Honkala, Mikko and Pihkala, Kari and Kinnunen, Kimmo and Grassel, Guido},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851611},
 isbn = {978-1-60558-835-3},
 keyword = {LinkedUI, browser, hypertext navigation, mobile, service aggregation, social networking services, web},
 link = {http://doi.acm.org/10.1145/1851600.1851611},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {45--54},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Linked Internet UI: A Mobile User Interface Optimized for Social Networking},
 year = {2010}
}


@inproceedings{Mulloni:2010:ZIA:1851600.1851629,
 abstract = {Augmented Reality combines real world and virtual information in interactive visualizations. Since phones started integrating GPS, compass and accelerometer, several Augmented Reality browsers for phones have hit the market. These are applications that access large amounts of geo-referenced information from online sources and present it at corresponding physical locations, superimposed onto a live video stream. However, Augmented Reality is constrained by the camera's field of view and restricted to first- person views, limiting the amount of overview that users can gain. We present two zooming interfaces that compensate for these constraints by enabling users to smoothly zoom between the Augmented Reality view and (1) an egocentric panoramic view of 360°, and (2) an exocentric top-down view. We present the results from two studies that show how in most search tasks our zooming interfaces are faster and require less panning than an overlay- based tool, scaling better as the amount of information grows.},
 acmid = {1851629},
 address = {New York, NY, USA},
 author = {Mulloni, Alessandro and D\"{u}nser, Andreas and Schmalstieg, Dieter},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851629},
 isbn = {978-1-60558-835-3},
 keyword = {mobile augmented reality, zooming interfaces},
 link = {http://doi.acm.org/10.1145/1851600.1851629},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {161--170},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Zooming Interfaces for Augmented Reality Browsers},
 year = {2010}
}


@inproceedings{Paek:2010:PEM:1851600.1851667,
 abstract = {Mobile devices with touch capabilities often utilize touchscreen keyboards. However, due to the lack of tactile feedback, users often have to switch their focus of attention between the keyboard area, where they must locate and click the correct keys, and the text area, where they must verify the typed output. This can impair user experience and performance. In this paper, we examine multimodal feedback and guidance signals that keep users' focus of attention in the keyboard area but also provide the kind of information users would normally receive in the text area. We evaluated whether combinations of multimodal signals could improve typing performance in a controlled experiment. One combination reduced keystrokes-per-character by 8% and correction backspaces by 28%.},
 acmid = {1851667},
 address = {New York, NY, USA},
 author = {Paek, Tim and Chang, Kenghao and Almog, Itai and Badger, Eric and Sengupta, Tirthankar},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851667},
 isbn = {978-1-60558-835-3},
 keyword = {mobile device, multimodal feedback, soft keyboard, touchscreen},
 link = {http://doi.acm.org/10.1145/1851600.1851667},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {365--368},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {A Practical Examination of Multimodal Feedback and Guidance Signals for Mobile Touchscreen Keyboards},
 year = {2010}
}


@inproceedings{Montero:2010:YUS:1851600.1851647,
 abstract = {With gesture-based interactions in mobile settings becoming more popular, there is a growing concern regarding the social acceptance of these interaction techniques. In this paper we begin by examining the various definitions of social acceptance that have been proposed in the literature to synthesize a definition that is based on how the user feels about performing a particular interaction as well as how the bystanders perceive the user during this interaction. We then present the main factors that influence gestures' social acceptance including culture, time, interaction type and the user's position on the innovation adoption curve. Through a user study we show that an important factor in determining social acceptance of gesture-based interaction techniques is the user's perception of others ability to interpret the potential effect of a manipulation.},
 acmid = {1851647},
 address = {New York, NY, USA},
 author = {Montero, Calkin S. and Alexander, Jason and Marshall, Mark T. and Subramanian, Sriram},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851647},
 isbn = {978-1-60558-835-3},
 keyword = {gestural interfaces, gestures' design, social acceptance},
 link = {http://doi.acm.org/10.1145/1851600.1851647},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {275--278},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Would You Do That?: Understanding Social Acceptance of Gestural Interfaces},
 year = {2010}
}


@inproceedings{Caballero:2010:BAV:1851600.1851704,
 abstract = {This paper introduces Behand. Behand is a new way of interaction that allows a mobile phone user to manipulate virtual three-dimensional objects inside the phone by gesturing with his hand. Behand provides a straightforward 3D interface, something current mobile phones do not offer, and extends the phone's input and display space. The 3D direct manipulation paradigm makes it intuitive for people of all cultural backgrounds. It is ergonomically appropriate and technically feasible. A user evaluation of the concept was carried out, showing that users find the concept "useful", "innovative" and "fun" and there are no acceptability issues. Please refer to the video accompanying this paper for a video prototype of Behand.},
 acmid = {1851704},
 address = {New York, NY, USA},
 author = {Caballero, Mar\'{\i}a Luz and Chang, Ting-Ray and Men{\'e}ndez, Mar\'{\i}a and Occhialini, Valentina},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851704},
 isbn = {978-1-60558-835-3},
 keyword = {3D, augmented virtuality, gestural interfaces, interaction strategies, manipulation, mixed reality, mobile devices},
 link = {http://doi.acm.org/10.1145/1851600.1851704},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {451--454},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Behand: Augmented Virtuality Gestural Interaction for Mobile Phones},
 year = {2010}
}


@inproceedings{Reis:2010:IMI:1851600.1851723,
 abstract = {Mobile devices are used by a wide range of users, both on-the-go and in stationary fashions, for several purposes, and in a broad variety of scenarios, characterized by constantly mutating environmental and privacy settings. Such contextual complexity introduces significant interaction limitations, which often force the users to adapt to both the interfaces and usage contexts. My PhD research intends to mitigate these limitations. I hypothesize that adaptive context-aware multimodal interfaces improve daily mobile activities in terms of the performance, usability, and user experience. The validation of this hypothesis focuses communication, media manipulation, and personal organization activities.},
 acmid = {1851723},
 address = {New York, NY, USA},
 author = {Reis, Tiago Alexandre Cust\'{o}dio},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851723},
 isbn = {978-1-60558-835-3},
 keyword = {context-awareness, contextual evaluation, mobile interaction, multimodal interaction},
 link = {http://doi.acm.org/10.1145/1851600.1851723},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {495--496},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Improving Mobile Interaction with Context-awareness, Multimodality, and Adaptive Interfaces.},
 year = {2010}
}


@inproceedings{Patel:2010:MTM:1851600.1851713,
 abstract = {My research examines challenges inherent in the design of mobile groupware systems. For my thesis work I am designing interfaces and interaction techniques that can be used to augment face-to-face communication within groups of collocated mobile users. In my initial research, which explored collocated mobile photo capture and sharing, I uncovered three fundamental challenges to designing mobile groupware. In this paper I discuss these challenges as well as my proposed research agenda to addresses the challenges.},
 acmid = {1851713},
 address = {New York, NY, USA},
 author = {Patel, Nirmal J.},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851713},
 isbn = {978-1-60558-835-3},
 keyword = {collocated, groupware, mobile},
 link = {http://doi.acm.org/10.1145/1851600.1851713},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {475--476},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Many Tabs Make a Light Board},
 year = {2010}
}


@inproceedings{Robinson:2010:IDM:1851600.1851660,
 abstract = {In this article we describe a novel approach to pedestrian navigation using bearing-based haptic feedback. People are guided in the general direction of their destination via vibration, but additional exploratory navigation is stimulated by varying feedback based on the potential for taking alternative routes. We describe two mobile prototypes that were created to examine the possible benefits of the approach. The successful use of this exploratory navigation method is demonstrated in a realistic field trial, and we discuss the results and interesting participant behaviours that were recorded.},
 acmid = {1851660},
 address = {New York, NY, USA},
 author = {Robinson, Simon and Jones, Matt and Eslambolchilar, Parisa and Murray-Smith, Roderick and Lindborg, Mads},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851660},
 isbn = {978-1-60558-835-3},
 keyword = {GPS, bearing-based, mobile, navigation, vibrotactile},
 link = {http://doi.acm.org/10.1145/1851600.1851660},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {341--344},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {"I Did It My Way": Moving Away from the Tyranny of Turn-by-turn Pedestrian Navigation},
 year = {2010}
}


@inproceedings{Kawsar:2010:ECM:1851600.1851627,
 abstract = {One shortcoming of self-describing smart objects augmented with digital resources is the limitation of output modalities due to their long established physical appearances. To overcome this drawback intangible representations e.g., sound, video projection etc. are usually coupled with the tangible representations of smart objects that enable access and interaction with their value added features. In this paper, we explore two mobile interaction techniques that associate such intangible representation to smart objects using a pico projector augmented camera phone. The first technique utilizes a Magic Lens metaphor applying mobile augmented reality (contextual information is overlaid while looking at a smart object through camera) to uncover and interact with smart objects. The second technique, Personal Projection follows similar mechanisms in discovery and interaction, except information is projected onto the nearest surface. We report the implementation of these two techniques and a comparative qualitative study with three prototype smart object applications. The findings give us deeper insights on the positive and negative aspects of these two techniques and open up a range of stimulating research issues that we discuss in the paper.},
 acmid = {1851627},
 address = {New York, NY, USA},
 author = {Kawsar, Fahim and Rukzio, Enrico and Kortuem, Gerd},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851627},
 isbn = {978-1-60558-835-3},
 keyword = {mobile interaction, projected interface, smart object},
 link = {http://doi.acm.org/10.1145/1851600.1851627},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {157--160},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {An Explorative Comparison of Magic Lens and Personal Projection for Interacting with Smart Objects},
 year = {2010}
}


@inproceedings{Sohn:2010:AMI:1851600.1851666,
 abstract = {Increasingly, smartphones are being used to access all manner of information: email messages, Facebook status updates, tweets, RSS feeds, photographs and more. Approaches to dealing with this multi-faceted information stream developed on the desktop, such as switching between multiple applications or multiple browser windows, are unwieldy and scale poorly for mobile devices. In this paper, we propose the combination of the universal inbox and a system called 'Lenses' for extracting information of interest as part of a solution to this problem. These mechanisms allow the user to easily specify ways to sort, filter and manage their universal inbox in an intuitive way. We culminate with a discussion of implications for mobile phone interface design.},
 acmid = {1851666},
 address = {New York, NY, USA},
 author = {Sohn, Timothy and Setlur, Vidya and Mori, Koichi and Kaye, Joseph 'Jofish' and Horii, Horishi and Battestini, Agathe and Ballagas, Rafael and Paretti, Christopher and Spasojevic, Mirjana},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851666},
 isbn = {978-1-60558-835-3},
 keyword = {entity resolution, information overload, lenses, mobile email, mobile interfaces, mobile messaging},
 link = {http://doi.acm.org/10.1145/1851600.1851666},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {361--364},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Addressing Mobile Information Overload in the Universal Inbox Through Lenses},
 year = {2010}
}


@inproceedings{Girardello:2010:ASM:1851600.1851715,
 abstract = {Most mobile operating systems provide users with an application portal where they can search for applications published by third-party developers. However, finding new apps is not an easy task and requires either to know what to look for or to go through an endless list of applications. In this short paper we present work in progress of a platform that allows its users to discover mobile applications in a serendipitous manner. AppAware is a mobile application that captures and shares installations, updates, and removals of Android programs in real time. Accordingly, AppAware allows its users to see what applications are being installed right now or around their position by other people, thus introducing a new way of interaction with application portals and other mobile users.},
 acmid = {1851715},
 address = {New York, NY, USA},
 author = {Girardello, Andrea},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851715},
 isbn = {978-1-60558-835-3},
 keyword = {AppAware, android, application portal, market, mobile, social network},
 link = {http://doi.acm.org/10.1145/1851600.1851715},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {479--480},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {AppAware: Serendipity in Mobile Applications},
 year = {2010}
}


@inproceedings{Waljas:2010:CSU:1851600.1851637,
 abstract = {Many web-based services utilize both desktop and mobile terminals in delivering content and functionality to their users. In terms of user experience (UX), the overall chain of interactions, including mobile and non-mobile settings, becomes a central design target. The aim of this study was to investigate, what are the key elements of user experience associated with these, cross-platform interactions. This paper presents the findings from a four week long field study with three web-based cross-platform services. During the study, participants used the services on both their PCs and mobile devices. Diaries and interviews were used for gathering users' experiences with the services. Based on our findings and reflection with related work, we argue that central elements of cross-platform service UX include fit for cross-contextual activities, flow of interactions and content, and perceived service coherence. We propose an initial conceptual framework of cross-platform user experience. The framework can be used to guide the design of cross-platform web services, as it draws attention to elements of user experience that are essentially influenced by the characteristics of cross-platform settings.},
 acmid = {1851637},
 address = {New York, NY, USA},
 author = {W\"{a}ljas, Minna and Segerst{\aa}hl, Katarina and V\"{a}\"{a}n\"{a}nen-Vainio-Mattila, Kaisa and Oinas-Kukkonen, Harri},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851637},
 isbn = {978-1-60558-835-3},
 keyword = {conceptual framework, cross-platform web services, crossmedial interactions, field study, user experience (UX)},
 link = {http://doi.acm.org/10.1145/1851600.1851637},
 location = {Lisbon, Portugal},
 numpages = {10},
 pages = {219--228},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Cross-platform Service User Experience: A Field Study and an Initial Framework},
 year = {2010}
}


@inproceedings{Magnusson:2010:SAD:1851600.1851684,
 abstract = {The present study was performed in order to get a better understanding of the influence of the scanning angle interval on navigation performance, gestures and strategies in a more realistic outdoor setting. Results indicate that users are able to handle a wide range of angle intervals. We observe different gestures and strategies and provide recommendations for suitable angle intervals. Our observations also support the notion that using this type of pointing gesture for navigation is intuitive and easy to use.},
 acmid = {1851684},
 address = {New York, NY, USA},
 author = {Magnusson, Charlotte and Rassmus-Gr\"{o}hn, Kirsten and Szymczak, Delphine},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851684},
 isbn = {978-1-60558-835-3},
 keyword = {angle, audio, gesture, navigation, non-visual, pointing},
 link = {http://doi.acm.org/10.1145/1851600.1851684},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {399--400},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Scanning Angles for Directional Pointing},
 year = {2010}
}


@inproceedings{Wu:2010:HIT:1851600.1851707,
 abstract = {Modern transportation has changed our lifestyle and allowed for many more options for the daily commute. Particularly in Taiwan, a unique regional phenomenon is that people tend to travel to almost anywhere by scooter. With the intention of replacing the scooter ride for short-distance journeys with walking, we introduce a system called "HappyFeet", which encourages users to walk more with various interactive ways. The user testing demonstrated that the users were enthusiastic about our design and they provided positive feedback as well as some comments for ways to improve.},
 acmid = {1851707},
 address = {New York, NY, USA},
 author = {Wu, Chia-Hsin and Wu, Tsai-Fang and Chou, Yu-Hong and Huang, Ko-Hsun and Wuang, Chen-Hao and Chen, Mon-Chu and Deng, Yi-Shin},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851707},
 isbn = {978-1-60558-835-3},
 keyword = {short-distance journey, turning point, user experience, user-centered design, walk},
 link = {http://doi.acm.org/10.1145/1851600.1851707},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {463--466},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {HappyFeet! Influencing at the Turning Points: Walking or Scooter Ride for Short-distance Journey?},
 year = {2010}
}


@inproceedings{Ahmet:2010:SMS:1851600.1851676,
 abstract = {The app store model used by Apple's iPhone has presented a successful model for installing new applications; however, only a fraction of current mobile phones have access to a dedicated app store. Thus there is need to investigate alternative ways of discovering and installing mobile services and applications. We performed studies on two services, focusing on the social aspects of sharing mobile apps between users. The services were a portrait sharing application prototype called Portrait Catalog, and a commercially available chat application called Hanashi. They differ not only by functionality and design, but also by their availability to the public as well as the means of distribution they offer. We present initial insights in how users share mobile services between each other, when using a phone that doesn't include mobile application distribution as part of the user experience. We found that factors such as users' habits of downloading and testing new applications, their understandings of the service they are using and the means of distribution the services offer, all affected how the services were shared.},
 acmid = {1851676},
 address = {New York, NY, USA},
 author = {Ahmet, Zeynep and Holmquist, Lars-Erik},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851676},
 isbn = {978-1-60558-835-3},
 keyword = {App stores, distribution channels, factors, mobile services, sharing},
 link = {http://doi.acm.org/10.1145/1851600.1851676},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {383--384},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Sharing Mobile Services: Beyond the App Store Model},
 year = {2010}
}


@inproceedings{BayroKaiser:2010:ISL:1851600.1851719,
 abstract = {Mobile human computer interaction by Wearable Computing is to improve and support humans in their daily tasks [1, 2]. Wearable computers are easily to wear or can be incorporated in the human's clothes. Wearable computers intend compared to smart phones to minimize the cognitive effort and manual computer interaction. Another important feature of this technology is the interaction with its environment by distributed sensors. This is called context awareness providing the user with relevant environmental information like: location, activity, identity, time, temperature, etc. This research project, at its initial phase, has the objective to provide indoor localization in known and unknown environments for pedestrians equipped with wearable computers. This information is useful in many applications. At the moment there are various methods for indoor and outdoor localization such as GPS, pre-installed indoor communication infrastructures, field strength measurements (WLAN, GSM, Bluetooth, etc), laser, radar, sonar, camera, motion sensors, etc. For a precise indoor localization the best strategy is to use laser, camera or motion sensors [3]. I intend to apply Simultaneous Localization and Mapping (SLAM) using a short range laser scanner as known from mobile robots [4]. Fusing the laser scanner data with data of accelerometers, gyroscope and magnetometer will increase the precision. SLAM is well known problem from robotic map building and localization, it is solved, but probably needs some algorithm improvements. The most popular algorithms are based on the Extended Kalman filter and the Rao-Blackwellized Particle Filters to solve the problem [4]. Basically a map is built and estimated and a position estimated using the odometry data of the robot, where distance and direction obtained from a laser scanner with respect to land mark data and position. Landmarks are basically features in an environment that can be used as reference, to make different measurements from different positions. For example in an indoor environment landmarks could be lines, walls, corners, edges or more specific obstacles. The implementation of SLAM for pedestrians based on [5] is one of the objectives; where the pedestrian was equipped with head worn sensors. Pedestrians have a much more complex odometry than mobile robots; they differ in the type of movements and degrees of freedom. The laser scanner position with mobile robots is stable compared to the surface. This cannot be guaranteed for humans. Furthermore the human build is specific for each person as is motion. Thus the challenge is the odometry to be extracted for each human. To solve the odometry extraction, I intend to use inertial measurement units (IMU) as motion sensors to indentify walking and change of direction filtering noise due to irregular movements of the pedestrian. In this dissertation project the pedestrian will be equipped with a short range laser scanner and an inertial measurement unit. The positioning of the sensors is crucial to reduce noise or incorrect measurements. In mobile robots the laser scanner is implemented on top of it and is able to scan a horizontal plane. The most stable positions on the human body are the shoulders and hips to place the sensors. To obtain horizontal laser scans, the raw data requires processing with the IMU data and projection into the horizontal plane. Additionally to reduce false laser scan readings we will regulate the scanner with a servo motor stabilizer so its measurements are always taking horizontally. Mapping will be achieved with occupancy grid mapping. The entire data should be processed using a wearable computer. The pedestrian should not have to interact with it or enter any kind of preexisting knowledge. I intend to achieve a precise pedestrian slam in a real time environment with persons and moving objects for a specific application.},
 acmid = {1851719},
 address = {New York, NY, USA},
 author = {Bayro Kaiser, Esteban Tobias},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851719},
 isbn = {978-1-60558-835-3},
 keyword = {pedestrian, slam, wearable computing},
 link = {http://doi.acm.org/10.1145/1851600.1851719},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {487--488},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Indoor Simultaneous Localization and Mapping for Pedestrian with Wearable Computing},
 year = {2010}
}


@inproceedings{Bohmer:2010:EIA:1851600.1851633,
 abstract = {The contextual relevance of a service can only be determined by the human himself. However, a measure for relevance is required for context-aware service delivery. In this paper, we draw attention to icon arrangement on mobile devices as a new source of information for adaptive menus. We conducted contextual inquiries to investigate how people arrange icons on a grid-based menu. Our results show that context has an impact on how users arrange their menus: during different activities they prefer different icons to be placed at specific positions. We discuss layout options for icon menus and argue how the relevance can be approximated by observing the icon arrangement. Our results informed the design of a context-aware client for mobile services, which is presented as a prototype.},
 acmid = {1851633},
 address = {New York, NY, USA},
 author = {B\"{o}hmer, Matthias and Bauer, Gernot},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851633},
 isbn = {978-1-60558-835-3},
 keyword = {context awareness, icon arrangement, implicit feedback},
 link = {http://doi.acm.org/10.1145/1851600.1851633},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {195--198},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Exploiting the Icon Arrangement on Mobile Devices As Information Source for Context-awareness},
 year = {2010}
}


@inproceedings{Pombinho:2010:LOB:1851600.1851672,
 abstract = {In this paper we present an interactive point of interest query interface, based on the location and orientation of the user. This interface gives clues about the position, relative to the user, of all the points of interest in the vicinity. The interaction provided can also be used to complement the presentation of points of interest on a map, helping identify the association between the icons drawn on a map, and the corresponding real world objects in the neighbourhood of the user.},
 acmid = {1851672},
 address = {New York, NY, USA},
 author = {Pombinho, Paulo and Carmo, Maria Beatriz and Afonso, Ana Paula and Aguiar, Hugo},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851672},
 isbn = {978-1-60558-835-3},
 keyword = {geo referenced information visualization, location and orientation services, mobile devices},
 link = {http://doi.acm.org/10.1145/1851600.1851672},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {375--376},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Location and Orientation Based Point of Interest Search Interface},
 year = {2010}
}


@inproceedings{Vartiainen:2010:DPS:1851600.1851664,
 abstract = {Internet services are becoming essential in people's daily lives. They offer functionality and content that are also relevant for mobile use, as mobile devices of today are technologically sophisticated enabling online access anytime, anywhere. Unfortunately, Internet services specifically designed for mobiles utilizing their capabilities to the fullest are largely still missing. In this paper, we introduce Image Exchange, a photo sharing Internet service, that exploits two essential things that a mobile device has to offer: a personal identifier (a user's phone number) and social network (phonebook contacts). We evaluated Image Exchange in a field study and the results show that the current design is a good starting point but needs to be extended to enable a truly social photo sharing service.},
 acmid = {1851664},
 address = {New York, NY, USA},
 author = {Vartiainen, Elina},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851664},
 isbn = {978-1-60558-835-3},
 keyword = {internet services, phonebook, photo sharing},
 link = {http://doi.acm.org/10.1145/1851600.1851664},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {353--356},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Designing a Photo Sharing Service for Mobile: A Phone Number As the Key Enabler},
 year = {2010}
}


@inproceedings{Serra:2010:IPN:1851600.1851683,
 abstract = {In this work we present a pedestrian navigation system for indoor environments based on the dead reckoning positioning method, 2D barcodes, and data from accelerometers and magnetometers. All the sensing and computing technologies of our solution are available in common smart phones. The need to create indoor navigation systems arises from the inaccessibility of the classic navigation systems, such as GPS, in indoor environments.},
 acmid = {1851683},
 address = {New York, NY, USA},
 author = {Serra, Alberto and Carboni, Davide and Marotto, Valentina},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851683},
 isbn = {978-1-60558-835-3},
 keyword = {accelerometer, compass, dead reckoning, indoor navigation, map},
 link = {http://doi.acm.org/10.1145/1851600.1851683},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {397--398},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Indoor Pedestrian Navigation System Using a Modern Smartphone},
 year = {2010}
}


@inproceedings{Girardello:2010:AMA:1851600.1851698,
 abstract = {Today most mobile operating systems provide users with an application portal where they can search for applications published by third-party developers. However, finding new apps is not an easy task and requires either to know what to look for or to go through an endless list of applications. In this paper we present work in progress of a platform that allows its users to discover mobile applications in a serendipitous manner. AppAware is a mobile application that captures and shares installations, updates, and removals of Android programs in real time. Accordingly, AppAware allows its users to see what applications are being installed right now or around their position by other people, thus introducing a new way of interaction with application portals and other mobile users.},
 acmid = {1851698},
 address = {New York, NY, USA},
 author = {Girardello, Andrea and Michahelles, Florian},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851698},
 isbn = {978-1-60558-835-3},
 keyword = {AppAware, android, application portal, applications, market, mobile, social network},
 link = {http://doi.acm.org/10.1145/1851600.1851698},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {431--434},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {AppAware: Which Mobile Applications Are Hot?},
 year = {2010}
}


@inproceedings{Henze:2010:PSA:1851600.1851671,
 abstract = {The introduction of publicly available application stores for mobile devices enables to publish research prototypes to a wide audience. This distribution channel can be used to conduct studies with participants from all over the world and diverse backgrounds. We report from a study that compares three visualization techniques for off-screen objects on digital maps. Usage data from 362 persons was collected and 105 persons completed an interactive tutorial. Significant differences between the three conditions were found. The results support previous findings but we conjecture that the results are affected by unintended influences.},
 acmid = {1851671},
 address = {New York, NY, USA},
 author = {Henze, Niels and Boll, Susanne},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851671},
 isbn = {978-1-60558-835-3},
 keyword = {android market, evaluation, map navigation, off-screen},
 link = {http://doi.acm.org/10.1145/1851600.1851671},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {373--374},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Push the Study to the App Store: Evaluating Off-screen Visualizations for Maps in the Android Market},
 year = {2010}
}


@inproceedings{Ketabdar:2010:MTT:1851600.1851701,
 abstract = {In this work, we present a new approach for text (mainly digit) entry based on digit shaped gestures created in 3D space around a mobile device. Some new mobile devices such as Apple iPhone 3GS and Google Android are equipped with magnetic (compass) sensor. The main idea is to influence the magnetic sensor using a magnet taken in hand. The user draws (writes) digits in the 3D space around the device using the magnet taken in hand. Movement of the magnet changes temporal pattern of magnetic field around the device which is sensed and registered by the magnetic (compass) sensor. The registered pattern is then compared against already recorded templates for different digits. Such a text (digit) entry approach can be especially useful for small mobile devices in which it is hard to operate small buttons or touch screen. Using our technique, the text entry space extends beyond physical boundaries of the device. A demonstrator for this approach is implemented on Apple iPhone 3GS platform. It demonstrates registering a few templates for different digits, and recognizing digits written in the space around the device},
 acmid = {1851701},
 address = {New York, NY, USA},
 author = {Ketabdar, Hamed and Roshandel, Mehran and Y\"{u}ksel, Kamer Ali},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851701},
 isbn = {978-1-60558-835-3},
 keyword = {around device 3D interaction, embedded compass (magnetic) sensor, mobile devices, properly shaped magnet, touchless text (digit) entry},
 link = {http://doi.acm.org/10.1145/1851600.1851701},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {443--446},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {MagiWrite: Towards Touchless Digit Entry Using 3D Space Around Mobile Devices},
 year = {2010}
}


@inproceedings{White:2010:DEA:1851600.1851663,
 abstract = {This paper describes the process of designing an enterprise application that connects employees, the unique interface challenges, research activities, and subsequent changes to the design. The user-centered design process was driven by three research activities that informed the design in stages. Focus group sessions enabled us to understand requirements, wireframe usability evaluations helped us to validate macro level design decisions, and live prototype testing provided feedback that helped refine the design and validate the interactions. The collective research activities contributed to improved usability for navigation, actions, search, and a hierarchical organization chart. In addition, social networking within the work context was better understood and important concerns were identified. Key changes to the design included a streamlined three-level organization chart, the reduction of icons, and a new layout for search.},
 acmid = {1851663},
 address = {New York, NY, USA},
 author = {White, Brent-Kaan and Rice, Sean and Chen, Chun-Yi},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851663},
 isbn = {978-1-60558-835-3},
 keyword = {enterprise applications, iterative design, mobile HCI, mobile browsers, social networking, usability testing},
 link = {http://doi.acm.org/10.1145/1851600.1851663},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {349--352},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Designing Enterprise Applications That Connect Employees on the Go},
 year = {2010}
}


@inproceedings{Vihavainen:2010:CSP:1851600.1851648,
 abstract = {The adoption of new technologies in primary schools has fallen behind in terms of children's everyday use of technology. The use of mobile phones has been proposed as a promising field for learning. To date, the mobile learning technologies have rarely been integrated with current educational practices, however. Here, we present the results of our intervention study in which a mobile hybrid media system that combines the use of the traditional printed book with the mobile phone was used in English as foreign language (EFL) education in primary school. The results revealed an increase in learning motivation but also some conflicts when the boundaries of the school world and everyday life were blurred through the use of new technology.},
 acmid = {1851648},
 address = {New York, NY, USA},
 author = {Vihavainen, Sami and Kuula, Timo and Federley, Maija},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851648},
 isbn = {978-1-60558-835-3},
 keyword = {EFL, education, english as foreign language, intervention, mobile, print, user experience},
 link = {http://doi.acm.org/10.1145/1851600.1851648},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {279--282},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Cross-use of Smart Phones and Printed Books in Primary School Education},
 year = {2010}
}


@inproceedings{Dicke:2010:FEI:1851600.1851705,
 abstract = {Graphical user interfaces for mobile devices have several drawbacks in mobile situations. In this paper, we present Foogue, an eyes-free interface that utilizes spatial audio and gesture input. Foogue does not require visual attention and hence does not divert visual attention from the task at hand. Foogue has two modes, which are designed to fit the usage patterns of mobile users. For user input we designed a gesture language build of a limited number of simple but also easy to differentiate gesture elements.},
 acmid = {1851705},
 address = {New York, NY, USA},
 author = {Dicke, Christina and Wolf, Katrin and Tal, Yaroslav},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851705},
 isbn = {978-1-60558-835-3},
 keyword = {3D, auditory interface, gesture interaction, mobile, spatial audio},
 link = {http://doi.acm.org/10.1145/1851600.1851705},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {455--458},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Foogue: Eyes-free Interaction for Smartphones},
 year = {2010}
}


@inproceedings{Guerreiro:2010:AMT:1851600.1851608,
 abstract = {Mobile touch-screen interfaces and tetraplegic people have a controversial connection. While users with residual capacities in their upper extremities could benefit immensely from a device which does not require strength to operate, the precision needed to effectively select a target bars these people access to countless communication, leisure and productivity opportunities. Insightful projects attempted to bridge this gap via either special hardware or particular interface tweaks. Still, we need further insight into the challenges and the frontiers separating failure from success for such applications to take hold. This paper discusses an evaluation conducted with 15 tetraplegic people to learn the limits to their performance within a comprehensive set of interaction methods. We then present the results concerning a particular interaction technique: Tapping. Results show that performance varies across different areas of the screen whose distribution changes with target size.},
 acmid = {1851608},
 address = {New York, NY, USA},
 author = {Guerreiro, Tiago Jo\~{a}o Vieira and Nicolau, Hugo and Jorge, Joaquim and Gon\c{c}alves, Daniel},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851608},
 isbn = {978-1-60558-835-3},
 keyword = {evaluation, interaction, mobile device, tapping, tetraplegic, touch-screen},
 link = {http://doi.acm.org/10.1145/1851600.1851608},
 location = {Lisbon, Portugal},
 numpages = {4},
 pages = {31--34},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Assessing Mobile Touch Interfaces for Tetraplegics},
 year = {2010}
}


@inproceedings{Jensen:2010:MAA:1851600.1851603,
 abstract = {The mobile handset (and now tablet) market is coming a tangled mess, with strong advocates for device specific applications on the one hand and strong web standards within the browser on the other. This talk will reflect a bit on the history of mobile applications, focusing on the user issues involved in this debate. This is critical as too often the debate focuses on the business needs of application development. The mobile space has gone through, and will continue to go through profound shifts in technology and user capabilities. This talk will focus on the heterogeneous set of devices that will descend upon us all, a 'zombie apocalypse' of devices that will swarm upon us and upset the simple 'one app, one device' model that we still so quaintly adhere to today.},
 acmid = {1851603},
 address = {New York, NY, USA},
 author = {Jensen, Scott},
 booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
 doi = {10.1145/1851600.1851603},
 isbn = {978-1-60558-835-3},
 keyword = {keynote talk},
 link = {http://doi.acm.org/10.1145/1851600.1851603},
 location = {Lisbon, Portugal},
 numpages = {2},
 pages = {5--6},
 publisher = {ACM},
 series = {MobileHCI '10},
 title = {Mobile Apps and the Approaching Zombie Apocalypse},
 year = {2010}
}


