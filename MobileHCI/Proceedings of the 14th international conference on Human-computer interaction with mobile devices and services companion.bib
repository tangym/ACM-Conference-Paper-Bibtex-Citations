@proceedings{Churchill:2012:2371574,
 abstract = {It is our great pleasure to welcome you to the 2012 ACM International Conference on Human-Computer Interaction with Mobile Devices and Services -- MobileHCI 2012. MobileHCI is the world's leading conference in the field of Human Computer Interaction concerned with portable and personal devices and with the services to which they enable access. Mobile HCI provides a multidisciplinary forum for academics, hardware and software developers, designers and practitioners to discuss the challenges and potential solutions for effective interaction with and through mobile devices, applications, and services. The conference continues to attract a significant number of submissions; this year we received 212 valid paper submissions. We have continued our commitment to improve the quality of the review process. A senior program committee of 38 internationally renowned scientists from academia and industry was assembled. Each paper received 3 or more high-quality peer reviews, as well as an additional meta review by the assigned PC member. Following last year's successful cross-Atlantic, split committee meeting, the 38 committee members assembled in two locations (Palo Alto and Berlin) that were linked by audio and video connections. This provided an opportunity for the papers and reviews to be discussed in detail and all final decisions to be agreed upon by the Program Committee as a whole. The outcome of this process was that 54 of the 212 submissions were accepted (25%) for inclusion in the final Program, to be presented in San Francisco in September 2012. Of these, 39 were full papers and 15 were notes. A shepherding process was also used in which 6 of the 54 accepted papers were revised and improved under the expert guidance of a dedicated committee member. In our commitment to continually improving the quality of the Program, 8 papers/notes were given special recognition of excellence by being nominated for consideration as a Best Paper. A jury, consisting of 5 members of the Program Committee, was established to judge which of these papers represented the highest caliber of research in the field to be deserving of the Best Paper award. The final decision is to be revealed at the conference itself.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1105-2},
 location = {San Francisco, California, USA},
 publisher = {ACM},
 title = {MobileHCI '12: Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services},
 year = {2012}
}


@inproceedings{Ketabdar:2012:MGP:2371664.2371704,
 abstract = {In this work we present MagiGuitar - a guitar music performance application played in air on iPhone 3GS using a magnet! Users can play the mobile guitar application by moving a permanent magnet around a mobile device embedding a compass sensor (magnetometer). The touch less magnetic music performance technique allows users to play the mobile guitar application using highly intuitive hand gestures in the form of strumming action similar to a real guitar but in air. The proposed technique provides higher degree of flexibility for music performance, as the interaction space is extended to 3D space around the device. This allows users to play music in mobile devices using more natural, comfortable and flexible hand gestures as done with real instruments.},
 acmid = {2371704},
 address = {New York, NY, USA},
 author = {Ketabdar, Hamed and Chang, Hengwei and Moghadam, Peyman and Roshandel, Mehran and Naderi, Babak},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371704},
 isbn = {978-1-4503-1443-5},
 keyword = {compass sensor (magnetometer), digital music instruments, magnet, magnetic interaction, mobile devices},
 link = {http://doi.acm.org/10.1145/2371664.2371704},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {181--184},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {MagiGuitar: A Guitar That is Played in Air!},
 year = {2012}
}


@inproceedings{Chang:2012:CGE:2371664.2371699,
 abstract = {Virtual keyboards and controls, commonly used on mobile multi-touch devices, occlude content of interest and do not provide tactile feedback. Clip-on Gadgets solve these issues by extending the interaction area of multi-touch devices with physical controllers. Clip-on Gadgets use only conductive materials to map user input on the controllers to touch points on the edges of screens; therefore, they are battery-free, lightweight, and low-cost. In addition, they can be used in combination with multi-touch gestures. We present two hardware designs and a software toolkit, which enable users to simply attach Clip-on Gadgets to an edge of a device and start interacting with it.},
 acmid = {2371699},
 address = {New York, NY, USA},
 author = {Chang, Tzuwen and Yu, Neng-Hao and Tsai, Sung-Sheng and Chen, Mike Y. and Hung, Yi-Ping},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371699},
 isbn = {978-1-4503-1443-5},
 keyword = {mobile devices, multi-touch, physical controllers, tactile input, tangible, toolkit},
 link = {http://doi.acm.org/10.1145/2371664.2371699},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {163--166},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Clip-on Gadgets: Expandable Tactile Controls for Multi-touch Devices},
 year = {2012}
}


@inproceedings{Boring:2012:FTU:2371664.2371711,
 abstract = {Modern mobile devices allow a rich set of multi-finger interactions that combine modes into a single fluid act. Such gestures may require the use of both hands: one holding the device while the other is interacting. While on the go, however, only one hand may be available to both hold the device and interact with it. In this demo, we present the Fat Thumb interaction technique, which uses the thumb's contact size as a form of simulated pressure. We present how this can be used, for example, to integrate panning and zooming into a single interaction. Contact size determines the mode (i.e., panning with a small size, zooming with a large one), while thumb movement performs the selected mode.},
 acmid = {2371711},
 address = {New York, NY, USA},
 author = {Boring, Sebastian and Ledo, David and Chen, Xiang 'Anthony' and Marquardt, Nicolai and Tang, Anthony and Greenberg, Saul},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371711},
 isbn = {978-1-4503-1443-5},
 keyword = {mobile device, single-handed interaction, touch-screen},
 link = {http://doi.acm.org/10.1145/2371664.2371711},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {207--208},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {The Fat Thumb: Using the Thumb's Contact Size for Single-handed Mobile Interaction},
 year = {2012}
}


@inproceedings{Lee:2012:EES:2371664.2371682,
 abstract = {Deformable user interfaces have received increasing attention in recent HCI research. However, the effect of device size on deformable user interfaces has not been studied yet. This study is aimed to investigate how the size of a deformable device affects users' interaction behavior and preferences. We observed users interacting with deformable mockup displays of two different sizes. Overall, 36 participants provided 769 user-defined gestures for 11 basic commands. We compared and discussed users' preferences toward two different sizes of deformable devices. We also covered user-defined gestures and patterns of use for each device size. As a preliminary study for understanding form factors for designing deformable user interfaces, this study clearly show that the device size is an important factor to consider when designing mobile devices which can be deformed.},
 acmid = {2371682},
 address = {New York, NY, USA},
 author = {Lee, Sang-su and Lim, Youn-kyung and Lee, Kun-Pyo},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371682},
 isbn = {978-1-4503-1443-5},
 keyword = {deformable user interface, flexible display, organic user interface, user interface},
 link = {http://doi.acm.org/10.1145/2371664.2371682},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {89--94},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Exploring the Effects of Size on Deformable User Interfaces},
 year = {2012}
}


@inproceedings{Pfleging:2012:MMP:2371664.2371706,
 abstract = {Mobile phones offer great potential for personalization. Besides apps and background images, ringtones are the major form of personalization. They are most often used to have a personal sound for incoming texts and calls. Furthermore, ringtones are used to identify the caller or sender of a message. In parts, this function is utilitarian (e.g., caller identification without looking at the phone) but it is also a form of self-expression (e.g., favorite tune as standard ringtone). We investigate how audio can be used to convey richer information. In this demo we show how sonifications of SMS can be used to encode information about the sender's identity as well as the content and intention of a message based on flexible, user-generated mappings. We present a platform that allows arbitrary mappings to be managed and apps to be connected in order to create a sonification of any message. Using a background app on Android, we show the utility of the approach for mobile devices.},
 acmid = {2371706},
 address = {New York, NY, USA},
 author = {Pfleging, Bastian and Alt, Florian and Schmidt, Albrecht},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371706},
 isbn = {978-1-4503-1443-5},
 keyword = {rich audible information, sonification, text messages},
 link = {http://doi.acm.org/10.1145/2371664.2371706},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {189--192},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Meaningful Melodies: Personal Sonification of Text Messages for Mobile Devices},
 year = {2012}
}


@inproceedings{Fortmann:2012:PIR:2371664.2371668,
 abstract = {This paper presents PaceGuard, a mobile phone-based system which supports runners in keeping their cadence by auditory feedback. Experts have reported that maintaining the cadence is a prominent challenge for many running beginners and less experienced runners. However, this is important to make the exercise healthy and effort-saving, and to avoid discomfort like side stitches. PaceGuard automatically determines a suitable target cadence on the basis of the measured accelerometer data of the first 150 seconds of a run. Then this cadence as the guideline is constantly signaled to the runner via rhythmic pulse beats, defined as beats per minute. On the basis of previous studies [5], we assume runners will adapt their cadence to the presented pulse beats and thus will run more consistently compared to running without the auditory feedback of PaceGuard. Our pilot study results encourage this assumption.},
 acmid = {2371668},
 address = {New York, NY, USA},
 author = {Fortmann, Jutta and Pielot, Martin and Mittelsdorf, Marco and B\"{u}scher, Martin and Trienen, Stefan and Boll, Susanne},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371668},
 isbn = {978-1-4503-1443-5},
 keyword = {auditory feedback, mobile training assistant, running cadence},
 link = {http://doi.acm.org/10.1145/2371664.2371668},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {5--10},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {PaceGuard: Improving Running Cadence by Real-time Auditory Feedback},
 year = {2012}
}


@inproceedings{Edge:2012:TTT:2371664.2371715,
 abstract = {Learning a second language is hard, especially when the learner's brain must be retrained to identify sounds not present in his or her native language. It also requires regular practice, but many learners struggle to find the time and motivation. Our solution is to break down the challenge of mastering a foreign sound system into minute-long episodes of "microtraining" delivered through mobile gaming. We present the example of Tip Tap Tones - a mobile game with the purpose of helping learners acquire the tonal sound system of Mandarin Chinese. Full details can be found in the paper [1].},
 acmid = {2371715},
 address = {New York, NY, USA},
 author = {Edge, Darren and Cheng, Kai-Yin and Whitney, Michael and Qian, Yao and Yan, Zhijie and Soong, Frank},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371715},
 isbn = {978-1-4503-1443-5},
 keyword = {language learning, microtraining, mobile gaming},
 link = {http://doi.acm.org/10.1145/2371664.2371715},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {215--216},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Tip Tap Tones: Mobile Microtraining of Mandarin Sounds},
 year = {2012}
}


@inproceedings{Dunlop:2012:QOS:2371664.2371671,
 abstract = {Mobile phone keyboards can be categorized as unambiguous (one key per letter) or ambiguous (multiple letters per key). In this poster we present QWERTH: a semi-ambiguous keyboard for English in which we have grouped keys together that are less likely to cause prediction problems, while keeping some other keys unique. This has allowed us to increase keys to 1/5 screen width instead of 1/10 while maintaining a near-QWERTY layout. A prototype keyboard built on the OpenAdaptxt text entry engine, results from initial user studies and future study plans are discussed.},
 acmid = {2371671},
 address = {New York, NY, USA},
 author = {Dunlop, Mark D. and Durga, Naveen and Motaparti, Sunil and Dona, Prima and Medapuram, Varun},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371671},
 isbn = {978-1-4503-1443-5},
 keyword = {keyboard layouts, semi-ambiguous entry, text entry},
 link = {http://doi.acm.org/10.1145/2371664.2371671},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {23--28},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {QWERTH: An Optimized Semi-ambiguous Keyboard Design},
 year = {2012}
}


@inproceedings{Liu:2012:AAC:2371664.2371695,
 abstract = {Revisitation in mobile Web browsers takes more time than that in desktop browsers due to the limitations of mobile phones. In this paper, we propose AutoWeb, a novel approach to speed up revisitation in mobile Web browsing. In AutoWeb, opened Web pages are automatically classified into different groups based on their contents. Users can more quickly revisit an opened Web page by narrowing down search scope into a group of pages that share the same topic. We evaluated the classification accuracy and the accuracy is 92.4%. Three experiments were conducted to investigate revisitation performance in three specific tasks. Results show AutoWeb can save significant time for revisitation by 29.5%, especially for long time Web browsing, and that it improves overall mobile Web revisitation experience. We also compare automatic classification with other revisitation methods.},
 acmid = {2371695},
 address = {New York, NY, USA},
 author = {Liu, Jie and Xu, Wenchang and Shi, Yuanchun},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371695},
 isbn = {978-1-4503-1443-5},
 keyword = {automatic classification, mobile web, revisitation},
 link = {http://doi.acm.org/10.1145/2371664.2371695},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {153--154},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {AutoWeb: Automatic Classification of Mobile Web Pages for Revisitation},
 year = {2012}
}


@inproceedings{Henze:2012:CMI:2371664.2371684,
 abstract = {A number of mobile applications enable users to take photos of physical objects to receive related information and services. Commercial implementations such as Google Goggles use a Point & Shoot interaction technique that requires to explicitly taking a photo to trigger the object recognition. In this paper we investigate alternative interaction techniques to receive information about physical objects. For the study we try to rule out all aspects but the basic interaction. We compare Point & Shoot with two other techniques to access information about music CDs and show that using handheld Augmented Reality is preferred by users and leads to a lower perceived task load. Our findings confirm that research and development effort towards handheld Augmented Reality is well invested.},
 acmid = {2371684},
 address = {New York, NY, USA},
 author = {Henze, Niels and Boll, Susanne},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371684},
 isbn = {978-1-4503-1443-5},
 keyword = {augmented reality, cd, handheld augmented reality, image analysis, mobile interaction, mobile phone, music},
 link = {http://doi.acm.org/10.1145/2371664.2371684},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {101--106},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Camera-based Mobile Interaction Techniques for Physical Objects},
 year = {2012}
}


@inproceedings{Cohen:2012:PPP:2371664.2371709,
 abstract = {We have built haptic interfaces featuring smartphones that use magnetometer-derived orientation sensing to modulate virtual displays. Embedding such devices into swinging a ordances allows a "poi"-style interface, whirling tethered devices, for a novel interaction technique. Dynamic twirling can be used to control multimodal displays - including positions of sources & sinks in spatial sound, subjects (avatars) & objects in virtual environments, and object movies ("turnos") & panoramas ("panos") in image-based renderings. This "practically panoramic" multimodal interface can be enjoyed in an appropriate spot as location-based entertainment, locative media for cross-platform, "mobile ambient" experience.},
 acmid = {2371709},
 address = {New York, NY, USA},
 author = {Cohen, Michael},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371709},
 isbn = {978-1-4503-1443-5},
 keyword = {cross-platform "ambient mobile" interface, locative, multimodal, practically panoramic interface, situated panorama},
 link = {http://doi.acm.org/10.1145/2371664.2371709},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {199--202},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {POI Poi: Point-of-interest Poi for Multimodal Tethered Whirling},
 year = {2012}
}


@inproceedings{Milanova:2012:DEC:2371664.2371677,
 abstract = {Increasing the potential of mobile applications to elicit positive emotions can help overcome the prevalent ephemerality of such applications. The current paper addresses the possibilities to support the elicitation of favorable emotions during the development process of mobile applications. It provides a short overview of the theoretical background of emotion research and design to subsequently present an experiential study, focused on the design of positive emotional resonance for an iPhone ride sharing service in terms of desire, satisfaction and fascination.},
 acmid = {2371677},
 address = {New York, NY, USA},
 author = {Milanova, Veselina and Mandl, Thomas and K\"{o}lle, Ralph},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371677},
 isbn = {978-1-4503-1443-5},
 keyword = {emotional design, mobile design, user experience},
 link = {http://doi.acm.org/10.1145/2371664.2371677},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {59--64},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Design for Emotion: A Case Study},
 year = {2012}
}


@inproceedings{Kim:2012:BMI:2371664.2371698,
 abstract = {Due to the convenience of digital photography, people often end up with multiple shots of the same scene with only slight variations. We propose an easy-to-use brush-and-drag interface, helping them to interactively explore and compare this type of photos on a tablet computer. First, we mark an area of interest on a photo with our finger(s). Next, our segmentation engine will automatically segment corresponding image elements among the photos, which we can then drag across a single screen to compare side-by-side. This can be followed by a series of simple finger gestures applied to the image elements (representing the photos) to rank, select favorites for sharing, or discard unwanted photos.},
 acmid = {2371698},
 address = {New York, NY, USA},
 author = {Kim, Seon Joo and Ng, Hongwei and Winkler, Stefan and Song, Peng and Fu, Chi-Wing},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371698},
 isbn = {978-1-4503-1443-5},
 keyword = {digital photo collections, user interaction},
 link = {http://doi.acm.org/10.1145/2371664.2371698},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {161--162},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Brush-and-drag: A Multi-touch Interface for Photo Triaging},
 year = {2012}
}


@inproceedings{Back:2012:MMC:2371664.2371708,
 abstract = {In this demonstration we will show a mobile remote control and monitoring application for a recipe development laboratory at a local chocolate production company. In collaboration with TCHO, a chocolate maker in San Francisco, we built a mobile Web app designed to allow chocolate makers to control their laboratory's machines. Sensor data is imported into the app from each machine in the lab. The mobile Web app is used for control, monitoring, and collaboration. We have tested and deployed this system at the real-world factory and it is now in daily use. This project is designed as part of a research exploration into enhanced collaboration in industrial settings between physically remote people and places, e.g. factories in China with clients in the US.},
 acmid = {2371708},
 address = {New York, NY, USA},
 author = {Back, Maribeth and Liew, Bee and Dunnigan, Anthony and Vaughan, James},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371708},
 isbn = {978-1-4503-1443-5},
 keyword = {industrial control systems, laboratory instrumentation, mobile collaboration, remote monitoring, smart laboratory},
 link = {http://doi.acm.org/10.1145/2371664.2371708},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {195--198},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Mobile Monitoring and Control System for a Food Industry Development Laboratory},
 year = {2012}
}


@inproceedings{Lee:2012:FCN:2371664.2371680,
 abstract = {This paper presents a new interaction technique for pass code inputting in a handheld device. This method adopts a tangential force to unlock the device instead of touch passwords or drawing patterns that require looking at the display. A user can grasp a mobile phone and apply pressure onto the display surface without having to look at the display. A tangential-force-based interface is implemented for a smart phone. The interface is devised to receive four directional force inputs: up, down, left, and right. The feasibility of the proposed method was evaluated, and it was found that a 92% success ratio can be achieved.},
 acmid = {2371680},
 address = {New York, NY, USA},
 author = {Lee, Hyunjoeng and Lee, Bhoram and Park, Joonah},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371680},
 isbn = {978-1-4503-1443-5},
 keyword = {force-based interface, input device, mobile interaction},
 link = {http://doi.acm.org/10.1145/2371664.2371680},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {77--82},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Force Code: A New Interaction Technique Using Tangential Force Input},
 year = {2012}
}


@inproceedings{Hwang:2012:MVC:2371664.2371688,
 abstract = {For the elderly people who have a low vision to safely navigate in unknown environments, the system should be developed to recognize where the obstacles in the scene are. In this paper, we present a vision system for obstacle detection, and implemented it on the Smartphone that provides real-time feedback to the user. In addition, various obstacles are localized using online background model, then viable paths to avoid them are determined by neural network-based classifier. Finally, the recognized results are verbally notified to the user through a visual interface. To demonstrate the effectiveness of the proposed method, it was tested on real indoors and outdoors with several environmental factors such as illumination type and complex structures. Then the results demonstrated the effectiveness of the proposed method.},
 acmid = {2371688},
 address = {New York, NY, USA},
 author = {Hwang, Jihye and Ji, Yeounggwang and Kim, Eun Yi},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371688},
 isbn = {978-1-4503-1443-5},
 keyword = {elderly people, multiple disabled people, obstacle detection, visual interface},
 link = {http://doi.acm.org/10.1145/2371664.2371688},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {125--130},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Monocular Vision-based Collision Avoidance System},
 year = {2012}
}


@inproceedings{Schulze:2012:EUE:2371664.2371691,
 abstract = {This paper introduces a structured approach to extract user experience centered product requirements based on a framework that aims at linking user needs regarding mobile social media with product quality. By means of a user study with the mobile sharing service LiveShare by Cooliris we derived general guidelines and clear recommendations for product requirements.},
 acmid = {2371691},
 address = {New York, NY, USA},
 author = {Schulze, Katrin and Kroemker, Heidi},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371691},
 isbn = {978-1-4503-1443-5},
 keyword = {application experiences, mobile social media, product requirements, usability, user experience, user needs},
 link = {http://doi.acm.org/10.1145/2371664.2371691},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {143--148},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Extracting User Experience Centered Product Requirements for Mobile Social Media Applications},
 year = {2012}
}


@inproceedings{Wechsung:2012:VDC:2371664.2371686,
 abstract = {This paper reports the results of an explorative field study investigating if and how remembered UX evaluations differ from evaluations collected during usage. Results show that while quantitative ratings are similar, qualitative data differs: Comments assessed during usage were less detailed but contained more affective evaluations compared to the retrospective remarks.},
 acmid = {2371686},
 address = {New York, NY, USA},
 author = {Wechsung, Ina and Jepsen, Kathrin and Burkhardt, Felix and K\"{o}hler, Annerose and Schleicher, Robert},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371686},
 isbn = {978-1-4503-1443-5},
 keyword = {evaluation, field study, methodology, user experience},
 link = {http://doi.acm.org/10.1145/2371664.2371686},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {113--118},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {View from a Distance: Comparing Online and Retrospective Ux-evaluations},
 year = {2012}
}


@inproceedings{Wilson:2012:THA:2371664.2371713,
 abstract = {Thermal stimulation is a rich, emotive and salient feedback channel that is suitable for mobile HCI. It can act as an alternative non-visual notification channel for mobile situations that are too bumpy or noisy for vibrotactile and audio feedback. It can augment both visual and non-visual feedback to add an extra richness to the interaction experience. In addition, thermal output is entirely private, so it is suitable for quiet environments or when secrecy is important. This demonstration will consist of some example applications which highlight a variety of uses. We show an application titled "Tempera-tour", where environmental temperatures from around the world can be felt. We also show thermal augmentation of visual and audio media as a means of influencing hedonic experience. Finally we show simple thermal widgets, such as a thermal progress bar, ambient notifications and thermal availability information. This demo accompanies the paper "Thermal Icons: Evaluating Structured Thermal Feedback for Mobile Interaction".},
 acmid = {2371713},
 address = {New York, NY, USA},
 author = {Wilson, Graham and Brewster, Stephen and Halvey, Martin and Hughes, Stephen},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371713},
 isbn = {978-1-4503-1443-5},
 keyword = {mobile interaction, non-visual feedback, thermal feedback},
 link = {http://doi.acm.org/10.1145/2371664.2371713},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {211--212},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Tempera-tour, Hot Apps, Cool Widgets: Thermal Feedback for Mobile Devices},
 year = {2012}
}


@inproceedings{Southern:2012:BTM:2371664.2371696,
 abstract = {We present a demonstration of BrailleTouch, an accessible keyboard for blind users on a touchscreen smartphone (see Figure 1). Based on the standard Perkins Brailler, BrailleTouch implements a six-key chorded braille soft keyboard [1]. We will briefly introduce audience members to the braille code, and then allow them to hold the BrailleTouch prototype and enter text, with the aid of a visual chart of the braille alphabet.},
 acmid = {2371696},
 address = {New York, NY, USA},
 author = {Southern, Caleb and Clawson, James and Frey, Brian and Abowd, Gregory and Romero, Mario},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371696},
 isbn = {978-1-4503-1443-5},
 keyword = {accessibility, blindness, chording, gestures, mobile devices, multi-touch interaction, text entry, touchscreens},
 link = {http://doi.acm.org/10.1145/2371664.2371696},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {155--156},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Braille Touch: Mobile Touchscreen Text Entry for the Visually Impaired},
 year = {2012}
}


@inproceedings{Willis:2012:SMG:2371664.2371710,
 abstract = {SideBySide is a system designed for ad-hoc multi-user interaction with handheld projectors. SideBySide does not require instrumentation of the environment and can be used almost anywhere. This paper examines the diverse ways that children interact with SideBySide when playing interactive games. Observations from a preliminary user study are presented along with quantitative evaluation of the SideBySide tracking approach.},
 acmid = {2371710},
 address = {New York, NY, USA},
 author = {Willis, Karl D.D. and Poupyrev, Ivan and Hudson, Scott and Mahler, Moshe},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371710},
 isbn = {978-1-4503-1443-5},
 keyword = {characters, children, handheld projector, infrared projector, multi-user interaction, pico projector, projector games},
 link = {http://doi.acm.org/10.1145/2371664.2371710},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {203--206},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {SideBySide: Multi-user Gestural Interaction with Handheld Projectors},
 year = {2012}
}


@inproceedings{Marques:2012:PSU:2371664.2371683,
 abstract = {This paper presents a study on privacy and secrecy requirements that users feel while in the presence of other people. They are viewed as issues of a social activity and pertain to the desire that the content of messages or the act of writing or reading them is not perceived by others. We assess the needs for privacy according to the message's themes and acquaintance type with the recipient. We also present and discuss our findings considering user strategies in coping with the required privacy using both a quantitative and a qualitative approach. The study results show clearly the need to consider those requirements in the design of messaging applications for mobile devices. Circa 50% of the messages analyzed required privacy on the act of writing/reading. The reasons are multifaceted and vary according to the addressees and the content type reaching 70% for specific cases. We close the paper, with a proposal of a personal, multimodal and inconspicuous communication framework, which not only allows users to define their vocabulary, but also entry and output methods from a range of different modalities.},
 acmid = {2371683},
 address = {New York, NY, USA},
 author = {Marques, Diogo and Duarte, Lu\'{\i}s and Carri\c{c}o, Lu\'{\i}s},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371683},
 isbn = {978-1-4503-1443-5},
 keyword = {inconspicuousness, privacy, text messaging, ubiquity},
 link = {http://doi.acm.org/10.1145/2371664.2371683},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {95--100},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Privacy and Secrecy in Ubiquitous Text Messaging},
 year = {2012}
}


@inproceedings{Ketabdar:2012:MSA:2371664.2371705,
 abstract = {Recently, a new authentication method based on 3D signatures created in air is proposed for mobile devices [4]. The 3D signature is created in air using a properly shaped magnet (a rod or ring) taken in hand. It is based on influencing compass sensor embedded in the new generation of mobile devices. In this paper, we present implementation of this technology on a mobile device (iPhone 3GS). It can demonstrate authentication process using a gesture in the from of a 3D signature freely created in the space around the device by a magnet held in hand. Movement of the magnet in the from of a signature produces a temporal change in the magnetic field sensed by the embedded compass sensor, and can be used as a basis for authentication. As magnetic signatures are performed in 3D space, they can provide a wider choice for authentication, and they can not be easily hardcopied.},
 acmid = {2371705},
 address = {New York, NY, USA},
 author = {Ketabdar, Hamed and Moghadam, Peyman and Naderi, Babak and Roshandel, Mehran},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371705},
 isbn = {978-1-4503-1443-5},
 keyword = {3d magnetic signature, embedded compass (magnetometer), magnetic field, mobile devices, user authentication},
 link = {http://doi.acm.org/10.1145/2371664.2371705},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {185--188},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Magnetic Signatures in Air for Mobile Devices},
 year = {2012}
}


@inproceedings{Alexander:2012:IDD:2371664.2371723,
 abstract = {Technological developments in display technologies allow us to explore the design of mobile devices that extend beyond the rigid, flat screen surfaces with which we are familiar. The next generation mobile devices will instead include deformable displays that users can physically push, pull, bend or flex or have those actions performed by the device so that it physically mutates to better represent the on-screen content. This workshop is interested in all aspects of Deformable Displays: from the methods, materials and alternatives for the construction of such displays to the design of input techniques for such devices and how shape change can be used as an additional channel for output. This workshop will bring together product developers, interaction designers and academics to create a community around deformable displays. We will preview the state-of-the-art through case studies and identify key research themes in this area.},
 acmid = {2371723},
 address = {New York, NY, USA},
 author = {Alexander, Jason and Kildal, Johan and Hornbaek, Kasper and Aaltonen, Viljakaisa and Lucero, Andr{\'e}s and Subramanian, Sriram},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371723},
 isbn = {978-1-4503-1443-5},
 keyword = {deformable displays, display surfaces, interaction, shape-changing displays},
 link = {http://doi.acm.org/10.1145/2371664.2371723},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {237--240},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Interaction with Deformable Displays},
 year = {2012}
}


@inproceedings{Nanavati:2012:SWS:2371664.2371727,
 abstract = {The SiMPE workshop series started in 2006 [2] with the goal of enabling speech processing on mobile and embedded devices to meet the challenges of pervasive environments (such as noise) and leveraging the context they offer (such as location). SiMPE 2010 and 2011 brought together researchers from the speech and the HCI communities. Multimodality got more attention in SiMPE 2008 than it had received in the previous years. In SiMPE 2007, the focus was on developing regions. Speech User interaction in cars was a focus area in 2009. With SiMPE 2012, the 7th in the series, we hope to explore the area of speech along with sound. When using the mobile in an eyes-free manner, it is natural and convenient to hear about notifications and events. The arrival of an SMS has used a very simple sound based notification for a long time now. The technologies underlying speech processing and sound processing are quite different and these communities have been working mostly independent of each other. And yet, for multimodal interactions on the mobile, it is perhaps natural to ask whether and how speech and sound can be mixed and used more effectively and naturally.},
 acmid = {2371727},
 address = {New York, NY, USA},
 author = {Nanavati, Amit A. and Rajput, Nitendra and Rudnicky, Alexander and Turunen, Markku and Sandholm, Thomas and Munteanu, Cosmin and Penn, Gerald},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371727},
 isbn = {978-1-4503-1443-5},
 keyword = {audio interaction, mobile computing, pervasive computing, sound, speech processing},
 link = {http://doi.acm.org/10.1145/2371664.2371727},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {251--254},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {SiMPE: 7th Workshop on Speech and Sound in Mobile and Pervasive Environments},
 year = {2012}
}


@inproceedings{Burigat:2012:SIV:2371664.2371700,
 abstract = {Overview+Detail and Wedge have been proposed in the literature as effective approaches to resolve the off-screen objects problem on mobile devices. However, they have been studied with a small number of off-screen objects and (in most studies) with static scenarios, in which users did not have to perform any navigation activity. In this demo, we show improved versions of Wedge and Overview+Detail which are specifically aimed at simplifying their use in dynamic scenarios that involve large numbers of off-screen objects.},
 acmid = {2371700},
 address = {New York, NY, USA},
 author = {Burigat, Stefano and Chittaro, Luca and Vianello, Andrea},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371700},
 isbn = {978-1-4503-1443-5},
 keyword = {map navigation, mobile devices, off-screen objects, overview+detail, peripheral awareness, visualization, wedge},
 link = {http://doi.acm.org/10.1145/2371664.2371700},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {167--168},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {A System for Interactive Visualization of Off-screen Objects on Mobile Devices},
 year = {2012}
}


@inproceedings{Gauglitz:2012:PSI:2371664.2371693,
 abstract = {In the accompanying paper [1], we describe a framework and prototype implementation for unobtrusive mobile remote collaboration on tasks that involve the physical environment. Our system uses model-free, markerless visual tracking to facilitate decoupled, live updated views of the environment and world-stabilized annotations while supporting a moving camera and unknown, unprepared environments. We conducted a user study with 48 participants to evaluate our concept. In this demo, we will present our system prototype and the setup used in the user study: a remote expert instructs a local user to operate a mock-up airplane. Users will be able to try out our interface as well as the two interfaces used as baseline in the study.},
 acmid = {2371693},
 address = {New York, NY, USA},
 author = {Gauglitz, Steffen and Lee, Cha and Turk, Matthew and H\"{o}llerer, Tobias},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371693},
 isbn = {978-1-4503-1443-5},
 keyword = {augmented reality, markerless visual tracking, telecollaboration, user study, video-mediated communication},
 link = {http://doi.acm.org/10.1145/2371664.2371693},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {149--150},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {A Prototype Setup to Integrate the Physical Environment into Mobile Remote Collaboration},
 year = {2012}
}


@inproceedings{Swaminathan:2012:MVV:2371664.2371726,
 abstract = {The explosion in smartphone and other mobile/hand-held devices' capabilities are increasingly being exploited to bring vision-based mobile applications to the user. Applications using technologies such as image recognition, augmented reality, amongst others are altering the way we interact with the world around us. This workshop aims to address the fundamental vision-based technologies that enable new interaction modalities and metaphors. It also addresses the exploration of new radical or experimental interactions as well as new design-oriented and social applications. The aim is to promote a discussion among researchers and practitioners working in the area of mobile HCI from the standpoint of computer vision as an enabling technology for new forms of mobile interaction, new application categories, and implications for user experience and design.},
 acmid = {2371726},
 address = {New York, NY, USA},
 author = {Swaminathan, Rahul and Rohs, Michael and \"{A}ngeslev\"{a}, Jussi},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371726},
 isbn = {978-1-4503-1443-5},
 keyword = {augmented reality, computer vision, design, interaction, mobile, vision-based applications},
 link = {http://doi.acm.org/10.1145/2371664.2371726},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {249--250},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Mobile Vision (MobiVis): Vision-based Applications and HCI},
 year = {2012}
}


@inproceedings{Manabe:2012:HTS:2371664.2371703,
 abstract = {A simple technique which changes regular headphones into input-and-output devices is proposed. It detects headphone taps and also captures user's voice. Two prototypes are implemented. Users can control music players and have phone conversation via their favorite headphones without attaching external switches or microphones. We confirm that they work well with many headphones in various environments.},
 acmid = {2371703},
 address = {New York, NY, USA},
 author = {Manabe, Hiroyuki and Fukumoto, Masaaki},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371703},
 isbn = {978-1-4503-1443-5},
 keyword = {headphones, input device, tap, wearable},
 link = {http://doi.acm.org/10.1145/2371664.2371703},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {177--180},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Headphone Taps: A Simple Technique to Add Input Function to Regular Headphones},
 year = {2012}
}


@inproceedings{Lamont:2012:TMT:2371664.2371716,
 abstract = {A tablet interface for manipulating microscopic particles is augmented with vibrotactile and audio feedback.The feedback is generated using a novel real-time synthesis library based on approximations to physical processes, and is efficient enough to run on mobile devices, despite their limited computational power. The feedback design and usability testing was done with a realistic simulator on appropriate tasks, allowing users to control objects more rapidly, with fewer errors and applying more consistent forces. The feedback makes the interaction more tangible, giving the user more awareness of changes in the characteristics of the optical tweezers as the number of optical traps changes.},
 acmid = {2371716},
 address = {New York, NY, USA},
 author = {Lamont, Stuart and Bowman, Richard and Williamson, John and Rath, Matthias and Murray-Smith, Roderick and Padgett, Miles},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371716},
 isbn = {978-1-4503-1443-5},
 keyword = {optical tweezers, real-time synthesis, tactile feedback},
 link = {http://doi.acm.org/10.1145/2371664.2371716},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {217--218},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Touching the Micron: Tactile Interactions with an Optical Tweezer},
 year = {2012}
}


@inproceedings{Kheiravar:2012:MAC:2371664.2371690,
 abstract = {Group work in classroom settings is an efficient approach used by many professors to provide a higher level of engagement [3]. Unfortunately, the classroom arrangement is often detrimental to group exercises in which every group member should participate equally. When a group includes more than 3 participants, students are often spread on one or two rows. This configuration makes communication and participation difficult for the students on the extremities. It also limits students from one of the two rows to feel engaged as soon as the exercise requires a specific orientation for the work to be done (such as reading or writing a program). This study explores the use of a touch screen mobile platform such as the iPAD for facilitating students' collaboration. The objective of the platform is to ease interaction among students by enabling students who are not in close proximity to each other to be active participants and work collaboratively. The current prototype allows a group of students to solve a problem individually or collaboratively on their own tablet devices. The finished software will be evaluated for its efficacy as a collaborative tool with on-line groups, as well as in-class groups.},
 acmid = {2371690},
 address = {New York, NY, USA},
 author = {Kheiravar, Salma and Lasserre, Patricia and Campbell, Robert},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371690},
 isbn = {978-1-4503-1443-5},
 keyword = {mobile learning, real-time collaborative educational software, team based learning},
 link = {http://doi.acm.org/10.1145/2371664.2371690},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {137--142},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {A Mobile Application for Collaborative Learning},
 year = {2012}
}


@inproceedings{Sundstrom:2012:CAG:2371664.2371722,
 abstract = {This workshop will be about contextual gaming where the arena for gaming is the car, and the space inside and outside the car while driving. We aim to gather both practitioners and academics to work out the possibilities and challenges of this design space that to our experience has been slightly forgotten about since Juhlin and colleagues' excellent work on the Backseat Playground [1], [2].},
 acmid = {2371722},
 address = {New York, NY, USA},
 author = {Sundstr\"{o}m, Petra and Wilfinger, David and Meschtscherjakov, Alexander and Tscheligi, Manfred and Schmidt, Albrecht and Juhlin, Oskar},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371722},
 isbn = {978-1-4503-1443-5},
 keyword = {automotive gaming},
 link = {http://doi.acm.org/10.1145/2371664.2371722},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {233--236},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {The Car As an Arena for Gaming},
 year = {2012}
}


@inproceedings{Chang:2012:TBL:2371664.2371717,
 abstract = {The popularization of Location Based Services (LBS) has created new challenges for interaction designers in validating the design of their applications. Existing tools designed to play back GPS location traces data streams have shown potential for testing LBS applications and for supporting rapid and reflective prototyping. However, selecting a useful set of location traces from among a large collection remains a difficult task. In this paper, we present TraceViz, the first system that is aimed specifically at supporting LBS designers in exploring, filtering, and selecting location traces. TraceViz employs dynamic queries and "brushing" to allow LBS designers to flexibly adjust their trajectory filter criteria to find location traces of interest. An evaluation performed with eight LBS designers and developers indicates that TraceViz is helpful for rapidly locating useful traces and also highlights areas for future improvement.},
 acmid = {2371717},
 address = {New York, NY, USA},
 author = {Chang, Yung-Ju and Hung, Pei-Yao and Newman, Mark},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371717},
 isbn = {978-1-4503-1443-5},
 keyword = {capture and playback, design tools, direct manipulation, information visualization, location-based services},
 link = {http://doi.acm.org/10.1145/2371664.2371717},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {219--220},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {TraceViz: "Brushing" for Location Based Services},
 year = {2012}
}


@inproceedings{Goncalves:2012:SMA:2371664.2371721,
 abstract = {In this document we propose the creation of the Second Mobile Accessibility Workshop at MobileHCI 2012. Mobile Accessibility is an area that has grown both in importance and number of researchers in recent years. After a successful first edition at Interact 2011, we propose to once again bring together researcher and practitioners in a fruitful workshop, leading to synergies and major developments in the area.},
 acmid = {2371721},
 address = {New York, NY, USA},
 author = {Gon\c{c}alves, Daniel and Carri\c{c}o, Luis and Magnusson, Charlotte},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371721},
 isbn = {978-1-4503-1443-5},
 keyword = {accessibility, mobile accessibility, workshop},
 link = {http://doi.acm.org/10.1145/2371664.2371721},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {229--232},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Second Mobile Accessibility Workshop},
 year = {2012}
}


@inproceedings{Edge:2012:MAF:2371664.2371707,
 abstract = {Flashcard systems typically help students learn facts (e.g., definitions, names, and dates), relying on intense initial memoriztion with subsequent tests delayed up to days later. This approach does not exploit the short, sparse, and mobile opportunities for microlearning throughout the day, nor does it support learners who need the motivation that comes from successful study sessions. In contrast, our MemReflex system of adaptive flashcards gives fast-feedback by retesting new items in quick succession, dynamically scheduling future tests according to a model of the learner's memory. Full details can be found in the paper [1].},
 acmid = {2371707},
 address = {New York, NY, USA},
 author = {Edge, Darren and Fitchett, Stephen and Whitney, Michael and Landay, James},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371707},
 isbn = {978-1-4503-1443-5},
 keyword = {adaptive systems, language learning, mobile flashcards},
 link = {http://doi.acm.org/10.1145/2371664.2371707},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {193--194},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {MemReflex: Adaptive Flashcards for Mobile Microlearning},
 year = {2012}
}


@inproceedings{Linnell:2012:WOT:2371664.2371678,
 abstract = {Although mobile-based prototyping platforms are numerous, there are currently no tools that support Wizard of Oz interactions on Android. This paper describes a Wizard of Oz prototyping system for Android, via which a designer can enhance digitally generated mock-ups or scanned-in paper sketches with interactive widgets and automated screen transitions. Screen transitions can be based on user action such as a button presses, triggered manually by an experimenter observing from a laptop or triggered based on the user's location or the time. We have integrated scenario-based user testing, a context in which Wizard of Oz testing is often used, by providing support for location- and time-based display of videos and screens in the prototype. It is our hope that this system will find wider use in the design community.},
 acmid = {2371678},
 address = {New York, NY, USA},
 author = {Linnell, Natalie and Bareiss, Ray and Pantic, Kristoffer},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371678},
 isbn = {978-1-4503-1443-5},
 keyword = {android, context aware, prototyping tools, ubiquitous computing, wizard of oz},
 link = {http://doi.acm.org/10.1145/2371664.2371678},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {65--70},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {A Wizard of Oz Tool for Android},
 year = {2012}
}


@inproceedings{Lee:2012:SSI:2371664.2371676,
 abstract = {This paper presents a smart and space-aware interaction(S2Interaction) technique using smartphones for co-located and collaborative interaction in a shared space. S2Interaction enables to interact with digital contents in a shared display or public space by spatially tracking multiple smartphones with a depth camera, KinectTM. Since the proposed approach detects the relative location of the smartphone with respect to the shared space without attaching any sensors, it provides very effective and natural interactions for local space exploration and collaboration, and it is also robust in most collaboration environments under low illumination condition.},
 acmid = {2371676},
 address = {New York, NY, USA},
 author = {Lee, Jae Yeol and Kim, Min Seok and Seo, Dong Woo and Lee, Sang Min and Kim, Jae Sung},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371676},
 isbn = {978-1-4503-1443-5},
 keyword = {collaboration, kinect, smartphone, space awareness, user interaction},
 link = {http://doi.acm.org/10.1145/2371664.2371676},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {53--58},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Smart and Space-aware Interactions Using Smartphones in a Shared Space},
 year = {2012}
}


@inproceedings{Wolf:2012:SOG:2371664.2371669,
 abstract = {Regardless of how gestural phone interaction (like pinching on a touch screen for content zooming) is implemented in almost any mobile device; there are still no design guidelines for gestural control. These should be designed with respect to ergonomics and hand anatomy. There are many human-side aspects to take care of when designing gestures. We evaluate gestures regarding the ergonomic aspects while interacting with mobile devices and present ergonomic requirements of finger gestures on the back and side of a vertically and as well as horizontally hand-held phone, such as dragging and lifting fingers from the surface. The results suggest that drag and lift gestures have the potential to be executed one-handed while using the phone and that certain device configurations may be accessed seamlessly with that type of gesture control.},
 acmid = {2371669},
 address = {New York, NY, USA},
 author = {Wolf, Katrin and McGee-Lennon, Marilyn and Brewster, Stephen},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371669},
 isbn = {978-1-4503-1443-5},
 keyword = {around device, back-of-device, gesture, probe.},
 link = {http://doi.acm.org/10.1145/2371664.2371669},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {11--16},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {A Study of On-device Gestures},
 year = {2012}
}


@inproceedings{Poppinga:2012:RLA:2371664.2371724,
 abstract = {Mobile HCI studies are often conducted in a highly controlled environment and with a small convenient sample. The findings cannot always be generalized to the behaviour of real users in real contexts. In contrast, researchers recently started to use apps and other wide distribution channels as an apparatus for mobile HCI research. Publishing apps in mobile application stores and public APIs for mobile services enable researchers to study large samples in their 'natural habitat'. This workshop continues the successful Research in the Large workshop series held at UbiComp 2010 and 2011. Relevant topics include the design of large-scale studies, reaching target users, dealing with new types of evaluation data, and heterogeneous usage contexts. We seek ways to systematically collect, analyse and make sense of large datasets, potentially in real-time. The goal of this workshop is to provide a forum for researchers and developers from academia and industry to exchange experiences, insights and strategies for wide distribution of user studies towards large-scale mobile HCI research.},
 acmid = {2371724},
 address = {New York, NY, USA},
 author = {Poppinga, Benjamin and Cramer, Henriette and B\"{o}hmer, Matthias and Morrison, Alistair and Bentley, Frank and Henze, Niels and Rost, Mattias and Michahelles, Florian},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371724},
 isbn = {978-1-4503-1443-5},
 keyword = {app store, game, large-scale, mobile hci, user study},
 link = {http://doi.acm.org/10.1145/2371664.2371724},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {241--244},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Research in the Large 3.0: App Stores, Wide Distribution, and Big Data in MobileHCI Research},
 year = {2012}
}


@inproceedings{Hagan:2012:SMM:2371664.2371675,
 abstract = {The spread of mobile phone usage to slum areas raises the possibility of using mobile technology to address problems facing the poorest of the world's poor. We present a case study of Safe Mathare, a design project aimed at improving women's safety in Nairobi, Kenya. Safe Mathare provides community patrols with basic smartphone technology to help women commute safely through a slum neighborhood during dusk and dawn hours. The project started as a prototype developed in a university course and has found willing partners with local NGOs and government. During its pilot phase, it has run into many challenges in particular around the issue of vigilantism. This paper explores the development and implementation of Safe Mathare, raising the questions of whether and how design can leverage technology to build a social network for security.},
 acmid = {2371675},
 address = {New York, NY, USA},
 author = {Hagan, Margaret and Zhang, Nan and Kaye, Joseph 'Jofish'},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371675},
 isbn = {978-1-4503-1443-5},
 keyword = {commuting, ict4d, kenya, mobiles, safety, security},
 link = {http://doi.acm.org/10.1145/2371664.2371675},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {47--52},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Safe Mathare: A Mobile System for Women's Safe Commutes in the Slums},
 year = {2012}
}


@inproceedings{Kjeldskov:2012:RMM:2371664.2371729,
 abstract = {This panel addresses the past, present and future of mobile HCI research in terms of methods and focus. The panel takes its offset in a new literature survey following up from Kjeldskov and Graham's survey from Mobile HCI 2003 [6]. Based on this, and their own experiences, the panelists will outline and discuss their views on current methodological trends in mobile HCI research, and suggest and discuss what opportunities they see for responding to these trends and pushing the research field further forward.},
 acmid = {2371729},
 address = {New York, NY, USA},
 author = {Kjeldskov, Jesper and Cheverst, Keith and de S\'{a}, Marco and Jones, Matt and Murray-Smith, Roderick},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371729},
 isbn = {978-1-4503-1443-5},
 keyword = {literature survey, research methods, research purpose},
 link = {http://doi.acm.org/10.1145/2371664.2371729},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {255--260},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Research Methods in Mobile HCI: Trends and Opportunities},
 year = {2012}
}


@inproceedings{deSa:2012:MAR:2371664.2371720,
 abstract = {Mobile devices have increasing computational power. Their sophistication in terms of network access, content rendering and interactivity, and data gathering is growing. Sensors such as microphones, cameras, gyroscopes, and accelerometers are routinely available and devices are enhanced with a various output modalities from visual to sound to vibroctactile. It is thus already possible for us as designers and developers to enhance the way people encounter content, create and experience content and express themselves. With improved access to Internet data service, including location-based services, we are able to build applications and services that profoundly shift the way people interact with their local environment--there are many opportunities to augment, enhance and transform people's experience of physical reality. This workshop will address emerging design techniques for Mobile Augmented Reality (MAR) applications. We invite designers, developers, users and evaluators of augmented and mobile augmented reality applications and/or those interested in augmented location-based services to submit papers that consider the opportunities and challenges of designing effective, engaging and usable augmented reality services and applications for mobile devices.},
 acmid = {2371720},
 address = {New York, NY, USA},
 author = {de Sa, Marco and Churchill, Elizabeth F.},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371720},
 isbn = {978-1-4503-1443-5},
 keyword = {augmented reality, design, hci, mobile devices},
 link = {http://doi.acm.org/10.1145/2371664.2371720},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {225--228},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Mobile Augmented Reality: Design, Prototyping and Evaluation},
 year = {2012}
}


@proceedings{Churchill:2012:2371664,
 abstract = {It is our great pleasure to welcome you to the 2012 ACM International Conference on Human-Computer Interaction with Mobile Devices and Services -- MobileHCI 2012. MobileHCI is the world's leading conference in the field of Human Computer Interaction concerned with portable and personal devices and with the services to which they enable access. Mobile HCI provides a multidisciplinary forum for academics, hardware and software developers, designers and practitioners to discuss the challenges and potential solutions for effective interaction with and through mobile devices, applications, and services. The conference continues to attract a significant number of submissions; this year we received 212 valid paper submissions. We have continued our commitment to improve the quality of the review process. A senior program committee of 38 internationally renowned scientists from academia and industry was assembled. Each paper received 3 or more high-quality peer reviews, as well as an additional meta review by the assigned PC member. Following last year's successful cross-Atlantic, split committee meeting, the 38 committee members assembled in two locations (Palo Alto and Berlin) that were linked by audio and video connections. This provided an opportunity for the papers and reviews to be discussed in detail and all final decisions to be agreed upon by the Program Committee as a whole. The outcome of this process was that 54 of the 212 submissions were accepted (25%) for inclusion in the final Program, to be presented in San Francisco in September 2012. Of these, 39 were full papers and 15 were notes. A shepherding process was also used in which 6 of the 54 accepted papers were revised and improved under the expert guidance of a dedicated committee member. In our commitment to continually improving the quality of the Program, 8 papers/notes were given special recognition of excellence by being nominated for consideration as a Best Paper. A jury, consisting of 5 members of the Program Committee, was established to judge which of these papers represented the highest caliber of research in the field to be deserving of the Best Paper award. The final decision is to be revealed at the conference itself.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-1443-5},
 location = {San Francisco, California, USA},
 publisher = {ACM},
 title = {MobileHCI '12: Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 year = {2012}
}


@inproceedings{Isbister:2012:SBD:2371664.2371666,
 abstract = {Most technology-supported dance games result in gameplay that looks very different than what we know as social dancing. For that matter, most 'social' games can involve a lot of solo staring at screens. Our lab re-examined the role of technology in supporting the dance experience, working with indie game developers and dancers to understand how to truly augment instead of override the joyful social and physical qualities of dancing together. Along the way, we learned some valuable lessons about how to reframe the conceptualization and development of mobile apps meant to augment everyday social experience. In this talk, I'll share these insights, toward opening your eyes as you tackle these kinds of design and development challenges in next-generation mobile applications.},
 acmid = {2371666},
 address = {New York, NY, USA},
 author = {Isbister, Katherine},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371666},
 isbn = {978-1-4503-1443-5},
 keyword = {augmented social interaction, indie game development, movement-based interaction, social dance, social game play},
 link = {http://doi.acm.org/10.1145/2371664.2371666},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {1--4},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {How to Stop Being a Buzzkill: Designing Yamove!, a Mobile Tech Mash-up to Truly Augment Social Play},
 year = {2012}
}


@inproceedings{Church:2012:WMW:2371664.2371725,
 abstract = {The goal of this workshop is to investigate the notion of mobility in the context of search and Web usage and to identify the most promising research directions with respect to enriching future mobility focused web services. In recent times, there has been a dramatic shift in what it means to be mobile. Mobile was traditionally associated with on-the-move, personal, portable and dynamic. While today, an increasing number of users are accessing the mobile Web in more stationary and familiar settings like at home and at work as well as in more social settings like in the presence of family and friends. Designing future mobile Web experiences requires a deeper understanding of these new information needs, behaviors and underlying motivations of mobile users.},
 acmid = {2371725},
 address = {New York, NY, USA},
 author = {Church, Karen and Teevan, Jaime and Jones, Matt},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371725},
 isbn = {978-1-4503-1443-5},
 keyword = {mobile computing, mobile search, mobile web, mobility, user behavior, web behavior},
 link = {http://doi.acm.org/10.1145/2371664.2371725},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {245--248},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Workshop on Mobility and Web Behaviors (MWB)},
 year = {2012}
}


@inproceedings{Thomason:2012:EMD:2371664.2371702,
 abstract = {ScatterDice Mobile (SDM) is a novel visualization system that leverages embodied motion and orientation gestures for intuitive and effective exploration of multi-dimensional data on mobile devices. Inspired by Elmqivist et al's recent work, SDM uses the gyroscope sensor available on mobile devices to establish an orientation aware "dice rolling" metaphor for browsing scatterplot matrix visualizations mapped to a cube on mainstream mobile devices without any hardware modification. SDM has the potential for applications that require prompt access and exploration of large scale, multi-dimensional data on mobile devices anytime, anywhere.},
 acmid = {2371702},
 address = {New York, NY, USA},
 author = {Thomason, Jesse and Wang, Jingtao},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371702},
 isbn = {978-1-4503-1443-5},
 keyword = {gesture, gyroscope, mobile devices, motion sensing, scatterplot, smart phones, visualization},
 link = {http://doi.acm.org/10.1145/2371664.2371702},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {173--176},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Exploring Multi-dimensional Data on Mobile Devices with Single Hand Motion and Orientation Gestures},
 year = {2012}
}


@inproceedings{Reitz:2012:ZIP:2371664.2371718,
 abstract = {Zone of Impulse is a fast-paced multiplayer action game, playable on mobile devices. By wearing sensors on the chest and palm the player's emotional state is integrated into gameplay. The processed physiological signals provide the basis for adaptation of several game elements. This creates a more personalized gaming experience and provides additional input modalities to an otherwise "casual" game.},
 acmid = {2371718},
 address = {New York, NY, USA},
 author = {Reitz, Katharina and Stockhausen, Claudia and Kr\"{o}mker, Detlef},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371718},
 isbn = {978-1-4503-1443-5},
 keyword = {adaptation, biofeedback, gameplay, mobile games},
 link = {http://doi.acm.org/10.1145/2371664.2371718},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {221--224},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Zone of Impulse: Physiological Data Enhanced Gaming},
 year = {2012}
}


@inproceedings{Hamilton:2012:WGG:2371664.2371670,
 abstract = {In recent years public health has become of great concern, in particular the personal and national economic burden resulting from increasingly sedentary lifestyles. Sedentary lifestyles are particularly serious for young people who are badly affected by obesity problems that impact on their current and future lives. In an effort to tackle this problem games designers are designing games aimed at motivating people to take part in physical activities and have coined the term exergaming. This poster presents a mobile exergaming application developed in Android Java and HTML 5 targeting under-active teenagers and young adults. The objective is to encourage users to increase walking by an incremental number of steps each week. This is visualized as an isometric virtual town on a web browser (with rewards for achieving targets) and published on Facebook to exploit social networking in supporting users. This poster will examine the motivation behind our game, design decisions, our prototype and concludes with future plans.},
 acmid = {2371670},
 address = {New York, NY, USA},
 author = {Hamilton, Iain and Imperatore, Gennaro and Dunlop, Mark D. and Rowe, David and Hewitt, Allan},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371670},
 isbn = {978-1-4503-1443-5},
 keyword = {exercise, healthy lifestyle, mobile support},
 link = {http://doi.acm.org/10.1145/2371664.2371670},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {17--22},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Walk2Build: A GPS Game for Mobile Exergaming with City Visualization},
 year = {2012}
}


@inproceedings{Sieger:2012:GDP:2371664.2371685,
 abstract = {In this paper we describe observed gender differences in the perception of security of mobile phones, especially on authentication and payment-related features and application on smartphones. The data was gathered in a focus group, two surveys and an experiment during November 2009 and September 2011. The data shows significant differences in perceived security and future use of security-related features and applications.},
 acmid = {2371685},
 address = {New York, NY, USA},
 author = {Sieger, Hanul and M\"{o}ller, Sebastian},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371685},
 isbn = {978-1-4503-1443-5},
 keyword = {gender, mobile phone, perceived security},
 link = {http://doi.acm.org/10.1145/2371664.2371685},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {107--112},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Gender Differences in the Perception of Security of Mobile Phones},
 year = {2012}
}


@inproceedings{FeijoFilho:2012:BML:2371664.2371697,
 abstract = {This work proposes the use of a low-cost software based breathing interface for mobile phones as an alternative interaction technology for people with motor disabilities. It attempts to explore the processing of the audio from the microphone in mobile phones to trigger and launch software events. A proof of concept of this work is demonstrated by the implementation and experimentation of a mobile application prototype that enables users to perform a basic operation on the phone, such as calling, through "puffing" interaction.},
 acmid = {2371697},
 address = {New York, NY, USA},
 author = {Feij\'{o} Filho, Jackson and Prata, Wilson and Valle, Thiago},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371697},
 isbn = {978-1-4503-1443-5},
 keyword = {accessibility, alternative hci, breathing, mobile},
 link = {http://doi.acm.org/10.1145/2371664.2371697},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {157--160},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Breath Mobile: A Low-cost Software-based Breathing Controlled Mobile Phone Interface},
 year = {2012}
}


@inproceedings{Alexander:2012:TDD:2371664.2371714,
 abstract = {This demonstration accompanies a full paper accepted into MobileHCI '12 [1]. We demonstrate a new type of actuatable display, called a Tilt Display, that provides visual feedback combined with multi-axis tilting and vertical actuation. Its ability to physically mutate provides users with an additional information channel that facilitates a range of new applications including collaboration and tangible entertainment while enhancing familiar applications such as terrain modelling by allowing 3D scenes to be rendered in a physical-3D manner.},
 acmid = {2371714},
 address = {New York, NY, USA},
 author = {Alexander, Jason and Lucero, Andr{\'e}s and Subramanian, Sriram},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371714},
 isbn = {978-1-4503-1443-5},
 keyword = {actuated displays, nonplanar surface interaction, physical actuation, tilt displays},
 link = {http://doi.acm.org/10.1145/2371664.2371714},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {213--214},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Tilt Display Demonstration: A Display Surface with Multi-axis Tilt \&\#38; Actuation},
 year = {2012}
}


@inproceedings{Frias-Martinez:2012:EML:2371664.2371701,
 abstract = {This paper describes EducaMovil, a tool to develop quiz-based mobile games for Java-enabled feature phones. The tool has two main components: a PC application that allows teachers to create educational contents, and a mobile game for students to learn while playing anytime, anywhere. EducaMovil works on feature phones and constitutes an affordable solution for low-income schools.},
 acmid = {2371701},
 address = {New York, NY, USA},
 author = {Frias-Martinez, Vanessa and Virseda, Jesus and Gomero, Aldo},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371701},
 isbn = {978-1-4503-1443-5},
 keyword = {learning gains, low-income schools, mobile games},
 link = {http://doi.acm.org/10.1145/2371664.2371701},
 location = {San Francisco, California, USA},
 numpages = {4},
 pages = {169--172},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {EducaMovil: A Mobile Learning Tool for Low-income Schools},
 year = {2012}
}


@inproceedings{Costa:2012:IMQ:2371664.2371672,
 abstract = {In recent years, mass adoption of increasingly powerful mobile devices and ubiquitous communication networks have paved the way to smart environments. Such environments allow for the collection of user and environment data with the final goal to improve users' experience. In this context a number of opportunities and challenges are presented to Human Computer Interaction. This poster explores Quality of Experience, a subjective aspect of interaction, informally defined as the degree to which a system meets users' expectations. Furthermore, a mobile application was developed for the collection of user and environment data and delivery of personalised services in the context of Public Transport. This application will be used in a real-world environment, to further investigate the factors that have an influence on User eXperience, as well as the delivery of relevant services with the potential to enhance users' journeys while in transit.},
 acmid = {2371672},
 address = {New York, NY, USA},
 author = {Costa, Pedro Maur\'{\i}cio and Pitt, Jeremy and Vieira, Jo\~{a}o G. and Galv\~{a}o, Teresa and Falc\~{a}o e Cunha, Jo\~{a}o},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371672},
 isbn = {978-1-4503-1443-5},
 keyword = {mobile cloud computing, quality of experience, service design, user experience},
 link = {http://doi.acm.org/10.1145/2371664.2371672},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {29--34},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Investigating Mobile Quality of Experience in Public Transport},
 year = {2012}
}


@inproceedings{Kulik:2012:HGM:2371664.2371712,
 abstract = {We present the hold-and-move interaction technique [2], which uses an implicit input differentiation based on Guiard's "left-hand precedence in action" principle [1]. Hold-and-move associates the first contact point with the background and thus motion input from a single finger always controls panning. In order to manipulate individual items, the background must be held with the first finger. A second finger may then select an individual item and move it in relation to the background. In addition, the first finger may perform panning of the background and clutching while the second finger holds on to the selected item.},
 acmid = {2371712},
 address = {New York, NY, USA},
 author = {Kulik, Alexander and Dittrich, Jan and Froehlich, Bernd},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371712},
 isbn = {978-1-4503-1443-5},
 keyword = {dwell times, hold-and-move, multi-touch},
 link = {http://doi.acm.org/10.1145/2371664.2371712},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {209--210},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {The Hold-and-move Gesture for Multi-touch Interfaces},
 year = {2012}
}


@inproceedings{Suzuki:2012:TRP:2371664.2371673,
 abstract = {Remote support for physical tasks often takes a longer time and involves more mistakes than on-site support. The reason for this is that it is difficult for remote supporters to know what happened at the site and show how to operate briefly. In this paper, we propose a remote support system named TeleTorchlight that works between a tablet and a mobile camera projector unit. The system expands traditional voice chat based remote support by providing a method to draw instructions to physical object directly from remote supporters. On-site workers can easily understand instructions from remote supporters and can efficiently learn tasks using our system. Remote supporters also provide instructions showing where to operate and how to operate.},
 acmid = {2371673},
 address = {New York, NY, USA},
 author = {Suzuki, Genta and Klemmer, Scott},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371673},
 isbn = {978-1-4503-1443-5},
 keyword = {augmented reality, camera, mobile, projector, telecollaboration, telecommunication},
 link = {http://doi.acm.org/10.1145/2371664.2371673},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {35--40},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {TeleTorchlight: Remote Pointing and Annotation Using a Mobile Camera Projector},
 year = {2012}
}


@inproceedings{Winkler:2012:WPN:2371664.2371687,
 abstract = {Currently we see the emergence of the first commercial projector phones. Besides the standard use case of projecting media content, they are also promising as a platform for new types of mobile gaming. In this paper, we present a novel interaction concept for mobile projected gaming which leverages specifically a wall and the floor in the environment to provide a new type of semi-realistic augmented gaming. Moreover, we present a preliminary bowling game prototype.},
 acmid = {2371687},
 address = {New York, NY, USA},
 author = {Winkler, Christian and Hutflesz, Patrick and Holzmann, Clemens and Rukzio, Enrico},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371687},
 isbn = {978-1-4503-1443-5},
 keyword = {concept, gaming, mobile, projection, projector phone},
 link = {http://doi.acm.org/10.1145/2371664.2371687},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {119--124},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Wall Play: A Novel Wall/Floor Interaction Concept for Mobile Projected Gaming},
 year = {2012}
}


@inproceedings{Szymczak:2012:DAT:2371664.2371694,
 abstract = {An audio-tactile interactive tourist guide is demonstrated, including the possibility to be guided to points of interest. In contrast with the key-hole like experience of on-screen augmented reality, this guide makes use of the non-visual modalities to create a more immersive augmented experience. Sound windows from the past and verbal historical information complement discrete tactile guidance along a trail.},
 acmid = {2371694},
 address = {New York, NY, USA},
 author = {Szymczak, Delphine and Rassmus-Gr\"{o}hn, Kirsten and Magnusson, Charlotte and Hedvall, Per-Olof},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371694},
 isbn = {978-1-4503-1443-5},
 keyword = {augmented reality, inclusive, multimodal, navigation, non-visual},
 link = {http://doi.acm.org/10.1145/2371664.2371694},
 location = {San Francisco, California, USA},
 numpages = {2},
 pages = {151--152},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Demonstration of an Audio-tactile Tourist Guide},
 year = {2012}
}


@proceedings{Bylund:2011:2037373,
 abstract = {We are proud to present the proceedings of the 13th International Conference on Human-Computer Interaction with Mobile Devices and Services-colloquially known as 'Mobile HCI'. Reflecting research conducted both in Universities and Industry, Mobile HCI focuses on next generation, meaningful interaction techniques and services for mobile devices. Research areas include technical, interactional, social and cultural aspects, as well as studies of social life with mobile devices. Mobile human-computer-interaction is one of the most rapidly growing areas in computing. The proliferation of smartphones, and the resultant expansion of mobile Internet access, underscore that this is a cardinal area of invention and innovation for both consumers and industry. There is a growing desire and a need for meaningful and useful applications, and a call for innovative content selection and presentation techniques and novel interaction models. The ever-increasing importance of this area for business, for social and for technical innovation is reflected in the growing interest in the Mobile HCI conference. With 276 valid submissions the number of technical papers and notes was at a record high, increasing by over 20% from the previous year, 2010. This growth has further fueled the longstanding commitment from the research community to continue to improve on the quality of the conference. This year we have made effort to improve the quality of the reviewing process. The papers and notes chairs broadened the group of peer reviewers and added a meta-reviewing step. The Senior Program Committee, over 35 people, met in person---across two locations connected by video and audio connections-to decide on the selection of papers and notes. A rigorous process of discussion and reflection was conducted wherein each paper was addressed and considered for inclusion. We instituted a shepherding process of revise-and-resubmit for papers and notes that showed great promise; all shepherded papers were ultimately accepted. As a result of this process, 63 papers and notes (an acceptance rate of 23%) of the submissions to the conference were selected for presentations in Stockholm at the end of August 2011. These proceedings contain the accepted papers and notes that resulted from our review process. The research topics herein reflect our ambition to provide cutting edge research that considers the challenges and potential solutions for effective and meaningful interaction with mobile systems and services. Research presented here covers the design, evaluation and application of techniques for all mobile and wearable computing devices and services. Topics include: next generation touch and gesture-based interaction, including more extended vibro - tactile solutions; the design of video-based interaction on-the go; projections and visualizations from small 'pica-projectors'; technical and social issues around mobile data security and privacy; and case studies of relationship management through mobile devices and location-based services. The global penetration and impact of mobile interaction is reflected. Examples range from interaction to social fabric, from research into various alphabets, such as handling Indian text input to phone use among workers in China. The conference also focuses on understanding various contexts where mobile technologies and services are having an impact on everyday recreational life-see for example the design and evaluation of mobile services for hedonic parts of life such as shopping and fashion. The Mobile HCI conference promises to be a vibrant and fast-paced event. Given the increasing number of selected papers, we have chosen to include more content-17 papers and notes sessions-in the program. We have thus reduced the time for each presentation, allowing the audience to enjoy a richer variety of research and demonstrations and encouraging broader debate. The audience will be diverse. The conference has traditionally provided a meeting ground for researchers from both industry and academia-this is also a hallmark of MobileHCI2011 in Stockholm. This combination is visible in the selection of technical contributions within these proceedings, with authors and projects hailing from industry research organizations and from universities from around the globe.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-0541-9},
 location = {Stockholm, Sweden},
 publisher = {ACM},
 title = {MobileHCI '11: Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services},
 year = {2011}
}


@inproceedings{TorrezRiley:2012:LST:2371664.2371674,
 abstract = {This paper looks at the potential for mobile technology that targets sports spectators. Preliminary survey results from 83 college sports fans suggest the current usage of mobile technology, like location-based services, when attending games. Findings offer insight as to the expectations and concerns of fans and inform the design for a social, local mobile application.},
 acmid = {2371674},
 address = {New York, NY, USA},
 author = {Torrez Riley, Jessica},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371674},
 isbn = {978-1-4503-1443-5},
 keyword = {college sports, location-based services, mobile social interaction, second-screen, spectators},
 link = {http://doi.acm.org/10.1145/2371664.2371674},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {41--46},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {A Look at Spectator Technology: Location-based Services and Mobile Habits of Collegiate Sports Fans},
 year = {2012}
}


@inproceedings{Niida:2012:USS:2371664.2371681,
 abstract = {The number of smartphone users has increased markedly in recent years. They enjoy multimedia services, such as video streaming, unconstrained by time and place. However, mobile streaming services require a high throughput, and may have an impact on network capacity. The control of service quality is important from both the perspective of user experience and network quality. However, the quality of a video service has mainly been evaluated by examining the picture quality. It is less common to use a network design viewpoint to evaluate video streaming services. In this paper, we discuss the subjective quality of streaming video on mobile terminals. The main contribution of this paper is to quantitatively show the relation between the overall satisfaction, network quality and picture quality, based on the results of the user study.},
 acmid = {2371681},
 address = {New York, NY, USA},
 author = {Niida, Sumaru and Uemura, Satoshi and Ano, Shigehiro},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371681},
 isbn = {978-1-4503-1443-5},
 keyword = {human-centered design: waiting time, mobile streaming, resolution, service quality, user experience},
 link = {http://doi.acm.org/10.1145/2371664.2371681},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {83--88},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {User Study of the Subjective Quality of Mobile Streaming Service},
 year = {2012}
}


@inproceedings{Fan:2012:CMA:2371664.2371689,
 abstract = {Performing real-time 3D motion interaction with a mobile phone is useful for extending interaction out of a limited screen. However, current phone motion detection approaches, which use only camera or accelerometer, have limitations in recognizing versatile 3D motions simultaneously. In this paper we present a real-time approach designed for 3D tasks by holding and moving a phone equipped with both a camera and an accelerometer. By analyzing both motion features from image frames and changes of accelerometer data simultaneously, our approach can naturally distinguish translation and rotation of a mobile phone. In a pilot user study, we demonstrated our design requires low learning effort and has high accuracy. Since it does not require any outside infrastructure, our approach can be applied to any phone with a camera and an accelerometer. Our main contribution is giving mobile phone users 3D interaction ability by exploiting hand translation and rotation.},
 acmid = {2371689},
 address = {New York, NY, USA},
 author = {Fan, Mingming and Patterson, Donald and Shi, Yuanchun},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371689},
 isbn = {978-1-4503-1443-5},
 keyword = {accelerometer, camera, fusion, mobile phone, real-time 3d motion, weak classifiers},
 link = {http://doi.acm.org/10.1145/2371664.2371689},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {131--136},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {When Camera Meets Accelerometer: A Novel Way for 3D Interaction of Mobile Phone},
 year = {2012}
}


@inproceedings{White:2012:VMD:2371664.2371679,
 abstract = {This paper describes the process of creating a design pattern management interface for a collection of mobile design patterns. The need to communicate how patterns are interrelated and work together to create solutions motivated the creation of this interface. Currently, most design pattern collections are presented in alphabetical lists. The Oracle Mobile User Experience team approach is to communicate relationships visually by highlighting and connecting related patterns. Before the team designed the interface, we first analyzed common relationships between patterns and created a pattern language map. Next, we organized the patterns into conceptual design categories. Last, we designed a pattern management interface that enables users to browse patterns and visualize their relationships.},
 acmid = {2371679},
 address = {New York, NY, USA},
 author = {White, Brent-Kaan},
 booktitle = {Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services Companion},
 doi = {10.1145/2371664.2371679},
 isbn = {978-1-4503-1443-5},
 keyword = {design patterns, mobile design, pattern languages, pattern tools},
 link = {http://doi.acm.org/10.1145/2371664.2371679},
 location = {San Francisco, California, USA},
 numpages = {6},
 pages = {71--76},
 publisher = {ACM},
 series = {MobileHCI '12},
 title = {Visualizing Mobile Design Pattern Relationships},
 year = {2012}
}


