@inproceedings{Weber:2016:SPW:2957265.2965025,
 abstract = {Today, many users of mobile devices are continuously confronted with a huge variety of information: notifications from Facebook, new application updates, won badges, or reminders. This leads to an information overload, which makes it hard to stay focused. This workshop will investigate approaches towards smart attention management systems. We will discuss the fundamental challenges of smart notifications and the design of proactive notification mechanisms. We invite submissions that focus on the understanding of users and their current, mobile information handling. We further appreciate contributions that propose design concepts for the interaction with smart attention management systems. The expected workshop outcome is a summary of emerging challenges in the design and development of smart attention management systems as well as approaches to address them.},
 acmid = {2965025},
 address = {New York, NY, USA},
 author = {Weber, Dominik and Shirazi, Alireza Sahami and Gehring, Sven and Henze, Niels and Poppinga, Benjamin and Pielot, Martin and Okoshi, Tadashi},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965025},
 isbn = {978-1-4503-4413-5},
 keyword = {attention management, multimodal interaction, notifications, smart systems},
 link = {http://doi.acm.org/10.1145/2957265.2965025},
 location = {Florence, Italy},
 numpages = {4},
 pages = {914--917},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Smarttention, Please!: 2Nd Workshop on Intelligent Attention Management on Mobile Devices},
 year = {2016}
}


@inproceedings{Worgan:2016:MES:2957265.2962655,
 abstract = {We foresee a future where energy in our mobile devices can be shared and redistributed to suit our current task needs. Many of us are beginning to carry multiple mobile devices and we seek to re-evaluate the traditional view of a mobile device as only accepting energy. In our vision, we can leverage the energy stored in our devices to wirelessly distribute energy between our friends, family, colleagues and strangers devices. In this paper we explore the opportunities and interactions presented by such spontaneous energy transfer interactions and present some envisaged collaborative energy sharing futures.},
 acmid = {2962655},
 address = {New York, NY, USA},
 author = {Worgan, Paul and Knibbe, Jarrod and Fraser, Mike and Plasencia, Diego Martinez},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962655},
 isbn = {978-1-4503-4413-5},
 keyword = {collaborative energy transfer, energy sharing, inductive power transfer},
 link = {http://doi.acm.org/10.1145/2957265.2962655},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1134--1137},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Mobile Energy Sharing Futures},
 year = {2016}
}


@inproceedings{Aiyoshizawa:2016:PPZ:2957265.2961828,
 abstract = {In this paper, we propose Predictive Zooming Keyboard (PZBoard) which predicts a target position from the finger movement above the touch-screen of a mobile device and that enlarges a part of the keyboard around the predicted position. We use a hover function of the mobile device to obtain the finger position above the touch-screen. While a finger is detected, a part of the keyboard around the finger position are enlarged. When the user moves his/her finger fast to enter a distant key, the target position is predicted and the center of enlargement moves to the predicted position. Using prediction, the system can start drawing the screen before the finger reaches the target position, which reduces the system's latency and quickens the user's response. The proposed interface does not force the user to perform additional operation for enlarging keys, and enables stable selection of both near and distant keys by fixing or changing the center of enlargement based on the velocity of the finger.},
 acmid = {2961828},
 address = {New York, NY, USA},
 author = {Aiyoshizawa, Toshiaki and Koarai, Naoto and Komuro, Takashi},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961828},
 isbn = {978-1-4503-4413-5},
 keyword = {hover input, text entry, touch-screen, zooming interface},
 link = {http://doi.acm.org/10.1145/2957265.2961828},
 location = {Florence, Italy},
 numpages = {6},
 pages = {627--632},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {PZBoard: A Prediction-based Zooming Interface for Supporting Text Entry on a Mobile Device},
 year = {2016}
}


@inproceedings{Yeo:2016:WAW:2957265.2961825,
 abstract = {In this demo, we show that it is possible to enhance touch interaction on unmodified smartwatch to support continuous pressure touch, twist and pan gestures, by only analyzing the real-time data of Inertial Measurement Unit (IMU). Our evaluation results show that the three proposed input interfaces are accurate, noise-resistant, easy to use and can be deployed to a variety of smartwatches. We then showcase the potential of this work with seven example applications. During the demo session, users can try the prototype.},
 acmid = {2961825},
 address = {New York, NY, USA},
 author = {Yeo, Hui-Shyong and Lee, Juyoung and Bianchi, Andrea and Quigley, Aaron},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961825},
 isbn = {978-1-4503-4413-5},
 keyword = {rich touch, small screen, smart watch, wearable devices},
 link = {http://doi.acm.org/10.1145/2957265.2961825},
 location = {Florence, Italy},
 numpages = {5},
 pages = {594--598},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {WatchMI: Applications of Watch Movement Input on Unmodified Smartwatches},
 year = {2016}
}


@inproceedings{Fadhil:2016:COM:2957265.2965004,
 abstract = {Promoting health and wellness reflects a holistic approach to maintain the overall wellbeing of the nation. This paper discusses challenges in dietary adherence and reviews approaches in promoting healthy diet, physical activity, and healthy lifestyle presented in the literature. After discussing persisting challenges, we propose our future approach and contribution to overcome these challenges.},
 acmid = {2965004},
 address = {New York, NY, USA},
 author = {Fadhil, Ahmed and Matteotti, Cristina and Armellin, Giampaolo and Villafiorita, Adolfo and Betti, Dario},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965004},
 isbn = {978-1-4503-4413-5},
 keyword = {coaching, health\&\#38;wellbeing, healthy diet, persuasive technology, tailored approach},
 link = {http://doi.acm.org/10.1145/2957265.2965004},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1077--1080},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {CoachMe: A Platform for Promoting Healthy Lifestyle},
 year = {2016}
}


@inproceedings{Sajjad:2016:BMA:2957265.2961856,
 abstract = {This paper investigates the use of an application, Baby+, designed to support pregnant women in Pakistan. Baby+ is a localized mobile application, which helps pregnant women in keeping track of their pregnancy and gives them more control over it by providing them with relevant information. The application was designed after investigating the needs of pregnant women in the Pakistani context. In our early evaluation, women appreciated the design and functionality of Baby+ and valued it as an assistive tool, which has a potential of aiding the pregnancy health management in the region.},
 acmid = {2961856},
 address = {New York, NY, USA},
 author = {Sajjad, Umaira Uzma and Shahid, Suleman},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961856},
 isbn = {978-1-4503-4413-5},
 keyword = {HCI4D, ICT4D, Pakistan, healthcare, mHealth, mobile, mothers, pregnancy},
 link = {http://doi.acm.org/10.1145/2957265.2961856},
 location = {Florence, Italy},
 numpages = {8},
 pages = {667--674},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Baby+: A Mobile Application to Support Pregnant Women in Pakistan},
 year = {2016}
}


@inproceedings{Luca:2016:PAI:2957265.2962649,
 abstract = {Proximity localization has become a common support in mobile-based personal CH fruition mobile assistants, notifying the visitor information about points of interest near to him but can hardly used to recognize its presence inside areas defining a semantic context in museums or expositions. In this paper we present an accurate indoor localization methodology relying on Bluetooth Low Energy technology that can be used to gently suggest to the user evidence of contextually coherent areas of interest around him. A localization accuracy as low as two meter has been measured and one meters limit evaluated during experimentation of a mobile guide in the Archeological Museum of Camarina, in province of Ragusa (Italy).},
 acmid = {2962649},
 address = {New York, NY, USA},
 author = {Luca, Dierna Giovanni and Alberto, Mach\`{\i}},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962649},
 isbn = {978-1-4503-4413-5},
 keyword = {context-aware information presentation, indoor positioning, mobile museum guides},
 link = {http://doi.acm.org/10.1145/2957265.2962649},
 location = {Florence, Italy},
 numpages = {8},
 pages = {1002--1009},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {From Proximity to Accurate Indoor Localization for Context Awareness in Mobile Museum Guides},
 year = {2016}
}


@inproceedings{Lander:2016:MCF:2957265.2963116,
 abstract = {Human beings sense and perceive most of the world through their eyes. The point of gaze clearly reflects our visual attention indicating our interests. Hence gaze can be used as a powerful tool in different research areas (e.g., marketing, psychology). The progress made over the years in eye tracking enables the creation of gaze-based interactive interfaces. However, these interfaces lack of generic usability outside a controlled environment in a spontaneous pervasive way. The main objective of this research is to investigate eye-tracking technologies by means of calibration. Since calibration is user, location, orientation and target dependent, it prevents from Multi-User interaction and gaze estimation on multiple various objects (e.g., multiple screens of different sizes). Tackling these issues, new mobile as well as remote interfaces are explored and new design spaces are opened.},
 acmid = {2963116},
 address = {New York, NY, USA},
 author = {Lander, Christian},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963116},
 isbn = {978-1-4503-4413-5},
 keyword = {calibration, eye tracking, gaze, multi-user},
 link = {http://doi.acm.org/10.1145/2957265.2963116},
 location = {Florence, Italy},
 numpages = {2},
 pages = {899--900},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Methods for Calibration Free and Multi-user Eye Tracking},
 year = {2016}
}


@inproceedings{Le:2016:MHB:2957265.2963113,
 abstract = {As mobile devices are becoming more ubiquitous, it is common for users to interact with them in many different situations. In our research, we focus on modeling human behavior during touchscreen interaction in mobile situations. Resulting models do not only increase our understanding of human behavior but also predict or infer intended user interaction. This enables us to design interfaces suited for one-handed interaction and to derive new interaction possibilities. In our work, we will collect data in lab studies as well as on a large scale to create models with high external validity.},
 acmid = {2963113},
 address = {New York, NY, USA},
 author = {Le, Huy Viet},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963113},
 isbn = {978-1-4503-4413-5},
 keyword = {human behavior, mobile device, research in the large, touchscreen},
 link = {http://doi.acm.org/10.1145/2957265.2963113},
 location = {Florence, Italy},
 numpages = {2},
 pages = {901--902},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Modeling Human Behavior During Touchscreen Interaction in Mobile Situations},
 year = {2016}
}


@inproceedings{Hakkila:2016:API:2957265.2965019,
 abstract = {In the area of wellness and health, people are currently logging and monitoring an increasing amount of information of their everyday lives. The visualization of the logged data is currently typically presented in a mobile phone app. Here, we present our ongoing research on physical visualizations of sleep data, monitored with a wearable sensor. Our aim is to create tangible artifacts where the data has been integrated to the design in an aesthetic way, and hence provide information appliances that people can reflect upon.},
 acmid = {2965019},
 address = {New York, NY, USA},
 author = {H\"{a}kkil\"{a}, Jonna and Virtanen, Lasse},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965019},
 isbn = {978-1-4503-4413-5},
 keyword = {aesthetics, data visualization, physical visualization, sleep, wearable computing, wellness},
 link = {http://doi.acm.org/10.1145/2957265.2965019},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1173--1177},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Aesthetic Physical Items for Visualizing Personal Sleep Data},
 year = {2016}
}


@inproceedings{Salazar:2016:ETP:2957265.2961864,
 abstract = {Interaction in mobile computing mainly relies on selecting targets by touch. A large body of work showed the effect of target size and target distance on selection time. Recent work on hand-held devices suggests that size and distance are not the only factors that affect selection time. In this paper, we investigate target selection performance of the thumb when interacting with grasping hands (see Figure 1). In the first study, we show that the relative direction of the target has a significant effect on selection time. In the second study we show that the direction of movement also has a significant effect. The results extend our knowledge about pointing on hand-held devices and can be used to improve transfer functions of mobile GUIs.},
 acmid = {2961864},
 address = {New York, NY, USA},
 author = {Salazar, Carlos A. F. and Henze, Niels and Wolf, Katrin},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961864},
 isbn = {978-1-4503-4413-5},
 link = {http://doi.acm.org/10.1145/2957265.2961864},
 location = {Florence, Italy},
 numpages = {8},
 pages = {730--737},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Ergonomics of Thumb-based Pointing While Holding Tablets},
 year = {2016}
}


@inproceedings{Hakkila:2016:RIA:2957265.2965024,
 abstract = {This workshop addresses a topic, which has been relatively (and surprisingly) little considered among mobile HCI research -- aesthetics in design. Whereas research in the area is under represented, aesthetics is one of the key parameters in product design, and an important part of user experience. By understanding the role and impact of aesthetics, we can better understand user behavior and preferences, create better user interfaces, and improve our design processes. As mobile HCI is expanding in mass markets to new areas and form factors such as bracelets, glasses and smart clothing, the possibilities for designers are growing. In this workshop, we consider, e.g., user research, design research, prototypes and case studies related to aesthetics in designing mobile devices and interactions, and draw a research agenda for the future.},
 acmid = {2965024},
 address = {New York, NY, USA},
 author = {H\"{a}kkil\"{a}, Jonna and Juhlin, Oskar and Boll, Susanne and Colley, Ashley},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965024},
 isbn = {978-1-4503-4413-5},
 keyword = {aesthetics, design, fashion, mobile devices, user experience, wearable computing},
 link = {http://doi.acm.org/10.1145/2957265.2965024},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1142--1145},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {The Role and Impact of Aesthetics in Designing Mobile Devices},
 year = {2016}
}


@proceedings{Boring:2015:2785830,
 abstract = {
                  An abstract is not available.
              },
 address = {New York, NY, USA},
 isbn = {978-1-4503-3652-9},
 location = {Copenhagen, Denmark},
 publisher = {ACM},
 title = {MobileHCI '15: Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 year = {2015}
}


@inproceedings{Yeo:2016:SIM:2957265.2963110,
 abstract = {Screen sizes on devices are becoming smaller, to allow them to fit in more places (e.g., wrists, sports bands and small music players). At the same time, screen sizes can be seen to become larger to accommodate new experiences (e.g., phablets, tablets, eReaders). Each of these trends can make devices difficult to use with only one hand (e.g., fat-finger or reachability). However, there are many occasions when the user's other hand is occupied (encumbered) or not available. The aim of this research is to explore, create and study novel interaction techniques that support effective single-hand usage on mobile and wearable devices.},
 acmid = {2963110},
 address = {New York, NY, USA},
 author = {Yeo, Hui-Shyong},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963110},
 isbn = {978-1-4503-4413-5},
 keyword = {encumbered, mobile, single-handed interaction, wearable},
 link = {http://doi.acm.org/10.1145/2957265.2963110},
 location = {Florence, Italy},
 numpages = {2},
 pages = {907--908},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Single-handed Interaction for Mobile and Wearable Computing},
 year = {2016}
}


@inproceedings{Voit:2016:ENS:2957265.2962661,
 abstract = {Notifications are a core mechanism of current smart devices. They inform about a variety of events including messages, social network comments, and application updates. While users appreciate the awareness that notifications provide, notifications cause distraction, higher cognitive load, and task interruptions. With the increasing importance of smart environments, the number of sensors that could trigger notifications will increase dramatically. A flower with a moisture sensor, for example, could create a notification whenever the flower needs water. We assume that current notification mechanisms will not scale with the increasing number of notifications. We therefore explore notification mechanisms for smart homes. Notifications are shown on smartphones, on displays in the environment, next to the sending objects, or on the user's body. In an online survey, we compare the four locations in four scenarios. While different aspects influence the perceived suitability of each notification location, the smartphone generally is rated the best.},
 acmid = {2962661},
 address = {New York, NY, USA},
 author = {Voit, Alexandra and Machulla, Tonja and Weber, Dominik and Schwind, Valentin and Schneegass, Stefan and Henze, Niels},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962661},
 isbn = {978-1-4503-4413-5},
 keyword = {ambient display, notifications, online study, peripheral display, reminder, smart home, wearable display},
 link = {http://doi.acm.org/10.1145/2957265.2962661},
 location = {Florence, Italy},
 numpages = {6},
 pages = {942--947},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Exploring Notifications in Smart Home Environments},
 year = {2016}
}


@inproceedings{Silina:2016:DSW:2957265.2963111,
 abstract = {There are many benefits to mediating intimate relationships through technology, and an increasing number of ways of doing so. Among these, there is a growing interest in social wearables. But most of these devices are either bespoke one-off items or generalized and lack consideration for cultural context and needs of varied user groups. Overall, our understanding of the design criteria for these artifacts and potential implications of their newly-afforded multifaceted interactions is lagging far behind. My research aims to extend this knowledge by adopting multidisciplinary perspective and developing design guidelines with a focus on meaningful use of social wearables over time.},
 acmid = {2963111},
 address = {New York, NY, USA},
 author = {Silina, Yulia},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963111},
 isbn = {978-1-4503-4413-5},
 keyword = {H2H, computational jewelry, computer-mediated communication, experience design, relationship, wearables},
 link = {http://doi.acm.org/10.1145/2957265.2963111},
 location = {Florence, Italy},
 numpages = {2},
 pages = {905--906},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Designing Social Wearables for Mediation of Intimate Relationships},
 year = {2016}
}


@inproceedings{Wenig:2016:ASS:2957265.2965021,
 abstract = {Maps are a very powerful form of information visualization. Beside their main purpose to communicate often very complex relationships between elements of some space, "good" maps are often perceived as aesthetically pleasing and beautiful. Maps are collected for those reasons; since centuries and ages they are "beautiful" --over all trends. Cartography, the study and practice of making maps, has long tradition. Even today, most of the maps, e.g., road maps and public you-are-here maps, are still crafted by professional cartographers. However, maps do require space to be displayed while mobile and wearable devices are getting smaller and smaller. This presents new challenges in cartography, as designing aesthetic user interfaces is an important aspect in the area of HCI. With StripeMaps we present a technique to bring maps to very small displays without destroying their utility and beauty. In this workshop paper we discuss our design considerations in depth and open up the discussion for alternative approaches.},
 acmid = {2965021},
 address = {New York, NY, USA},
 author = {Wenig, Dirk and Sch\"{o}ning, Johannes},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965021},
 isbn = {978-1-4503-4413-5},
 keyword = {cartography, mobile maps, smartwatches, stripe maps},
 link = {http://doi.acm.org/10.1145/2957265.2965021},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1150--1154},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {The Aesthetics of StripeMaps: Being Small and Beautiful},
 year = {2016}
}


@inproceedings{Siebra:2016:OBA:2957265.2961848,
 abstract = {The current efforts to specify an usability guideline for accessible mobile applications are sparse and they are still far to present a concrete pattern. Our previous work carried out a broad survey to consolidate the findings of these efforts in a unique list with 36 requirements, 13 of them focused on vision impairments. In this paper we show the results of an observation-based analysis involving visually impaired volunteers, whose aim was to complement this review and confirm if the lack of these requirements in fact affects the use of mobile applications.},
 acmid = {2961848},
 address = {New York, NY, USA},
 author = {Siebra, Clauirton and Gouveia, Tatiana and Macedo, Jefte and Correia, Walter and Penha, Marcelo and Anjos, Marcelo and Florentin, Fabiana and Silva, Fabio Q. B. and Santos, Andre L. M.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961848},
 isbn = {978-1-4503-4413-5},
 keyword = {accessibility, mobile devices, user interfaces},
 link = {http://doi.acm.org/10.1145/2957265.2961848},
 location = {Florence, Italy},
 numpages = {8},
 pages = {807--814},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Observation Based Analysis on the Use of Mobile Applications for Visually Impaired Users},
 year = {2016}
}


@inproceedings{Pakanen:2016:UPI:2957265.2965020,
 abstract = {In this paper, we address handbags as interactive mobile devices. As handbags are typical accessories carried practically by half of the adult population when on the move, they offer an interesting and widely distributed platform for mobile computing. As handbags are visible items representing the user's style, and form part of the user's overall outfit, aesthetics form an important part of their design. In this paper, we report ideas gathered from 20 participants that participated to a user study on the topic.},
 acmid = {2965020},
 address = {New York, NY, USA},
 author = {Pakanen, Minna and Lappalainen, Tuomas and Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965020},
 isbn = {978-1-4503-4413-5},
 keyword = {aesthetics, handbags, user studies, wearable computing},
 link = {http://doi.acm.org/10.1145/2957265.2965020},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1155--1158},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {User Perspective for Interactive Handbag Design},
 year = {2016}
}


@inproceedings{Brosda:2016:UAE:2957265.2964198,
 abstract = {An easy-to-use tool is presented that supports educators to create geogames for smartphones with media. The research questions are addressed whether educators use audios to support learning, and if they do, how do they use them? First results of the actual usage indicate that the potential of audio has not been fully exploited in all cases.},
 acmid = {2964198},
 address = {New York, NY, USA},
 author = {Brosda, Constantin and Bartsch, Silke and Oppermann, Leif and Schaal, Steffen},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2964198},
 isbn = {978-1-4503-4413-5},
 keyword = {audio, cognitive load, education, location based game, nutrition},
 link = {http://doi.acm.org/10.1145/2957265.2964198},
 location = {Florence, Italy},
 numpages = {6},
 pages = {1049--1054},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {On the Use of Audio in the Educational Location Based Game Platform MILE},
 year = {2016}
}


@inproceedings{Pohl:2016:MIL:2957265.2961855,
 abstract = {Interaction with mobile devices currently requires close engagement with them. For example, users need to pick them up and unlock them, just to check whether the last notification was for an urgent message. But such close engagement is not always desirable, e.g., when working on a project with the phone just laying around on the table. Instead, we explore around-device interactions to bring up and control notifications. As users get closer to the device, more information is revealed and additional input options become available. This allows users to control how much they want to engage with the device. For feedback, we use a custom LED-matrix display prototype on the edge of the device. This allows for coarse, but bright, notifications in the periphery of attention, but scales up to allow for slightly higher resolution feedback as well.},
 acmid = {2961855},
 address = {New York, NY, USA},
 author = {Pohl, Henning and Krefeld, Bastian and Rohs, Michael},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961855},
 isbn = {978-1-4503-4413-5},
 keyword = {LEDs, auxiliary display, casual interaction, dot-matrix display, edge display, proxemics},
 link = {http://doi.acm.org/10.1145/2957265.2961855},
 location = {Florence, Italy},
 numpages = {7},
 pages = {839--845},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Multi-level Interaction with an LED-matrix Edge Display},
 year = {2016}
}


@inproceedings{Park:2016:CWT:2957265.2961861,
 abstract = {In recent years, deep learning algorithms have been widely used in both academic research and practical applications. This study uses a deep convolutional neural network to analyze and predict physical movements. We evaluated the effectiveness of our proposed network by recruiting a professional fitness trainer and let the trainer wear a smart watch equipped with an accelerometer capable of assessing physical movement. The results confirmed the ability of the network to correctly predict the bench press, dips, squat, deadlift, and military press with an accuracy rate of 92.8%. This preliminary study has several limitations such as a low sample size and the lack of a specified network layer. In subsequent studies we plan to address these limitations by extending our investigation to include the analysis of diverse movements.},
 acmid = {2961861},
 address = {New York, NY, USA},
 author = {Park, Jaehyun},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961861},
 isbn = {978-1-4503-4413-5},
 keyword = {deep learning, movement analysis, smart watch, weight training},
 link = {http://doi.acm.org/10.1145/2957265.2961861},
 location = {Florence, Italy},
 numpages = {5},
 pages = {854--858},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Classifying Weight Training Workouts with Deep Convolutional Neural Networks: A Precedent Study},
 year = {2016}
}


@inproceedings{Lee:2016:RDS:2957265.2962662,
 abstract = {Smartwatches are overloaded with various notifications from smartphones. Users are largely distracted, while they may benefit from these relayed notification. To reduce smartwatch user's distraction, we propose an intelligent notification delivery system that relays only important notifications to the smartwatch. We claim that important notifications should be handled within a certain time and they are involved in launching mobile applications. To build model, we collect 6491 notifications and sensor data from three users. A mobile application has been developed to unobtrusively monitor relevant data Then, we implemented a binary classifier which identifies important notifications using deep learning and 8 features are extracted from sensor data. Our classifier shows that an important notification can be predicted with 61% - 90% and 51% - 99% of precision and recall.},
 acmid = {2962662},
 address = {New York, NY, USA},
 author = {Lee, Jemin and Kwon, Jinse and Kim, Hyungshin},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962662},
 isbn = {978-1-4503-4413-5},
 keyword = {deep learning, notification, smartwatch},
 link = {http://doi.acm.org/10.1145/2957265.2962662},
 location = {Florence, Italy},
 numpages = {6},
 pages = {948--953},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Reducing Distraction of Smartwatch Users with Deep Learning},
 year = {2016}
}


@inproceedings{Murnane:2016:OTS:2957265.2965008,
 abstract = {Mental health is becoming an increasingly pressing healthcare issue on a worldwide level. Chronic mental health conditions such as bipolar disorder are some of the most challenging illnesses to treat and are associated with considerable negative consequences, both in terms of societal costs as well as individual patients' quality of life. Mobile and wearable devices, with their rising ownership levels and sensing capabilities, have the potential to enable more personalized and broadly deployable forms of condition monitoring, symptom detection, and timely intervention. In this workshop paper, we overview our research into the lived experiences and self-management practices of individuals with bipolar disorder, the resultant implications for designing technology-based solutions, and the steps we have taken towards development of such assessment and intervention oriented tools. Importantly, we surface tensions between the opportunities of technology and the potential risks associated with their usage in the context of mental health.},
 acmid = {2965008},
 address = {New York, NY, USA},
 author = {Murnane, Elizabeth L. and Matthews, Mark and Gay, Geri},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965008},
 isbn = {978-1-4503-4413-5},
 keyword = {bipolar disorder, intervention, mHealth, mental health, mobile sensing, self-assessment},
 link = {http://doi.acm.org/10.1145/2957265.2965008},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1093--1096},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Opportunities for Technology in the Self-management of Mental Health},
 year = {2016}
}


@inproceedings{Lee:2016:SFW:2957265.2961858,
 abstract = {As mobile instant messaging has become a major means of communication with the widespread use of smartphones, emoticons, symbols that are meant to indicate particular emotions in instant messages, have also developed into various forms. The primary purpose of this study is to classify the usage patterns of emoticons focusing on a particular variant known as "stickers" to observe individual and social characteristics of emoticon use and reinterpret the meaning of emoticons in instant messages. A qualitative approach with an in-depth semi-structured interview was used to uncover the motive in using emoticon stickers. The study suggests that besides using emoticon stickers for expressing emotions, users may have other motives: strategic and functional purposes.},
 acmid = {2961858},
 address = {New York, NY, USA},
 author = {Lee, Joon Young and Hong, Nahi and Kim, Soomin and Oh, Jonghwan and Lee, Joonhwan},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961858},
 isbn = {978-1-4503-4413-5},
 keyword = {emoticon sticker, emoticons, mobile messages, mobile usage, usage pattern},
 link = {http://doi.acm.org/10.1145/2957265.2961858},
 location = {Florence, Italy},
 numpages = {7},
 pages = {760--766},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Smiley Face: Why We Use Emoticon Stickers in Mobile Messaging},
 year = {2016}
}


@inproceedings{Pinder:2016:THE:2957265.2961837,
 abstract = {Implementation intentions, 'if-then' plans where 'if's are contextual cues and 'then's are specific goal-related behaviours, hold much promise as an effective behaviour change technique to support habit formation. Nevertheless, they have been underused in digital behaviour change interventions. To address this gap, we outline a novel design of an implementation intention intervention that exploits the context-aware functionality of smartphones to extend the scope of these goal constructs. The results of a probe study and qualitative data from an elicitation survey are presented, from which we derive a set of key design recommendations and pointers for future research.},
 acmid = {2961837},
 address = {New York, NY, USA},
 author = {Pinder, Charlie and Vermeulen, Jo and Wicaksono, Adhi and Beale, Russell and Hendley, Robert J.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961837},
 isbn = {978-1-4503-4413-5},
 keyword = {context-aware smartphones, implementation intentions, nonconscious behaviour change technology},
 link = {http://doi.acm.org/10.1145/2957265.2961837},
 location = {Florence, Italy},
 numpages = {8},
 pages = {690--697},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {If This, then Habit: Exploring Context-aware Implementation Intentions on Smartphones},
 year = {2016}
}


@inproceedings{Schneegass:2016:ENI:2957265.2962663,
 abstract = {Notifications are an important function of mobile devices. They inform users about important events such as incoming messages or upcoming events. Prior work, however, showed that notifications can be disruptive which will become worse with the increasing number of notifications. Since notifications are currently not prioritized, disruption may lead to disregard of many important notifications. We propose embodied notification, a novel way of gaining the attention of the user. In contrast to regular ways of notifying the user such as presenting visual, auditory, or vibro-tactile cues, embodied notification use the body of the user as feedback channel. Thus, embodied notifications provide benefit to the user due to their embodiment and implicit nature. This novel type of notification can help gaining the attention of the user.},
 acmid = {2962663},
 address = {New York, NY, USA},
 author = {Schneegass, Stefan and Rzayev, Rufat},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962663},
 isbn = {978-1-4503-4413-5},
 keyword = {electrical muscle stimulation, notifications},
 link = {http://doi.acm.org/10.1145/2957265.2962663},
 location = {Florence, Italy},
 numpages = {6},
 pages = {954--959},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Embodied Notifications: Implicit Notifications Through Electrical Muscle Stimulation},
 year = {2016}
}


@inproceedings{Lopes:2016:TSP:2957265.2970371,
 abstract = {Technology becomes part of our daily life. The new technological solutions turned more sophisticated to surpass communication barriers. The online therapeutic work presents new possibilities and challenges for the professionals. We found in literature several computerized psychological treatment applications and also text-based sentiment analysis studies. However, we did not find an application that makes text analysis based on emotional clues and conversely serves as a management tool for psychologists. This paper reflects the increasing role of technology in health care delivery and the potential benefits that this could bring either to psychologists or to patients. We present a technological tool, which was developed following the human work interaction design approach to support interactions between patients and clinicians in psychological treatment. We are convinced that we will find some significant problems with sentiments analysis and with identification of positive and negative language. However, the proposed solution seems to fit the interviewees demand in a primary phase.},
 acmid = {2970371},
 address = {New York, NY, USA},
 author = {Lopes, Arminda Guerra},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2970371},
 isbn = {978-1-4503-4413-5},
 keyword = {analysis, computerized psychological treatment, interaction design, patient, psychologist, text analytics, therapeutic writing, work analysis},
 link = {http://doi.acm.org/10.1145/2957265.2970371},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1113--1116},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Technologies to Support Psychologists and Patients Interactions},
 year = {2016}
}


@inproceedings{Schroder:2016:CCC:2957265.2962658,
 abstract = {CoConUT is an Android app for collecting the mobile context as well as the frequency of interactions during mobile field studies (for example usability studies) using sensor data on the test device. For evaluation purposes the recorded user trial sessions can be visually explored. This facilitates an assessment of the user's attention patterns and enables the detection of limited cognitive resources caused by distracting contextual factors. The app was tested in a preliminary study for technical feasibility and is planned to be extended in the near future.},
 acmid = {2962658},
 address = {New York, NY, USA},
 author = {Schr\"{o}der, Svenja and Hirschl, Jakob and Reichl, Peter},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962658},
 isbn = {978-1-4503-4413-5},
 keyword = {app, attention, context, field studies, human factors, mobile HCI, mobile context, usability},
 link = {http://doi.acm.org/10.1145/2957265.2962658},
 location = {Florence, Italy},
 numpages = {6},
 pages = {924--929},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {CoConUT: Context Collection for Non-stationary User Testing},
 year = {2016}
}


@inproceedings{Holzer:2016:RTE:2957265.2961842,
 abstract = {Social buttons are now widespread in social media apps. They are used to assign weight to user content and trigger user engagement. They come in different shapes (e.g., thumb in Facebook, arrows in Reddit or StackOverflow, plus one in Google+) but very little is known about the influence of the shape on user behaviour. This paper, addresses this issue by presenting results of a controlled randomized experiment with 173 users. The results suggest that thumbs up / thumbs down icons are significantly more engaging than the plus one / minus one icons. At the same time the result shows that type of the icon used has no significant influence on the direction of the vote.},
 acmid = {2961842},
 address = {New York, NY, USA},
 author = {Holzer, Adrian and Vozniuk, Andrii and Bendahan, Samuel and Gillet, Denis},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961842},
 isbn = {978-1-4503-4413-5},
 keyword = {HCI, interaction design, social buttons, social media},
 link = {http://doi.acm.org/10.1145/2957265.2961842},
 location = {Florence, Italy},
 numpages = {8},
 pages = {659--666},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Rule of Thumb: Effect of Social Button Icons on Interaction},
 year = {2016}
}


@inproceedings{Korzetz:2016:NCI:2957265.2961839,
 abstract = {In collocated collaborative work, group members typically create, edit and share content to perform specific tasks. Working digitally, e.g. with mobile devices, facilitates the further processing. However, direct communication plays a decisive role. Since some tasks have to be split to be worked on, individual results have to be discussed and merged for a final solution. We provide intuitive multi-device interactions to support group members in merging multiple partial solutions to one integrated solution seamlessly. Each mobile device shows one solution that can be used completely or in parts. Our proposed interactions include complementing one part of a solution with further parts. Furthermore, content can be added or replaced by "pouring" content between several mobile devices. We implemented an application prototype to show the feasibility of our interactions. They enable an integration of mobile devices in collaborative work without replacing direct communication and support users in fulfilling their given tasks.},
 acmid = {2961839},
 address = {New York, NY, USA},
 author = {Korzetz, Mandy and K\"{u}hn, Romina and Heisig, Peter and Schlegel, Thomas},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961839},
 isbn = {978-1-4503-4413-5},
 keyword = {collaboration, interaction design, merging content, multi-device, user experience},
 link = {http://doi.acm.org/10.1145/2957265.2961839},
 location = {Florence, Italy},
 numpages = {7},
 pages = {746--752},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Natural Collocated Interactions for Merging Results with Mobile Devices},
 year = {2016}
}


@inproceedings{Pernencar:2016:MAI:2957265.2965007,
 abstract = {Smart technology, like wearable sensors or biochips, presents a vast capacity for monitoring vital signs, assess patients' behaviour and context, and simultaneously provide feedback with a significant effect in diagnosis, treatment, and control of diseases. Many chronic disease, in particular Inflammatory Bowel Disease (IBD), patients need to monitor their behaviour and register their disease history (e.g. symptoms, medication intake), as well as collect their physiological data, in order to control the disease, find correlations between their behaviour and the disease progress and help doctors to adjust treatment and promote patients behaviour changes. We have been working in the use of m-health applications by chronic disease patients to facilitate self-management of their diseases and increase their autonomy. We are now studying the use of wearable devices and biochips to automatically collect patients' data and empower them in managing their own health conditions.},
 acmid = {2965007},
 address = {New York, NY, USA},
 author = {Pernencar, Cl\'{a}udia and Rom\~{a}o, Teresa},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965007},
 isbn = {978-1-4503-4413-5},
 keyword = {chronic diseases, health self-management, m-Health, monitoring, wearable devices},
 link = {http://doi.acm.org/10.1145/2957265.2965007},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1089--1092},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Mobile Apps for IBD Self: Management Using Wearable Devices and Sensors},
 year = {2016}
}


@inproceedings{Iakovakis:2016:SHP:2957265.2970370,
 abstract = {The number of wearable and smart devices which are connecting every day in the Internet of Things (IoT) is continuously growing. We have a great opportunity though to improve the quality of life (QoL) standards by adding medical value to these devices. Especially, by exploiting IoT technology, we have the potential to create useful tools which utilize the sensors to provide biometric data. This novel study aims to use a smartwatch, independent from other hardware, to predict the Blood Pressure (BP) drop caused by postural changes. In cases that the drop is due to orthostatic hypotension (OH) can cause dizziness or even faint factors, which increase the risk of fall in the elderly but, as well as, in younger groups of people. A mathematical prediction model is proposed here which can reduce the risk of fall due to OH by sensing heart rate variability (data and drops in systolic BP after standing in a healthy group of 10 subjects. The experimental results justify the efficiency of the model, as it can perform correct prediction in 86.7% of the cases, and are encouraging enough for extending the proposed approach to pathological cases, such as patients with Parkinson's disease, involving large scale experiments.},
 acmid = {2970370},
 address = {New York, NY, USA},
 author = {Iakovakis, Dimitrios and Hadjileontiadis, Leontios},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2970370},
 isbn = {978-1-4503-4413-5},
 keyword = {blood pressure drop, heart rate variability, regression, smartwatch},
 link = {http://doi.acm.org/10.1145/2957265.2970370},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1109--1112},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Standing Hypotension Prediction Based on Smartwatch Heart Rate Variability Data: A Novel Approach},
 year = {2016}
}


@inproceedings{Ali-Hasan:2016:DAM:2957265.2957273,
 abstract = {When a user presses physical hardware volume keys on a smartphone, volume controls appears on the screen. Traditionally, these volume controls are represented by a single slider. Android's Lollipop release introduced new functionality into the volume controls: a way to temporarily silence interruptions from notifications and phone calls. After the launch of Android Lollipop, we discovered some usability issues with the more robust volume controls interface. We decided to address these issues in Android's next release, Marshmallow. In this case study, we describe the trade-offs we faced in designing Android Marshmallow volume controls and how our interdisciplinary user experience team designed a longitudinal study that helped us evaluate two designs we were considering. We also describe the impact of our research approach and how we arrived at a final design.},
 acmid = {2957273},
 address = {New York, NY, USA},
 author = {Ali-Hasan, Noor and Garb, Rachel and Pereira, Mindy},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2957273},
 isbn = {978-1-4503-4413-5},
 keyword = {Android Marshmallow, longitudinal research, mobile user experience, smartphones, usability, user experience, volume controls},
 link = {http://doi.acm.org/10.1145/2957265.2957273},
 location = {Florence, Italy},
 numpages = {7},
 pages = {557--563},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Designing Android Marshmallow Volume Controls: A User Experience Case Study},
 year = {2016}
}


@inproceedings{Wang:2016:EBS:2957265.2961846,
 abstract = {In recent years, there has been a rise in the use of virtual reality (VR) both in specialized fields and commercial settings. Modern applications of VR include games, films, education, arts, and healthcare, etc. Today, VR applications exist beyond expensive research labs; they are being employed to solve real world problems. To explore a new practical application of VR, we designed and prototyped a work-in-progress VR mobile app of common biking incidents in the form of a choose-your-own-adventure game. Our goal is to teach people about bicycle safety in cities, and to foster empathy within the driving community towards cyclists.},
 acmid = {2961846},
 address = {New York, NY, USA},
 author = {Wang, Wesley and Singh, Karan Pratap and Chu, Yan Ting Mandy and Huber, Annick},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961846},
 isbn = {978-1-4503-4413-5},
 keyword = {accessibility, education, empathy, human computer interaction, instructional design, transportation, virtual reality},
 link = {http://doi.acm.org/10.1145/2957265.2961846},
 location = {Florence, Italy},
 numpages = {8},
 pages = {883--890},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Educating Bicycle Safety and Fostering Empathy for Cyclists with an Affordable and Game-based VR App},
 year = {2016}
}


@inproceedings{Papangelis:2016:NDP:2957265.2962643,
 abstract = {While many cultural heritage projects currently exist, few explore the full potential of mobile technologies as a mechanism to explore intangible heritage as a way to preserve culture. This paper outlines three distinct areas necessary for the design, development and application of mobile technologies within this domain. We represent these as: a) The documentation of traditions within their unique context, as articulated by the represented community---co-curated; b) The translation of traditions and their modes of expression into emerging technology-based designs; c) Co-design and ethnography as approaches to build meaningful mobile experiences.},
 acmid = {2962643},
 address = {New York, NY, USA},
 author = {Papangelis, Konstantinos and Chamberlain, Alan and Liang, Hai-Ning},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962643},
 isbn = {978-1-4503-4413-5},
 keyword = {cultural preservation, design, indigenous, intangible cultural heritage, mobile technologies},
 link = {http://doi.acm.org/10.1145/2957265.2962643},
 location = {Florence, Italy},
 numpages = {4},
 pages = {964--967},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {New Directions for Preserving Intangible Cultural Heritage Through the Use of Mobile Technologies},
 year = {2016}
}


@inproceedings{Shrestha:2016:CPS:2957265.2962644,
 abstract = {The purpose of this research is to synthesize and transform real world physical environments (PE) into a CAVE automatic virtual reality system (CAVE) by using three-dimensional (3D) models of cultural and historical artifacts. 3D models are often used in many applications including visualizations and digital preservation. Virtual reality is used to improve perception and sensation and to better understand products and environments for studying human factors and behaviors. As a pilot study, we developed and prototyped a customizable 3D physical environment using historical data and archives into an interactive CAVE virtual reality (VR) system. We then conducted a study of user preferences using pretest and post-test questionnaires of the CAVE versus paper-based artifacts.},
 acmid = {2962644},
 address = {New York, NY, USA},
 author = {Shrestha, Sujan and Chakraborty, Joyram and Mohamed, Mona A.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962644},
 isbn = {978-1-4503-4413-5},
 keyword = {3D modeling, 3D visualization, CAVE automatic virtual reality, human computer interaction, human factors, user-centered design},
 link = {http://doi.acm.org/10.1145/2957265.2962644},
 location = {Florence, Italy},
 numpages = {10},
 pages = {968--977},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Comparative Pilot Study of Historical Artifacts in a CAVE Automatic Virtual Reality Environment Versus Paper-based Artifacts},
 year = {2016}
}


@inproceedings{Hsiu:2016:FUF:2957265.2961827,
 abstract = {Various typing methods of qwerty-based keyboards on smartwatches have been proposed in recent years. However, since each key can only occupy limited input space and our fingers are too big, recent solutions are mainly two-step typing methods. Users have to navigate the desired key on an enlarged keyboard, and then select the target. The two-step process is distant from our physical keyboard experiences, and requires users to frequently change the keyboard layouts. The aim of this paper is to propose a single-step typing technique that allows users to key in a character with a single touch. We introduce ForceBoard, which combines two adjacent keys into one region and uses force as selecting mechanism. By using that, it not only provides more precise selection, but also allows users to type texts without changing the visual contents of keyboard. We conducted a study comparing the performance of ForceBoard with other two state-of-the-art two-step methods, ZoomBoard and SplitBoard. Our results showed that ForceBoard outperformed ZoomBoard significantly with 30.52% on average, and was slightly better than SplitBoard. Furthermore, ForceBoard also received higher preferences on text speed and satisfaction.},
 acmid = {2961827},
 address = {New York, NY, USA},
 author = {Hsiu, Min-Chieh and Huang, Da-Yuan and Chen, Chi An and Lin, Yu-Chih and Hung, Yi-ping and Yang, De-Nian and Chen, Mike},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961827},
 isbn = {978-1-4503-4413-5},
 keyword = {ForceBoard, smartwatch, soft keyboard, text entry},
 link = {http://doi.acm.org/10.1145/2957265.2961827},
 location = {Florence, Italy},
 numpages = {6},
 pages = {599--604},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {ForceBoard: Using Force As Input Technique on Size-limited Soft Keyboard},
 year = {2016}
}


@inproceedings{Ghosh:2016:MES:2957265.2961854,
 abstract = {In this paper, we investigate the potential of using musical feedback to enhance the skateboarding experience and to encourage skaters to gain more skills. We adhere to the UCD (User-Centered Design) process to discover opportunities for technological contributions in skating, followed by proposing MusiSkate as a solution based on user needs and contexts. Our findings suggest that MusiSkate has the potential to enhance the satisfaction of skating. Furthermore, it conforms to the guidelines for designing skateboarding applications as set forth by existing literature. Finally, we suggest future explorations for using audio feedback with skateboarding based on the results of our pilot study.},
 acmid = {2961854},
 address = {New York, NY, USA},
 author = {Ghosh, Sarthak and Shah, Pratik and Navarro, Lorina and Chen, Xiaowei},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961854},
 isbn = {978-1-4503-4413-5},
 keyword = {audio feedback, skateboarding, user-centered design},
 link = {http://doi.acm.org/10.1145/2957265.2961854},
 location = {Florence, Italy},
 numpages = {7},
 pages = {753--759},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {MusiSkate: Enhancing the Skateboarding Experience Through Musical Feedback},
 year = {2016}
}


@inproceedings{Shema:2016:ICE:2957265.2962653,
 abstract = {Prior research has investigated how to improve awareness of collocation at neighborhood scales or citywide through the use of smartphone apps. The availability of indoor maps and more accurate indoor navigation technologies motivate us to investigate the concept of collocation in the context of indoor settings. In this paper, we introduce the notion of ultralocality, which involves people and various kinds of resources collocated in an indoor environment. We present our interview study and initial results that help us understand how people perceive collocation in an ultralocal enviornment. We also introduce a mobile application that helps people explore an ultralocal environment in the college campus buildings.},
 acmid = {2962653},
 address = {New York, NY, USA},
 author = {Shema, Alain and Huang, Yun},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962653},
 isbn = {978-1-4503-4413-5},
 keyword = {hyperlocal, indoor maps, mobile collocation, ultralocal},
 link = {http://doi.acm.org/10.1145/2957265.2962653},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1125--1128},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Indoor Collocation: Exploring the Ultralocal Context},
 year = {2016}
}


@inproceedings{Faklaris:2016:LEI:2957265.2961845,
 abstract = {The introduction of mobile apps such as Meerkat, Periscope, and Facebook Live has sparked enthusiasm for live-streaming video. This study explores the legal and ethical implications of mobile live-streaming video apps through a review of public-policy considerations and the computing literature as well as analyses of a mix of quantitative and qualitative user data. We identify lines of research inquiry for five policy challenges and two areas of the literature in which the impact of these apps is so far unaddressed. The detailed data gathered from these inquiries will significantly contribute to the design and development of tools, signals or affordances to address the concerns that our study identifies. We hope our work will help shape the fields of ubiquitous computing and collaborative and social computing, jurisprudence, public policy and applied ethics in the future.},
 acmid = {2961845},
 address = {New York, NY, USA},
 author = {Faklaris, Cori and Cafaro, Francesco and Hook, Sara Anne and Blevins, Asa and O'Haver, Matt and Singhal, Neha},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961845},
 isbn = {978-1-4503-4413-5},
 keyword = {informatics, intellectual property, mobile live-streaming video, privacy, security, surveillance},
 link = {http://doi.acm.org/10.1145/2957265.2961845},
 location = {Florence, Italy},
 numpages = {8},
 pages = {722--729},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Legal and Ethical Implications of Mobile Live-streaming Video Apps},
 year = {2016}
}


@inproceedings{Aly:2016:SGA:2957265.2961863,
 abstract = {The security of authentication mechanisms on touchscreen mobile devices is often at risk due to various usability barriers. The most common authentication step mobile users go through is the lock screen that blocks access to the entire device. This is subject to a usability-vs-security tension: users want quick and easy access to their phones while ensuring it is protected from unauthorized access. Since ease-of-use is a critical attribute for any new authentication mechanism, we propose an authentication system inspired by an intuitive real-life paradigm, the single dial combination (spin) lock, and evaluate its usability and user acceptance. We show that a Spin-lock authentication is perceived by users as more enjoyable than other lock methods. We use this to discuss implications for the design of mobile authentication mechanisms and suggest situations for which real-life inspired locking systems may be preferable.},
 acmid = {2961863},
 address = {New York, NY, USA},
 author = {Aly, Yomna and Munteanu, Cosmin and Raimondo, Stefania and Wu, Alan Yusheng and Wei, Molly},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961863},
 isbn = {978-1-4503-4413-5},
 keyword = {dial combination lock, mobile lock screen, smart phone},
 link = {http://doi.acm.org/10.1145/2957265.2961863},
 location = {Florence, Italy},
 numpages = {8},
 pages = {775--782},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Spin-lock Gesture Authentication for Mobile Devices},
 year = {2016}
}


@inproceedings{Kim:2016:LLD:2957265.2957275,
 abstract = {This paper discusses challenges and lessons learned from designing and launching consumer-facing wearable technologies that Intel developed with other companies. The lessons are drawn from the perspective of a user experience team working in a traditionally hardware company.},
 acmid = {2957275},
 address = {New York, NY, USA},
 author = {Kim, Kahyun Sophie and Mansour, Anna-Marie and Lundell, Jay W.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2957275},
 isbn = {978-1-4503-4413-5},
 keyword = {agile UX, display-less devices, wearable devices},
 link = {http://doi.acm.org/10.1145/2957265.2957275},
 location = {Florence, Italy},
 numpages = {6},
 pages = {585--590},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Lessons Learned from Designing a Displayless Consumer Wearable Tech},
 year = {2016}
}


@inproceedings{Pinder:2016:ZED:2957265.2961838,
 abstract = {Hoarding disorder is a complex condition that has attracted little research attention, despite adversely affecting 2-5% of the population. We review the options and difficulties in the treatment of hoarding disorder using technology. We present a novel intervention design, delivered on tablets, that combines a Cognitive Bias Modification game with goal tracking functionality. We outline two experiments in progress: a lab study to measure the impact of our game on a non-hoarding population, and a probe study to determine the suitability of the intervention for participants with hoarding disorder.},
 acmid = {2961838},
 address = {New York, NY, USA},
 author = {Pinder, Charlie and Beale, Russell and Hendley, Robert J.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961838},
 isbn = {978-1-4503-4413-5},
 keyword = {cognitive bias modification, goal setting, hoarding, nonconscious behaviour change using technology},
 link = {http://doi.acm.org/10.1145/2957265.2961838},
 location = {Florence, Italy},
 numpages = {8},
 pages = {875--882},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Zephyr: Exploring Digital Behaviour Change Interventions to Treat Hoarding},
 year = {2016}
}


@inproceedings{Cramer:2016:LSS:2957265.2964197,
 abstract = {While audio in itself may appear place-less, audio content is in many cases implicitly or explicitly tied to location. Focusing on primarily music content, this position paper outlines a number of dimensions of the interplay of audio and place, and the ways in which locality can play a role in people's engagement with music. An example of different locality levels is provided using the example of streaming content in the car as a personal space traversing from A to B.},
 acmid = {2964197},
 address = {New York, NY, USA},
 author = {Cramer, Henriette},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2964197},
 isbn = {978-1-4503-4413-5},
 keyword = {audio, location, music, singing-along-in-cars},
 link = {http://doi.acm.org/10.1145/2957265.2964197},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1055--1058},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Local Sounds \&\#38; Singing Along in Cars},
 year = {2016}
}


@inproceedings{McNally:2016:EBP:2957265.2957270,
 abstract = {We describe a series of studies using three methods to understand usage of a cards-based mobile queryless search experience. An existing product was chosen as stimuli to allow for quick execution to learn from participants who have had experience over an extended period of time, as opposed to only studying first time use. Findings from these studies provide implications that can be used to inform products aimed at satisfying user needs for personal information while on the go. Focus is placed on the ability for queryless search results to display actionable information as well as provide direct actions without additional clicks.},
 acmid = {2957270},
 address = {New York, NY, USA},
 author = {McNally, Jennifer and Bentley, Frank and Peesapati, S. Tejaswi and Ponnada, Soujanya},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2957270},
 isbn = {978-1-4503-4413-5},
 keyword = {Google now, anticipatory search, cards, crowdsourcing, design, diary studies, experimentation, human factors, mixed-methods, triangulation},
 link = {http://doi.acm.org/10.1145/2957265.2957270},
 location = {Florence, Italy},
 numpages = {10},
 pages = {541--550},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Exploring Best Practices for Card Interactions Through a Three-method Triangulation},
 year = {2016}
}


@inproceedings{Ardissono:2016:ECH:2957265.2962648,
 abstract = {Searching information in a Geographical Information System (GIS) usually imposes that users explore precompiled category catalogs and select the types of information they are looking for. Unfortunately, that approach is challenging because it forces people to adhere to a conceptualization of the information space that might be different from their own. In order to address this issue, we propose to support textual search as the basic interaction model, exploiting linguistic information, together with category exploration, for query interpretation and expansion. This paper describes our model and its adoption in the OnToMap Participatory GIS.},
 acmid = {2962648},
 address = {New York, NY, USA},
 author = {Ardissono, Liliana and Lucenteforte, Maurizio and Mauro, Noemi and Savoca, Adriano and Voghera, Angioletta and La Riccia, Luigi},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962648},
 isbn = {978-1-4503-4413-5},
 keyword = {GIS, community maps, text-based information search},
 link = {http://doi.acm.org/10.1145/2957265.2962648},
 location = {Florence, Italy},
 numpages = {10},
 pages = {992--1001},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Exploration of Cultural Heritage Information via Textual Search Queries},
 year = {2016}
}


@inproceedings{Lucero:2016:ITM:2957265.2962651,
 abstract = {Research on mobile collocated interactions has been exploring situations where collocated users engage in collaborative activities using their personal mobile devices (e.g., smartphones and tablets), thus going from personal/individual toward shared/multiuser experiences and interactions. The proliferation of ever-smaller computers that can be worn on our wrists (e.g., Apple Watch) and other parts of the body (e.g., Google Glass), have expanded the possibilities and increased the complexity of interaction in what we term "mobile collocated" situations. The focus of this workshop is to bring together a community of researchers, designers and practitioners to explore novel interaction techniques for mobile collocated interactions.},
 acmid = {2962651},
 address = {New York, NY, USA},
 author = {Lucero, Andr{\'e}s and Quigley, Aaron and Rekimoto, Jun and Roudaut, Anne and Porcheron, Martin and Serrano, Marcos},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962651},
 isbn = {978-1-4503-4413-5},
 keyword = {collaboration, collocated, handheld devices, multi-device, multi-user},
 link = {http://doi.acm.org/10.1145/2957265.2962651},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1117--1120},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Interaction Techniques for Mobile Collocation},
 year = {2016}
}


@inproceedings{Kerber:2016:MSN:2957265.2962657,
 abstract = {The ongoing development of smart, wearable devices opens up a new range of possibilities with respect to human-computer interaction. Recent research has confirmed that smartwatches are primarily used to visualize notifications. However, the limited screen size is at odds with the ever-growing amount of information. Often, explicit interaction is needed to get an overview on the currently available information. We provide an aggregation/filtering approach as well as several displaying concepts based on a self-built, power-efficient smartwatch prototype with twelve full-color LEDs around a low-resolution display. In a user study with twelve participants, we evaluated our concepts, and we conclude with guidelines that could easily be applied to today's smartwatches to provide more expressive notification systems.},
 acmid = {2962657},
 address = {New York, NY, USA},
 author = {Kerber, Frederic and Hirtz, Christoph and Gehring, Sven and L\"{o}chtefeld, Markus and Kr\"{u}ger, Antonio},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962657},
 isbn = {978-1-4503-4413-5},
 keyword = {LED, notification filtering, notifications, smartwatch},
 link = {http://doi.acm.org/10.1145/2957265.2962657},
 location = {Florence, Italy},
 numpages = {6},
 pages = {918--923},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Managing Smartwatch Notifications Through Filtering and Ambient Illumination},
 year = {2016}
}


@inproceedings{Georgiadi:2016:PRG:2957265.2963117,
 abstract = {This paper presents ongoing work on the design and prototyping of a pervasive, role-playing game for elementary school students. The game takes place in a designated space presented as an excavation site, in which students become acquainted with a number of principal roles and tasks taking place in archaeological fieldwork. The educational goals are to introduce students to fundamental archaeology concepts and to inform them about the historical background of a specific site and the discovered artifacts. The game apparatus consists of a mobile application (android), a number of small wireless sensors (beacons), tangible models of the antiquities and simplified prop tools of the archaeological equipment (3D printed). The paper outlines the main design concepts, technologies used and gameplay and reports on a preliminary evaluation.},
 acmid = {2963117},
 address = {New York, NY, USA},
 author = {Georgiadi, Natalia and Kokkoli-Papadopoulou, Eleni and Kordatos, George and Partheniadis, Konstantinos and Sparakis, Manos and Koutsabasis, Panayiotis and Vosinakis, Spyros and Zissis, Dimitris and Stavrakis, Modestos},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963117},
 isbn = {978-1-4503-4413-5},
 keyword = {archaeology, beacons, cultural heritage, interaction design for children, mobile, pervasive games, role-playing games, serious games, wireless sensors},
 link = {http://doi.acm.org/10.1145/2957265.2963117},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1016--1020},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Pervasive Role-playing Game for Introducing Elementary School Students to Archaeology},
 year = {2016}
}


@inproceedings{Tzovaras:2016:WMH:2957265.2965002,
 abstract = {The wave of digital health is continuously growing and promises to transform the experience of patients, redefining their role as empowered actors of the healthcare processes rather than passive receivers of medical help. Mobile technologies are a fundamental component of this transformation since they have provided a platform for the development of novel solutions, allowing a gradual shift of healthcare closer to the patients' daily living and away from the traditional clinical environment. Chronic diseases are in the center of these developments as they require the continuous and active involvement of not only healthcare professionals but also patients both of who can be empowered through the use of specialized mobile applications and the analysis of data from modern miniaturized and wearable sensing devices. Furthermore, the communication channels introduced by mobile technologies can significantly increase the efficiency of the healthcare system and facilitate the communication between patients and healthcare professionals. The current workshop invites researchers from the fields of Information Technologies and Medical Sciences as well as healthcare professionals and technology developers to demonstrate and discuss innovative approaches related to the utilization of mobile Human Computer Interaction approaches in the modern healthcare environment.},
 acmid = {2965002},
 address = {New York, NY, USA},
 author = {Tzovaras, Dimitrios and Valtolina, Stefano and Abdelnour-Nocera, Jose and Votis, Konstantinos and Barricelli, Barbara Rita and Moustakas, Konstantinos and Kikidis, Dimitrios},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965002},
 isbn = {978-1-4503-4413-5},
 keyword = {chronic diseases, disease self-management, electronic health records, medical privacy protection, mobile health, mobile technologies, patient decision support, patient education and training, patient empowerment, personalized user interfaces, visual analytics},
 link = {http://doi.acm.org/10.1145/2957265.2965002},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1069--1072},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Workshop on Mobile Healthcare for the Self-management of Chronic Diseases and the Empowerment of Patients},
 year = {2016}
}


@inproceedings{Shahid:2016:SFM:2957265.2961866,
 abstract = {This study explores the user interface design requirements for developing a mobile planning application for students with autism spectrum disorder (ASD). We developed a mobile agenda application to support students in planning their activities. To test students' preference for a particular style, we designed three versions of the app, based on three different design styles (flat design, material design, and skeuomorphic design). Results show that the app was perceived as useful, likeable and user-friendly. Although, no significant difference was found between three designs, the material design was largely preferred over other two designs.},
 acmid = {2961866},
 address = {New York, NY, USA},
 author = {Shahid, Suleman and ter Voort, Jip and Somers, Maarten and Mansour, Inti},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961866},
 isbn = {978-1-4503-4413-5},
 keyword = {autism, flat design, material, mobile, skeuomorphic},
 link = {http://doi.acm.org/10.1145/2957265.2961866},
 location = {Florence, Italy},
 numpages = {8},
 pages = {738--745},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Skeuomorphic, Flat or Material Design: Requirements for Designing Mobile Planning Applications for Students with Autism Spectrum Disorder},
 year = {2016}
}


@inproceedings{Mashhadi:2016:CSC:2957265.2957272,
 abstract = {Face-to-face interactions have proven to accelerate team and larger organisation success. Many past research has explored the benefits of quantifying face-to-face interactions for informed workplace management, with little attention being paid to how this information is perceived by the employees. In this paper, we offer a reflection on the automated feedback of personal interactions in a workplace through a longitudinal study of capturing, modelling and visualisation of face-to-face interactions of 47 employees for 4 months in an industrial research lab in Europe. We conducted semi-structured interviews with 20 employees to understand their perception and experience with the system. Our findings suggest that the short-term feedback on personal face-to-face interactions was not perceived as an effective external cue to promote self-reflection by most, and that employees desire long-term feedback annotated with actionable attributes.},
 acmid = {2957272},
 address = {New York, NY, USA},
 author = {Mashhadi, Afra and Mathur, Akhil and Van Den Broeck, Marc and Vanderhulst, Geert and Godon, Marc and Kawsar, Fahim},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2957272},
 isbn = {978-1-4503-4413-5},
 link = {http://doi.acm.org/10.1145/2957265.2957272},
 location = {Florence, Italy},
 numpages = {10},
 pages = {575--584},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Case Study on Capturing and Visualising Face-to-face Interactions in the Workplace},
 year = {2016}
}


@inproceedings{Jokela:2016:UES:2957265.2962654,
 abstract = {Elicitation studies allow collecting interaction methods directly from end-users by presenting the users with the end effect of an operation and then asking them to perform the action that caused it. Applying elicitation studies in the domain of collocated interaction might enable designing more intuitive and natural group interaction methods. However, in the past elicitation studies have primarily been conducted with individual users -- they have rarely been applied to groups. In this paper, we report our initial experiences in using the elicitation study methodology to generate interaction methods for groups of collocated users with wearable devices.},
 acmid = {2962654},
 address = {New York, NY, USA},
 author = {Jokela, Tero and Rezaei, Parisa Pour and V\"{a}\"{a}n\"{a}nen, Kaisa},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962654},
 isbn = {978-1-4503-4413-5},
 keyword = {collocated interaction, elicitation study, guessability study, multi-device user interfaces, wearable devices},
 link = {http://doi.acm.org/10.1145/2957265.2962654},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1129--1133},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Using Elicitation Studies to Generate Collocated Interaction Methods},
 year = {2016}
}


@inproceedings{Weber:2016:NDE:2957265.2962660,
 abstract = {Notifications are a key feature on current smartphones. Apps gain the attention of the users to inform them about new messages, upcoming appointments or system updates. Previous studies investigated how many notifications users receive and how users interact with those notifications. Related work explored means to manage incoming notifications. In this work, we present the Notification Dashboard to enable users to reflect on their received notifications and to identify unwanted interruptions. We conducted a user study, in which we logged participants' smartphone notifications for one month. Afterwards, we visualized the log files using the dashboard and interviewed the participants about their impressions. The results show that participants underestimated the amount of notifications and were positive about using the dashboard to reflect on their received notifications.},
 acmid = {2962660},
 address = {New York, NY, USA},
 author = {Weber, Dominik and Voit, Alexandra and Le, Huy Viet and Henze, Niels},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962660},
 isbn = {978-1-4503-4413-5},
 keyword = {dashboard, mobile notifications, visualization},
 link = {http://doi.acm.org/10.1145/2957265.2962660},
 location = {Florence, Italy},
 numpages = {6},
 pages = {936--941},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Notification Dashboard: Enabling Reflection on Mobile Notifications},
 year = {2016}
}


@inproceedings{Ghiani:2016:EPC:2957265.2965005,
 abstract = {The design and development of flexible applications able to match the many possible user needs and provide high quality user experience is still a major issue. In ambient-assisted living scenarios there is the need of giving adequate support to elderly so that they can independently live at home. Thus, providing personalized assistance is particularly critical because ageing people often have different ranges of individual needs, requirements and disabilities. In this position paper we introduce a solution based on an End-User Development environment that allows patients and caregivers to tailor the context-dependent behaviour of their Web applications in order to facilitate patients' life. This is done through the specification of trigger-action rules to support application customization.},
 acmid = {2965005},
 address = {New York, NY, USA},
 author = {Ghiani, Giuseppe and Manca, Marco and Patern\`{o}, Fabio and Santoro, Carmen},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965005},
 isbn = {978-1-4503-4413-5},
 keyword = {AAL, end-user development, personalization},
 link = {http://doi.acm.org/10.1145/2957265.2965005},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1081--1084},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {End-user Personalization of Context-dependent Applications in AAL Scenarios},
 year = {2016}
}


@inproceedings{Wang:2016:DSN:2957265.2965023,
 abstract = {This paper presents a design workshop that explores the future of fashionable wearable technology focusing on aesthetics. The results of the workshop include four fashion design concepts and the implications emerged from the discussions on each concept during the workshop. These implications open up new design space of technologies and materials that account for aesthetics beyond traditional fabric, i.e. transparency, scale, irregularity, movement, contextual expressions and fashion intelligence.},
 acmid = {2965023},
 address = {New York, NY, USA},
 author = {Wang, Jinyi and Juhlin, Oskar and Blomgren, Erika and B{\aa}gander, Linnea and K\"{a}go, Evelin and Meier, Florian and Takahashi, Mariko and Thornquist, Clemens},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965023},
 isbn = {978-1-4503-4413-5},
 keyword = {aesthetics, design, fashion, wearable technology},
 link = {http://doi.acm.org/10.1145/2957265.2965023},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1159--1162},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Design Space of the New Materials for Fashionable Wearables},
 year = {2016}
}


@inproceedings{Gobel:2016:IVA:2957265.2962659,
 abstract = {Efficient user interfaces help their users to accomplish their tasks by adapting to their current needs. The processes involved before and during interface adaptation are complex and crucial for the success and acceptance of a user interface. In this work we identify these processes and propose a framework that demonstrates the benefits that can be gained by utilizing the user's visual attention in the context of adaptive cartographic maps.},
 acmid = {2962659},
 address = {New York, NY, USA},
 author = {G\"{o}bel, Fabian and Giannopoulos, Ioannis and Raubal, Martin},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962659},
 isbn = {978-1-4503-4413-5},
 keyword = {gaze-based interaction, interface adaptation, visual attention},
 link = {http://doi.acm.org/10.1145/2957265.2962659},
 location = {Florence, Italy},
 numpages = {6},
 pages = {930--935},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {The Importance of Visual Attention for Adaptive Interfaces},
 year = {2016}
}


@inproceedings{Ross:2016:LLD:2957265.2961853,
 abstract = {While the technology field is growing very fast and is important to our day-to-day lives, very few women consider this field as one they would like to pursue. While the reasons for this are primarily cultural, early exposure to these fields is also very important. In this small study, we tested a customized mobile application (App) we designed to teach middle school girls about computer science concepts. We used surveys to determine which content presentation methods were more effective for learning and to find out their perception of the App. We also tracked participants' movements in the App. We found that among our 7 participants, interactive presentation methods seemed to be better for teaching than heavy text-based methods. We also found out that no participant took the same path through the App. We hope the results from this preliminary study will help add to the knowledge of this demographic in both teaching and design work.},
 acmid = {2961853},
 address = {New York, NY, USA},
 author = {Ross, Rachael and Zhou, Wenjin},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961853},
 isbn = {978-1-4503-4413-5},
 keyword = {Android, computer science education, menu layout, mobile development},
 link = {http://doi.acm.org/10.1145/2957265.2961853},
 location = {Florence, Italy},
 numpages = {8},
 pages = {831--838},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Lessons Learned: Designing a Mobile Application for Teaching Computer Science Concepts to Middle School Girls},
 year = {2016}
}


@inproceedings{Zhang:2016:MNK:2957265.2963115,
 abstract = {Internet communication has revolutionised human communication, which is rapidly migrating from the physical world to the digital world. However, digital communication is often criticised for encouraging social isolation, and diminishing our abilities to empathise and form emotional bonds. Communication technologies still focus on transmitting visual and audio information, thus missing the emotional exchange during face-to-face interaction expressed through physical contact and non-verbal cues.},
 acmid = {2963115},
 address = {New York, NY, USA},
 author = {Zhang, Emma Yann},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963115},
 isbn = {978-1-4503-4413-5},
 keyword = {affective communication, force control, haptics, mediated kissing, multimodal interface},
 link = {http://doi.acm.org/10.1145/2957265.2963115},
 location = {Florence, Italy},
 numpages = {3},
 pages = {911--913},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Multimodal Networked Kissing Machine for Mobile Phones},
 year = {2016}
}


@inproceedings{Filho:2016:ACA:2957265.2961834,
 abstract = {This work proposes the use of system to perform affective-ready, contextual and automated usability tests for mobile software. Our proposal augments the traditional methods of software usability evaluation by monitoring users' location, weather conditions, moving/stationary status, data connection availability and spontaneous facial expressions automatically. This aims to identify the moment of negative and positive events. Identifying those situations and systematically associating them to the context of interaction, assisted software creators to overcome design flaws and enhancing interfaces' strengths. The validation of our approach include post-test questionnaires with test subjects. The results indicate that the automated user-context logging can be a substantial supplement to mobile software usability tests.},
 acmid = {2961834},
 address = {New York, NY, USA},
 author = {Filho, Jackson Feij\'{o} and Prata, Wilson and Oliveira, Juan},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961834},
 isbn = {978-1-4503-4413-5},
 keyword = {affective computing, mobile software, usability},
 link = {http://doi.acm.org/10.1145/2957265.2961834},
 location = {Florence, Italy},
 numpages = {7},
 pages = {638--644},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Affective-ready, Contextual and Automated Usability Test for Mobile Software},
 year = {2016}
}


@inproceedings{Krainz:2016:AWF:2957265.2961847,
 abstract = {Modern technology provides various apps for navigation and routing, but these are not always accessible for anyone. People with special needs have different requirements for the suggested walking path and also other demands to the user interface. In this work we combine an accessible routing service with an accessible smartphone app, to support people with varying impairments. In a field study with 12 participants usability and accessibility issues of the concept were identified.},
 acmid = {2961847},
 address = {New York, NY, USA},
 author = {Krainz, Elmar and Lind, Viktoria and Moser, Werner and Dornhofer, Markus},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961847},
 isbn = {978-1-4503-4413-5},
 keyword = {accessibility, assisting technology, blind, cognitive impairment, elderly people, routing, visually impaired, way finding},
 link = {http://doi.acm.org/10.1145/2957265.2961847},
 location = {Florence, Italy},
 numpages = {8},
 pages = {799--806},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Accessible Way Finding on Mobile Devices for Different User Groups},
 year = {2016}
}


@inproceedings{Barricelli:2016:SDM:2957265.2965009,
 abstract = {This workshop paper aims at briefly presenting the authors' previous experience in the field of sociotechnical design of mHealth applications and at illustrating the opportunity in joining forces of multidisciplinary researchers, domain experts, and practitioners for improving the field.},
 acmid = {2965009},
 address = {New York, NY, USA},
 author = {Barricelli, Barbara Rita and Valtolina, Stefano and Abdelnour-Nocera, Jose},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965009},
 isbn = {978-1-4503-4413-5},
 keyword = {chronic diseases, mHealth, mobile devices, patient empowerment, patient engagement, personal health records, sociotechnical design},
 link = {http://doi.acm.org/10.1145/2957265.2965009},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1097--1100},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Sociotechnical Design of mHealth Applications for Chronic Diseases},
 year = {2016}
}


@inproceedings{DeRoure:2016:NPC:2957265.2964199,
 abstract = {Ada Lovelace noted that Charles Babbage's Analytical Engine "might compose elaborate and scientific pieces of music of any degree of complexity or extent". The Numbers into Notes project, in its first phase, explored how this might have occurred nearly two centuries ago on the giant steam-powered machine using the mathematics of the time. Now we are asking what Lovelace might do today, with a microcontroller instead of the analytical engine. In our experiment, multiple devices are programmed to generate music, with creative interventions by humans to compose and influence the experience in locative sound.},
 acmid = {2964199},
 address = {New York, NY, USA},
 author = {De Roure, David and Willcox, Pip},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2964199},
 isbn = {978-1-4503-4413-5},
 keyword = {Ada Lovelace, algorithmic composition, analytical engine},
 link = {http://doi.acm.org/10.1145/2957265.2964199},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1059--1063},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Numbers in Places: Creative Interventions in Musical Space \&\#38; Time},
 year = {2016}
}


@inproceedings{Kim:2016:DAU:2957265.2957271,
 abstract = {Accessibility is the major social responsibility of the Information Technology (IT) companies. New accessibility technology can make IT devices more accessible to diverse users, thus it can reduce barriers to the use of IT devices. The objective of this study is to inform the procedures to develop accessibility UX guidelines in Samsung. In 2014, the comprehensive literature survey was conducted including academic research papers, accessibility laws, and international standard documents. In 2015, a user test was conducted to clarify and specify the guidelines. In 2016, lawyers reviewed the guidelines to increase the reliability of them. The proposed procedure is helpful to develop new accessibility UX guidelines.},
 acmid = {2957271},
 address = {New York, NY, USA},
 author = {Kim, Hyun K. and Kim, Changwon and Lim, Eunyoung and Kim, Hyunjin},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2957271},
 isbn = {978-1-4503-4413-5},
 keyword = {IT devices, accessibility guideline, user interface},
 link = {http://doi.acm.org/10.1145/2957265.2957271},
 location = {Florence, Italy},
 numpages = {6},
 pages = {551--556},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {How to Develop Accessibility UX Design Guideline in Samsung},
 year = {2016}
}


@inproceedings{Kono:2016:WHS:2957265.2962652,
 abstract = {This paper presents our new wearable handwriting input system that tracks user's index finger in the air and the finger loci are stored to the user location as handwriting and the handwritings can be shared by users as virtual scribbles and/or messages in the air. Our proposed method detects the finger locus to the location by descending the user's head motion from finger tracking reading. Their head posture is calculated in semi real time by integrating the image processing from the head-worn camera images into acceleration/gyro sensor readings equipped with the head-mounted display.},
 acmid = {2962652},
 address = {New York, NY, USA},
 author = {Kono, Yasuyuki and Tanaka, Yuki},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962652},
 isbn = {978-1-4503-4413-5},
 keyword = {finger tracking, handwriting, memory augmentation, wearable interface},
 link = {http://doi.acm.org/10.1145/2957265.2962652},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1121--1124},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Wearable Handwriting System for Time-warping Collocation},
 year = {2016}
}


@inproceedings{Runge:2016:TYE:2957265.2961836,
 abstract = {People tend to collect more and more data, this is especially true for images on mobile devices. Tagging images is a good way to sort such collections. While automatic tagging systems are often focused on the content, such as objects or persons in the image, manual annotations are very important to describe the context of an image. Often especially emotions are important, e.g., when a person reflects a situation, shows images from a very personal collection to others, or when using images to illustrate presentations. Unfortunately, manual annotation is often very boring and users are not very motivated to do so. While there are many approaches to motivate people to annotate data in a conventional way, none of them has focused on emotions. In this poster abstract, we present EmoWheel; an innovative interface to annotate images with emotional tags. We conducted a user study with 18 participants. Results show that the EmoWheel can enhance the motivation to annotate images.},
 acmid = {2961836},
 address = {New York, NY, USA},
 author = {Runge, Nina and Hellmeier, Marius and Wenig, Dirk and Malaka, Rainer},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961836},
 isbn = {978-1-4503-4413-5},
 keyword = {apps, emotions, image tagging, mobile devices, plutchik, user interfaces},
 link = {http://doi.acm.org/10.1145/2957265.2961836},
 location = {Florence, Italy},
 numpages = {8},
 pages = {846--853},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Tag Your Emotions: A Novel Mobile User Interface for Annotating Images with Emotions},
 year = {2016}
}


@inproceedings{Aranda:2016:IJT:2957265.2957274,
 abstract = {There is a prevailing sentiment in popular culture that we have become too attached to our phones. Smartphone notifications play a critical role in drawing people's attention to their phones. As user experience researchers on the Android team at Google, we used an ethnographic approach to understand how people experience smartphone notifications. We conducted an ethnographic study of smartphone users in New York City, while engaging members of our product team (including product managers, engineers, and designers) in the data collection and analysis. In this case study, we describe our research methods, what we learned about notifications' role in people's lives, and discuss the impact that our research has had on various product teams at Google.},
 acmid = {2957274},
 address = {New York, NY, USA},
 author = {Aranda, Julie and Ali-Hasan, Noor and Baig, Safia},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2957274},
 isbn = {978-1-4503-4413-5},
 keyword = {attention management, ethnographic research, mobile user experience, notifications, smartphones, user experience},
 link = {http://doi.acm.org/10.1145/2957265.2957274},
 location = {Florence, Italy},
 numpages = {11},
 pages = {564--574},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {I'M Just Trying to Survive: An Ethnographic Look at Mobile Notifications and Attention Management},
 year = {2016}
}


@inproceedings{Toivanen:2016:IUA:2957265.2965016,
 abstract = {Gaze tracking in psychological, cognitive, and user interaction studies has recently evolved toward mobile solutions, as they enable direct assessing of users' visual attention in natural environments, and augmented and virtual reality (AR/VR) applications. Productive approaches in analyzing and predicting user actions with gaze data require a multidisciplinary approach with experts in cognitive and behavioral sciences, machine vision, and machine learning. This workshop brings together a cross-domain group of individuals to (i) discuss and contribute to the problem of using mobile gaze tracking for inferring user action, (ii) advance the sharing of data and analysis algorithms as well as device solutions, and (iii) increase understanding of behavioral aspects of gaze-action sequences in natural environments and AR/VR applications.},
 acmid = {2965016},
 address = {New York, NY, USA},
 author = {Toivanen, Miika and Puolam\"{a}ki, Kai and Lukander, Kristian and H\"{a}kkinen, Jukka and Radun, Jenni},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965016},
 isbn = {978-1-4503-4413-5},
 keyword = {action inference, augmented reality, behavioral analysis, gaze tracking algorithms, machine learning, mobile gaze tracking, natural environments, virtual reality},
 link = {http://doi.acm.org/10.1145/2957265.2965016},
 location = {Florence, Italy},
 numpages = {3},
 pages = {1026--1028},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Inferring User Action with Mobile Gaze Tracking},
 year = {2016}
}


@inproceedings{Wecker:2016:DPB:2957265.2962645,
 abstract = {Systems often try to give advice to users. Personalization and the use of personality in the use of recommendation systems is a very topical. Examining the Cultural Heritage Domain, we propose a framework how we can monitor visitor behavior on the go, something that is mildly volatile, to determine personality traits, something that is more stable. This knowledge can be then used along with context to give tailored advice. Methods of monitoring visitor behavior, converting that to traits and that to personality types are described. Different dimensions of how to give tailored advice based on personality are described.},
 acmid = {2962645},
 address = {New York, NY, USA},
 author = {Wecker, Alan J. and Kuflik, Tsvi and Stock, Oliviero},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962645},
 isbn = {978-1-4503-4413-5},
 keyword = {lifelong cultural heritage, museum visitor types, personality, personalization},
 link = {http://doi.acm.org/10.1145/2957265.2962645},
 location = {Florence, Italy},
 numpages = {6},
 pages = {978--983},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Dynamic Personalization Based on Mobile Behavior: From Personality to Personalization: a Blueprint},
 year = {2016}
}


@inproceedings{Ardissono:2016:MAC:2957265.2965001,
 abstract = {The Mobile-CH workshop, held in conjunction with the MOBILE HCI Conference, will be the meeting point between cultural heritage research and personalization -- using any kind of technology, especially mobile and ubiquitous ones, to enhance the personal experience in cultural heritage sites. The workshop is aimed at bringing together researchers and practitioners who are working on various aspects of CH and are interested in exploring the potential of state of the art technology to enhance the CH visit experience. The result of the workshop is a multidisciplinary research agenda that will inform future research directions and hopefully, forge some research collaborations.},
 acmid = {2965001},
 address = {New York, NY, USA},
 author = {Ardissono, Liliana and Gena, Cristina and Kuflik, Tsvi},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965001},
 isbn = {978-1-4503-4413-5},
 keyword = {cultural heritage, mobile guides, mobile user interfaces, personalization, pervasive systems, tangible user interfaces},
 link = {http://doi.acm.org/10.1145/2957265.2965001},
 location = {Florence, Italy},
 numpages = {4},
 pages = {960--963},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Mobile Access to Cultural Heritage: Mobile-CH 2016},
 year = {2016}
}


@inproceedings{Hannula:2016:IOS:2957265.2965018,
 abstract = {In this paper, we present the IoT Owl, which is the result of exploration of the use of textile materials as part of a visualization system. After hectic workshop days, our development team had several ideas to be prototyped. The IoT Owl is a prototype of a system that, via lighting and movement, displays the presence information from a sensor at a remote location, based on scan of available Bluetooth devices. It can be completely operated via Internet. The purpose of the IoT Owl is to help the user to avoid a rush hour in a chosen public space and meet the right people at the right time for example during lunch hours. The IoT Owl can calculate the crowd amount but it can also recognize familiar devices. We present a concept design for the device and create an initial prototype with features and technology in it.},
 acmid = {2965018},
 address = {New York, NY, USA},
 author = {Hannula, Petri and Harjuniemi, Emmi and Napari, Emma},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965018},
 isbn = {978-1-4503-4413-5},
 keyword = {E-textile, IoT, bluetooth, connected environments},
 link = {http://doi.acm.org/10.1145/2957265.2965018},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1168--1172},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {IoT Owl: Soft Tangible User Interface for Detecting the Presence of People},
 year = {2016}
}


@inproceedings{Lucero:2016:CUM:2957265.2961830,
 abstract = {We demonstrate a prototype mobile application designed to support individually collecting personal sources of inspiration on mobile phones, and then the sharing and curating of these collected materials in a face-to-face situation.},
 acmid = {2961830},
 address = {New York, NY, USA},
 author = {Lucero, Andr{\'e}s and Porcheron, Martin and Fischer, Joel E.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961830},
 isbn = {978-1-4503-4413-5},
 keyword = {collocated interaction, handheld devices, ideation, interaction design, mood boards, smartphones},
 link = {http://doi.acm.org/10.1145/2957265.2961830},
 location = {Florence, Italy},
 numpages = {6},
 pages = {611--616},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Collaborative Use of Mobile Devices to Curate Sources of Inspiration},
 year = {2016}
}


@inproceedings{Lim:2016:WAR:2957265.2961857,
 abstract = {As mobile users often operate their devices with one enhancing one-handed interaction. In this paper, we present WhichHand, a system that 1) automatically detects which hand is holding a mobile phone and then 2) enhances user interfaces by adapting layouts to left-or right-handed use. For WhichHand, we utilize orientation sensors from a smartphone and a smartwatch. The relationship of sensor data between two mobile devices plays an important role in our recognition system. We evaluated WhichHand in a controlled study with 14 participants and conducted a user study with 10 participants to receive feedback. The accuracy of over 97% and early feedback on WhichHand provide useful insights on the design for one-handed interaction.},
 acmid = {2961857},
 address = {New York, NY, USA},
 author = {Lim, Hyunchul and An, Gwangseok and Cho, Yoonkyong and Lee, Kyogu and Suh, Bongwon},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961857},
 isbn = {978-1-4503-4413-5},
 keyword = {adaptive user interface, machine learning, one-handed interaction, sensors, smart phone, smart watch},
 link = {http://doi.acm.org/10.1145/2957265.2961857},
 location = {Florence, Italy},
 numpages = {7},
 pages = {675--681},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {WhichHand: Automatic Recognition of a Smartphone's Position in the Hand Using a Smartwatch},
 year = {2016}
}


@inproceedings{Chamberlain:2016:APM:2957265.2964195,
 abstract = {Audio-based content, location and mobile technologies can offer a multitude of interactional possibilities when combined in innovative and creative ways. It is important not to underestimate impact of the interplay between location, place and sound. Even if intangible and ephemeral, sounds impact upon the way in which we experience the built as well as the natural world. As technology offer us the opportunity to augment and access the world, mobile technologies offer us the opportunity to interact while moving though the world. They are technologies that can mediate, provide and locate experience in the world. Vision, and to some extent the tactile senses have been dominant modalities discussed in experiential terms within HCI. This workshop suggests that there is a need to better understand how sound can be used for shaping and augmenting the experiential qualities of places through mobile computing.},
 acmid = {2964195},
 address = {New York, NY, USA},
 author = {Chamberlain, Alan and B{\o}dker, Mads and Hazzard, Adrian and Benford, Steve},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2964195},
 isbn = {978-1-4503-4413-5},
 keyword = {HCI, audio, design, evaluation, location, mobile, music, place, semantic, software, sonic, sound},
 link = {http://doi.acm.org/10.1145/2957265.2964195},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1045--1048},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Audio in Place: Media, Mobility \&\#38; HCI - Creating Meaning in Space},
 year = {2016}
}


@inproceedings{Rantakari:2016:EDN:2957265.2965017,
 abstract = {In this workshop paper we present our exploration into using different natural materials and digital-fabricated patterns for mobile devices. We present different methods of altering natural materials through digital fabrication that alter their shape, flexibility and other characteristics. Using these methods, we believe that natural materials could be used more in mobile devices which could create more engaging user experiences.},
 acmid = {2965017},
 address = {New York, NY, USA},
 author = {Rantakari, Juho and Virtanen, Lasse and Yliniva, Jenni-Liisa},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965017},
 isbn = {978-1-4503-4413-5},
 keyword = {aesthetic, design, digital fabrication, mobile, natural material, pattern},
 link = {http://doi.acm.org/10.1145/2957265.2965017},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1146--1149},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Exploring Digital-fabricated Natural Materials and Patterns for Mobile Devices},
 year = {2016}
}


@inproceedings{Anagnostakis:2016:AMC:2957265.2963118,
 abstract = {This paper describes an affordable approach and prototype system that can enhance the accessibility of museum exhibits to visually impaired users. The approach supports the navigation in exhibition halls and the tactual exploration of exhibit replicas using touch-sensitive audio descriptions and touch gestures on a mobile device. The required technology includes 3D printed exhibits, attached touch sensors, Arduino boards, and a respective mobile app. A preliminary usability evaluation with ten users (blind, visually impaired and blindfolded) revealed a positive user experience with satisfactory and similar performance.},
 acmid = {2963118},
 address = {New York, NY, USA},
 author = {Anagnostakis, Giorgos and Antoniou, Michalis and Kardamitsi, Elena and Sachinidis, Thodoris and Koutsabasis, Panayiotis and Stavrakis, Modestos and Vosinakis, Spyros and Zissis, Dimitris},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963118},
 isbn = {978-1-4503-4413-5},
 keyword = {Arduino, audio guide, blind users, exhibit, gesture control, mobile device, museum, tactile exploration, visually impaired users},
 link = {http://doi.acm.org/10.1145/2957265.2963118},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1021--1025},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Accessible Museum Collections for the Visually Impaired: Combining Tactile Exploration, Audio Descriptions and Mobile Gestures},
 year = {2016}
}


@inproceedings{Ren:2016:FPE:2957265.2961841,
 abstract = {In this paper, we present an exploratory study of the prototype of FLOW, a portable exercise platform that aims at aiding sedentary behavior among elderly people by offering them a more active sitting experience in their daily routines. We designed FLOW based on three iterations, revolving technology implementation, interaction design, and user experience design. With our prototype, we conducted a pilot study with elderly people (n=5) in a care center in the Netherlands. We evaluated user experiences and interactions with the FLOW pillow through observation, interview, and questionnaire techniques from Flow Theory. By analyzing the obtained data from the pilot study, we discussed the opportunities of FLOW in motivating active sitting behaviors for elderly and implications for future works.},
 acmid = {2961841},
 address = {New York, NY, USA},
 author = {Ren, Xipei and Visser, Vincent and Lu, Yuan and Brankaert, Rens and Offermans, Serge and Nagtzaam, Hugo},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961841},
 isbn = {978-1-4503-4413-5},
 keyword = {active ageing, gerotechnology, interactive music, sitting exercise, user experience},
 link = {http://doi.acm.org/10.1145/2957265.2961841},
 location = {Florence, Italy},
 numpages = {8},
 pages = {706--713},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {FLOW Pillow: Exploring Sitting Experience Towards Active Ageing},
 year = {2016}
}


@inproceedings{Tsai:2016:TPI:2957265.2961859,
 abstract = {We propose an input device, ThumbRing, for items selection on head-mounted displays (HMDs) or smart glasses. ThumbRing is a ring with an inertial measurement unit (IMU) worn on the thumb to track the motion. By arranging an item to a finger segment, users touch and slide finger segments to select the items. To resist shake in mobile conditions such as walking, another IMU is attached to the back of the hand to compute relative angles between the hand and the thumb. Sliding and touching the segments with the thumb in the hand provide privacy, subtlety, natural haptic feedback and similar input area to smartphones. A pilot study is performed to obtain users' preference finger segments. We evaluate the performance of ThumbRing in different conditions and commitment approaches in a user study. The results show that accuracy are 92.3% and 89.7% in the sitting and walking conditions, respectively.},
 acmid = {2961859},
 address = {New York, NY, USA},
 author = {Tsai, Hsin-Ruey and Wu, Cheng-Yuan and Huang, Lee-Ting and Hung, Yi-Ping},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961859},
 isbn = {978-1-4503-4413-5},
 keyword = {finger ring, mobile, private input, subtle},
 link = {http://doi.acm.org/10.1145/2957265.2961859},
 location = {Florence, Italy},
 numpages = {8},
 pages = {791--798},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {ThumbRing: Private Interactions Using One-handed Thumb Motion Input on Finger Segments},
 year = {2016}
}


@inproceedings{Kuflik:2016:IGM:2957265.2961849,
 abstract = {The mobile scenario is an extremely challenging one when it comes to providing personalized, context aware services to mobile users. Users may dynamically and continuously enter and leave smart environments that may offer them relevant services. However, the environments may not know anything about the users and hence, providing personalized, context aware services becomes a challenge: users need to be identified, queried for their preferences and monitored before a service can be provided. The lack of standard, easy to use personalization infrastructure worsens the problem -- every service provider needs to build a proprietary, add-hoc user modeling component from scratch, thus to invest considerable effort in the task. This work builds on top of previous work on Info-Beads user modeling. Following past research, it suggests an Info-Beads approach for mobile user modeling for monitoring users and enabling standardization in building user models, reusing both components and data. The specific contribution is to allow monitoring mobile users, reasoning on their data and creating individual and group models from it. We demonstrate the ideas in the area of media content recommendations for groups and individual mobile users in smart environments, as a possible case study.},
 acmid = {2961849},
 address = {New York, NY, USA},
 author = {Kuflik, Tsvi and Variat, Yuri and Dim, Eyal and Mumblat, Yevgeni},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961849},
 isbn = {978-1-4503-4413-5},
 keyword = {Info-Bead, Info-Bead group modeling, Info-Bead user modeling, group modeling, mobile user modeling, user modeling},
 link = {http://doi.acm.org/10.1145/2957265.2961849},
 location = {Florence, Italy},
 numpages = {8},
 pages = {682--689},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Info-Bead Group Modeling in a Mobile Scenario},
 year = {2016}
}


@inproceedings{Tsai:2016:MSH:2957265.2961835,
 abstract = {Smartphone screen size becomes larger nowadays. However, it causes users hard to reach a target with the thumb when using the smartphone in one hand. We propose an interaction method MovingScreen to solve the hard-to-reach problem by making the smartphone screen view movable. Users move the screen view to make the target into their comfort zone, an area users comfortably performing touch input with the thumb. They then select a target easily. Using the proposed triggering gesture bezel-scroll, MovingScreen automatically calibrates the comfort zone. Bezel-scroll detects the comfort zone and provides different screen moving ratios for users in different poses to hold the smartphone. Users are even allowed to adjust screen moving speed by altering bezel-scroll length. We evaluate performance of MovingScreen and other methods in a user study. The results show that MovingScreen has similar selection time (1030.58ms) but lower error rate (4.57%) to the other methods.},
 acmid = {2961835},
 address = {New York, NY, USA},
 author = {Tsai, Hsin-Ruey and Huang, Da-Yuan and Hsieh, Chen-Hsin and Huang, Lee-Ting and Hung, Yi-Ping},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961835},
 isbn = {978-1-4503-4413-5},
 keyword = {hard-to-reach problem, mobile devices, one-handed interaction, thumb-based interaction, touch-screen},
 link = {http://doi.acm.org/10.1145/2957265.2961835},
 location = {Florence, Italy},
 numpages = {8},
 pages = {651--658},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {MovingScreen: Selecting Hard-to-reach Targets with Automatic Comfort Zone Calibration on Mobile Devices},
 year = {2016}
}


@inproceedings{Tsai:2016:TSA:2957265.2961860,
 abstract = {We propose a finger-worn touch device TouchRing to provide subtle and multi-touch input. TouchRing leverages printed electrodes and the capacitive sensing technique to detect touch input. It allows users to perform multi-touch gestures in one hand to increase input modality. TouchRing worn on the index finger allows multi-touch using the thumb and middle finger. Ten multi-touch gestures are designed in this paper. We also propose touch detection and gesture recognition approaches in TouchRing. Gesture Recognition accuracy is evaluated in the user study. Applications for TouchRing are also proposed to make controlling smart glasses more convenient.},
 acmid = {2961860},
 address = {New York, NY, USA},
 author = {Tsai, Hsin-Ruey and Hsiu, Min-Chieh and Hsiao, Jui-Chun and Huang, Lee-Ting and Chen, Mike and Hung, Yi-Ping},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961860},
 isbn = {978-1-4503-4413-5},
 keyword = {always-available, capacitive touch, gesture recognition, multi-touch, printed electronics, subtle, touch input, wearable device},
 link = {http://doi.acm.org/10.1145/2957265.2961860},
 location = {Florence, Italy},
 numpages = {8},
 pages = {891--898},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {TouchRing: Subtle and Always-available Input Using a Multi-touch Ring},
 year = {2016}
}


@inproceedings{Martin-Albo:2016:GBS:2957265.2961833,
 abstract = {Stroke gestures are becoming increasingly important with the ongoing success of touchscreen-capable devices. However, training a high-quality gesture recognizer requires providing a large number of examples to enable good performance on unseen, future data. Furthermore, recruiting participants, data collection and labeling, etc. necessary for achieving this goal are usually time-consuming and expensive. In response to this need, we introduce G3, a mobile-first web application for bootstrapping unistroke, multistroke, or multitouch gestures. The user only has to provide a gesture example once, and G3 will create a kinematic model of that gesture. Then, by introducing local and global perturbations to the model parameters, G3 will generate any number of synthetic human-like samples. In addition, the user can get a gesture recognizer together with the synthesized data. As such, the outcome of G3 can be directly incorporated into production-ready applications.},
 acmid = {2961833},
 address = {New York, NY, USA},
 author = {Mart\'{\i}n-Albo, Daniel and Leiva, Luis A.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961833},
 isbn = {978-1-4503-4413-5},
 keyword = {bootstrapping, gesture recognition, gesture synthesis, kinematics, marks, multistrokes, multitouch, rapid prototyping, strokes, symbols, unistrokes, user interfaces},
 link = {http://doi.acm.org/10.1145/2957265.2961833},
 location = {Florence, Italy},
 numpages = {5},
 pages = {633--637},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {G3: Bootstrapping Stroke Gestures Design with Synthetic Samples and Built-in Recognizers},
 year = {2016}
}


@inproceedings{Sankar:2016:ISM:2957265.2963109,
 abstract = {Semantic 3D models of indoor scenes enable compelling interior design applications such as remodeling, refurnishing and rearrangement of furniture. However, creating these models is still a challenging task. Most existing approaches are designed to work ex-situ or out of context, and rely on the modeler's memory, photographs or measurements from the scene. We propose a novel in-situ, mobile capture system that leverages quick and easy semantic input from the user and offloads tedious reconstruction and modeling tasks to the computer. In this way, our system combines the advantages of automatic and manual CAD based methods to significantly reduce modeling time and effort. Our approach runs on commodity mobile devices and can potentially scale to a much larger audience of casual mobile phone users.},
 acmid = {2963109},
 address = {New York, NY, USA},
 author = {Sankar, Aditya},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963109},
 isbn = {978-1-4503-4413-5},
 keyword = {algorithms, design, human factors, interactive 3D modeling, mobile augmented reality, sketching},
 link = {http://doi.acm.org/10.1145/2957265.2963109},
 location = {Florence, Italy},
 numpages = {2},
 pages = {909--910},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {In-situ Semantic 3D Modeling},
 year = {2016}
}


@inproceedings{Kaul:2016:WHT:2957265.2965022,
 abstract = {Current generation virtual reality (VR) and augmented reality (AR) head-mounted displays (HMDs) usually include no or only a single vibration motor for haptic feedback and do not use it for guidance. In a previous work, we presented HapticHead, a potentially mobile system utilizing vibration motors distributed in three concentric ellipses around the head to give intuitive haptic guidance hints and to increase immersion for VR and AR applications. The purpose of this paper is to explore potential application scenarios and aesthetic possibilities of the proposed concept in order to create an active discussion amongst workshop participants.},
 acmid = {2965022},
 address = {New York, NY, USA},
 author = {Kaul, Oliver Beren and Rohs, Michael},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965022},
 isbn = {978-1-4503-4413-5},
 keyword = {assistive technology, augmented reality, guidance, haptic feedback, immersion, vibrotactile, virtual reality},
 link = {http://doi.acm.org/10.1145/2957265.2965022},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1163--1167},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Wearable Head-mounted 3D Tactile Display Application Scenarios},
 year = {2016}
}


@inproceedings{Wolf:2016:MDR:2957265.2961865,
 abstract = {The rise of smart rings enables for ubiquitous control of computers that are wearable or mobile. We developed a ring interface using a 9 DOF IMU for detecting microgestures that can be executed while performing another task that involve hands, e.g. riding a bicycle. For the gesture classification we implemented 4 classifiers that run on the Android operating system without the need of clutch events. In a user study, we compared the success of 4 classifiers in a cycling scenario. We found that Random Forest (RF) works better for microgesture detection on Android than Dynamic Time Warping (DTW), K-Nearest-Neighbor (KNN), and than a Threshold (TH)-based approach as it has the best detection rate while it runs in real-time on Android. This work shell encourages other researchers to develop further mobile applications for using remote microgesture control in encumbered contexts.},
 acmid = {2961865},
 address = {New York, NY, USA},
 author = {Wolf, Katrin and Mayer, Sven and Meyer, Stephan},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961865},
 isbn = {978-1-4503-4413-5},
 keyword = {bio-mechanic, encumbered contexts, ergonomics, gesture, microgesture},
 link = {http://doi.acm.org/10.1145/2957265.2961865},
 location = {Florence, Italy},
 numpages = {8},
 pages = {783--790},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Microgesture Detection for Remote Interaction with Mobile Devices},
 year = {2016}
}


@inproceedings{Fitzpatrick:2016:DTF:2957265.2963112,
 abstract = {More people are turning to apps for connecting with others nearby for a range of relational goals (i.e. dates, sex). These apps themselves constrain profiles in certain ways, while also supplementing them with additional system-generated cues. The proposed experiments are designed to investigate three such popular cues (distance, time, and number of friends) and how they affect the impression formation process in this context of varied relational goals.},
 acmid = {2963112},
 address = {New York, NY, USA},
 author = {Fitzpatrick, Colin},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2963112},
 isbn = {978-1-4503-4413-5},
 keyword = {attraction, impression formation, location-based social apps, system-generated cues},
 link = {http://doi.acm.org/10.1145/2957265.2963112},
 location = {Florence, Italy},
 numpages = {2},
 pages = {903--904},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Distance, Time, and Friends: System-generated Cues and Impression Formation in Mediated Spaces},
 year = {2016}
}


@inproceedings{Tibrewal:2016:MCM:2957265.2961831,
 abstract = {We demonstrate a crowd-powered model for the early diagnosis of stroke using a mobile device. The simple approach consists of monitoring the subject's health in three simple steps including the smile test for facial weakness, raising hands test for arm weakness and speech test for slurring of speech. Our demonstrated system shows a performance accuracy of 87.5% over a total number of 40 test cases.},
 acmid = {2961831},
 address = {New York, NY, USA},
 author = {Tibrewal, Richa and Singh, Ankita and Bhattacharyya, Malay},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961831},
 isbn = {978-1-4503-4413-5},
 keyword = {crowdsourcing, human computer interaction, medical diagnosis, sensors},
 link = {http://doi.acm.org/10.1145/2957265.2961831},
 location = {Florence, Italy},
 numpages = {6},
 pages = {645--650},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {mSTROKE: A Crowd-powered Mobility Towards Stroke Recognition},
 year = {2016}
}


@inproceedings{Oppermann:2016:MCV:2957265.2961852,
 abstract = {The advent of Building Information Modelling (BIM) provides geometry data that can be easily used for visualisations. We present six demonstrators made from the same data using similar workflows. They cover different categories of mobile devices, ranging from head-mounted displays to smartphones and tablets with inside-out positional tracking. They showcase cross-media visualisations depending on the device capabilities, which vary from a sophisticated car-based AR-setup, over wired and wireless VR, to see-through AR on smart glasses, and video-based AR on tablets.},
 acmid = {2961852},
 address = {New York, NY, USA},
 author = {Oppermann, Leif and Shekow, Marius and Bicer, Deniz},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961852},
 isbn = {978-1-4503-4413-5},
 keyword = {3D, CAD data, architecture, augmented reality, building information modelling, construction, mixed reality, mobile, virtual reality, visualisations},
 link = {http://doi.acm.org/10.1145/2957265.2961852},
 location = {Florence, Italy},
 numpages = {8},
 pages = {823--830},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Mobile Cross-media Visualisations Made from Building Information Modelling Data},
 year = {2016}
}


@inproceedings{Wang:2016:FDM:2957265.2965006,
 abstract = {Personalized and contextual interventions are promising techniques for mobile persuasive technologies in mobile health. In this paper, we propose the "fingerprints" technique to analyze the users' daily behavior patterns to find the meaningful moments to better support mobile persuasive technologies, especially mobile health interventions. We assume that for many persons, their behaviors have patterns and can be detected through the sensor data from smartphones. We develop a three-step interactive machine learning workflow to describe the concept and approach of the "fingerprints" technique. By this we aim to implement a practical and light-weight mobile intervention system without burdening the users with manual logging. In our feasibility study, we show results that provide first insights into the design of the "fingerprints" technique.},
 acmid = {2965006},
 address = {New York, NY, USA},
 author = {Wang, Yunlong and Duan, Le and Butscher, Simon and Mueller, Jens and Reiterer, Harald},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965006},
 isbn = {978-1-4503-4413-5},
 keyword = {interactive machine learning, mobile intervention, mobile persuasive technologies},
 link = {http://doi.acm.org/10.1145/2957265.2965006},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1085--1088},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Fingerprints: Detecting Meaningful Moments for Mobile Health Intervention},
 year = {2016}
}


@inproceedings{Al-Naser:2016:KTE:2957265.2965013,
 abstract = {Minimally invasive catheter-mediated (MIC) interventions represent a key approach to treat patients with a wide range of cardiovascular diseases; the operators' performance rely on his or her ability to read the dynamic (cine, fluoroscopy) and static x-rays images rapidly, and accurately. Here, we demonstrate the feasibility of expertise transfer employing a low cost eye tracking system for experts gaze visualization in real-life (MIC) interventional scenario. As the video quality from head-mounted eye tracker is not sufficient for data analysis, due to head-movement, dark shades, blurring, etc., therefore we have developed an automatic method for mapping the recorded gaze from the eye-tracker video to high quality x-ray video, allowing for tracking of the complete visual perception of individual operators throughout the life performance of individual interventions based on high resolution image recordings. The high quality gaze video from an expert doctors provide an important educational resource to teach novices how to read the dynamic x-ray images.},
 acmid = {2965013},
 address = {New York, NY, USA},
 author = {Al-Naser, Mohammad and Lanzer, Peter and Dengel, Andreas and Bukhari, Syed Saqib and Chanijani, Seyyed Saleh Mozaffari},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965013},
 isbn = {978-1-4503-4413-5},
 keyword = {cognitive learning, detection, eye-tracking, gaze mapping, minimally invasive cardiovascular interventions},
 link = {http://doi.acm.org/10.1145/2957265.2965013},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1033--1036},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Knowledge Transfer from Experts to Novices in Minimally Invasive Catheter-mediated (MIC) Interventions, Eye-tracking Study},
 year = {2016}
}


@inproceedings{Kit:2016:CME:2957265.2965014,
 abstract = {Naturalistic eye movement behavior has been measured in a variety of scenarios [15] and eye movement patterns appear indicative of task demands [16]. However, systematic task classification of eye movement data is a relatively recent development [1,3,7]. Additionally, prior work has focused on classification of eye movements while viewing 2D screen based imagery. In the current study, eye movements from eight participants were recorded with a mobile eye tracker. Participants performed five everyday tasks: Making a sandwich, transcribing a document, walking in an office and a city street, and playing catch with a flying disc [14]. Using only saccadic direction and amplitude time series data, we trained a hidden Markov model for each task and classified unlabeled data by calculating the probability that each model could generate the observed sequence. We present accuracy and time to recognize results, demonstrating better than chance performance.},
 acmid = {2965014},
 address = {New York, NY, USA},
 author = {Kit, Dmitry and Sullivan, Brian},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965014},
 isbn = {978-1-4503-4413-5},
 keyword = {machine learning, mobile eye tracking, natural tasks, task classification},
 link = {http://doi.acm.org/10.1145/2957265.2965014},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1037--1040},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Classifying Mobile Eye Tracking Data with Hidden Markov Models},
 year = {2016}
}


@inproceedings{Chanijani:2016:SRC:2957265.2965012,
 abstract = {In this paper, we have conducted an eye tracking experiment by employing an inexpensive, lightweight, and portable eye tracker paired with a tablet. Students were instructed to solve the physics problems by presenting them three coherent representations about a phenomenon: Vectorial representations, data tables and diagrams. The effectiveness of each representation was assessed for three levels of student expertise (experts, intermediates and novices) using eye-tracking gaze data. The results show that students of different skill level (a) prefer different representations for problem-solving, (b) switch between representations with different frequencies, and (c) can be distinguished by the density of representation use. The obtained results confirm earlier findings of physics education research quantitatively which were initially obtained by student interviews and observational studies.},
 acmid = {2965012},
 address = {New York, NY, USA},
 author = {Chanijani, Seyyed Saleh Mozaffari and Klein, Pascal and Al-Naser, Mohammad and Bukhari, Syed Saqib and Kuhn, Jochen and Dengel, Andreas},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965012},
 isbn = {978-1-4503-4413-5},
 keyword = {education, mobile remote eye tracker, physics, representational competence},
 link = {http://doi.acm.org/10.1145/2957265.2965012},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1029--1032},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Study on Representational Competence in Physics Using Mobile Eye Tracking Systems},
 year = {2016}
}


@proceedings{Paterno:2016:2935334,
 abstract = {MobileHCI brings together people from diverse backgrounds and areas of expertise to provide a truly multidisciplinary forum. Academics, hardware and software developers, designers and practitioners alike can discuss challenges encountered on different frontiers of mobility, as well as potential solutions that will advance the field. The conference covers both academic and industry research, ranging from fundamental interaction models and techniques to social and cultural aspects of everyday life with mobile devices and services.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4408-1},
 location = {Florence, Italy},
 publisher = {ACM},
 title = {MobileHCI '16: Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 year = {2016}
}


@inproceedings{Li:2016:MVD:2957265.2961826,
 abstract = {Modern mobile phones can capture and process high quality videos, which makes them a very popular tool to create and watch video content. However when watching a video together with a group, it is not convenient to watch on one mobile display due to its small form factor. One idea is to combine multiple mobile displays together to create a larger interactive surface for sharing visual content. However so far a practical framework supporting synchronous video playback on multiple mobile displays is still missing. We present the design of "MobileVideoTiles", a mobile application that enables users to watch local or online videos on a big virtual screen composed of multiple mobile displays. We focus on improving video quality and usability of the tiled virtual screen. The major technical contributions include: mobile peer-to-peer video streaming, playback synchronization, and accessibility of video resources. The prototype application has got several thousand downloads since release and received very positive feedback from users.},
 acmid = {2961826},
 address = {New York, NY, USA},
 author = {Li, Ming and Scharf, Kaspar Maximilian and Kobbelt, Leif},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961826},
 isbn = {978-1-4503-4413-5},
 keyword = {displays, multiple mobile, synchronization, tiled, user interface, video streaming},
 link = {http://doi.acm.org/10.1145/2957265.2961826},
 location = {Florence, Italy},
 numpages = {6},
 pages = {621--626},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {MobileVideoTiles: Video Display on Multiple Mobile Devices},
 year = {2016}
}


@inproceedings{Tigwell:2016:OTY:2957265.2961844,
 abstract = {Emoji provide a way to express nonverbal conversational cues in computer-mediated communication. However, people need to share the same understanding of what each emoji symbolises, otherwise communication can breakdown. We surveyed 436 people about their use of emoji and ran an interactive study using a two-dimensional emotion space to investigate (1) the variation in people's interpretation of emoji and (2) their interpretation of corresponding Android and iOS emoji. Our results show variations between people's ratings within and across platforms. We outline our solution to reduce misunderstandings that arise from different interpretations of emoji.},
 acmid = {2961844},
 address = {New York, NY, USA},
 author = {Tigwell, Garreth W. and Flatla, David R.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961844},
 isbn = {978-1-4503-4413-5},
 keyword = {computer-mediated communication, emoji, emotion},
 link = {http://doi.acm.org/10.1145/2957265.2961844},
 location = {Florence, Italy},
 numpages = {8},
 pages = {859--866},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Oh That's What You Meant!: Reducing Emoji Misunderstanding},
 year = {2016}
}


@inproceedings{Serna:2016:FCD:2957265.2962656,
 abstract = {Mobile devices offer great opportunities in the field of collaborative learning for providing digital information while still supporting social interactions between group members. We designed and tested an orienteering mobile learning game to better understand how device use shaped collaboration in highly mobile conditions. The study involved four groups of three students all equipped with tablets. We focused our analysis on the relationship between participants' arrangements (F-formations), their device usage and coordination mechanisms (i.e. awareness, regulation, information sharing, and discussion). Our results emphasize the importance of considering the transitions between arrangements. From these observations we derive recommendations for the design of relevant interactions techniques for mobile collaborative activities.},
 acmid = {2962656},
 address = {New York, NY, USA},
 author = {Serna, Audrey and Tong, Lili and Tabard, Aur{\'e}lien and Pageaud, Simon and George, S{\'e}bastien},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962656},
 isbn = {978-1-4503-4413-5},
 keyword = {F-formation, collaboration, collaboration dynamics, coordination, group regulation, mobile learning, ubiquitous computing},
 link = {http://doi.acm.org/10.1145/2957265.2962656},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1138--1141},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {F-formations and Collaboration Dynamics Study for Designing Mobile Collocation},
 year = {2016}
}


@proceedings{Paterno:2016:2957265,
 abstract = {MobileHCI brings together people from diverse backgrounds and areas of expertise to provide a truly multidisciplinary forum. Academics, hardware and software developers, designers and practitioners alike can discuss challenges encountered on different frontiers of mobility, as well as potential solutions that will advance the field. The conference covers both academic and industry research, ranging from fundamental interaction models and techniques to social and cultural aspects of everyday life with mobile technologies.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-4413-5},
 location = {Florence, Italy},
 publisher = {ACM},
 title = {MobileHCI '16: Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 year = {2016}
}


@inproceedings{Araki:2016:OPE:2957265.2961829,
 abstract = {In this paper, we propose On-mouse projector, an interface that combines a mouse and a mobile projector. This system satisfies both portability and large information space and enables stable operation. The mobile projector is placed on the mouse and projects images on a surface in front of the mouse. The projected image presents a part of large information space and users can change the area to see by moving the mouse. The system is assumed to be used on a flat surface such as a desk and users can stably perform the same operation as the ordinary mouse operation. We created a prototype in which a projector is fixed above a mouse using acrylic plates. This prototype works in a standalone configuration by using a stick PC and realizes various operations such as object selection, object moving and image zooming.},
 acmid = {2961829},
 address = {New York, NY, USA},
 author = {Araki, Tomohiro and Komuro, Takashi},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961829},
 isbn = {978-1-4503-4413-5},
 keyword = {information space, mobile projector, mouse input, peephole interaction},
 link = {http://doi.acm.org/10.1145/2957265.2961829},
 location = {Florence, Italy},
 numpages = {6},
 pages = {605--610},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {On-mouse Projector: Extended Workspace Using a Mouse with a Projector},
 year = {2016}
}


@inproceedings{Kwon:2016:MRL:2957265.2961850,
 abstract = {Webtoon is a popular content in South Korea that has more fun techniques by using both IT and cartoon elements. However, the rating system for webtoon is still unsatisfying which have limitations on comprehending users' unconscious behavior. In this paper, we explore the value of using users' laughter reaction data for humor webtoons. Users' laughter reaction data and the rating scores were extracted simultaneously in user observation. As a result, the laughter reaction significantly correlates with the manual rating score. Also, we elicited each participants' flow of laughter which enabled to understand their laughter behavior and scenes that were attractive. With those data, ideation was conducted to generate ideas on how laughter reaction data can be used in new ways for humor webtoons. Thus, we proposed the potential values that suggest viable solutions of capturing laughter reactions for humor webtoons.},
 acmid = {2961850},
 address = {New York, NY, USA},
 author = {Kwon, Soyoung and Lee, Kun-Pyo},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961850},
 isbn = {978-1-4503-4413-5},
 keyword = {content rating, reaction sensing, smile and laughter, user study, web cartoon},
 link = {http://doi.acm.org/10.1145/2957265.2961850},
 location = {Florence, Italy},
 numpages = {8},
 pages = {867--874},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {What Makes Readers Laugh?: Value of Sensing Laughter for Humor Webtoon},
 year = {2016}
}


@inproceedings{Baretta:2016:WDA:2957265.2965011,
 abstract = {Physical activity (PA) is considered one of the most important factors for the prevention and management of non-communicable diseases (NCDs). Mobile technologies offer several opportunities for supporting PA, especially if combined with psychological aspects, model-based reasoning systems and personalized human computer interaction. This still on-going research aims at developing a scalable framework that targets PA promotion among both clinical and non-clinical population, exploiting Bayesian Networks and Expert Systems to characterize and predict qualitative variables like self-efficacy. The expected outcomes are the collection and management of real-time behavioral and psychological data to define a personalized strategy for increasing PA.},
 acmid = {2965011},
 address = {New York, NY, USA},
 author = {Baretta, Dario and Sartori, Fabio and Greco, Andrea and Melen, Riccardo and Stella, Fabio and Bollini, Letizia and D'addario, Marco and Steca, Patrizia},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965011},
 isbn = {978-1-4503-4413-5},
 keyword = {bayesian networks, behavior change techniques, expert systems, self-efficacy, wearable devices},
 link = {http://doi.acm.org/10.1145/2957265.2965011},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1105--1108},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Wearable Devices and AI Techniques Integration to Promote Physical Activity},
 year = {2016}
}


@inproceedings{Shibata:2016:RTA:2957265.2961851,
 abstract = {This paper proposes a new user interface technique to specify sending data across digital devices. In this approach, users specify what to send from what device to what device by tapping them rhythmically. This technique is easy to operate, low implementation cost, applicable to a wide range of devices, and scalable by adding numerous rhythmical tap sequences. We confirmed the feasibility of this approach through preliminary experiments.},
 acmid = {2961851},
 address = {New York, NY, USA},
 author = {Shibata, Hirohito and Ichino, Junko and Hashiyama, Tomonori and Tano, Shun'ichi},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961851},
 isbn = {978-1-4503-4413-5},
 keyword = {ad-hoc network connections, cross-device interaction, rhythmical taps},
 link = {http://doi.acm.org/10.1145/2957265.2961851},
 location = {Florence, Italy},
 numpages = {8},
 pages = {815--822},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Rhythmical Tap Approach for Sending Data Across Devices},
 year = {2016}
}


@inproceedings{Ardito:2016:SPG:2957265.2962650,
 abstract = {Information and communication technologies have a great potential to enhance personal experience in cultural heritage sites. Our research in the Cultural Heritage (CH) aims to foster a wider appreciation of archaeology by offering tools able to engage the general public and to increase awareness of the importance of CH. In this paper we discuss how a generic mashup platform can be used to support the work of professional guides of CH sites, in order to support them creating personalized and engaging visit experiences.},
 acmid = {2962650},
 address = {New York, NY, USA},
 author = {Ardito, Carmelo and Costabile, Maria Francesca and Desolda, Giuseppe and Matera, Maristella},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962650},
 isbn = {978-1-4503-4413-5},
 keyword = {cultural heritage, mashups, web composition environments},
 link = {http://doi.acm.org/10.1145/2957265.2962650},
 location = {Florence, Italy},
 numpages = {6},
 pages = {1010--1015},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Supporting Professional Guides to Create Personalized Visit Experiences},
 year = {2016}
}


@inproceedings{Jain:2016:ICM:2957265.2961862,
 abstract = {With influx of new devices and applications over the past few years, computer mediated communication has developed as an alternate to face-to-face communication. Through our study we attempt to understand how individuals communicate in mediated settings in emotion-laden situations. We explore their preferred medium of communication in different situations along with analysis of the content of communication. Spatial arrays, lexical surrogates, vocal spellings and grammatical markers were used as strategies by individuals for communicating non-verbal cues in text based communication. We also look at how messages sent on IMs or posts on social networks are interpreted by readers in terms of the emotional state of the sender. We found that while valence of the sender gets easily and accurately communicated, arousal is misinterpreted in most situations. In this paper, we present findings from our study which can be valuable for technology companies looking to better the current communication experience across different media.},
 acmid = {2961862},
 address = {New York, NY, USA},
 author = {Jain, Minal and Seshagiri, Sarita and Chopra, Simran},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961862},
 isbn = {978-1-4503-4413-5},
 keyword = {IM, communication, emotion, social networks},
 link = {http://doi.acm.org/10.1145/2957265.2961862},
 location = {Florence, Italy},
 numpages = {8},
 pages = {767--774},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {How Do I Communicate My Emotions on SNS and IMs?},
 year = {2016}
}


@inproceedings{McGookin:2016:TUL:2957265.2964196,
 abstract = {Through the discussion of one completed and one on-going study, we outline how location-based audio interaction must move beyond the constraints of solely manually curated content, to consider how the influx of location-based social and cultural media databases can be used to provide more ubiquitous interaction about places. We outline our experience of these through a completed study, identifying challenges and opportunities for research, before discussing our current work on a cultural heritage app to support some of these challenges.},
 acmid = {2964196},
 address = {New York, NY, USA},
 author = {McGookin, David},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2964196},
 isbn = {978-1-4503-4413-5},
 keyword = {Twitter, cultural heritage, location-based media},
 link = {http://doi.acm.org/10.1145/2957265.2964196},
 location = {Florence, Italy},
 numpages = {5},
 pages = {1064--1068},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Towards Ubiquitous Location-based Audio: Challenges and Future Directions},
 year = {2016}
}


@inproceedings{Rigby:2016:WMN:2957265.2961843,
 abstract = {Film and television content is moving out of the living room and onto mobile devices - viewers are now watching when and where it suits them, on devices of differing sizes. This freedom is convenient, but could lead to differing experiences across devices. Larger screens are often believed to be favourable, e.g. to watch films or sporting events. This is partially supported in the literature, which shows that larger screens lead to greater presence and more intense physiological responses. However, a more broadly-defined measure of experience, such as that of immersion from computer games research, has not been studied. In this study, 19 participants watched content on three different screens and reported their immersion level via questionnaire. Results showed that the 4.5-inch phone screen elicited lower immersion scores when compared to the 13-inch laptop and 30-inch monitor, but there was no difference when comparing the two larger screens. This suggests that very small screens lead to reduced immersion, but after a certain size the effect is less pronounced.},
 acmid = {2961843},
 address = {New York, NY, USA},
 author = {Rigby, Jacob M. and Brumby, Duncan P. and Cox, Anna L. and Gould, Sandy J. J.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961843},
 isbn = {978-1-4503-4413-5},
 keyword = {experience, film, immersion, mobile devices, on-demand video, screen size, television},
 link = {http://doi.acm.org/10.1145/2957265.2961843},
 location = {Florence, Italy},
 numpages = {8},
 pages = {714--721},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Watching Movies on Netflix: Investigating the Effect of Screen Size on Viewer Immersion},
 year = {2016}
}


@inproceedings{Gai:2016:UNG:2957265.2961824,
 abstract = {Most of current virtual/augmented reality games focus on players' immersive experience. The creative process of game design is usually not accessible to the player. In this paper, we present a new game genre that combines player initiated game design with game play. This new genre enables users to design games in a physical space and then play in a rendered virtual space. To this aim we illustrate our conceptual design of a virtual reality game, called UbiMaze, which promotes player participation, and provides a rich, interactive and engaging experience.},
 acmid = {2961824},
 address = {New York, NY, USA},
 author = {Gai, Wei and Yang, Chenglei and Bian, Yulong and Dong, Mingda and Liu, Juan and Dong, Yifan and Niu, Chengjie and Lin, Cheng and Meng, Xiangxu and Shen, Chia},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961824},
 isbn = {978-1-4503-4413-5},
 keyword = {head-mounted displays, mobile 3D, natural interaction, virtual reality},
 link = {http://doi.acm.org/10.1145/2957265.2961824},
 location = {Florence, Italy},
 numpages = {3},
 pages = {591--593},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {UbiMaze: A New Genre of Virtual Reality Game Based on Mobile Devices},
 year = {2016}
}


@inproceedings{Eardley:2016:IHI:2957265.2961840,
 abstract = {In this paper we investigate the physical interaction between the hand and three types of mobile device interaction: touchscreen, physical keyboard and stylus. Through a controlled study using video observational analysis, we observed firstly, how the participants gripped the three devices and how these grips were device dependent. Secondly we looked closely at these grips to uncover how participants performed what we call micro-movements to facilitate a greater range of interaction, e.g. reaching across the keyboard. The results extend current knowledge by comparing three handheld device input methods and observing the movements, which the hand makes in five grips. The paper concludes by describing the development of a conceptual design, proposed as a provocation for the opening of dialogue on how we conceive hand usage and how it might be optimized when designed for mobile devices.},
 acmid = {2961840},
 address = {New York, NY, USA},
 author = {Eardley, Rachel and Gill, Steve and Roudaut, Anne and Thompson, Stephen and Hare, Joanna},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961840},
 isbn = {978-1-4503-4413-5},
 keyword = {design, grasp, hand, interaction, interaction design, mobile device, product design},
 link = {http://doi.acm.org/10.1145/2957265.2961840},
 location = {Florence, Italy},
 numpages = {8},
 pages = {698--705},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Investigating How the Hand Interacts with Different Mobile Phones},
 year = {2016}
}


@inproceedings{Zechmann:2016:TSS:2957265.2965010,
 abstract = {People suffering from Chronic Obstructive Pulmonary Disease (COPD) have to deal with the disease throughout their lifetime and there is no getting around without a successful self-management process. However, a poor adherence to COPD treatment is common in COPD patients and responsible for increased hospitalizations, mortality, reduced quality of life and loss of productivity. This paper envisions a novel, technology assisted solution and describes the steps needed to cover the full process of self-management. Thereby, it highlights general requirements of a technology assisted self-management device for chronic diseases and depicts a solution especially for people living with COPD.},
 acmid = {2965010},
 address = {New York, NY, USA},
 author = {Zechmann, Beatrix and Bobeth, Jan and Tscheligi, Manfred},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965010},
 isbn = {978-1-4503-4413-5},
 keyword = {COPD, adherence, awareness, chronic obstructive pulmonary disease, empowerment, lifestyle change, self-management, treatment},
 link = {http://doi.acm.org/10.1145/2957265.2965010},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1101--1104},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Towards Successful Self-management and Empowerment for COPD Patients},
 year = {2016}
}


@inproceedings{Roinesalo:2016:CIV:2957265.2961832,
 abstract = {In this demo, we present a concept where garment-integrated visual markers are used for self-expression. We present a wearable design, where clothing design style integrates with the visual design of AR markers, which are read with a mobile phone or tablet. The garment functions as a platform for self-expression, and the demo illustrates how both the AR content and the placement of the markers can play a role in the self-expression.},
 acmid = {2961832},
 address = {New York, NY, USA},
 author = {Roinesalo, Paula and Rantakari, Juho and Virtanen, Lasse and H\"{a}kkil\"{a}, Jonna},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2961832},
 isbn = {978-1-4503-4413-5},
 keyword = {clothing design, mobile AR, outfit centric design, self-expression tools, visual markers, wearable computing},
 link = {http://doi.acm.org/10.1145/2957265.2961832},
 location = {Florence, Italy},
 numpages = {4},
 pages = {617--620},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Clothes Integrated Visual Markers As Self-expression Tool},
 year = {2016}
}


@inproceedings{Mokatren:2016:NIB:2957265.2962647,
 abstract = {Eye tracking can be an easy way for identifying users' focus of attention and interests. This promise triggered large and continues research and technology development efforts with remarkable results. In this paper we aim at developing a novel technique for location awareness, interest detection and focus of attention using computer vision techniques and mobile eye-tracking technology. Our focus will be on museum visit and optimizing the positioning procedure by exploiting the visit style to choose the appropriate algorithm.},
 acmid = {2962647},
 address = {New York, NY, USA},
 author = {Mokatren, Moayad and Kuflik, Tsvi and Shimshoni, Ilan},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2962647},
 isbn = {978-1-4503-4413-5},
 keyword = {context aware service, mobile eye tracking, mobile guide, personalized information, smart environment},
 link = {http://doi.acm.org/10.1145/2957265.2962647},
 location = {Florence, Italy},
 numpages = {8},
 pages = {984--991},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {A Novel Image Based Positioning Technique Using Mobile Eye Tracker for a Museum Visit},
 year = {2016}
}


@inproceedings{Kultsova:2016:AMA:2957265.2965003,
 abstract = {This paper describes the mobile application 'Travel and Communication Assistant' which supports the mobility and communication of people with Intellectual and Development Disabilities (IDD). This application provides the possibility to people with IDD to independently perform a known route (for example a route from home to the day care center, from home to the baker's, etc.) under the remote supervision of their caregivers and to communicate with them using text, voice and pictogram messages.},
 acmid = {2965003},
 address = {New York, NY, USA},
 author = {Kultsova, Marina and Romanenko, Roman and Zhukova, Irina and Usov, Andrey and Penskoy, Nikita and Potapova, Tatiana},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965003},
 isbn = {978-1-4503-4413-5},
 keyword = {adaptive user interface, assistive technologies, intellectual and developmental disabilities, mobile applications, special needs assessment},
 link = {http://doi.acm.org/10.1145/2957265.2965003},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1073--1076},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Assistive Mobile Application for Support of Mobility and Communication of People with IDD},
 year = {2016}
}


@inproceedings{Rothkopf:2016:MSG:2957265.2965015,
 abstract = {Eye movements in extended sequential behavior are known to reflect task demands much more than low-level feature saliency. However, the more naturalistic the task is the more difficult it becomes to establish what cognitive processes a particular task elicits moment by moment. Here we ask the question, which sequential model is required to capture gaze sequences so that the ongoing task can be inferred reliably. Specifically, we consider eye movements of human subjects navigating a walkway while avoiding obstacles and approaching targets in a virtual environment. We show that Hidden-Markov Models, which have been used extensively in modeling human sequential behavior, can be augmented with few state variables describing the egocentric position of subjects relative to objects in the environment to dramatically increase successful classification of the ongoing task and to generate gaze sequences, that are very close to those observed in human subjects.},
 acmid = {2965015},
 address = {New York, NY, USA},
 author = {Rothkopf, Constantin A.},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
 doi = {10.1145/2957265.2965015},
 isbn = {978-1-4503-4413-5},
 keyword = {hidden Markov models, inferring human actions, sequential gaze models},
 link = {http://doi.acm.org/10.1145/2957265.2965015},
 location = {Florence, Italy},
 numpages = {4},
 pages = {1041--1044},
 publisher = {ACM},
 series = {MobileHCI '16},
 title = {Minimal Sequential Gaze Models for Inferring Walkers' Tasks},
 year = {2016}
}


