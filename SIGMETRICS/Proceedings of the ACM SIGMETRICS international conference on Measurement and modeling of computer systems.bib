@inproceedings{Park:2010:CCF:1811039.1811089,
 abstract = {The flash translation layer (FTL) is a software/hardware in terface inside NAND flash memory. Since FTL has a critical impact on the performance of NAND flash-based devices, a variety of FTL schemes have been proposed to improve their performance. In this paper, we propose a novel hybrid FTL scheme named Convertible Flash Translation Layer (CFTL). Unlike other existing FTLs using static address mapping schemes, CFTL is adaptive to data access patterns so that it can dynamically switch its mapping scheme to either a read-optimized or a write-optimized mapping scheme. In addition to this convertible scheme, we propose an efficient caching strategy to further improve the CFTL performance with only a simple hint. Consequently, both the convertible feature and the caching strategy empower CFTL to achieve good read performance as well as good write performance.},
 acmid = {1811089},
 address = {New York, NY, USA},
 author = {Park, Dongchul and Debnath, Biplob and Du, David},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811089},
 isbn = {978-1-4503-0038-4},
 keyword = {CFTL, FTL, flash memory, flash translation layer},
 link = {http://doi.acm.org/10.1145/1811039.1811089},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {365--366},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {CFTL: A Convertible Flash Translation Layer Adaptive to Data Access Patterns},
 year = {2010}
}


@article{Khouzani:2010:OPS:1811099.1811084,
 abstract = {Reliable security measures against outbreaks of malware is imperative to enable large scale proliferation of wireless technologies. Immunization and healing of the nodes through dissemination of security patches can counter the spread of a malware upon an epidemic outbreak. The distribution of patches however burdens the bandwidth which is scarce in wireless networks. The trade-offs between security risks and resource consumption can be attained by activating at any given time only fractions of dispatchers and dynamically selecting their packet transmission rates. We formulate the above trade-offs as an optimal control problem that seek to minimize the aggregate network costs that depend on security risks and resource consumed by the countermeasures. Using Pontryagin's maximum principle, we prove that the dynamic control strategies have simple structures. When the resource consumption cost is concave, optimal strategy is to use maximum resources for distribution of patches until a threshold time, upon which, the patching should halt. When the resource consumption cost is convex, the above transition is strict but continuous.},
 acmid = {1811084},
 address = {New York, NY, USA},
 author = {Khouzani, M.H. R. and Sarkar, Saswati and Altman, Eitan},
 doi = {10.1145/1811099.1811084},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {dynamic patching, optimal control, security-performance trade-off},
 link = {http://doi.acm.org/10.1145/1811099.1811084},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {355--356},
 publisher = {ACM},
 title = {Optimal Propagation of Security Patches in Mobile Wireless Networks: Extended Abstract},
 volume = {38},
 year = {2010}
}


@inproceedings{Bermond:2010:DSA:1811039.1811079,
 abstract = {
                  An abstract is not available.
              },
 acmid = {1811079},
 address = {New York, NY, USA},
 author = {Bermond, Jean-Claude and Mazauric, Dorian and Misra, Vishal and Nain, Philippe},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811079},
 isbn = {978-1-4503-0038-4},
 keyword = {distributed algorithm, interference, stability, transmission scheduling, wireless network},
 link = {http://doi.acm.org/10.1145/1811039.1811079},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {345--346},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {A Distributed Scheduling Algorithm for Wireless Networks with Constant Overhead and Arbitrary Binary Interference},
 year = {2010}
}


@inproceedings{Antunes:2010:AFI:1811039.1811076,
 abstract = {Due to complexity and intractability reasons, most of the analytical studies on the reliability of communication paths in mobile ad hoc networks are based on the assumption of link independence. In this paper, an analytical framework is developed to characterize the random behavior of a multihop path and derive path metrics to characterize the reliability of paths. This is achieved through the modeling of a multihop path as a PDMP (piecewise deterministic Markov process). Two path based metrics are obtained as expectations of functionals of the process: the mean path duration and the path persistence. We show that these metrics are the unique solution of a set of integro-differential equations and provide a recursive scheme for their computation. Finally, numerical results illustrate the computation of the metrics; these results are compared with independent link approximation results.},
 acmid = {1811076},
 address = {New York, NY, USA},
 author = {Antunes, Nelson and Jacinto, Gon\c{c}alo and Pacheco, Ant\'{o}nio},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811076},
 isbn = {978-1-4503-0038-4},
 keyword = {mobile ad hoc networks, mobility, multihop path reliability, piecewise deterministic markov processes, random walk},
 link = {http://doi.acm.org/10.1145/1811039.1811076},
 location = {New York, New York, USA},
 numpages = {10},
 pages = {323--332},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {An Analytical Framework to Infer Multihop Path Reliability in MANETs},
 year = {2010}
}


@article{Ni:2010:CSP:1811099.1811059,
 abstract = {In this paper, we study distributed channel assignment in wireless networks with applications to peer discovery in ad hoc wireless networks. We model channel assignment as a coloring problem for spatial point processes in which n nodes are located in a unit cube uniformly at random and each node is assigned one of K colors, where each color represents a channel. The objective is to maximize the spatial separation between nodes of the same color. In general, it is hard to derive the optimal coloring algorithm and therefore, we consider a natural greedy coloring algorithm, first proposed in [5]. We prove two key results: (i) with just a small number of colors when K is roughly of the order of log(n) loglog(n), the distance separation achieved by the greedy coloring algorithm asymptotically matches the optimal distance separation that can be achieved by an algorithm which is allowed to select the locations of the nodes but is allowed to use only one color, and (ii) when K = Omega(log(n)), the greedy coloring algorithm asymptotically achieves the best distance separation that can be achieved by an algorithm which is allowed to both optimally color and place nodes. The greedy coloring algorithm is also shown to dramatically outperform a simple random coloring algorithm. Moreover, the results continue to hold under node mobilities.},
 acmid = {1811059},
 address = {New York, NY, USA},
 author = {Ni, Jian and Srikant, R. and Wu, Xinzhou},
 doi = {10.1145/1811099.1811059},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {channel assignment, coloring algorithms, spatial point processes, wireless networks},
 link = {http://doi.acm.org/10.1145/1811099.1811059},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {167--178},
 publisher = {ACM},
 title = {Coloring Spatial Point Processes with Applications to Peer Discovery in Large Wireless Networks},
 volume = {38},
 year = {2010}
}


@article{Laadan:2010:TLA:1811099.1811057,
 abstract = {We present Scribe, the first system to provide transparent, low-overhead application record-replay and the ability to go live from replayed execution. Scribe introduces new lightweight operating system mechanisms, rendezvous and sync points, to efficiently record nondeterministic interactions such as related system calls, signals, and shared memory accesses. Rendezvous points make a partial ordering of execution based on system call dependencies sufficient for replay, avoiding the recording overhead of maintaining an exact execution ordering. Sync points convert asynchronous interactions that can occur at arbitrary times into synchronous events that are much easier to record and replay. We have implemented Scribe without changing, relinking, or recompiling applications, libraries, or operating system kernels, and without any specialized hardware support such as hardware performance counters. It works on commodity Linux operating systems, and commodity multi-core and multiprocessor hardware. Our results show for the first time that an operating system mechanism can correctly and transparently record and replay multi-process and multi-threaded applications on commodity multiprocessors. Scribe recording overhead is less than 2.5% for server applications including Apache and MySQL, and less than 15% for desktop applications including Firefox, Acrobat, OpenOffice, parallel kernel compilation, and movie playback.},
 acmid = {1811057},
 address = {New York, NY, USA},
 author = {Laadan, Oren and Viennot, Nicolas and Nieh, Jason},
 doi = {10.1145/1811099.1811057},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {debugging, fault-tolerance, record-replay, virtualization},
 link = {http://doi.acm.org/10.1145/1811099.1811057},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {155--166},
 publisher = {ACM},
 title = {Transparent, Lightweight Application Execution Replay on Commodity Multiprocessor Operating Systems},
 volume = {38},
 year = {2010}
}


@inproceedings{Shah:2010:DOQ:1811039.1811093,
 abstract = {In the past year or so, an exciting progress has led to throughput optimal design of CSMA-based algorithms for wireless networks. However, such an algorithm suffers from very poor delay performance. A recent work suggests that it is impossible to design a CSMA-like simple algorithm that is throughput optimal and induces low delay for any wireless network. However, wireless networks arising in practice are formed by nodes placed, possibly arbitrarily, in some geographic area. In this paper, we propose a CSMA algorithm with per-node average-delay bounded by a constant, independent of the network size, when the network has geometry (precisely, polynomial growth structure) that is present in any practical wireless network. Two novel features of our algorithm, crucial for its performance, are (a) choice of access probabilities as an appropriate function of queue-sizes, and (b) use of local network topological structures. Essentially, our algorithm is a queue-based CSMA with a minor difference that at each time instance a very small fraction of frozen nodes do not execute CSMA. Somewhat surprisingly, appropriate selection of such frozen nodes, in a distributed manner, lead to the delay optimal performance.},
 acmid = {1811093},
 address = {New York, NY, USA},
 author = {Shah, Devavrat and Shin, Jinwoo},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811093},
 isbn = {978-1-4503-0038-4},
 keyword = {aloha, markov chain, mixing time, wireless multi-access},
 link = {http://doi.acm.org/10.1145/1811039.1811093},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {373--374},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Delay Optimal Queue-based CSMA},
 year = {2010}
}


@inproceedings{Balsamo:2010:UAP:1811039.1811043,
 abstract = {In queueing networks with blocking, stations wishing to transmit customers to a full queue are blocked and need to take alternative action on completing a service. In general, product-forms, i.e. separable solutions for such a network's equilibrium state probabilities, do not exist but some product-forms have been obtained over the years in special cases, using a variety of techniques. We show that the Reversed Compound Agent Theorem (RCAT) can obtain these diverse results in a uniform way by its direct application, so unifying product-forms in networks with and without blocking. New product-forms are also constructed for a type of blocking we call `skipping', where a blocked station sends its output-customers to the queue after the one causing the blocking in that customer's path. Finally, we investigate a novel congestion management scheme for networks of finite-capacity queues in which a station with a full queue transmits signals that delete customers from upstream queues in order to reduce incoming traffic.},
 acmid = {1811043},
 address = {New York, NY, USA},
 author = {Balsamo, Simonetta and Harrison, Peter G. and Marin, Andrea},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811043},
 isbn = {978-1-4503-0038-4},
 keyword = {product-form solutions, queueing theory},
 link = {http://doi.acm.org/10.1145/1811039.1811043},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {25--36},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {A Unifying Approach to Product-forms in Networks with Finite Capacity Constraints},
 year = {2010}
}


@article{Mishra:2010:CPM:1811099.1811086,
 abstract = {Multiple clock domain architectures have recently been proposed to alleviate the power problem in CMPs by having different frequency/voltage values assigned to each domain based on workload requirements. However, accurate allocation of power to these voltage/frequency islands based on time varying workload characteristics as well as controlling the power consumption at the provisioned power level is non-trivial. Toward this end, we propose a two-tier feedback-based control theoretic solution. Our first-tier consists of a global power manager that allocates power targets to individual islands based on the workload dynamics. The power consumptions of these islands are in turn controlled by a second-tier, consisting of local controllers that regulate island power using dynamic voltage and frequency scaling in response to workload requirements.},
 acmid = {1811086},
 address = {New York, NY, USA},
 author = {Mishra, Asit K. and Srikantaiah, Shekhar and Kandemir, Mahmut and Das, Chita R.},
 doi = {10.1145/1811099.1811086},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {DVFs, GALs, chip multiprocessors (CMP), control theory},
 link = {http://doi.acm.org/10.1145/1811099.1811086},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {359--360},
 publisher = {ACM},
 title = {Coordinated Power Management of Voltage Islands in CMPs},
 volume = {38},
 year = {2010}
}


@article{Thereska:2010:PPM:1811099.1811041,
 abstract = {Perhaps surprisingly, no practical performance models exist for popular (and complex) client applications such as Adobe's Creative Suite, Microsoft's Office and Visual Studio, Mozilla, Halo 3, etc. There is currently no tool that automatically answers program developers', IT administrators' and end-users' simple what-if questions like "what happens to the performance of my favorite application X if I upgrade from Windows Vista to Windows 7?". This paper describes our approach towards constructing practical, versatile performance models to address this problem. The goal is to have these models be useful for application developers to help expand application testing coverage and for IT administrators to assist with understanding the performance consequences of a software, hardware or configuration change. This paper's main contributions are in system building and performance modeling. We believe we have built applications that are easier to model because we have proactively instrumented them to export their state and associated metrics. This application-specific monitoring is always on and interesting data is collected from real, "in-the-wild" deployments. The models we are experimenting with are based on statistical techniques. They require no modifications to the OS or applications beyond the above instrumentation, and no explicit a priori model on how an OS or application should behave. We are in the process of learning from models we have constructed for several Microsoft products, including the Office suite, Visual Studio and Media Player. This paper presents preliminary findings from a large user deployment (several hundred thousand user sessions) of these applications that show the coverage and limitations of such models. These findings pushed us to move beyond averages/means and go into some depth into why client application performance has an inherently large variance.},
 acmid = {1811041},
 address = {New York, NY, USA},
 author = {Thereska, Eno and Doebel, Bjoern and Zheng, Alice X. and Nobel, Peter},
 doi = {10.1145/1811099.1811041},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {IT administrators, developers, performance variance, what-if},
 link = {http://doi.acm.org/10.1145/1811099.1811041},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {1--12},
 publisher = {ACM},
 title = {Practical Performance Models for Complex, Popular Applications},
 volume = {38},
 year = {2010}
}


@inproceedings{Shye:2010:CMU:1811039.1811094,
 abstract = {In this paper, we present a comprehensive analysis of real smartphone usage during a 6-month study of real user activity on the Android G1 smartphone. Our goal is to study the high-level characteristics of smartphone usage, and to understand the implications on optimizing smartphones, and their networks. Overall, we present 11 findings that cover general usage behavior, interaction with the battery, power consumption, network activity, frequently-run applications, and modeling usage states.},
 acmid = {1811094},
 address = {New York, NY, USA},
 author = {Shye, Alex and Scholbrock, Benjamin and Memik, Gokhan and Dinda, Peter A.},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811094},
 isbn = {978-1-4503-0038-4},
 keyword = {embedded systems, human factors},
 link = {http://doi.acm.org/10.1145/1811039.1811094},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {375--376},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Characterizing and Modeling User Activity on Smartphones: Summary},
 year = {2010}
}


@article{Bramson:2010:RLB:1811099.1811071,
 abstract = {Randomized load balancing greatly improves the sharing of resources in a number of applications while being simple to implement. One model that has been extensively used to study randomized load balancing schemes is the supermarket model. In this model, jobs arrive according to a rate-nλ Poisson process at a bank of n rate-1 exponential server queues. A notable result, due to Vvedenskaya et.al. (1996), showed that when each arriving job is assigned to the shortest of d ≥ 2 randomly chosen queues, the equilibrium queue sizes decay doubly exponentially in the limit as n to ∞. This is a substantial improvement over the case d=1, where queue sizes decay exponentially. The method of analysis used in the above paper and in the subsequent literature applies to jobs with exponential service time distributions and does not easily generalize. It is desirable to study load balancing models with more general, especially heavy-tailed, service time distributions since such service times occur widely in practice. This paper describes a modularized program for treating randomized load balancing problems with general service time distributions and service disciplines. The program relies on an ansatz which asserts that any finite set of queues in a randomized load balancing scheme becomes independent as n to ∞. This allows one to derive queue size distributions and other performance measures of interest. We establish the ansatz when the service discipline is FIFO and the service time distribution has a decreasing hazard rate (this includes heavy-tailed service times). Assuming the ansatz, we also obtain the following results: (i) as n to ∞, the process of job arrivals at any fixed queue tends to a Poisson process whose rate depends on the size of the queue, (ii) when the service discipline at each server is processor sharing or LIFO with preemptive resume, the distribution of the number of jobs is insensitive to the service distribution, and (iii) the tail behavior of the queue-size distribution in terms of the service distribution for the FIFO service discipline.},
 acmid = {1811071},
 address = {New York, NY, USA},
 author = {Bramson, Maury and Lu, Yi and Prabhakar, Balaji},
 doi = {10.1145/1811099.1811071},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {asymptotic independence, load balancing, randomized algorithms},
 link = {http://doi.acm.org/10.1145/1811099.1811071},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {275--286},
 publisher = {ACM},
 title = {Randomized Load Balancing with General Service Time Distributions},
 volume = {38},
 year = {2010}
}


@article{Gast:2010:MFM:1811099.1811042,
 abstract = {In this paper, we consider a generic model of computational grids, seen as several clusters of homogeneous processors. In such systems, a key issue when designing efficient job allocation policies is to balance the workload over the different resources. We present a Markovian model for performance evaluation of such a policy, namely work stealing (idle processors steal work from others) in large-scale heterogeneous systems. Using mean field theory, we show that when the size of the system grows, it converges to a system of deterministic ordinary differential equations that allows one to compute the expectation of performance functions (such as average response times) as well as the distributions of these functions.},
 acmid = {1811042},
 address = {New York, NY, USA},
 author = {Gast, Nicolas and Bruno, Gaujal},
 doi = {10.1145/1811099.1811042},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {grid computing, load balancing, mean field},
 link = {http://doi.acm.org/10.1145/1811099.1811042},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {13--24},
 publisher = {ACM},
 title = {A Mean Field Model of Work Stealing in Large-scale Systems},
 volume = {38},
 year = {2010}
}


@article{Tomozei:2010:DUP:1811099.1811098,
 abstract = {User profiling is a useful primitive for constructing personalized services, such as content recommendation. In the present work we investigate the feasibility of user profiling in a distributed setting, with no central authority and only local information exchanges between users. Our main contributions are: (i)~We propose a spectral clustering technique, and prove its ability to recover unknown user profiles with only few measures of affinity between users. (ii)~We develop distributed algorithms which achieve an embedding of users into a low-dimensional space, based on spectral transformation. These involve simple message passing among users, and provably converge to the desired embedding.},
 acmid = {1811098},
 address = {New York, NY, USA},
 author = {Tomozei, Dan-Cristian and Massouli{\'e}, Laurent},
 doi = {10.1145/1811099.1811098},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {clustering, distributed spectral embedding, gossip},
 link = {http://doi.acm.org/10.1145/1811099.1811098},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {383--384},
 publisher = {ACM},
 title = {Distributed User Profiling via Spectral Methods},
 volume = {38},
 year = {2010}
}


@inproceedings{Shah:2010:DCG:1811039.1811052,
 abstract = {Game theoretic modeling and equilibrium analysis of congestion games have provided insights in the performance of Internet congestion control, road transportation networks, etc. Despite the long history, very little is known about their transient (non equilibrium) performance. In this paper, we are motivated to seek answers to questions such as how long does it take to reach equilibrium, when the system does operate near equilibrium in the presence of dynamics, e.g. nodes join or leave. , or the tradeoff between performance and the rate of dynamics. In this pursuit, we provide three contributions in this paper. First, a novel probabilistic model to capture realistic behaviors of agents allowing for the possibility of arbitrariness in conjunction with rationality. Second, evaluation of (a) time to converge to equilibrium under this behavior model and (b) distance to Nash equilibrium. Finally, determination of tradeoff between the rate of dynamics and quality of performance (distance to equilibrium) which leads to an interesting uncertainty principle. The novel technical ingredients involve analysis of logarithmic Sobolov constant of Markov process with time varying state space and methodically this should be of broader interest in the context of dynamical systems.},
 acmid = {1811052},
 address = {New York, NY, USA},
 author = {Shah, Devavrat and Shin, Jinwoo},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811052},
 isbn = {978-1-4503-0038-4},
 keyword = {congestion game, logarithmic sobolov constant, logit-response},
 link = {http://doi.acm.org/10.1145/1811039.1811052},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {107--118},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Dynamics in Congestion Games},
 year = {2010}
}


@inproceedings{Rajagopalan:2010:DAD:1811039.1811091,
 abstract = {Distributed averaging is a well-studied problem, and often a "prototype" for a class of fundamental questions arising in various disciplines. Previous work has considered the effect of dynamics in the network topology, in terms of changes in which communication links are present. Here, we analyze the other forms of dynamics, namely: changes in the values at the nodes, and nodes joining or leaving the network.},
 acmid = {1811091},
 address = {New York, NY, USA},
 author = {Rajagopalan, Shreevatsa and Shah, Devavrat},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811091},
 isbn = {978-1-4503-0038-4},
 keyword = {distributed averaging, distributed networks, dynamics, message-passing},
 link = {http://doi.acm.org/10.1145/1811039.1811091},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {369--370},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Distributed Averaging in Dynamic Networks},
 year = {2010}
}


@inproceedings{Shah:2010:QP9:1811039.1811067,
 abstract = {We consider a switched network, a fairly general constrained queueing network model that has been used successfully to model the detailed packet-level dynamics in communication networks, such as input-queued switches and wireless networks. The main operational issue in this model is that of deciding which queues to serve, subject to certain constraints. In this paper, we study qualitative performance properties of the well known α-weighted scheduling policies. The stability, in the sense of positive recurrence, of these policies has been well understood. We establish exponential upper bounds on the tail of the steady-state distribution of the backlog. Along the way, we prove finiteness of the expected steady-state backlog when α<1, a property that was known only for α ≥ 1. Finally, we analyze the excursions of the maximum backlog over a finite time horizon for α ≥ 1. As a consequence, for α ≥ 1, we establish the full state space collapse property.},
 acmid = {1811067},
 address = {New York, NY, USA},
 author = {Shah, Devavrat and Tsitsiklis, John N. and Zhong, Yuan},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811067},
 isbn = {978-1-4503-0038-4},
 keyword = {Markov chain, exponential bound, maximum weight-alpha, state space collapse, switched network},
 link = {http://doi.acm.org/10.1145/1811039.1811067},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {239--250},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Qualitative Properties of {\$\alpha\$}-weighted Scheduling Policies},
 year = {2010}
}


@article{Ghanbari:2010:QLR:1811099.1811055,
 abstract = {As modern multi-tier systems are becoming increasingly large and complex, it becomes more difficult for system analysts to understand the overall behavior of the system, and diagnose performance problems. To assist analysts inspect performance behavior, we introduce SelfTalk, a novel declarative language that allows analysts to query and understand the status of a large scale system. SelfTalk is sufficiently expressive to encode an analyst's high-level hypotheses about system invariants, normal correlations between system metrics, or other a priori derived performance models, such as, "I expect that the throughputs of interconnected system components are linearly correlated". Given a hypothesis, Dena, our runtime support system, instantiates and validates it using actual monitoring data within specific system configurations. We evaluate SelfTalk/Dena by posing several hypotheses about system behavior and querying Dena to validate system behavior in a multi-tier dynamic content server. We find that Dena automatically validates the system performance based on the pre-existing hypotheses and helps to diagnose system misbehavior.},
 acmid = {1811055},
 address = {New York, NY, USA},
 author = {Ghanbari, Saeed and Soundararajan, Gokul and Amza, Cristiana},
 doi = {10.1145/1811099.1811055},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {expectation, hypothesis, management, performance models},
 link = {http://doi.acm.org/10.1145/1811099.1811055},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {131--142},
 publisher = {ACM},
 title = {A Query Language and Runtime Tool for Evaluating Behavior of Multi-tier Servers},
 volume = {38},
 year = {2010}
}


@inproceedings{Zhao:2010:UMF:1811039.1811073,
 abstract = {This paper addresses the problem of distributed resource allocation in general fork and join processing networks. The problem is motivated by the complicated processing requirements arising from distributed data intensive computing. In such applications, the underlying data processing software consists of a rich set of semantics that include synchronous and asynchronous data fork and data join. The different types of semantics and processing requirements introduce complex interdependence between various data flows within the network. We study the distributed resource allocation problem in such systems with the goal of achieving the maximum total utility of output streams. Past research has dealt with networks with specific types of fork/join semantics, but none of them included all four types. We propose a novel modeling framework that can represent all combinations of fork and join semantics, and formulate the resource allocation problem as a convex optimization problem on this model. We propose a shadow-queue based decentralized iterative algorithm to solve the resource allocation problem. We show that the algorithm guarantees optimality and demonstrate through simulation that it can adapt quickly to dynamically changing environments.},
 acmid = {1811073},
 address = {New York, NY, USA},
 author = {Zhao, Haiquan (Chuck) and Xia, Cathy H. and Liu, Zhen and Towsley, Don},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811073},
 isbn = {978-1-4503-0038-4},
 keyword = {distributed algorithm, fork and join networks, resource allocation},
 link = {http://doi.acm.org/10.1145/1811039.1811073},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {299--310},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {A Unified Modeling Framework for Distributed Resource Allocation of General Fork and Join Processing Networks},
 year = {2010}
}


@article{Nguyen:2010:RSA:1811099.1811087,
 abstract = {In this paper we present a rigorous technique for estimating confidence intervals of packet loss measurements. Our approach is motivated by simple observations that the loss process can be modelled as an alternating renewal process. We use this structure to build a Hidden Semi-Markov Model (HSMM) for the measurement process, and from this estimate both loss rates, and their confidence intervals. We use both simulations and a set of more than 18000 hours of real Internet measurements (between dedicated measurement hosts, PlanetLab hosts, web and DNS servers) to cross-validate our estimates, and show that they are significantly more accurate than any current alternative.},
 acmid = {1811087},
 address = {New York, NY, USA},
 author = {Nguyen, Hung X. and Roughan, Matthew},
 doi = {10.1145/1811099.1811087},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {accuracy, loss rate, performance measurement},
 link = {http://doi.acm.org/10.1145/1811099.1811087},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {361--362},
 publisher = {ACM},
 title = {Rigorous Statistical Analysis of Internet Loss Measurements},
 volume = {38},
 year = {2010}
}


@proceedings{Misra:2010:1811039,
 abstract = {Welcome to ACM SIGMETRICS 2010! And to the city so nice, they named it twice. This year's conference continues the rich SIGMETRICS tradition of being the premier forum for the presentation of research on the measurement and modeling of computer systems. The technical program for 2010 features a set of outstanding papers that covers both theory and applications from a wide variety of areas, including dynamics and control, load balancing, measurement, network traffic, optimization, performance modeling and analysis, resource allocation, scheduling, sensor and wireless networks, and systems, among others. This year's call for papers attracted 184 submissions from all over the world (and a few beyond). The 90 member Technical Program Committee along with a selected group of external experts carefully considered all of the submissions with a total of 716 detailed reviews completed. The TPC meeting to select the final program was held on the campus of Columbia University in mid January, 2010. At the conclusion of the meeting, the committee had assembled a wonderful program composed of 29 papers and 20 posters, to be presented over three days at the conference. The quality of submissions was extremely high as reflected in the final technical program. Following the TPC meeting, a subcommittee had the pleasure (yet very difficult task) of selecting the best paper award winners. The paper entitled "Load Balancing via Randomized Local Search in Closed and Open Systems" by A. Ganesh, S. Lilienthal, D. Manjunath, A. Proutiere and F. Simatos received the Best Paper Award. The paper entitled "Distributed Sensor Network Localization from Local Connectivity: Performance Analysis for the HOP-TERRAIN Algorithm" by A. Karbasi and S. Oh received the Kenneth C. Sevcik Outstanding Student Paper Award. Please join us in congratulating the authors!},
 address = {New York, NY, USA},
 isbn = {978-1-4503-0038-4},
 location = {New York, New York, USA},
 publisher = {ACM},
 title = {SIGMETRICS '10: Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 year = {2010}
}


@article{vandeVen:2010:OTE:1811099.1811060,
 abstract = {Wireless networks equipped with the CSMA protocol are subject to collisions due to interference. For a given interference range we investigate the tradeoff between collisions (hidden nodes) and unused capacity (exposed nodes). We show that the sensing range that maximizes throughput critically depends on the activation rate of nodes. For infinite line networks, we prove the existence of a threshold: When the activation rate is below this threshold the optimal sensing range is small (to maximize spatial reuse). When the activation rate is above the threshold the optimal sensing range is just large enough to preclude all collisions. Simulations suggest that this threshold policy extends to more complex linear and non-linear topologies.},
 acmid = {1811060},
 address = {New York, NY, USA},
 author = {van de Ven, Peter M. and Janssen, Augustus J.E.M. and van Leeuwaarden, Johan S.H.},
 doi = {10.1145/1811099.1811060},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {carrier-sensing range, exposed nodes, hidden nodes, markov processes, multi-access, throughput, wireless networks},
 link = {http://doi.acm.org/10.1145/1811099.1811060},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {179--190},
 publisher = {ACM},
 title = {Optimal Tradeoff Between Exposed and Hidden Nodes in Large Wireless Networks},
 volume = {38},
 year = {2010}
}


@article{Shah:2010:DSC:1811099.1811063,
 abstract = {We provide a systematic study of the problem of finding the source of a computer virus in a network. We model virus spreading in a network with a variant of the popular SIR model and then construct an estimator for the virus source. This estimator is based upon a novel combinatorial quantity which we term rumor centrality. We establish that this is an ML estimator for a class of graphs. We find the following surprising threshold phenomenon: on trees which grow faster than a line, the estimator always has non-trivial detection probability, whereas on trees that grow like a line, the detection probability will go to 0 as the network grows. Simulations performed on synthetic networks such as the popular small-world and scale-free networks, and on real networks such as an internet AS network and the U.S. electric power grid network, show that the estimator either finds the source exactly or within a few hops in different network topologies. We compare rumor centrality to another common network centrality notion known as distance centrality. We prove that on trees, the rumor center and distance center are equivalent, but on general networks, they may differ. Indeed, simulations show that rumor centrality outperforms distance centrality in finding virus sources in networks which are not tree-like.},
 acmid = {1811063},
 address = {New York, NY, USA},
 author = {Shah, Devavrat and Zaman, Tauhid},
 doi = {10.1145/1811099.1811063},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {epidemics, estimation},
 link = {http://doi.acm.org/10.1145/1811099.1811063},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {203--214},
 publisher = {ACM},
 title = {Detecting Sources of Computer Viruses in Networks: Theory and Experiment},
 volume = {38},
 year = {2010}
}


@inproceedings{Moallemi:2010:FDP:1811039.1811050,
 abstract = {The packet is the fundamental unit of transportation in modern communication networks such as the Internet. Physical layer scheduling decisions are made at the level of packets, and packet-level models with exogenous arrival processes have long been employed to study network performance, as well as design scheduling policies that more efficiently utilize network resources. On the other hand, a user of the network is more concerned with end-to-end bandwidth, which is allocated through congestion control policies such as TCP. Utility-based flow-level models have played an important role in understanding congestion control protocols. In summary, these two classes of models have provided separate insights for flow-level and packet-level dynamics of a network. In this paper, we wish to study these two dynamics together. We propose a joint flow-level and packet-level stochastic model for the dynamics of a network, and an associated policy for congestion control and packet scheduling that is based on alpha-weighted policies from the literature. We provide a fluid analysis for the model that establishes the throughput optimality of the proposed policy, thus validating prior insights based on separate packet-level and flow-level models. By analyzing a critically scaled fluid model under the proposed policy, we provide constant factor performance bounds on the delay performance and characterize the invariant states of the system.},
 acmid = {1811050},
 address = {New York, NY, USA},
 author = {Moallemi, Ciamac and Shah, Devavrat},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811050},
 isbn = {978-1-4503-0038-4},
 keyword = {congestion control, flow-level model, maximum weight, packet-level model, scheduling, utility maximizaiton},
 link = {http://doi.acm.org/10.1145/1811039.1811050},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {83--94},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {On the Flow-level Dynamics of a Packet-switched Network},
 year = {2010}
}


@inproceedings{Dong:2010:EEE:1811039.1811046,
 abstract = {We present a new mechanism called Elon for enabling efficient and long-term reprogramming in wireless sensor networks. Elon reduces the transferred code size significantly by introducing the concept of replaceable component. It avoids the cost of hardware reboot with a novel software reboot mechanism. Moreover, it significantly prolongs the reprogramming lifetime by avoiding flash writes for TelosB nodes. Experimental results show that Elon transfers up to 120--389 times less information than Deluge, and 18-42 times less information than Stream. The software reboot mechanism that Elon applies reduces the rebooting cost by 50.4%-53.87% in terms of beacon packets, and 56.83% in terms of unsynchronized nodes. In addition, Elon prolongs the reprogramming lifetime by a factor of 2.3.},
 acmid = {1811046},
 address = {New York, NY, USA},
 author = {Dong, Wei and Liu, Yunhao and Wu, Xiaofan and Gu, Lin and Chen, Chun},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811046},
 isbn = {978-1-4503-0038-4},
 keyword = {component, reboot, reprogramming, wireless sensor network},
 link = {http://doi.acm.org/10.1145/1811039.1811046},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {49--60},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Elon: Enabling Efficient and Long-term Reprogramming for Wireless Sensor Networks},
 year = {2010}
}


@inproceedings{Silveira:2010:DTA:1811039.1811095,
 abstract = {When many flows are multiplexed on a non-saturated link, their volume changes over short timescales tend to cancel each other out, making the average change across flows close to zero. This equilibrium property holds if the flows are nearly independent, and it is violated by traffic changes caused by several correlated flows. We exploit this empirical property to design a computationally simple anomaly detection method.},
 acmid = {1811095},
 address = {New York, NY, USA},
 author = {Silveira, Fernando and Diot, Christophe and Taft, Nina and Govindan, Ramesh},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811095},
 isbn = {978-1-4503-0038-4},
 keyword = {anomaly detection, statistical test},
 link = {http://doi.acm.org/10.1145/1811039.1811095},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {377--378},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Detecting Traffic Anomalies Using an Equilibrium Property},
 year = {2010}
}


@article{Osogami:2010:SOT:1811099.1811088,
 abstract = {We derive an upper bound on the tail distribution of the transient waiting time for the GI/GI/1 queue from a formulation of semidefinite programming (SDP). Our upper bounds are expressed in closed forms using the first two moments of the service time and the interarrival time. The upper bounds on the tail distributions are integrated to obtain the upper bounds on the corresponding expectations. We also extend the formulation of the SDP, using the higher moments of the service time and the interarrival time, and calculate upper bounds and lower bounds numerically.},
 acmid = {1811088},
 address = {New York, NY, USA},
 author = {Osogami, Takayuki and Raymond, Rudy},
 doi = {10.1145/1811099.1811088},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {bounds, duality, g/g/1 queue, moments, occupation measure, semidefinite programming, transient},
 link = {http://doi.acm.org/10.1145/1811099.1811088},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {363--364},
 publisher = {ACM},
 title = {Semidefinite Optimization for Transient Analysis of Queues},
 volume = {38},
 year = {2010}
}


@inproceedings{Liu:2010:SMW:1811039.1811061,
 abstract = {This paper studies scheduling in multichannel wireless networks with flow-level dynamics. We consider a downlink network with a single base station, M channels (frequency bands), and multiple mobile users (flows). We also assume mobiles dynamically join the network to receive finite-size files and leave after downloading the complete files. A recent study [16] has shown that the MaxWeight algorithm fails to be throughput-optimal under this flow-level dynamics. The main contribution of this paper is the development of joint channel-assignment and workload-based scheduling algorithms for multichannel downlink networks with dynamic flow arrivals/departures. We prove that these algorithms are throughput-optimal. Our simulations further demonstrate that a hybrid channel-assignment and workload-based scheduling algorithm significantly improves the network performance (in terms of both file-transfer delay and blocking probability) compared to the existing algorithms.},
 acmid = {1811061},
 address = {New York, NY, USA},
 author = {Liu, Shihuan and Ying, Lei and Srikant, R.},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811061},
 isbn = {978-1-4503-0038-4},
 keyword = {flow-level dynamics, multichannel downlink network, wireless scheduling},
 link = {http://doi.acm.org/10.1145/1811039.1811061},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {191--202},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Scheduling in Multichannel Wireless Networks with Flow-level Dynamics},
 year = {2010}
}


@article{Sarikaya:2010:PBP:1811099.1811092,
 abstract = {Adaptive computing systems rely on predictions of program behavior to understand and respond to the dynamically varying application characteristics. This study describes an accurate statistical workload metric modeling scheme for predicting program phases. Our evaluations demonstrate the superior performance of this predictor over existing predictors on a wide range of benchmarks. This prediction accuracy lends itself to improved power-performance trade-offs when applied to dynamic power management.},
 acmid = {1811092},
 address = {New York, NY, USA},
 author = {Sarikaya, Ruhi and Isci, Canturk and Buyuktosunoglu, Alper},
 doi = {10.1145/1811099.1811092},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {computer architecture, system performance measurement, monitoring and forecasting, workload characterization},
 link = {http://doi.acm.org/10.1145/1811099.1811092},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {371--372},
 publisher = {ACM},
 title = {Program Behavior Prediction Using a Statistical Metric Model},
 volume = {38},
 year = {2010}
}


@inproceedings{Xu:2010:SPC:1811039.1811048,
 abstract = {We show that CSMA is able to spontaneously synchronize transmissions in a wireless network with constant-size packets, and that this property can be used to devise efficient synchronized CSMA scheduling mechanisms without message passing. Using tools from queuing theory, we prove that for any connected wireless networks with arbitrary interference constraints, it is possible to implement self-synchronizing TDMA schedules without any explicit message passing or clock synchronization besides transmitting the original data packets, and the interaction can be fully local in that each node decides when to transmit next only by overhearing its neighbors' transmissions. We also provide a necessary and sufficient condition on the emergence of self-synchronization for a given TDMA schedule, and prove that such conditions for self-synchronization can be checked in a finite number of steps for a finite network topology.},
 acmid = {1811048},
 address = {New York, NY, USA},
 author = {Xu, Kuang and Dousse, Olivier and Thiran, Patrick},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811048},
 isbn = {978-1-4503-0038-4},
 keyword = {scheduling algorithm, self-synchronization, stochastic recursive sequence},
 link = {http://doi.acm.org/10.1145/1811039.1811048},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {71--82},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Self-synchronizing Properties of CSMA Wireless Multi-hop Networks},
 year = {2010}
}


@inproceedings{Andrew:2010:OFR:1811039.1811044,
 abstract = {This work examines fundamental tradeoffs incurred by a speed scaler seeking to minimize the sum of expected response time and energy use per job. We prove that a popular speed scaler is 2-competitive for this objective and no "natural" speed scaler can do better. Additionally, we prove that energy-proportional speed scaling works well for both Shortest Remaining Processing Time (SRPT) and Processor Sharing (PS) and we show that under both SRPT and PS, gated-static speed scaling is nearly optimal when the mean workload is known, but that dynamic speed scaling provides robustness against uncertain workloads. Finally, we prove that speed scaling magnifies unfairness under SRPT but that PS remains fair under speed scaling. These results show that these speed scalers can achieve any two, but only two, of optimality, fairness, and robustness.},
 acmid = {1811044},
 address = {New York, NY, USA},
 author = {Andrew, Lachlan L.H. and Lin, Minghong and Wierman, Adam},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811044},
 isbn = {978-1-4503-0038-4},
 keyword = {PS, SRPT, energy, fairness, robustness, scheduling, speed scaling},
 link = {http://doi.acm.org/10.1145/1811039.1811044},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {37--48},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Optimality, Fairness, and Robustness in Speed Scaling Designs},
 year = {2010}
}


@article{Coffman:2010:CFD:1811099.1811077,
 abstract = {Dynamic Spectrum Access systems exploit temporarily available spectrum ('white spaces') and can spread transmissions over a number of non-contiguous sub-channels. Such methods are highly beneficial in terms of spectrum utilization. However, excessive fragmentation degrades performance and hence off-sets the benefits. Thus, there is a need to study these processes so as to determine how to ensure acceptable levels of fragmentation. Hence, we present experimental and analytical results derived from a mathematical model. We model a system operating at capacity serving requests for bandwidth by assigning a collection of gaps (sub-channels) with no limitations on the fragment size. Our main theoretical result shows that even if fragments can be arbitrarily small, the system does not degrade with time. Namely, the average total number of fragments remains bounded. Within the very difficult class of dynamic fragmentation models (including models of storage fragmentation), this result appears to be the first of its kind. Extensive experimental results describe behavior, at times unexpected, of fragmentation under different algorithms. Our model also applies to dynamic linked-list storage allocation, and provides a novel analysis in that domain. We prove that, interestingly, the 50% rule of the classical (non-fragmented) allocation model carries over to our model. Overall, the paper provides insights into the potential behavior of practical fragmentation algorithms.},
 acmid = {1811077},
 address = {New York, NY, USA},
 author = {Coffman, Ed and Robert, Philippe and Simatos, Florian and Tarumi, Shuzo and Zussman, Gil},
 doi = {10.1145/1811099.1811077},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {cognitive radio, dynamic spectrum access, ergodicity of markov chains, fragmentation},
 link = {http://doi.acm.org/10.1145/1811099.1811077},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {333--344},
 publisher = {ACM},
 title = {Channel Fragmentation in Dynamic Spectrum Access Systems: A Theoretical Study},
 volume = {38},
 year = {2010}
}


@inproceedings{Misra:2010:IPS:1811039.1811064,
 abstract = {A new generation of content delivery networks for live streaming, video on demand, and software updates takes advantage of a peer-to-peer architecture to reduce their operating cost. In contrast with previous uncoordinated peer-to-peer schemes, users opt-in to dedicate part of the resources they own to help the content delivery, in exchange for receiving the same service at a reduced price. Such incentive mechanisms are appealing, as they simplify coordination and accounting. However, they also increase a user's expectation that she will receive a fair price for the resources she provides. Addressing this issue carefully is critical in ensuring that all interested parties--including the provider--are willing to participate in such a system, thereby guaranteeing its stability. In this paper, we take a cooperative game theory approach to identify the ideal incentive structure that follows the axioms formulated by Lloyd Shapley. This ensures that each player, be it the provider or a peer, receives an amount proportional to its contribution and bargaining power when entering the game. In general, the drawback of this ideal incentive structure is its computational complexity. However, we prove that as the number of peers receiving the service becomes large, the Shapley value received by each player approaches a fluid limit. This limit follows a simple closed form expression and can be computed in several scenarios of interest: by applying our technique, we show that several peer-assisted services, deployed on both wired and wireless networks, can benefit from important cost and energy savings with a proper incentive structure that follows simple compensation rules.},
 acmid = {1811064},
 address = {New York, NY, USA},
 author = {Misra, Vishal and Ioannidis, Stratis and Chaintreau, Augustin and Massouli{\'e}, Laurent},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811064},
 isbn = {978-1-4503-0038-4},
 keyword = {cooperative game theory, incentive mechanisms},
 link = {http://doi.acm.org/10.1145/1811039.1811064},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {215--226},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Incentivizing Peer-assisted Services: A Fluid Shapley Value Approach},
 year = {2010}
}


@inproceedings{Cuevas:2010:DDB:1811039.1811081,
 abstract = {A substantial amount of work has recently gone into localizing BitTorrent traffic within an ISP in order to avoid excessive and often times unnecessary transit costs. In this work we aim to answer yet unanswered questions such as: what is the minimum and the maximum transit traffic reduction across hundreds of ISPs?, what are the win-win boundaries for ISPs and their users?, what is the maximum amount of transit traffic that can be localized without requiring fine-grained control of inter-AS overlay connections?, what is the impact to transit traffic from upgrades of residential broadband speeds?.},
 acmid = {1811081},
 address = {New York, NY, USA},
 author = {Cuevas, Rub{\'e}n and Laoutaris, Nikolaos and Yang, Xiaoyuan and Siganos, Georgos and Rodriguez, Pablo},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811081},
 isbn = {978-1-4503-0038-4},
 keyword = {BitTorrent, locality, measurements},
 link = {http://doi.acm.org/10.1145/1811039.1811081},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {349--350},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Deep Diving into BitTorrent Locality},
 year = {2010}
}


@inproceedings{Xiang:2010:ORS:1811039.1811054,
 abstract = {Modern storage systems use thousands of inexpensive disks to meet the storage requirement of applications. To enhance the data availability, some form of redundancy is used. For example, conventional RAID-5 systems provide data availability for single disk failure only, while recent advanced coding techniques such as row-diagonal parity (RDP) can provide data availability with up to two disk failures. To reduce the probability of data unavailability, whenever a single disk fails, disk recovery (or rebuild) will be carried out. We show that conventional recovery scheme of RDP code for a single disk failure is inefficient and suboptimal. In this paper, we propose an optimal and efficient disk recovery scheme, Row-Diagonal Optimal Recovery (RDOR), for single disk failure of RDP code that has the following properties: (1) it is read optimal in the sense that it issues the smallest number of disk reads to recover the failed disk; (2) it has the load balancing property that all surviving disks will be subjected to the same amount of additional workload in rebuilding the failed disk. We carefully explore the design state space and theoretically show the optimality of RDOR. We carry out performance evaluation to quantify the merits of RDOR on some widely used disks.},
 acmid = {1811054},
 address = {New York, NY, USA},
 author = {Xiang, Liping and Xu, Yinlong and Lui, John C.S. and Chang, Qian},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811054},
 isbn = {978-1-4503-0038-4},
 keyword = {RDP code, disk failure, raid recovery, recovery algorithm},
 link = {http://doi.acm.org/10.1145/1811039.1811054},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {119--130},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Optimal Recovery of Single Disk Failure in RDP Code Storage Systems},
 year = {2010}
}


@article{Goel:2010:SSQ:1811099.1811056,
 abstract = {Associative memories offer high levels of parallelism in matching a query against stored entries. We design and analyze an architecture which uses single lookup into a Ternary Content Addressable Memory (TCAM) to solve the subset query problem for small sets, i.e., to check whether a given set (the query) contains (or alternately, is contained in) any one of a large collection of sets in a database. We use each TCAM entry as a small Ternary Bloom Filter (each 'bit' of which is one of {0,1,wildcard}) to store one of the sets in the collection. Like Bloom filters, our architecture is susceptible to false positives. Since each TCAM entry is quite small, asymptotic analyses of Bloom filters do not directly apply. Surprisingly, we are able to show that the asymptotic false positive probability formula can be safely used if we penalize the small Bloom filter by taking away just one bit of storage and adding just half an extra set element before applying the formula. We believe that this analysis is independently interesting. The subset query problem has applications in databases, network intrusion detection, packet classification in Internet routers, and Information Retrieval. We demonstrate our architecture on one illustrative streaming application -- intrusion detection in network traffic. Be shingling (i.e., taking consecutive bytes of) the strings in the database, we can perform a single subset query and hence a single TCAM search, to skip many bytes in the stream. We evaluate our scheme on the open source CLAM anti-virus database, for worst-case as well as random streams. Our architecture appears to be at least one order of magnitude faster than previous approaches. Since the individual Bloom filters must fit in a single TCAM entry (currently 72 to 576 bits), our solution applies only when each set is of a small cardinality. However, this is sufficient for many typical applications. Also, recent algorithms for the subset-query problem use a small-set version as a subroutine},
 acmid = {1811056},
 address = {New York, NY, USA},
 author = {Goel, Ashish and Gupta, Pankaj},
 doi = {10.1145/1811099.1811056},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {TCAM, bloom filters, subset queries},
 link = {http://doi.acm.org/10.1145/1811099.1811056},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {143--154},
 publisher = {ACM},
 title = {Small Subset Queries and Bloom Filters Using Ternary Associative Memories, with Applications},
 volume = {38},
 year = {2010}
}


@proceedings{Douceur:2009:1555349,
 abstract = {It is our great pleasure to welcome you to SIGMETRICS/Performance 2009. SIGMETRICS is the flagship conference of the ACM special interest group for the computer systems performance evaluation community. Performance is the flagship conference of the IFIP working group on performance modeling and analysis. Every three years, the two conferences are held jointly, and this is the eleventh joint conference. This year, we will continue with several of the innovations introduced at last year's SIGMETRICS program. The main conference will again be a full three days, featuring 27 papers, 21 posters, and three invited talks from computer science luminaries, both academic and industrial. We will also reprise the demo competition and student thesis panel that were so well received last year. We are introducing an industrial information seminar, to provide an opportunity for students and academics to hear from representatives in industrial research about performance-related projects and their impact on deployed products and services. Supplementing the main conference are four interesting workshops, ranging from the venerable to the avant-garde. The workshop on MAthematical performance Modeling and Analysis (MAMA) continues its eleventh year as a forum for talks on early research in the more mathematical areas of computer performance analysis. The workshop on Hot Topics in Metrics (HotMetrics), which had a stellar inauguration last year, will reprise its role in helping to identify "big" and "hard" problems in performance evaluation and to develop innovative approaches to solving them. We also introduce two new workshops this year: GreenMetrics will explore how improvements to or new uses of Information and Communication Technology (ICT) can contribute towards efforts to minimize global climate change, a problem of increasing importance in modern society. The Learning for Networking workshop will investigate the use of machine learning techniques to tackle the increasingly complex architecture and control features in telecommunications and computer networks. This year also features a splendid series of tutorials, on topics ranging from social networks to data-center networks, from data-flow programming to packet-flow configuration, and from internet measurement to internet service construction.},
 address = {New York, NY, USA},
 isbn = {978-1-60558-511-6},
 location = {Seattle, WA, USA},
 note = {81900901},
 publisher = {ACM},
 title = {SIGMETRICS '09: Proceedings of the Eleventh International Joint Conference on Measurement and Modeling of Computer Systems},
 year = {2009}
}


@article{Soundararajan:2010:CSE:1811099.1811096,
 abstract = {Multicores have become the platform of choice across all market segments. Cost-effective protection against soft errors is important in these environments, due to the need to move to lower technology generations and the exploding number of transistors on a chip. While multicores offer the flexibility of varying the number of application threads and the number of cores on which they run, the reliability impact of choosing one configuration over another is unclear. Our study reveals that the reliability costs vary dramatically between configurations and being unaware could lead to a sub-optimal choice.},
 acmid = {1811096},
 address = {New York, NY, USA},
 author = {Soundararajan, Niranjan and Sivasubramaniam, Anand and Narayanan, Vijay},
 doi = {10.1145/1811099.1811096},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {fit rate, multicore, soft errors},
 link = {http://doi.acm.org/10.1145/1811099.1811096},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {379--380},
 publisher = {ACM},
 title = {Characterizing the Soft Error Vulnerability of Multicores Running Multithreaded Applications},
 volume = {38},
 year = {2010}
}


@inproceedings{Qian:2010:CUS:1811039.1811090,
 abstract = {
                  An abstract is not available.
              },
 acmid = {1811090},
 address = {New York, NY, USA},
 author = {Qian, Feng and Pathak, Abhinav and Hu, Yu Charlie and Mao, Zhuoqing Morley and Xie, Yinglian},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811090},
 isbn = {978-1-4503-0038-4},
 keyword = {latent semantics analysis (LSA), spam campaign, spamcampaignassassin (SCA), unsupervised learning},
 link = {http://doi.acm.org/10.1145/1811039.1811090},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {367--368},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {A Case for Unsupervised-learning-based Spam Filtering},
 year = {2010}
}


@inproceedings{Sagnol:2010:SCD:1811039.1811080,
 abstract = {We propose a new approach to optimize the deployment and the sampling rates of network monitoring tools, such as Netflow, on a large IP network. It reduces to solving a stochastic sequence of Second Order Cone Programs. We validate our approach with experiments relying on real data from a commercial network.},
 acmid = {1811080},
 address = {New York, NY, USA},
 author = {Sagnol, Guillaume and Bouhtou, Mustapha and Gaubert, St{\'e}phane},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811080},
 isbn = {978-1-4503-0038-4},
 keyword = {SOCP, c-optimality, netflow, optimal experimental design},
 link = {http://doi.acm.org/10.1145/1811039.1811080},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {347--348},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Successive C-optimal Designs: A Scalable Technique to Optimize the Measurements on Large Networks},
 year = {2010}
}


@inproceedings{Zheng:2010:RAU:1811039.1811069,
 abstract = {We present RSIO, a processor scheduling framework for improving the response time of latency-sensitive applications by monitoring accesses to I/O channels and inferring when user interactions occur. RSIO automatically identifies processes involved in a user interaction and boosts their priorities at the time the interaction occurs to improve system response time. RSIO also detects processes indirectly involved in processing an interaction, automatically accounting for dependencies and boosting their priorities accordingly. RSIO works with existing schedulers and requires no application modifications to identify periods of latency-sensitive application activity. We have implemented RSIO in Linux and measured its effectiveness on microbenchmarks and real applications. Our results show that RSIO is easy to use and can provide substantial improvements in system performance for latency-sensitive applications.},
 acmid = {1811069},
 address = {New York, NY, USA},
 author = {Zheng, Haoqiang and Nieh, Jason},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811069},
 isbn = {978-1-4503-0038-4},
 keyword = {dependencies, interactive applications, scheduling},
 link = {http://doi.acm.org/10.1145/1811039.1811069},
 location = {New York, New York, USA},
 numpages = {12},
 pages = {263--274},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {RSIO: Automatic User Interaction Detection and Scheduling},
 year = {2010}
}


@article{Le:2010:MCE:1811099.1811085,
 abstract = {The large amount of energy consumed by Internet services represents significant and fast-growing financial and environmental costs. This paper introduces a general, optimization-based framework and several request distribution policies that enable multi-data-center services to manage their brown energy consumption and leverage green energy, while respecting their service-level agreements (SLAs) and minimizing energy cost. Our policies can be used to abide by caps on brown energy consumption that might arise from various scenarios such as government imposed Kyoto-style carbon limits. Extensive simulations and real experiments show that our policies allow a service to trade off consumption and cost. For example, using our policies, a service can reduce brown energy consumption by 24% for only a 10% increase in cost, while still abiding by SLAs.},
 acmid = {1811085},
 address = {New York, NY, USA},
 author = {Le, Kien and Bilgir, Ozlem and Bianchini, Ricardo and Martonosi, Margaret and Nguyen, Thu D.},
 doi = {10.1145/1811099.1811085},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {data center, energy cap, optimization, renewable energy, request distribution},
 link = {http://doi.acm.org/10.1145/1811099.1811085},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {357--358},
 publisher = {ACM},
 title = {Managing the Cost, Energy Consumption, and Carbon Footprint of Internet Services},
 volume = {38},
 year = {2010}
}


@article{Ma:2010:LPM:1811099.1811065,
 abstract = {We present a software-based solution to the multi-dimensional packet classification problem which can operate at high line speeds, e.g., in excess of 10 Gbps, using high-end multi-core desktop platforms available today. Our solution, called Storm, leverages a common notion that a subset of rules are likely to be popular over short durations of time. By identifying a suitable set of popular rules one can significantly speed up existing software-based classification algorithms. A key aspect of our design is in partitioning processor resources into various relevant tasks, such as continuously computing the popular rules based on a sampled subset of traffic, fast classification for traffic that matches popular rules, dealing with packets that do not match the most popular rules, and traffic sampling. Our results show that by using a single 8-core Xeon processor desktop platform, it is possible to sustain classification rates of more than 15 Gbps for representative rule sets of size in excess of 5-dimensional 9000 rules, with no packet losses. This performance is significantly superior to a 8-way implementation of a state-of-the-art packet classification software system running on the same 8-core machine. Therefore, we believe that our design of packet classification functions can be a useful classification building block for RouteBricks-style designs, where a core router might be constructed as a mesh of regular desktop machines.},
 acmid = {1811065},
 address = {New York, NY, USA},
 author = {Ma, Yadi and Banerjee, Suman and Lu, Shan and Estan, Cristian},
 doi = {10.1145/1811099.1811065},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {packet classification, parallelism, storm},
 link = {http://doi.acm.org/10.1145/1811099.1811065},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {227--238},
 publisher = {ACM},
 title = {Leveraging Parallelism for Multi-dimensional Packetclassification on Software Routers},
 volume = {38},
 year = {2010}
}


@article{Ganesh:2010:LBV:1811099.1811072,
 abstract = {In this paper, we analyze the performance of random load resampling and migration strategies in parallel server systems. Clients initially attach to an arbitrary server, but may switch servers independently at random instants of time in an attempt to improve their service rate. This approach to load balancing contrasts with traditional approaches where clients make smart server selections upon arrival (e.g., Join-the-Shortest-Queue policy and variants thereof). Load resampling is particularly relevant in scenarios where clients cannot predict the load of a server before being actually attached to it. An important example is in wireless spectrum sharing where clients try to share a set of frequency bands in a distributed manner. We first analyze the natural Random Local Search (RLS) strategy. Under this strategy, after sampling a new server randomly, clients only switch to it if their service rate is improved. In closed systems, where the client population is fixed, we derive tight estimates of the time it takes under RLS strategy to balance the load across servers. We then study open systems where clients arrive according to a random process and leave the system upon service completion. In this scenario, we analyze how client migrations within the system interact with the system dynamics induced by client arrivals and departures. We compare the load-aware RLS strategy to a load-oblivious strategy in which clients just randomly switch server without accounting for the server loads. Surprisingly, we show that both load-oblivious and load-aware strategies stabilize the system whenever this is at all possible. We further demonstrate, using large-system asymptotics, that the average client sojourn time under the load-oblivious strategy is not considerably reduced when clients apply smarter load-aware strategies.},
 acmid = {1811072},
 address = {New York, NY, USA},
 author = {Ganesh, Ayalvadi and Lilienthal, Sarah and Manjunath, D. and Proutiere, Alexandre and Simatos, Florian},
 doi = {10.1145/1811099.1811072},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {mean field asymptotics, stability analysis},
 link = {http://doi.acm.org/10.1145/1811099.1811072},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {287--298},
 publisher = {ACM},
 title = {Load Balancing via Random Local Search in Closed and Open Systems},
 volume = {38},
 year = {2010}
}


@article{Ioannidis:2010:DCO:1811099.1811075,
 abstract = {Sharing content over a mobile network through opportunistic contacts has recently received considerable attention. In proposed scenarios, users store content they download in a local cache and share it with other users they meet, e.g., via Bluetooth or WiFi. The storage capacity of mobile devices is typically limited; therefore, identifying which content a user should store in her cache is a fundamental problem in the operation of any such content distribution system. In this work, we propose Psephos, a novel mechanism for determining the caching policy of each mobile user. Psephos is fully distributed: users compute their own policies individually, in the absence of a central authority. Moreover, it is designed for a heterogeneous environment, in which demand for content, access to resources, and mobility characteristics may vary across different users. Most importantly, the caching policies computed by our mechanism are optimal: we rigorously show that Psephos maximizes the system's social welfare. Our results are derived formally using techniques from stochastic approximation and convex optimization; to the best of our knowledge, our work is the first to address caching with heterogeneity in a fully distributed manner.},
 acmid = {1811075},
 address = {New York, NY, USA},
 author = {Ioannidis, Stratis and Massoulie, Laurent and Chaintreau, Augustin},
 doi = {10.1145/1811099.1811075},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {caching, content distribution, heterogeneity, opportunistic networks},
 link = {http://doi.acm.org/10.1145/1811099.1811075},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {311--322},
 publisher = {ACM},
 title = {Distributed Caching over Heterogeneous Mobile Networks},
 volume = {38},
 year = {2010}
}


@proceedings{Merchant:2011:1993744,
 abstract = {Welcome to San Jose, to ACM's Federated Computing Research Conference (FCRC), and to SIGMETRICS 2011! We are proud to carry on the SIGMETRICS tradition of presenting highquality, innovative research on the measurement and modeling of computer systems. The program includes papers on a wide variety of topics, including resource allocation, multicore processing, network protocols, failure analysis, power management and network characterization, using a wide variety of techniques, including mathematical analysis, simulation, emulation, prototype experimentation, observation of real systems, and combinations thereof. SIGMETRICS 2011 received 177 submissions, from which 26 papers were accepted, for an acceptance rate of 15%. Additionally, 20 submissions were selected to appear as posters, leading to a combined paper and poster acceptance rate of 26%. Each paper received at least three reviews from PC members. Over 90% of papers received four or more reviews. Overall, program committee and external reviewers provided a total of 756 reviews. The review process was conducted online using the HotCRP conference management software over a period of two months. The program committee meeting, held at Columbia University in New York, NY, in January 2011, was attended in person by 36 of the 57 PC members, and "virtually" by another four members. During the review, deliberation, and decision process, we emphasized novelty and excitement: papers that took risks and were controversial were viewed more favorably than solid papers that provided limited new insights and took limited risks. As a result, we expect the program to generate active discussion.},
 address = {New York, NY, USA},
 isbn = {978-1-4503-0814-4},
 location = {San Jose, California, USA},
 note = {81901101},
 publisher = {ACM},
 title = {SIGMETRICS '11: Proceedings of the ACM SIGMETRICS Joint International Conference on Measurement and Modeling of Computer Systems},
 year = {2011}
}


@inproceedings{Tan:2010:MMP:1811039.1811097,
 abstract = {
                  An abstract is not available.
              },
 acmid = {1811097},
 address = {New York, NY, USA},
 author = {Tan, Jian and Wei, Wei and Jiang, Bo and Shroff, Ness and Towsley, Don},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811097},
 isbn = {978-1-4503-0038-4},
 keyword = {multipath, parallelism, power law, redundant transmission, split transmission},
 link = {http://doi.acm.org/10.1145/1811039.1811097},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {381--382},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Can Multipath Mitigate Power Law Delays?: Effects of Parallelism on Tail Performance},
 year = {2010}
}


@inproceedings{Jin:2010:IAN:1811039.1811082,
 abstract = {In this paper, we propose a novel technique for inferring the distribution of application classes present in the aggregated traffic flows between endpoints, which exploits both the statistics of the traffic flows, and the spatial distribution of those flows across the network. Our method employs a two-step supervised model, where the bootstrapping step provides initial (inaccurate) inference on the traffic application classes, and the graph-based calibration step adjusts the initial inference through the collective spatial traffic distribution. In evaluations using real traffic flow measurements from a large ISP, we show how our method can accurately classify application types within aggregate traffic between endpoints, even without the knowledge of ports and other traffic features. While the bootstrap estimate classifies the aggregates with 80% accuracy, incorporating spatial distributions through calibration increases the accuracy to 92%, i.e., roughly halving the number of errors.},
 acmid = {1811082},
 address = {New York, NY, USA},
 author = {Jin, Yu and Duffield, Nick and Haffner, Patrick and Sen, Subhabrata and Zhang, Zhi-Li},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811082},
 isbn = {978-1-4503-0038-4},
 keyword = {application identification, collective traffic statistics, graph-based calibration, two-step model},
 link = {http://doi.acm.org/10.1145/1811039.1811082},
 location = {New York, New York, USA},
 numpages = {2},
 pages = {351--352},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Inferring Applications at the Network Layer Using Collective Traffic Statistics},
 year = {2010}
}


@article{Godfrey:2010:ICD:1811099.1811051,
 abstract = {his paper studies under what conditions congestion control schemes can be both efficient, so that capacity is not wasted, and incentive compatible, so that each participant can maximize its utility by following the prescribed protocol. We show that both conditions can be achieved if routers run strict priority queueing (SPQ) or weighted fair queueing (WFQ) and end-hosts run any of a family of protocols which we call Probing Increase Educated Decrease (PIED). A natural question is whether incentive compatibility and efficiency are possible while avoiding the per-flow processing of WFQ. We partially address that question in the negative by showing that any policy satisfying a certain "locality" condition cannot guarantee both properties. Our results also have implication for convergence to some steady-state throughput for the flows. Even when senders transmit at a fixed rate (as in a UDP flow which does not react to congestion), feedback effects among the routers can result in complex dynamics which do not appear in the simple topologies studied in past work.},
 acmid = {1811051},
 address = {New York, NY, USA},
 author = {Godfrey, P. Brighten and Schapira, Michael and Zohar, Aviv and Shenker, Scott},
 doi = {10.1145/1811099.1811051},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {TCP, congestion control, incentives, queueing},
 link = {http://doi.acm.org/10.1145/1811099.1811051},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {95--106},
 publisher = {ACM},
 title = {Incentive Compatibility and Dynamics of Congestion Control},
 volume = {38},
 year = {2010}
}


@article{Casale:2010:CMS:1811099.1811068,
 abstract = {We define CWS, a non-preemptive scheduling policy for workloads with correlated job sizes. CWS tackles the scheduling problem by inferring the expected sizes of upcoming jobs based on the structure of correlations and on the outcome of past scheduling decisions. Size prediction is achieved using a class of Hidden Markov Models (HMM) with continuous observation densities that describe job sizes. We show how the forward-backward algorithm of HMMs applies effectively in scheduling applications and how it can be used to derive closed-form expressions for size prediction. This is particularly simple to implement in the case of observation densities that are phase-type (PH-type) distributed, where existing fitting methods for Markovian point processes may also simplify the parameterization of the HMM workload model. Based on the job size predictions, CWS emulates size-based policies which favor short jobs, with accuracy depending mainly on the HMM used to parametrize the scheduling algorithm. Extensive simulation and analysis illustrate that CWS is competitive with policies that assume exact information about the workload.},
 acmid = {1811068},
 address = {New York, NY, USA},
 author = {Casale, Giuliano and Mi, Ningfang and Smirni, Evgenia},
 doi = {10.1145/1811099.1811068},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {correlated workload, model-driven scheduling, response time, stochastic sheduling},
 link = {http://doi.acm.org/10.1145/1811099.1811068},
 month = {jun},
 number = {1},
 numpages = {12},
 pages = {251--262},
 publisher = {ACM},
 title = {CWS: A Model-driven Scheduling Policy for Correlated Workloads},
 volume = {38},
 year = {2010}
}


@article{Anselmi:2010:PAP:1811099.1811083,
 abstract = {We consider a network of parallel, non-observable queues and analyze the Price of Anarchy (PoA) from the new point of view where the router has the memory of previous dispatching choices. In the regime where the demands grow with the network size, we provide an upper bound on the PoA by means of convex programming. To study the impact of non-Bernoulli routers, we introduce the Price of Forgetting (PoF) and prove that it is bounded from above by two. Numerical experiments show that the benefit of having memory in the router is independent of the network size and heterogeneity, and monotonically depends on the network load only.},
 acmid = {1811083},
 address = {New York, NY, USA},
 author = {Anselmi, Jonatha and Gaujal, Bruno},
 doi = {10.1145/1811099.1811083},
 issn = {0163-5999},
 issue_date = {June 2010},
 journal = {SIGMETRICS Perform. Eval. Rev.},
 keyword = {convex programming, parallel queues, price of anarchy, price of forgetting},
 link = {http://doi.acm.org/10.1145/1811099.1811083},
 month = {jun},
 number = {1},
 numpages = {2},
 pages = {353--354},
 publisher = {ACM},
 title = {The Price of Anarchy in Parallel Queues Revisited},
 volume = {38},
 year = {2010}
}


@inproceedings{Karbasi:2010:DSN:1811039.1811047,
 abstract = {This paper addresses the problem of determining the node locations in ad-hoc sensor networks when only connectivity information is available. In previous work, we showed that the localization algorithm MDS-MAP proposed by Y. Shang et al. is able to localize sensors up to a bounded error decreasing at a rate inversely proportional to the radio range r. The main limitation of MDS-MAP is the assumption that the available connectivity information is processed in a centralized way. In this work we investigate a practically important question whether similar performance guarantees can be obtained in a distributed setting. In particular, we analyze the performance of the HOP-TERRAIN algorithm proposed by C. Savarese et al. This algorithm can be seen as a distributed version of the MDS-MAP algorithm. More precisely, assume that the radio range r=o(1) and that the network consists of n sensors positioned randomly on a d-dimensional unit cube and d+1 anchors in general positions. We show that when only connectivity information is available, for every unknown node i, the Euclidean distance between the estimate xi and the correct position xi is bounded by ||xi-xi|| < r0/r + o(1), where r0=Cd (log n/ n)(1/d) for some constant Cd which only depends on d. Furthermore, we illustrate that a similar bound holds for the range-based model, when the approximate measurement for the distances is provided.},
 acmid = {1811047},
 address = {New York, NY, USA},
 author = {Karbasi, Amin and Oh, Sewoong},
 booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
 doi = {10.1145/1811039.1811047},
 isbn = {978-1-4503-0038-4},
 keyword = {distributed, localization, sensor network},
 link = {http://doi.acm.org/10.1145/1811039.1811047},
 location = {New York, New York, USA},
 numpages = {10},
 pages = {61--70},
 publisher = {ACM},
 series = {SIGMETRICS '10},
 title = {Distributed Sensor Network Localization from Local Connectivity: Performance Analysis for the HOP-TERRAIN Algorithm},
 year = {2010}
}


